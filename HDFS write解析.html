<!doctype html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="google-site-verification" content="0hClWroWscvQbyOyRPhAZWjOZJ6g3SFCdO47yYakvdk">







  <meta name="baidu-site-verification" content="27E5EbutCm">







  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="Hadoop,BigData,HDFS,write,">








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="本篇主要记录下HDFS写文件的流程。其写入流程与普通文件写入流程类似，首先创建一个输出流OutputStream，然后通过这个输出流写入数据。在HDFS中数据传输的基本单元为Packet(默认64k)，每个packet又由很多个chunk组成，chunk是文件校验的基本单位，一个chunk一个chunksum，chunk是校验单位也就是写入单位，将chunk写入packet，一个packet写满之">
<meta name="keywords" content="Hadoop,BigData,HDFS,write">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS write解析">
<meta property="og:url" content="http://bigdatadecode.club/HDFS write解析.html">
<meta property="og:site_name" content="big data decode club">
<meta property="og:description" content="本篇主要记录下HDFS写文件的流程。其写入流程与普通文件写入流程类似，首先创建一个输出流OutputStream，然后通过这个输出流写入数据。在HDFS中数据传输的基本单元为Packet(默认64k)，每个packet又由很多个chunk组成，chunk是文件校验的基本单位，一个chunk一个chunksum，chunk是校验单位也就是写入单位，将chunk写入packet，一个packet写满之">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://bigdatadecode.club/blogimgs/HDFS%20write解析/hdfs-write-flow.png">
<meta property="og:updated_time" content="2016-11-28T09:45:02.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="HDFS write解析">
<meta name="twitter:description" content="本篇主要记录下HDFS写文件的流程。其写入流程与普通文件写入流程类似，首先创建一个输出流OutputStream，然后通过这个输出流写入数据。在HDFS中数据传输的基本单元为Packet(默认64k)，每个packet又由很多个chunk组成，chunk是文件校验的基本单位，一个chunk一个chunksum，chunk是校验单位也就是写入单位，将chunk写入packet，一个packet写满之">
<meta name="twitter:image" content="http://bigdatadecode.club/blogimgs/HDFS%20write解析/hdfs-write-flow.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"right","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://bigdatadecode.club/HDFS write解析.html">





  <title> HDFS write解析 | big data decode club </title>
</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-Hans">

  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-80813521-1', 'auto');
  ga('send', 'pageview');
</script>








  <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1260961002&web_id=1260961002" language="JavaScript"></script>
  </div>






  
  
    
  

  <div class="container sidebar-position-right page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">big data decode club</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">hunhun -- Any answers you can find in source code.</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope="" itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://bigdatadecode.club/HDFS write解析.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="混绅士">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="big data decode club">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">
            
            
              
                HDFS write解析
              
            
          </h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2016-11-28T17:45:02+08:00">
                2016-11-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2016-11-28T17:45:02+08:00">
                2016-11-28
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/HDFS write解析.html" class="leancloud_visitors" data-flag-title="HDFS write解析">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本篇主要记录下HDFS写文件的流程。其写入流程与普通文件写入流程类似，首先创建一个输出流OutputStream，然后通过这个输出流写入数据。在HDFS中数据传输的基本单元为Packet(默认64k)，每个packet又由很多个chunk组成，chunk是文件校验的基本单位，一个chunk一个chunksum，chunk是校验单位也就是写入单位，将chunk写入packet，一个packet写满之后，将packet发送到pipeline中。</p>
<p>下面从代码层次去详细解读下write流程。其写入流程图如下：<br><img src="/blogimgs/HDFS write解析/hdfs-write-flow.png" alt="write流程图" title="write流程图"></p>
<a id="more"></a>
<h2 id="创建一个输出流"><a href="#创建一个输出流" class="headerlink" title="创建一个输出流"></a>创建一个输出流</h2><p>HDFS写文件跟java写文件类似，都需要先打开一个文件流，HDFS是通过<em>FileSystem</em>对象打开文件流的，代码流程为通过<code>FileSystem.get(conf)</code>得到一个<code>FileSystem</code>对象，然后调用<code>create(Path)</code>或者<code>append(Path)</code>打开一个FSDataOutputStream流，看下create代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">create</span><span class="params">(Path f)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> create(f, <span class="keyword">true</span>); <span class="comment">// Path overwrite</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>FileSystem是一个抽象类，将具体的<code>create</code>的具体操作留给子类实现，例如DistributedFileSystem、WebHdfsFileSystem等，不同的文件系统具有不同打开文件的行为，我们以DistributedFileSystem为例，create方法实现，代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">create</span><span class="params">(<span class="keyword">final</span> Path f, <span class="keyword">final</span> FsPermission permission,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="keyword">final</span> EnumSet&lt;CreateFlag&gt; cflags, <span class="keyword">final</span> <span class="keyword">int</span> bufferSize,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="keyword">final</span> <span class="keyword">short</span> replication, <span class="keyword">final</span> <span class="keyword">long</span> blockSize, <span class="keyword">final</span> Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="keyword">final</span> ChecksumOpt checksumOpt)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  statistics.incrementWriteOps(<span class="number">1</span>);</span><br><span class="line">  Path absF = fixRelativePart(f);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> FileSystemLinkResolver&lt;FSDataOutputStream&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">doCall</span><span class="params">(<span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException, UnresolvedLinkException </span>&#123;</span><br><span class="line">      <span class="keyword">final</span> DFSOutputStream dfsos = dfs.create(getPathName(p), permission,</span><br><span class="line">              cflags, replication, blockSize, progress, bufferSize,</span><br><span class="line">              checksumOpt);</span><br><span class="line">      <span class="keyword">return</span> dfs.createWrappedOutputStream(dfsos, statistics);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">next</span><span class="params">(<span class="keyword">final</span> FileSystem fs, <span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> fs.create(p, permission, cflags, bufferSize,</span><br><span class="line">          replication, blockSize, progress, checksumOpt);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;.resolve(<span class="keyword">this</span>, absF);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DistributedFileSystem.create()中new一个FileSystemLinkResolver的匿名类，在resolve中调用在匿名类中重写的<code>doCall()</code>方法，如果doCall抛出UnresolvedLinkException异常，被resolve捕获调用<code>next()</code>，进行再次打开。(<em>这段代码跟open一个FSDataInputStream类似</em>)</p>
<p>在<code>doCall()</code>中调用<code>dfs.create</code>返回一个<em>DFSOutputStream</em>对象，然后再通过<code>dfs.createWrappedOutputStream</code>包装一个<em>HdfsDataOutputStream</em>对象返回给<em>FSDataOutputStream</em>，FSDataOutputStream是HdfsDataOutputStream的父类，这样就通过FileSystem.create(path)打开了一个文件流。</p>
<p>doCall中dfs是FSDataOutputStream的成员变量DFSClient，其create方法中得到一个DFSOutputStream实例，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DFSOutputStream <span class="title">create</span><span class="params">(String src, </span></span></span><br><span class="line"><span class="function"><span class="params">                           FsPermission permission,</span></span></span><br><span class="line"><span class="function"><span class="params">                           EnumSet&lt;CreateFlag&gt; flag, </span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">short</span> replication,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">long</span> blockSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">int</span> buffersize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           ChecksumOpt checksumOpt)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> create(src, permission, flag, <span class="keyword">true</span>,</span><br><span class="line">      replication, blockSize, progress, buffersize, checksumOpt, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> DFSOutputStream <span class="title">create</span><span class="params">(String src, </span></span></span><br><span class="line"><span class="function"><span class="params">                           FsPermission permission,</span></span></span><br><span class="line"><span class="function"><span class="params">                           EnumSet&lt;CreateFlag&gt; flag, </span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">boolean</span> createParent,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">short</span> replication,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">long</span> blockSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">int</span> buffersize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           ChecksumOpt checksumOpt,</span></span></span><br><span class="line"><span class="function"><span class="params">                           InetSocketAddress[] favoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  checkOpen();</span><br><span class="line">  <span class="keyword">if</span> (permission == <span class="keyword">null</span>) &#123;</span><br><span class="line">    permission = FsPermission.getFileDefault();</span><br><span class="line">  &#125;</span><br><span class="line">  FsPermission masked = permission.applyUMask(dfsClientConf.uMask);</span><br><span class="line">  <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">    LOG.debug(src + <span class="string">": masked="</span> + masked);</span><br><span class="line">  &#125;</span><br><span class="line">  String[] favoredNodeStrs = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (favoredNodes != <span class="keyword">null</span>) &#123;</span><br><span class="line">    favoredNodeStrs = <span class="keyword">new</span> String[favoredNodes.length];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; favoredNodes.length; i++) &#123;</span><br><span class="line">      favoredNodeStrs[i] = </span><br><span class="line">          favoredNodes[i].getHostName() + <span class="string">":"</span> </span><br><span class="line">                       + favoredNodes[i].getPort();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 在得到输出流的过程中，不会对lease进行检查，</span></span><br><span class="line">  <span class="comment">// 只是在创建file时，添加lease？？？</span></span><br><span class="line">  <span class="comment">// 创建file之后，根据创建的file new一个FSDataOutputStream</span></span><br><span class="line">  <span class="keyword">final</span> DFSOutputStream result = DFSOutputStream.newStreamForCreate(<span class="keyword">this</span>,</span><br><span class="line">      src, masked, flag, createParent, replication, blockSize, progress,</span><br><span class="line">      buffersize, dfsClientConf.createChecksum(checksumOpt),</span><br><span class="line">      favoredNodeStrs);</span><br><span class="line">  <span class="comment">// 得到输出流，也就得到了该file的lease，得到lease之后就应该起个线程对其进行续约</span></span><br><span class="line">  beginFileLease(result.getFileId(), result);</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>文件的父目录如果不存在，dfs.create时会自动创建其父目录，在dfs.create传参时，将createParent设置为true。</p>
<p>dfs.create中得到一个DFSOutputStream的实例，DFSOutputStream实例通过静态方法newStreamForCreate得到。在HDFS写文件中是通过Lease(租约)来维护写文件凭证的，所以得到一个文件的写权限之后将其租约进行存储并定时更新。</p>
<h3 id="DFSOutputStream实例"><a href="#DFSOutputStream实例" class="headerlink" title="DFSOutputStream实例"></a>DFSOutputStream实例</h3><p>DFSOutputStream的构造方法是私有的，则实例通过静态方法newStreamForCreate得到。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> DFSOutputStream <span class="title">newStreamForCreate</span><span class="params">(DFSClient dfsClient, String src,</span></span></span><br><span class="line"><span class="function"><span class="params">    FsPermission masked, EnumSet&lt;CreateFlag&gt; flag, <span class="keyword">boolean</span> createParent,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, Progressable progress, <span class="keyword">int</span> buffersize,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum checksum, String[] favoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  HdfsFileStatus stat = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Retry the create if we get a RetryStartFileException up to a maximum</span></span><br><span class="line">  <span class="comment">// number of times</span></span><br><span class="line">  <span class="keyword">boolean</span> shouldRetry = <span class="keyword">true</span>;</span><br><span class="line">  <span class="comment">// retryCount 是 10</span></span><br><span class="line">  <span class="keyword">int</span> retryCount = CREATE_RETRY_COUNT;</span><br><span class="line">  <span class="keyword">while</span> (shouldRetry) &#123;</span><br><span class="line">    shouldRetry = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// rpc 调用</span></span><br><span class="line">      stat = dfsClient.namenode.create(src, masked, dfsClient.clientName,</span><br><span class="line">          <span class="keyword">new</span> EnumSetWritable&lt;CreateFlag&gt;(flag), createParent, replication,</span><br><span class="line">          blockSize, SUPPORTED_CRYPTO_VERSIONS);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RemoteException re) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (e <span class="keyword">instanceof</span> RetryStartFileException) &#123;</span><br><span class="line">        <span class="keyword">if</span> (retryCount &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          shouldRetry = <span class="keyword">true</span>;</span><br><span class="line">          retryCount--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Too many retries because of encryption"</span> +</span><br><span class="line">              <span class="string">" zone operations"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  Preconditions.checkNotNull(stat, <span class="string">"HdfsFileStatus should not be null!"</span>);</span><br><span class="line">  <span class="keyword">final</span> DFSOutputStream out = <span class="keyword">new</span> DFSOutputStream(dfsClient, src, stat,</span><br><span class="line">      flag, progress, checksum, favoredNodes);</span><br><span class="line">  <span class="comment">// 启动DataStreamer线程</span></span><br><span class="line">  out.start();</span><br><span class="line">  <span class="keyword">return</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>newStreamForCreate先通过rpc请求namenode创建一个文件，然后通过该文件打开一个输出流。</p>
<p>rpc请求创建文件启动了重试机制，默认重试10次，通过<code>stat = dfsClient.namenode.create</code>创建，成功之后break出while循环。create远程调用的流程为NameNodeRpcServer.create -&gt; namesystem.startFile -&gt; startFileInt -&gt; startFileInternal。在startFileInternal中通过<code>newNode = dir.addFile(src, permissions, replication, blockSize, holder, clientMachine);</code>向namenode中添加一个文件，并将clientname对src的租约进行存储<code>leaseManager.addLease(newNode.getFileUnderConstructionFeature().getClientName(), src);</code>，关于租约的更多内容请看<a href="http://bigdatadecode.club/HDFS租约解析.html">HDFS中租约解析</a></p>
<p>先看下startFileInternal的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSNamesystem.java</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> BlocksMapUpdateInfo <span class="title">startFileInternal</span><span class="params">(FSPermissionChecker pc, </span></span></span><br><span class="line"><span class="function"><span class="params">    String src, PermissionStatus permissions, String holder, </span></span></span><br><span class="line"><span class="function"><span class="params">    String clientMachine, <span class="keyword">boolean</span> create, <span class="keyword">boolean</span> overwrite, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> createParent, <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isLazyPersist, CipherSuite suite, CryptoProtocolVersion version,</span></span></span><br><span class="line"><span class="function"><span class="params">    EncryptedKeyVersion edek, <span class="keyword">boolean</span> logRetryEntry)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> FileAlreadyExistsException, AccessControlException,</span></span><br><span class="line"><span class="function">    UnresolvedLinkException, FileNotFoundException,</span></span><br><span class="line"><span class="function">    ParentNotDirectoryException, RetryStartFileException, IOException </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">assert</span> <span class="title">hasWriteLock</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="comment">// Verify that the destination does not exist as a directory already.</span></span><br><span class="line">  <span class="keyword">final</span> INodesInPath iip = dir.getINodesInPath4Write(src);</span><br><span class="line">  <span class="keyword">final</span> INode inode = iip.getLastINode();</span><br><span class="line">  <span class="comment">// 这里判断该path是否已经以路径的形式存在</span></span><br><span class="line">  <span class="keyword">if</span> (inode != <span class="keyword">null</span> &amp;&amp; inode.isDirectory()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> FileAlreadyExistsException(src +</span><br><span class="line">        <span class="string">" already exists as a directory"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">final</span> INodeFile myFile = INodeFile.valueOf(inode, src, <span class="keyword">true</span>);</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    BlocksMapUpdateInfo toRemoveBlocks = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 该file不存在则create</span></span><br><span class="line">    <span class="keyword">if</span> (myFile == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!create) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException(<span class="string">"Can't overwrite non-existent "</span> +</span><br><span class="line">            src + <span class="string">" for client "</span> + clientMachine);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 该file已经存在，则重写</span></span><br><span class="line">      <span class="keyword">if</span> (overwrite) &#123;</span><br><span class="line">        toRemoveBlocks = <span class="keyword">new</span> BlocksMapUpdateInfo();</span><br><span class="line">        List&lt;INode&gt; toRemoveINodes = <span class="keyword">new</span> ChunkedArrayList&lt;INode&gt;();</span><br><span class="line">        <span class="keyword">long</span> ret = dir.delete(src, toRemoveBlocks, toRemoveINodes, now());</span><br><span class="line">        <span class="keyword">if</span> (ret &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">          incrDeletedFileCount(ret);</span><br><span class="line">          removePathAndBlocks(src, <span class="keyword">null</span>, toRemoveINodes, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="comment">// 这是怎么执行到这的？？</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// If lease soft limit time is expired, recover the lease</span></span><br><span class="line">        recoverLeaseInternal(myFile, src, holder, clientMachine, <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FileAlreadyExistsException(src + <span class="string">" for client "</span> +</span><br><span class="line">            clientMachine + <span class="string">" already exists"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里会检查整个hdfs上inode的上限，一般不设置</span></span><br><span class="line">    <span class="comment">// 曾经被问过hdfs中block的上限是多少，估计问的就是这个吧</span></span><br><span class="line">    <span class="comment">// 由dfs.namenode.max.objects控制</span></span><br><span class="line">    <span class="comment">// 还有个属性控制一个file的最多block个数，默认是1024*1024</span></span><br><span class="line">    <span class="comment">// dfs.namenode.fs-limits.max-blocks-per-file控制</span></span><br><span class="line">    checkFsObjectLimit();</span><br><span class="line">    INodeFile newNode = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Always do an implicit mkdirs for parent directory tree.</span></span><br><span class="line">    Path parent = <span class="keyword">new</span> Path(src).getParent();</span><br><span class="line">    <span class="comment">// 递归的创建父目录</span></span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span> &amp;&amp; mkdirsRecursively(parent.toString(),</span><br><span class="line">            permissions, <span class="keyword">true</span>, now())) &#123;</span><br><span class="line">      <span class="comment">// 将file添加到namespace中</span></span><br><span class="line">      newNode = dir.addFile(src, permissions, replication, blockSize,</span><br><span class="line">                            holder, clientMachine);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (newNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unable to add "</span> + src +  <span class="string">" to namespace"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将clientName对file的lease放入LeaseManager中</span></span><br><span class="line">    leaseManager.addLease(newNode.getFileUnderConstructionFeature()</span><br><span class="line">        .getClientName(), src);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// record file record in log, record new generation stamp</span></span><br><span class="line">    getEditLog().logOpenFile(src, newNode, overwrite, logRetryEntry);</span><br><span class="line">    <span class="keyword">if</span> (NameNode.stateChangeLog.isDebugEnabled()) &#123;</span><br><span class="line">      NameNode.stateChangeLog.debug(<span class="string">"DIR* NameSystem.startFile: added "</span> +</span><br><span class="line">          src + <span class="string">" inode "</span> + newNode.getId() + <span class="string">" "</span> + holder);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> toRemoveBlocks;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">    NameNode.stateChangeLog.warn(<span class="string">"DIR* NameSystem.startFile: "</span> + src + <span class="string">" "</span> +</span><br><span class="line">        ie.getMessage());</span><br><span class="line">    <span class="keyword">throw</span> ie;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>在得到FSDataOutputStream时，并没有对lease进行校验，那么当client1得到fileA的FSDataOutputStream之后，将其对应的租约add到LeaseManager中，此时client2也再申请fileA的FSDataOutputStream，此时会发生什么？client2也得到fileA的输出流，并将client2对应的lease也放入LeaseManager中？那么此时就有两个client持有文件fileA的租约。  是在写入bytes时进行lease 检查吗？？？疑惑中。。。</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> Lease <span class="title">addLease</span><span class="params">(String holder, String src)</span> </span>&#123;</span><br><span class="line">  Lease lease = getLease(holder);</span><br><span class="line">  <span class="keyword">if</span> (lease == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 如果当前client没有租约，则创建一个</span></span><br><span class="line">    lease = <span class="keyword">new</span> Lease(holder);</span><br><span class="line">    leases.put(holder, lease);</span><br><span class="line">    sortedLeases.add(lease);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 当前client已经持有lease，则更新时间</span></span><br><span class="line">    renewLease(lease);</span><br><span class="line">  &#125;</span><br><span class="line">  sortedLeasesByPath.put(src, lease);</span><br><span class="line">  lease.paths.add(src);</span><br><span class="line">  <span class="keyword">return</span> lease;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回到newStreamForCreate中，通过namenode创建的文件new一个输出流<code>DFSOutputStream out = new DFSOutputStream(dfsClient, src, stat, flag, progress, checksum, favoredNodes)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">DFSOutputStream</span><span class="params">(DFSClient dfsClient, String src, HdfsFileStatus stat,</span></span></span><br><span class="line"><span class="function"><span class="params">    EnumSet&lt;CreateFlag&gt; flag, Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum checksum, String[] favoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>(dfsClient, src, progress, stat, checksum);</span><br><span class="line">  <span class="keyword">this</span>.shouldSyncBlock = flag.contains(CreateFlag.SYNC_BLOCK);</span><br><span class="line">  <span class="comment">// packet默认大小64k</span></span><br><span class="line">  <span class="comment">// 计算每个packet的chunk个数，和packet的大小</span></span><br><span class="line">  computePacketChunkSize(dfsClient.getConf().writePacketSize, bytesPerChecksum);</span><br><span class="line">  Span traceSpan = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (Trace.isTracing()) &#123;</span><br><span class="line">    traceSpan = Trace.startSpan(<span class="keyword">this</span>.getClass().getSimpleName()).detach();</span><br><span class="line">  &#125;</span><br><span class="line">  streamer = <span class="keyword">new</span> DataStreamer(stat, traceSpan);</span><br><span class="line">  <span class="keyword">if</span> (favoredNodes != <span class="keyword">null</span> &amp;&amp; favoredNodes.length != <span class="number">0</span>) &#123;</span><br><span class="line">    streamer.setFavoredNodes(favoredNodes);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DFSOutputStream中有个重要的线程DataStreamer，该线程主要负责向pipeline中的dn发送packet。</p>
<p>再次回到newStreamForCreate中，调用<code>out.start()</code>启动DataStreamer线程。</p>
<p>DFSOutputStream创建完毕之后，回到DFSClient.create中，执行<code>beginFileLease(result.getFileId(), result)</code>开启Lease定时Renew机制LeaseRenewer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Get a lease and start automatic renewal */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">beginFileLease</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> inodeId, <span class="keyword">final</span> DFSOutputStream out)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  getLeaseRenewer().put(inodeId, out, <span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// LeaseRenewer 是客户端check是否更新租约</span></span><br><span class="line"><span class="comment">// A thread per namenode per user</span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> inodeId, <span class="keyword">final</span> DFSOutputStream out,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DFSClient dfsc)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (dfsc.isClientRunning()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isRunning() || isRenewerExpired()) &#123;</span><br><span class="line">      <span class="comment">//start a new deamon with a new id.</span></span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">int</span> id = ++currentId;</span><br><span class="line">      daemon = <span class="keyword">new</span> Daemon(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"Lease renewer daemon for "</span> + clientsString()</span><br><span class="line">                  + <span class="string">" with renew id "</span> + id + <span class="string">" started"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 调用LeaseRenewer.run(final int id)</span></span><br><span class="line">            <span class="comment">// 在run中调用renew对租约续约</span></span><br><span class="line">            LeaseRenewer.<span class="keyword">this</span>.run(id);</span><br><span class="line">          &#125; <span class="keyword">catch</span>(InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(LeaseRenewer.<span class="keyword">this</span>.getClass().getSimpleName()</span><br><span class="line">                  + <span class="string">" is interrupted."</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(LeaseRenewer.<span class="keyword">this</span>) &#123;</span><br><span class="line">              Factory.INSTANCE.remove(LeaseRenewer.<span class="keyword">this</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"Lease renewer daemon for "</span> + clientsString()</span><br><span class="line">                  + <span class="string">" with renew id "</span> + id + <span class="string">" exited"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> String.valueOf(LeaseRenewer.<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      daemon.start();</span><br><span class="line">    &#125;</span><br><span class="line">    dfsc.putFileBeingWritten(inodeId, out);</span><br><span class="line">    emptyTime = Long.MAX_VALUE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回到daCall方法中，调用<code>dfs.createWrappedOutputStream(dfsos, statistics)</code>，将DFSOutputStream封装为HdfsDataOutputStream类型(FSDataOutputStream子类)，将结果return给FSDataOutputStream类型的输出流。到此FSDataOutputStream输出流创建完毕。接着该调用write方法，进行数据的写入。</p>
<h2 id="向输出流中写bytes数据流"><a href="#向输出流中写bytes数据流" class="headerlink" title="向输出流中写bytes数据流"></a>向输出流中写bytes数据流</h2><p>写入操作的API是通过FSDataOutputStream的对象out调用write(byte[])，调用流程为out.write(bytes) -&gt; FilterOutputStream.write -&gt; DataOutputStream.write -&gt; out.write(byte[], off, len) -&gt; FSOutputSummer.write(byte b[], int off, int len)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;  </span><br><span class="line">  checkClosed();</span><br><span class="line">  <span class="keyword">if</span> (off &lt; <span class="number">0</span> || len &lt; <span class="number">0</span> || off &gt; b.length - len) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ArrayIndexOutOfBoundsException();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> n=<span class="number">0</span>;n&lt;len;n+=write1(b, off+n, len-n)) &#123;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在write中根据写入len不断的调用<code>write1</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">write1</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 写入长度大于本地buf的长度时，直接写入本地buf的长度</span></span><br><span class="line">  <span class="keyword">if</span>(count==<span class="number">0</span> &amp;&amp; len&gt;=buf.length) &#123;</span><br><span class="line">    <span class="comment">// local buffer is empty and user buffer size &gt;= local buffer size, so</span></span><br><span class="line">    <span class="comment">// simply checksum the user buffer and send it directly to the underlying</span></span><br><span class="line">    <span class="comment">// stream</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> length = buf.length;</span><br><span class="line">    writeChecksumChunks(b, off, length);</span><br><span class="line">    <span class="keyword">return</span> length;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 当len小于本地buf的长度时，先写入buf，当buf写满之后，flushBuffer</span></span><br><span class="line">  <span class="comment">// copy user data to local buffer</span></span><br><span class="line">  <span class="keyword">int</span> bytesToCopy = buf.length-count;</span><br><span class="line">  bytesToCopy = (len&lt;bytesToCopy) ? len : bytesToCopy;</span><br><span class="line">  System.arraycopy(b, off, buf, count, bytesToCopy);</span><br><span class="line">  count += bytesToCopy;</span><br><span class="line">  <span class="keyword">if</span> (count == buf.length) &#123;</span><br><span class="line">    <span class="comment">// local buffer is full</span></span><br><span class="line">    flushBuffer();</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="keyword">return</span> bytesToCopy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>写入数据时，是先将数据写入本地buf</em>，buf默认长度为<code>this.buf = new byte[sum.getBytesPerChecksum() * BUFFER\_NUM\_CHUNKS]; BUFFER\_NUM\_CHUNKS = 9</code>，即9个chunk的长度4608。buf写满之后对其数据生成chunksum写入packet。</p>
<p>当写入数据的len大于buf的长度时，则数据不写入buf，直接调用<code>writeChecksumChunks</code>将buf长度大小的数据生成chunksum，并写入packet中。<br>当写入数据的len小于buf的长度时，则将数据copy到buf中，等buf满时，调用<code>flushBuffer</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">flushBuffer</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  flushBuffer(<span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">flushBuffer</span><span class="params">(<span class="keyword">boolean</span> keep,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> flushPartial)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> bufLen = count;</span><br><span class="line">  <span class="keyword">int</span> partialLen = bufLen % sum.getBytesPerChecksum();</span><br><span class="line">  <span class="keyword">int</span> lenToFlush = flushPartial ? bufLen : bufLen - partialLen;</span><br><span class="line">  <span class="keyword">if</span> (lenToFlush != <span class="number">0</span>) &#123;</span><br><span class="line">    writeChecksumChunks(buf, <span class="number">0</span>, lenToFlush);</span><br><span class="line">    <span class="keyword">if</span> (!flushPartial || keep) &#123;</span><br><span class="line">      count = partialLen;</span><br><span class="line">      System.arraycopy(buf, bufLen - count, buf, <span class="number">0</span>, count);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// total bytes left minus unflushed bytes left</span></span><br><span class="line">  <span class="keyword">return</span> count - (bufLen - lenToFlush);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在flushBuffer中依然会调用<code>writeChecksumChunks</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeChecksumChunks</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 计算checksum</span></span><br><span class="line">  sum.calculateChunkedSums(b, off, len, checksum, <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i += sum.getBytesPerChecksum()) &#123;</span><br><span class="line">    <span class="keyword">int</span> chunkLen = Math.min(sum.getBytesPerChecksum(), len - i);</span><br><span class="line">    <span class="keyword">int</span> ckOffset = i / sum.getBytesPerChecksum() * getChecksumSize();</span><br><span class="line">    <span class="comment">// 一个chunk一个chunk的写入packet</span></span><br><span class="line">    writeChunk(b, off + i, chunkLen, checksum, ckOffset, getChecksumSize());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在writeChecksumChunks中先调用<code>calculateChunkedSums</code>计算数据的checksum，然后调用<code>writeChunk</code>将每个chunk写入packet中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DFSOutputStream.class</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">writeChunk</span><span class="params">(<span class="keyword">byte</span>[] b, <span class="keyword">int</span> offset, <span class="keyword">int</span> len,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">byte</span>[] checksum, <span class="keyword">int</span> ckoff, <span class="keyword">int</span> cklen)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 如果当前currentPacket为null，则新创建一个</span></span><br><span class="line">  <span class="keyword">if</span> (currentPacket == <span class="keyword">null</span>) &#123;</span><br><span class="line">    currentPacket = createPacket(packetSize, chunksPerPacket, </span><br><span class="line">        bytesCurBlock, currentSeqno++);</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 先写入checksum，然后写入data</span></span><br><span class="line">  currentPacket.writeChecksum(checksum, ckoff, cklen);</span><br><span class="line">  currentPacket.writeData(b, offset, len);</span><br><span class="line">  currentPacket.numChunks++;</span><br><span class="line">  bytesCurBlock += len;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If packet is full, enqueue it for transmission</span></span><br><span class="line">  <span class="comment">// currentPacket已满 或者当前写入block的长度等于block的大小</span></span><br><span class="line">  <span class="keyword">if</span> (currentPacket.numChunks == currentPacket.maxChunks ||</span><br><span class="line">      bytesCurBlock == blockSize) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 将packet放入队列dataQueue中</span></span><br><span class="line">    waitAndQueueCurrentPacket();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If the reopened file did not end at chunk boundary and the above</span></span><br><span class="line">    <span class="comment">// write filled up its partial chunk. Tell the summer to generate full </span></span><br><span class="line">    <span class="comment">// crc chunks from now on.</span></span><br><span class="line">    <span class="keyword">if</span> (appendChunk &amp;&amp; bytesCurBlock%bytesPerChecksum == <span class="number">0</span>) &#123;</span><br><span class="line">      appendChunk = <span class="keyword">false</span>;</span><br><span class="line">      resetChecksumBufSize();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 最后一个packet时，可能会小于block的大小，需重新计算下packet的大小</span></span><br><span class="line">    <span class="keyword">if</span> (!appendChunk) &#123;</span><br><span class="line">      <span class="keyword">int</span> psize = Math.min((<span class="keyword">int</span>)(blockSize-bytesCurBlock), dfsClient.getConf().writePacketSize);</span><br><span class="line">      computePacketChunkSize(psize, bytesPerChecksum);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// if encountering a block boundary, send an empty packet to </span></span><br><span class="line">    <span class="comment">// indicate the end of block and reset bytesCurBlock.</span></span><br><span class="line">    <span class="comment">// 达到block大小之后，发生一个空的packet</span></span><br><span class="line">    <span class="keyword">if</span> (bytesCurBlock == blockSize) &#123;</span><br><span class="line">      currentPacket = createPacket(<span class="number">0</span>, <span class="number">0</span>, bytesCurBlock, currentSeqno++);</span><br><span class="line">      currentPacket.lastPacketInBlock = <span class="keyword">true</span>;</span><br><span class="line">      currentPacket.syncBlock = shouldSyncBlock;</span><br><span class="line">      waitAndQueueCurrentPacket();</span><br><span class="line">      bytesCurBlock = <span class="number">0</span>;</span><br><span class="line">      lastFlushOffset = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>writeChunk</code>先将chunk写入currentPacket中，当currentPacket写满之后调用<code>waitAndQueueCurrentPacket</code>，将packet放入dataQueue队列，等待DataStreamer线程将packet写入pipeline中，<em>整个block发送完毕之后将发送一个空的packet</em>。</p>
<p>将packet放入dataQueue的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">waitAndQueueCurrentPacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// If queue is full, then wait till we have enough space</span></span><br><span class="line">    <span class="comment">// dfs.client.write.max-packets-in-flight 默认值80</span></span><br><span class="line">    <span class="comment">// 当dataQueue和ackQueue的大小之和大于80时，等待</span></span><br><span class="line">    <span class="keyword">while</span> (!closed &amp;&amp; dataQueue.size() + ackQueue.size()  &gt; dfsClient.getConf().writeMaxPackets) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        dataQueue.wait();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        <span class="comment">// If we get interrupted while waiting to queue data, we still need to get rid</span></span><br><span class="line">        <span class="comment">// of the current packet. This is because we have an invariant that if</span></span><br><span class="line">        <span class="comment">// currentPacket gets full, it will get queued before the next writeChunk.</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// Rather than wait around for space in the queue, we should instead try to</span></span><br><span class="line">        <span class="comment">// return to the caller as soon as possible, even though we slightly overrun</span></span><br><span class="line">        <span class="comment">// the MAX_PACKETS length.</span></span><br><span class="line">        Thread.currentThread().interrupt();</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    checkClosed();</span><br><span class="line">    <span class="comment">// 将currentPacket放入dataQueue</span></span><br><span class="line">    queueCurrentPacket();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ClosedChannelException e) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">queueCurrentPacket</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">    <span class="keyword">if</span> (currentPacket == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">    dataQueue.addLast(currentPacket);</span><br><span class="line">    lastQueuedSeqno = currentPacket.seqno;</span><br><span class="line">    <span class="keyword">if</span> (DFSClient.LOG.isDebugEnabled()) &#123;</span><br><span class="line">      DFSClient.LOG.debug(<span class="string">"Queued packet "</span> + currentPacket.seqno);</span><br><span class="line">    &#125;</span><br><span class="line">    currentPacket = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 通知DataStreamer线程消费</span></span><br><span class="line">    dataQueue.notifyAll();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="DFSOutputStream-DataStreamer发送packet"><a href="#DFSOutputStream-DataStreamer发送packet" class="headerlink" title="DFSOutputStream.DataStreamer发送packet"></a>DFSOutputStream.DataStreamer发送packet</h2><p>DFSOutputStream中有两个队列，一个dataQueue一个ackQueue，两个队列大小的和不能超过<em>dfs.client.write.max-packets-in-flight</em>的值。<br>将currentPacket放入dataQueue中，并通知DataStreamer线程来消费，DataStreamer的run方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataStreamer.run</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> lastPacket = Time.now();</span><br><span class="line">  TraceScope traceScope = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (traceSpan != <span class="keyword">null</span>) &#123;</span><br><span class="line">    traceScope = Trace.continueSpan(traceSpan);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if the Responder encountered an error, shutdown Responder</span></span><br><span class="line">    <span class="keyword">if</span> (hasError &amp;&amp; response != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        response.close();</span><br><span class="line">        response.join();</span><br><span class="line">        response = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Packet one;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// process datanode IO errors if any</span></span><br><span class="line">      <span class="keyword">boolean</span> doSleep = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (hasError &amp;&amp; (errorIndex &gt;= <span class="number">0</span> || restartingNodeIndex &gt;= <span class="number">0</span>)) &#123;</span><br><span class="line">        doSleep = processDatanodeError();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        <span class="comment">// wait for a packet to be sent.</span></span><br><span class="line">        <span class="keyword">long</span> now = Time.now();</span><br><span class="line">        <span class="comment">// dataQueue为null，并且时间未超时，则等待</span></span><br><span class="line">        <span class="keyword">while</span> ((!streamerClosed &amp;&amp; !hasError &amp;&amp; dfsClient.clientRunning </span><br><span class="line">            &amp;&amp; dataQueue.size() == <span class="number">0</span> &amp;&amp; </span><br><span class="line">            (stage != BlockConstructionStage.DATA_STREAMING || </span><br><span class="line">             stage == BlockConstructionStage.DATA_STREAMING &amp;&amp; </span><br><span class="line">             now - lastPacket &lt; dfsClient.getConf().socketTimeout/<span class="number">2</span>)) || doSleep ) &#123;</span><br><span class="line">          <span class="keyword">long</span> timeout = dfsClient.getConf().socketTimeout/<span class="number">2</span> - (now-lastPacket);</span><br><span class="line">          timeout = timeout &lt;= <span class="number">0</span> ? <span class="number">1000</span> : timeout;</span><br><span class="line">          timeout = (stage == BlockConstructionStage.DATA_STREAMING)?</span><br><span class="line">             timeout : <span class="number">1000</span>;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            dataQueue.wait(timeout);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">            DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">          &#125;</span><br><span class="line">          doSleep = <span class="keyword">false</span>;</span><br><span class="line">          now = Time.now();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// get packet to be sent.</span></span><br><span class="line">        <span class="comment">// 发送packet，dataQueue为null，则发送一个心跳</span></span><br><span class="line">        <span class="keyword">if</span> (dataQueue.isEmpty()) &#123;</span><br><span class="line">          one = createHeartbeatPacket();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          one = dataQueue.getFirst(); <span class="comment">// regular data packet</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">assert</span> one != <span class="keyword">null</span>;</span><br><span class="line">      <span class="comment">// get new block from namenode.</span></span><br><span class="line">      <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_SETUP_CREATE) &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// 建立pipeline</span></span><br><span class="line">        setPipeline(nextBlockOutputStream());</span><br><span class="line">        <span class="comment">// 启动ResponseProcessor线程，更新DataStreamer的状态为DATA_STREAMING</span></span><br><span class="line">        initDataStreaming();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_SETUP_APPEND) &#123;</span><br><span class="line">        ...</span><br><span class="line">        setupPipelineForAppendOrRecovery();</span><br><span class="line">        initDataStreaming();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">long</span> lastByteOffsetInBlock = one.getLastByteOffsetBlock();</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// 当前packet是block的最后一个packet，等待接收之前所有packet的ack</span></span><br><span class="line">      <span class="keyword">if</span> (one.lastPacketInBlock) &#123;</span><br><span class="line">        <span class="comment">// wait for all data packets have been successfully acked</span></span><br><span class="line">        <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">          <span class="keyword">while</span> (!streamerClosed &amp;&amp; !hasError &amp;&amp; </span><br><span class="line">              ackQueue.size() != <span class="number">0</span> &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="comment">// wait for acks to arrive from datanodes</span></span><br><span class="line">              dataQueue.wait(<span class="number">1000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">              DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        stage = BlockConstructionStage.PIPELINE_CLOSE;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// send the packet</span></span><br><span class="line">      <span class="comment">// 将packet从dataQueue移到ackQueue，准备发送packet</span></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        <span class="comment">// move packet from dataQueue to ackQueue</span></span><br><span class="line">        <span class="keyword">if</span> (!one.isHeartbeatPacket()) &#123;</span><br><span class="line">          dataQueue.removeFirst();</span><br><span class="line">          ackQueue.addLast(one);</span><br><span class="line">          dataQueue.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// write out data to remote datanode</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 将packet写入pipeline</span></span><br><span class="line">        one.writeTo(blockStream);</span><br><span class="line">        blockStream.flush();   </span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="comment">// HDFS-3398 treat primary DN is down since client is unable to </span></span><br><span class="line">        <span class="comment">// write to primary DN. If a failed or restarting node has already</span></span><br><span class="line">        <span class="comment">// been recorded by the responder, the following call will have no </span></span><br><span class="line">        <span class="comment">// effect. Pipeline recovery can handle only one node error at a</span></span><br><span class="line">        <span class="comment">// time. If the primary node fails again during the recovery, it</span></span><br><span class="line">        <span class="comment">// will be taken out then.</span></span><br><span class="line">        tryMarkPrimaryDatanodeFailed();</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">      &#125;</span><br><span class="line">      lastPacket = Time.now();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// update bytesSent</span></span><br><span class="line">      <span class="keyword">long</span> tmpBytesSent = one.getLastByteOffsetBlock();</span><br><span class="line">      <span class="keyword">if</span> (bytesSent &lt; tmpBytesSent) &#123;</span><br><span class="line">        bytesSent = tmpBytesSent;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Is this block full?</span></span><br><span class="line">      <span class="comment">// 将当前packet发送之后，即将当前packet放入ackQueue</span></span><br><span class="line">      <span class="comment">// 如果当前packet是最后一个，则继续等待此packet的ack，</span></span><br><span class="line">      <span class="comment">// 然后endBlock</span></span><br><span class="line">      <span class="keyword">if</span> (one.lastPacketInBlock) &#123;</span><br><span class="line">        <span class="comment">// wait for the close packet has been acked</span></span><br><span class="line">        <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">          <span class="keyword">while</span> (!streamerClosed &amp;&amp; !hasError &amp;&amp; </span><br><span class="line">              ackQueue.size() != <span class="number">0</span> &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">            dataQueue.wait(<span class="number">1000</span>);<span class="comment">// wait for acks to arrive from datanodes</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        endBlock();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (progress != <span class="keyword">null</span>) &#123; progress.progress(); &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// This is used by unit test to trigger race conditions.</span></span><br><span class="line">      <span class="keyword">if</span> (artificialSlowdown != <span class="number">0</span> &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">        Thread.sleep(artificialSlowdown); </span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      <span class="comment">// Log warning if there was a real error.</span></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"DataStreamer Exception"</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (e <span class="keyword">instanceof</span> IOException) &#123;</span><br><span class="line">        setLastException((IOException)e);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        setLastException(<span class="keyword">new</span> IOException(<span class="string">"DataStreamer Exception: "</span>,e));</span><br><span class="line">      &#125;</span><br><span class="line">      hasError = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">if</span> (errorIndex == -<span class="number">1</span> &amp;&amp; restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// Not a datanode issue</span></span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (traceScope != <span class="keyword">null</span>) &#123;</span><br><span class="line">    traceScope.close();</span><br><span class="line">  &#125;</span><br><span class="line">  closeInternal();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DataStreamer线程主要是从dataQueue中拿出packet发送到pipeline，通过<code>setPipeline(nextBlockOutputStream())</code>创建pipeline，<code>nextBlockOutputStream</code>打开一个DataOutputStream</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> LocatedBlock <span class="title">nextBlockOutputStream</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  LocatedBlock lb = <span class="keyword">null</span>;</span><br><span class="line">  DatanodeInfo[] nodes = <span class="keyword">null</span>;</span><br><span class="line">  StorageType[] storageTypes = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">int</span> count = dfsClient.getConf().nBlockWriteRetry;</span><br><span class="line">  <span class="keyword">boolean</span> success = <span class="keyword">false</span>;</span><br><span class="line">  ExtendedBlock oldBlock = block;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    hasError = <span class="keyword">false</span>;</span><br><span class="line">    lastException.set(<span class="keyword">null</span>);</span><br><span class="line">    errorIndex = -<span class="number">1</span>;</span><br><span class="line">    success = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> startTime = Time.now();</span><br><span class="line">    DatanodeInfo[] excluded =</span><br><span class="line">        excludedNodes.getAllPresent(excludedNodes.asMap().keySet())</span><br><span class="line">        .keySet()</span><br><span class="line">        .toArray(<span class="keyword">new</span> DatanodeInfo[<span class="number">0</span>]);</span><br><span class="line">    block = oldBlock;</span><br><span class="line">    <span class="comment">// 向namenode发送add block请求</span></span><br><span class="line">    <span class="comment">// add block 时会checkLease(在analyzeFileState中调用)</span></span><br><span class="line">    lb = locateFollowingBlock(startTime,</span><br><span class="line">        excluded.length &gt; <span class="number">0</span> ? excluded : <span class="keyword">null</span>);</span><br><span class="line">    block = lb.getBlock();</span><br><span class="line">    block.setNumBytes(<span class="number">0</span>);</span><br><span class="line">    bytesSent = <span class="number">0</span>;</span><br><span class="line">    accessToken = lb.getBlockToken();</span><br><span class="line">    nodes = lb.getLocations();</span><br><span class="line">    storageTypes = lb.getStorageTypes();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Connect to first DataNode in the list.</span></span><br><span class="line">    <span class="comment">// 与nodes中的第一个datanode建立连接</span></span><br><span class="line">    <span class="comment">// 向下游发送写请求，由Sender发送</span></span><br><span class="line">    success = createBlockOutputStream(nodes, storageTypes, <span class="number">0L</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">      DFSClient.LOG.info(<span class="string">"Abandoning "</span> + block);</span><br><span class="line">      dfsClient.namenode.abandonBlock(block, fileId, src,</span><br><span class="line">          dfsClient.clientName);</span><br><span class="line">      block = <span class="keyword">null</span>;</span><br><span class="line">      DFSClient.LOG.info(<span class="string">"Excluding datanode "</span> + nodes[errorIndex]);</span><br><span class="line">      excludedNodes.put(nodes[errorIndex], nodes[errorIndex]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">while</span> (!success &amp;&amp; --count &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unable to create new block."</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> lb;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">createBlockOutputStream</span><span class="params">(DatanodeInfo[] nodes,</span></span></span><br><span class="line"><span class="function"><span class="params">    StorageType[] nodeStorageTypes, <span class="keyword">long</span> newGS, <span class="keyword">boolean</span> recoveryFlag)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  Status pipelineStatus = SUCCESS;</span><br><span class="line">  String firstBadLink = <span class="string">""</span>;</span><br><span class="line">  <span class="keyword">boolean</span> checkRestart = <span class="keyword">false</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// persist blocks on namenode on next flush</span></span><br><span class="line">  persistBlocks.set(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> refetchEncryptionKey = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">boolean</span> result = <span class="keyword">false</span>;</span><br><span class="line">    DataOutputStream out = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">null</span> == s : <span class="string">"Previous socket unclosed"</span>;</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">null</span> == blockReplyStream : <span class="string">"Previous blockReplyStream unclosed"</span>;</span><br><span class="line">      <span class="comment">// 建立socket连接</span></span><br><span class="line">      s = createSocketForPipeline(nodes[<span class="number">0</span>], nodes.length, dfsClient);</span><br><span class="line">      <span class="keyword">long</span> writeTimeout = dfsClient.getDatanodeWriteTimeout(nodes.length);</span><br><span class="line">      </span><br><span class="line">      OutputStream unbufOut = NetUtils.getOutputStream(s, writeTimeout);</span><br><span class="line">      InputStream unbufIn = NetUtils.getInputStream(s);</span><br><span class="line">      IOStreamPair saslStreams = dfsClient.saslClient.socketSend(s,</span><br><span class="line">        unbufOut, unbufIn, dfsClient, accessToken, nodes[<span class="number">0</span>]);</span><br><span class="line">      unbufOut = saslStreams.out;</span><br><span class="line">      unbufIn = saslStreams.in;</span><br><span class="line">      out = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(unbufOut,</span><br><span class="line">          HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">      blockReplyStream = <span class="keyword">new</span> DataInputStream(unbufIn);</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// send the request</span></span><br><span class="line">      <span class="comment">// 向dn发送写请求，由DataXceiver接收</span></span><br><span class="line">      <span class="keyword">new</span> Sender(out).writeBlock(blockCopy, nodeStorageTypes[<span class="number">0</span>], accessToken,</span><br><span class="line">          dfsClient.clientName, nodes, nodeStorageTypes, <span class="keyword">null</span>, bcs, </span><br><span class="line">          nodes.length, block.getNumBytes(), bytesSent, newGS,</span><br><span class="line">          checksum4WriteBlock, cachingStrategy.get(), isLazyPersistFile);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// receive ack for connect</span></span><br><span class="line">      BlockOpResponseProto resp = BlockOpResponseProto.parseFrom(</span><br><span class="line">          PBHelper.vintPrefixed(blockReplyStream));</span><br><span class="line">      pipelineStatus = resp.getStatus();</span><br><span class="line">      firstBadLink = resp.getFirstBadLink();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Got an restart OOB ack.</span></span><br><span class="line">      <span class="comment">// If a node is already restarting, this status is not likely from</span></span><br><span class="line">      <span class="comment">// the same node. If it is from a different node, it is not</span></span><br><span class="line">      <span class="comment">// from the local datanode. Thus it is safe to treat this as a</span></span><br><span class="line">      <span class="comment">// regular node error.</span></span><br><span class="line">      <span class="keyword">if</span> (PipelineAck.isRestartOOBStatus(pipelineStatus) &amp;&amp;</span><br><span class="line">        restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        checkRestart = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"A datanode is restarting."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (pipelineStatus != SUCCESS) &#123;</span><br><span class="line">        <span class="keyword">if</span> (pipelineStatus == Status.ERROR_ACCESS_TOKEN) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> InvalidBlockTokenException(</span><br><span class="line">              <span class="string">"Got access token error for connect ack with firstBadLink as "</span></span><br><span class="line">                  + firstBadLink);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad connect ack with firstBadLink as "</span></span><br><span class="line">              + firstBadLink);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">null</span> == blockStream : <span class="string">"Previous blockStream unclosed"</span>;</span><br><span class="line">      blockStream = out;</span><br><span class="line">      result =  <span class="keyword">true</span>; <span class="comment">// success</span></span><br><span class="line">      restartingNodeIndex = -<span class="number">1</span>;</span><br><span class="line">      hasError = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Exception in createBlockOutputStream"</span>, ie);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (ie <span class="keyword">instanceof</span> InvalidEncryptionKeyException &amp;&amp; refetchEncryptionKey &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Will fetch a new encryption key and retry, "</span> </span><br><span class="line">            + <span class="string">"encryption key was invalid when connecting to "</span></span><br><span class="line">            + nodes[<span class="number">0</span>] + <span class="string">" : "</span> + ie);</span><br><span class="line">        <span class="comment">// The encryption key used is invalid.</span></span><br><span class="line">        refetchEncryptionKey--;</span><br><span class="line">        dfsClient.clearDataEncryptionKey();</span><br><span class="line">        <span class="comment">// Don't close the socket/exclude this node just yet. Try again with</span></span><br><span class="line">        <span class="comment">// a new encryption key.</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// find the datanode that matches</span></span><br><span class="line">      <span class="keyword">if</span> (firstBadLink.length() != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nodes.length; i++) &#123;</span><br><span class="line">          <span class="comment">// NB: Unconditionally using the xfer addr w/o hostname</span></span><br><span class="line">          <span class="keyword">if</span> (firstBadLink.equals(nodes[i].getXferAddr())) &#123;</span><br><span class="line">            errorIndex = i;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">assert</span> checkRestart == <span class="keyword">false</span>;</span><br><span class="line">        errorIndex = <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Check whether there is a restart worth waiting for.</span></span><br><span class="line">      <span class="keyword">if</span> (checkRestart &amp;&amp; shouldWaitForRestart(errorIndex)) &#123;</span><br><span class="line">        restartDeadline = dfsClient.getConf().datanodeRestartTimeout +</span><br><span class="line">            Time.now();</span><br><span class="line">        restartingNodeIndex = errorIndex;</span><br><span class="line">        errorIndex = -<span class="number">1</span>;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Waiting for the datanode to be restarted: "</span> +</span><br><span class="line">            nodes[restartingNodeIndex]);</span><br><span class="line">      &#125;</span><br><span class="line">      hasError = <span class="keyword">true</span>;</span><br><span class="line">      setLastException(ie);</span><br><span class="line">      result =  <span class="keyword">false</span>;  <span class="comment">// error</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">        IOUtils.closeSocket(s);</span><br><span class="line">        s = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(out);</span><br><span class="line">        out = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(blockReplyStream);</span><br><span class="line">        blockReplyStream = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>nextBlockOutputStream中通过<code>locateFollowingBlock</code>得到block的locateLocations，由<code>createBlockOutputStream</code>与nodes中的第一个dn建立socket连接(<em>此过程中会建立一个输出流和一个输入流，其中输出流用来向下游发送packet，输入流用来接收下游发来的ack</em>)，<em>并发送writeBlock请求</em>。最后nextBlockOutputStream返回nodes列表，由<code>setPipeline</code>设置当前block的pipeLine</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setPipeline</span><span class="params">(DatanodeInfo[] nodes, StorageType[] storageTypes,</span></span></span><br><span class="line"><span class="function"><span class="params">    String[] storageIDs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.nodes = nodes;</span><br><span class="line">  <span class="keyword">this</span>.storageTypes = storageTypes;</span><br><span class="line">  <span class="keyword">this</span>.storageIDs = storageIDs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>建立pipeLine之后，还要启一个新的线程<code>ResponseProcessor</code>接收packet的ack，这个线程在<code>initDataStreaming</code>中启动，并更新DataStreamer线程的状态为<em>DATA_STREAMING</em></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initDataStreaming</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.setName(<span class="string">"DataStreamer for file "</span> + src +</span><br><span class="line">      <span class="string">" block "</span> + block);</span><br><span class="line">  response = <span class="keyword">new</span> ResponseProcessor(nodes);</span><br><span class="line">  response.start();</span><br><span class="line">  stage = BlockConstructionStage.DATA_STREAMING;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>准备工作结束之后，就是发送packet，调用<code>one.writeTo(blockStream)</code>，<strong>这里只是将packet写入pipeline中的第一个dn</strong>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">writeTo</span><span class="params">(DataOutputStream stm)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> dataLen = dataPos - dataStart;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> checksumLen = checksumPos - checksumStart;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> pktLen = HdfsConstants.BYTES_IN_INTEGER + dataLen + checksumLen;</span><br><span class="line"></span><br><span class="line">  PacketHeader header = <span class="keyword">new</span> PacketHeader(</span><br><span class="line">    pktLen, offsetInBlock, seqno, lastPacketInBlock, dataLen, syncBlock);</span><br><span class="line">  <span class="comment">// checksumPos不等于dataStart时，将checksum移动到data前面，</span></span><br><span class="line">  <span class="comment">// 紧挨着data，为header空出足够的空间</span></span><br><span class="line">  <span class="keyword">if</span> (checksumPos != dataStart) &#123;</span><br><span class="line">    <span class="comment">// Move the checksum to cover the gap. This can happen for the last</span></span><br><span class="line">    <span class="comment">// packet or during an hflush/hsync call.</span></span><br><span class="line">    System.arraycopy(buf, checksumStart, buf, </span><br><span class="line">                     dataStart - checksumLen , checksumLen); </span><br><span class="line">    checksumPos = dataStart;</span><br><span class="line">    checksumStart = checksumPos - checksumLen;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> headerStart = checksumStart - header.getSerializedSize();</span><br><span class="line">  <span class="keyword">assert</span> checksumStart + <span class="number">1</span> &gt;= header.getSerializedSize();</span><br><span class="line">  <span class="keyword">assert</span> checksumPos == dataStart;</span><br><span class="line">  <span class="keyword">assert</span> headerStart &gt;= <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">assert</span> headerStart + header.getSerializedSize() == checksumStart;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Copy the header data into the buffer immediately preceding the checksum</span></span><br><span class="line">  <span class="comment">// data.</span></span><br><span class="line">  <span class="comment">// 将header复制到packet的buf中，组成一个完整的packet</span></span><br><span class="line">  System.arraycopy(header.getBytes(), <span class="number">0</span>, buf, headerStart,</span><br><span class="line">      header.getSerializedSize());</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// corrupt the data for testing.</span></span><br><span class="line">  <span class="keyword">if</span> (DFSClientFaultInjector.get().corruptPacket()) &#123;</span><br><span class="line">    buf[headerStart+header.getSerializedSize() + checksumLen + dataLen-<span class="number">1</span>] ^= <span class="number">0xff</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Write the now contiguous full packet to the output stream.</span></span><br><span class="line">  <span class="comment">// 将buf写入输出流中</span></span><br><span class="line">  stm.write(buf, headerStart, header.getSerializedSize() + checksumLen + dataLen);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// undo corruption.</span></span><br><span class="line">  <span class="keyword">if</span> (DFSClientFaultInjector.get().uncorruptPacket()) &#123;</span><br><span class="line">    buf[headerStart+header.getSerializedSize() + checksumLen + dataLen-<span class="number">1</span>] ^= <span class="number">0xff</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="DataXceiver线程写入DataNode"><a href="#DataXceiver线程写入DataNode" class="headerlink" title="DataXceiver线程写入DataNode"></a>DataXceiver线程写入DataNode</h2><p>以上的流程可以看做是client端，client端将数据发送到dn上，由dn负责将packet写入本地磁盘，并向下一个dn发送。这其中涉及到DataXceiverServer线程和DataXceiver线程，DataXceiverServer相当于监听器，而DataXceiver相当于handle，由DataXceiverServer监听来自client的socket请求，根据请求创建DataXceiver线程。由DataXceiver线程进行写dn。看下DataXceiverServer.run方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Peer peer = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">while</span> (datanode.shouldRun &amp;&amp; !datanode.shutdownForUpgrade) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 接收client的socket请求</span></span><br><span class="line">      peer = peerServer.accept();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Make sure the xceiver count is not exceeded</span></span><br><span class="line">      <span class="keyword">int</span> curXceiverCount = datanode.getXceiverCount();</span><br><span class="line">      <span class="comment">// 查看当前线程是否超出上限 dfs.datanode.max.transfer.threads控制</span></span><br><span class="line">      <span class="keyword">if</span> (curXceiverCount &gt; maxXceiverCount) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Xceiver count "</span> + curXceiverCount</span><br><span class="line">            + <span class="string">" exceeds the limit of concurrent xcievers: "</span></span><br><span class="line">            + maxXceiverCount);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 新启一个DataXceiver线程</span></span><br><span class="line">      <span class="keyword">new</span> Daemon(datanode.threadGroup,</span><br><span class="line">          DataXceiver.create(peer, datanode, <span class="keyword">this</span>))</span><br><span class="line">          .start();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SocketTimeoutException ignored)</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>具体的处理逻辑在DataXceiver线程中，查看run方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> opsProcessed = <span class="number">0</span>;</span><br><span class="line">  Op op = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// We process requests in a loop, and stay around for a short timeout.</span></span><br><span class="line">    <span class="comment">// This optimistic behaviour allows the other end to reuse connections.</span></span><br><span class="line">    <span class="comment">// Setting keepalive timeout to 0 disable this behavior.</span></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      updateCurrentThreadName(<span class="string">"Waiting for operation #"</span> + (opsProcessed + <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// 读取操作码</span></span><br><span class="line">        op = readOp();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedIOException ignored) &#123;</span><br><span class="line">        <span class="comment">// Time out while we wait for client rpc</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException err) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// 处理操作码</span></span><br><span class="line">      processOp(op);</span><br><span class="line">      ++opsProcessed;</span><br><span class="line">    &#125; <span class="keyword">while</span> ((peer != <span class="keyword">null</span>) &amp;&amp;</span><br><span class="line">        (!peer.isClosed() &amp;&amp; dnConf.socketKeepaliveTimeout &gt; <span class="number">0</span>));</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DataXceiver.run方法中主要是读取操作码(readOp)并解析操作码(processOp)，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Receiver.class</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">processOp</span><span class="params">(Op op)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">switch</span>(op) &#123;</span><br><span class="line">  <span class="keyword">case</span> READ_BLOCK:</span><br><span class="line">    opReadBlock();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> WRITE_BLOCK:</span><br><span class="line">    opWriteBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> REPLACE_BLOCK:</span><br><span class="line">    opReplaceBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> COPY_BLOCK:</span><br><span class="line">    opCopyBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> BLOCK_CHECKSUM:</span><br><span class="line">    opBlockChecksum(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> TRANSFER_BLOCK:</span><br><span class="line">    opTransferBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> REQUEST_SHORT_CIRCUIT_FDS:</span><br><span class="line">    opRequestShortCircuitFds(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> RELEASE_SHORT_CIRCUIT_FDS:</span><br><span class="line">    opReleaseShortCircuitFds(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> REQUEST_SHORT_CIRCUIT_SHM:</span><br><span class="line">    opRequestShortCircuitShm(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unknown op "</span> + op + <span class="string">" in data stream"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里是写入操作，则调用<code>opWriteBlock</code>，opWriteBlock中又调用writeBlock，DataXceiver重新了writeBlock，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataXceiver.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeBlock</span><span class="params">(<span class="keyword">final</span> ExtendedBlock block,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType storageType, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> Token&lt;BlockTokenIdentifier&gt; blockToken,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> String clientname,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo[] targets,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType[] targetStorageTypes, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo srcDataNode,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> BlockConstructionStage stage,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">int</span> pipelineSize,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> minBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> maxBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> latestGenerationStamp,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum requestedChecksum,</span></span></span><br><span class="line"><span class="function"><span class="params">    CachingStrategy cachingStrategy,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">boolean</span> allowLazyPersist)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  previousOpClientName = clientname;</span><br><span class="line">  updateCurrentThreadName(<span class="string">"Receiving block "</span> + block);</span><br><span class="line">  <span class="comment">// clientname不为null，则isDatanode为false，isClient为true</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> isDatanode = clientname.length() == <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> isClient = !isDatanode;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> isTransfer = stage == BlockConstructionStage.TRANSFER_RBW</span><br><span class="line">      || stage == BlockConstructionStage.TRANSFER_FINALIZED;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// We later mutate block's generation stamp and length, but we need to</span></span><br><span class="line">  <span class="comment">// forward the original version of the block to downstream mirrors, so</span></span><br><span class="line">  <span class="comment">// make a copy here.</span></span><br><span class="line">  <span class="keyword">final</span> ExtendedBlock originalBlock = <span class="keyword">new</span> ExtendedBlock(block);</span><br><span class="line">  <span class="keyword">if</span> (block.getNumBytes() == <span class="number">0</span>) &#123;</span><br><span class="line">    block.setNumBytes(dataXceiverServer.estimateBlockSize);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// reply to upstream datanode or client</span></span><br><span class="line">  <span class="comment">// 向upstream或者client建立一个输出流，用于发送ack </span></span><br><span class="line">  <span class="keyword">final</span> DataOutputStream replyOut = <span class="keyword">new</span> DataOutputStream(</span><br><span class="line">      <span class="keyword">new</span> BufferedOutputStream(</span><br><span class="line">          getOutputStream(),</span><br><span class="line">          HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">  ...</span><br><span class="line">  DataOutputStream mirrorOut = <span class="keyword">null</span>;  <span class="comment">// stream to next target</span></span><br><span class="line">  DataInputStream mirrorIn = <span class="keyword">null</span>;    <span class="comment">// reply from next target</span></span><br><span class="line">  Socket mirrorSock = <span class="keyword">null</span>;           <span class="comment">// socket to next target</span></span><br><span class="line">  String mirrorNode = <span class="keyword">null</span>;           <span class="comment">// the name:port of next target</span></span><br><span class="line">  String firstBadLink = <span class="string">""</span>;           <span class="comment">// first datanode that failed in connection setup</span></span><br><span class="line">  Status mirrorInStatus = SUCCESS;</span><br><span class="line">  <span class="keyword">final</span> String storageUuid;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (isDatanode || </span><br><span class="line">        stage != BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) &#123;</span><br><span class="line">      <span class="comment">// open a block receiver</span></span><br><span class="line">      <span class="comment">// 实例化blockReceiver，用于接收packet</span></span><br><span class="line">      blockReceiver = <span class="keyword">new</span> BlockReceiver(block, storageType, in,</span><br><span class="line">          peer.getRemoteAddressString(),</span><br><span class="line">          peer.getLocalAddressString(),</span><br><span class="line">          stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,</span><br><span class="line">          clientname, srcDataNode, datanode, requestedChecksum,</span><br><span class="line">          cachingStrategy, allowLazyPersist);</span><br><span class="line"></span><br><span class="line">      storageUuid = blockReceiver.getStorageUuid();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      storageUuid = datanode.data.recoverClose(</span><br><span class="line">          block, latestGenerationStamp, minBytesRcvd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Connect to downstream machine, if appropriate</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">if</span> (targets.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      InetSocketAddress mirrorTarget = <span class="keyword">null</span>;</span><br><span class="line">      <span class="comment">// Connect to backup machine</span></span><br><span class="line">      <span class="comment">// 得到downstream的dn</span></span><br><span class="line">      mirrorNode = targets[<span class="number">0</span>].getXferAddr(connectToDnViaHostname);</span><br><span class="line">      ...</span><br><span class="line">      mirrorTarget = NetUtils.createSocketAddr(mirrorNode);</span><br><span class="line">      mirrorSock = datanode.newSocket();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> timeoutValue = dnConf.socketTimeout</span><br><span class="line">            + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);</span><br><span class="line">        <span class="keyword">int</span> writeTimeout = dnConf.socketWriteTimeout + </span><br><span class="line">                    (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);</span><br><span class="line">        <span class="comment">// 建立连接</span></span><br><span class="line">        NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);</span><br><span class="line">        mirrorSock.setSoTimeout(timeoutValue);</span><br><span class="line">        mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);</span><br><span class="line">        </span><br><span class="line">        OutputStream unbufMirrorOut = NetUtils.getOutputStream(mirrorSock,</span><br><span class="line">            writeTimeout);</span><br><span class="line">        InputStream unbufMirrorIn = NetUtils.getInputStream(mirrorSock);</span><br><span class="line">        DataEncryptionKeyFactory keyFactory =</span><br><span class="line">          datanode.getDataEncryptionKeyFactoryForBlock(block);</span><br><span class="line">        IOStreamPair saslStreams = datanode.saslClient.socketSend(mirrorSock,</span><br><span class="line">          unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[<span class="number">0</span>]);</span><br><span class="line">        unbufMirrorOut = saslStreams.out;</span><br><span class="line">        unbufMirrorIn = saslStreams.in;</span><br><span class="line">        mirrorOut = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(unbufMirrorOut,</span><br><span class="line">            HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">        mirrorIn = <span class="keyword">new</span> DataInputStream(unbufMirrorIn);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Do not propagate allowLazyPersist to downstream DataNodes.</span></span><br><span class="line">        <span class="comment">// 向downstream发送写请求</span></span><br><span class="line">        <span class="keyword">new</span> Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[<span class="number">0</span>],</span><br><span class="line">            blockToken, clientname, targets, targetStorageTypes, srcDataNode,</span><br><span class="line">            stage, pipelineSize, minBytesRcvd, maxBytesRcvd,</span><br><span class="line">            latestGenerationStamp, requestedChecksum, cachingStrategy, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        mirrorOut.flush();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// read connect ack (only for clients, not for replication req)</span></span><br><span class="line">        <span class="comment">// 得到下游的connect-ack</span></span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          BlockOpResponseProto connectAck =</span><br><span class="line">            BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));</span><br><span class="line">          mirrorInStatus = connectAck.getStatus();</span><br><span class="line">          firstBadLink = connectAck.getFirstBadLink();</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled() || mirrorInStatus != SUCCESS) &#123;</span><br><span class="line">            LOG.info(<span class="string">"Datanode "</span> + targets.length +</span><br><span class="line">                     <span class="string">" got response for connect ack "</span> +</span><br><span class="line">                     <span class="string">" from downstream datanode with firstbadlink as "</span> +</span><br><span class="line">                     firstBadLink);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="comment">// 这个catch捕获的是pipeline建立时的异常</span></span><br><span class="line">      <span class="comment">// 当前dn与下游建立连接时发生的异常</span></span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          BlockOpResponseProto.newBuilder()</span><br><span class="line">            .setStatus(ERROR)</span><br><span class="line">             <span class="comment">// NB: Unconditionally using the xfer addr w/o hostname</span></span><br><span class="line">            .setFirstBadLink(targets[<span class="number">0</span>].getXferAddr())</span><br><span class="line">            .build()</span><br><span class="line">            .writeDelimitedTo(replyOut);</span><br><span class="line">          replyOut.flush();</span><br><span class="line">        &#125;</span><br><span class="line">        IOUtils.closeStream(mirrorOut);</span><br><span class="line">        mirrorOut = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(mirrorIn);</span><br><span class="line">        mirrorIn = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeSocket(mirrorSock);</span><br><span class="line">        mirrorSock = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          LOG.error(datanode + <span class="string">":Exception transfering block "</span> +</span><br><span class="line">                    block + <span class="string">" to mirror "</span> + mirrorNode + <span class="string">": "</span> + e);</span><br><span class="line">          <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          LOG.info(datanode + <span class="string">":Exception transfering "</span> +</span><br><span class="line">                   block + <span class="string">" to mirror "</span> + mirrorNode +</span><br><span class="line">                   <span class="string">"- continuing without the mirror"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;<span class="comment">// if结束，判断是否有下游dn，是否建立连接</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// send connect-ack to source for clients and not transfer-RBW/Finalized</span></span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; !isTransfer) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// 向upstream发送connect-ack</span></span><br><span class="line">      BlockOpResponseProto.newBuilder()</span><br><span class="line">        .setStatus(mirrorInStatus)</span><br><span class="line">        .setFirstBadLink(firstBadLink)</span><br><span class="line">        .build()</span><br><span class="line">        .writeDelimitedTo(replyOut);</span><br><span class="line">      replyOut.flush();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 向上游发送connect-ack之后准备接收block packet</span></span><br><span class="line">    <span class="comment">// receive the block and mirror to the next target</span></span><br><span class="line">    <span class="keyword">if</span> (blockReceiver != <span class="keyword">null</span>) &#123;</span><br><span class="line">      String mirrorAddr = (mirrorSock == <span class="keyword">null</span>) ? <span class="keyword">null</span> : mirrorNode;</span><br><span class="line">      <span class="comment">// 接收block</span></span><br><span class="line">      blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,</span><br><span class="line">          mirrorAddr, <span class="keyword">null</span>, targets, <span class="keyword">false</span>);</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update its generation stamp</span></span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; </span><br><span class="line">        stage == BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) &#123;</span><br><span class="line">      block.setGenerationStamp(latestGenerationStamp);</span><br><span class="line">      block.setNumBytes(minBytesRcvd);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// if this write is for a replication request or recovering</span></span><br><span class="line">    <span class="comment">// a failed close for client, then confirm block. For other client-writes,</span></span><br><span class="line">    <span class="comment">// the block is finalized in the PacketResponder.</span></span><br><span class="line">    <span class="keyword">if</span> (isDatanode ||</span><br><span class="line">        stage == BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) &#123;</span><br><span class="line">      datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);</span><br><span class="line">      LOG.info(<span class="string">"Received "</span> + block + <span class="string">" src: "</span> + remoteAddress + <span class="string">" dest: "</span></span><br><span class="line">          + localAddress + <span class="string">" of size "</span> + block.getNumBytes());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">    LOG.info(<span class="string">"opWriteBlock "</span> + block + <span class="string">" received exception "</span> + ioe);</span><br><span class="line">    <span class="keyword">throw</span> ioe;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// close all opened streams</span></span><br><span class="line">    ...</span><br><span class="line">    blockReceiver = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>writeBlock中实例化blockReceiver，由blockReceiver.receiveBlock接收packet并写入downstream和本地磁盘，在接收packet之前先创建于downstream的连接，并向downstream发送写请求</em>。下面来看下receiveBlock的代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">receiveBlock</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    DataOutputStream mirrOut, // output to next datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    DataInputStream mirrIn,   // input from next datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    DataOutputStream replyOut,  // output to previous datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    String mirrAddr, DataTransferThrottler throttlerArg,</span></span></span><br><span class="line"><span class="function"><span class="params">    DatanodeInfo[] downstreams,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isReplaceBlock)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">    syncOnClose = datanode.getDnConf().syncOnClose;</span><br><span class="line">    <span class="keyword">boolean</span> responderClosed = <span class="keyword">false</span>;</span><br><span class="line">    mirrorOut = mirrOut;</span><br><span class="line">    mirrorAddr = mirrAddr;</span><br><span class="line">    throttler = throttlerArg;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.replyOut = replyOut;</span><br><span class="line">    <span class="keyword">this</span>.isReplaceBlock = isReplaceBlock;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; !isTransfer) &#123;</span><br><span class="line">      responder = <span class="keyword">new</span> Daemon(datanode.threadGroup, </span><br><span class="line">          <span class="keyword">new</span> PacketResponder(replyOut, mirrIn, downstreams));</span><br><span class="line">      responder.start(); <span class="comment">// start thread to processes responses</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里是个空循环</span></span><br><span class="line">    <span class="comment">// 不停的调用receivePacket接收packet，直到整个block的packet接收完</span></span><br><span class="line">    <span class="keyword">while</span> (receivePacket() &gt;= <span class="number">0</span>) &#123; <span class="comment">/* Receive until the last packet */</span> &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// wait for all outstanding packet responses. And then</span></span><br><span class="line">    <span class="comment">// indicate responder to gracefully shutdown.</span></span><br><span class="line">    <span class="comment">// Mark that responder has been closed for future processing</span></span><br><span class="line">    <span class="keyword">if</span> (responder != <span class="keyword">null</span>) &#123;</span><br><span class="line">      ((PacketResponder)responder.getRunnable()).close();</span><br><span class="line">      responderClosed = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If this write is for a replication or transfer-RBW/Finalized,</span></span><br><span class="line">    <span class="comment">// then finalize block or convert temporary to RBW.</span></span><br><span class="line">    <span class="comment">// For client-writes, the block is finalized in the PacketResponder.</span></span><br><span class="line">    <span class="keyword">if</span> (isDatanode || isTransfer) &#123;</span><br><span class="line">      <span class="comment">// close the block/crc files</span></span><br><span class="line">      close();</span><br><span class="line">      block.setNumBytes(replicaInfo.getNumBytes());</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (stage == BlockConstructionStage.TRANSFER_RBW) &#123;</span><br><span class="line">        <span class="comment">// for TRANSFER_RBW, convert temporary to RBW</span></span><br><span class="line">        datanode.data.convertTemporaryToRbw(block);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// for isDatnode or TRANSFER_FINALIZED</span></span><br><span class="line">        <span class="comment">// Finalize the block.</span></span><br><span class="line">        datanode.data.finalizeBlock(block);</span><br><span class="line">      &#125;</span><br><span class="line">      datanode.metrics.incrBlocksWritten();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>receiveBlock会启动PacketResponder线程来接收来自downstream的packet ack和向upstream发送packet ack。<em>PacketResponder中也有个ackQueue队列</em>(注意和DFSOutputStream中的dataQueue和ackQueue区分)，receivePacket将接收的packet放入ackQueue中，由PacketResponder接收ack并从ackQueue中取出packet。receivePacket代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">receivePacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// read the next packet</span></span><br><span class="line">  <span class="comment">// 从流中读取packet</span></span><br><span class="line">  packetReceiver.receiveNextPacket(in);</span><br><span class="line"></span><br><span class="line">  PacketHeader header = packetReceiver.getHeader();</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Sanity check the header</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">long</span> offsetInBlock = header.getOffsetInBlock();</span><br><span class="line">  <span class="keyword">long</span> seqno = header.getSeqno();</span><br><span class="line">  <span class="keyword">boolean</span> lastPacketInBlock = header.isLastPacketInBlock();</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> len = header.getDataLen();</span><br><span class="line">  <span class="keyword">boolean</span> syncBlock = header.getSyncBlock();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// avoid double sync'ing on close</span></span><br><span class="line">  <span class="keyword">if</span> (syncBlock &amp;&amp; lastPacketInBlock) &#123;</span><br><span class="line">    <span class="keyword">this</span>.syncOnClose = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// update received bytes</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> firstByteInBlock = offsetInBlock;</span><br><span class="line">  offsetInBlock += len;</span><br><span class="line">  <span class="keyword">if</span> (replicaInfo.getNumBytes() &lt; offsetInBlock) &#123;</span><br><span class="line">    replicaInfo.setNumBytes(offsetInBlock);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// put in queue for pending acks, unless sync was requested</span></span><br><span class="line">  <span class="comment">// 在向downstream发送packet之前，将packet放入ackQueue中</span></span><br><span class="line">  <span class="keyword">if</span> (responder != <span class="keyword">null</span> &amp;&amp; !syncBlock &amp;&amp; !shouldVerifyChecksum()) &#123;</span><br><span class="line">    ((PacketResponder) responder.getRunnable()).enqueue(seqno,</span><br><span class="line">        lastPacketInBlock, offsetInBlock, Status.SUCCESS);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//First write the packet to the mirror:</span></span><br><span class="line">  <span class="keyword">if</span> (mirrorOut != <span class="keyword">null</span> &amp;&amp; !mirrorError) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">long</span> begin = Time.monotonicNow();</span><br><span class="line">      <span class="comment">// 向downstream发送packet</span></span><br><span class="line">      packetReceiver.mirrorPacketTo(mirrorOut);</span><br><span class="line">      mirrorOut.flush();</span><br><span class="line">      <span class="keyword">long</span> duration = Time.monotonicNow() - begin;</span><br><span class="line">      <span class="keyword">if</span> (duration &gt; datanodeSlowLogThresholdMs) &#123;</span><br><span class="line">        LOG.warn(<span class="string">"Slow BlockReceiver write packet to mirror took "</span> + duration</span><br><span class="line">            + <span class="string">"ms (threshold="</span> + datanodeSlowLogThresholdMs + <span class="string">"ms)"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      handleMirrorOutError(e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将packet的data部分写入本地时的buf</span></span><br><span class="line">  ByteBuffer dataBuf = packetReceiver.getDataSlice();</span><br><span class="line">  ByteBuffer checksumBuf = packetReceiver.getChecksumSlice();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (lastPacketInBlock || len == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"Receiving an empty packet or the end of the block "</span> + block);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// sync block if requested</span></span><br><span class="line">    <span class="keyword">if</span> (syncBlock) &#123;</span><br><span class="line">      flushOrSync(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> checksumLen = diskChecksum.getChecksumSize(len);</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> checksumReceivedLen = checksumBuf.capacity();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (checksumReceivedLen &gt; <span class="number">0</span> &amp;&amp; checksumReceivedLen != checksumLen) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Invalid checksum length: received length is "</span></span><br><span class="line">          + checksumReceivedLen + <span class="string">" but expected length is "</span> + checksumLen);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (checksumReceivedLen &gt; <span class="number">0</span> &amp;&amp; shouldVerifyChecksum()) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 校验checksum</span></span><br><span class="line">        verifyChunks(dataBuf, checksumBuf);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">        <span class="comment">// checksum error detected locally. there is no reason to continue.</span></span><br><span class="line">        <span class="keyword">if</span> (responder != <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            ((PacketResponder) responder.getRunnable()).enqueue(seqno,</span><br><span class="line">                lastPacketInBlock, offsetInBlock,</span><br><span class="line">                Status.ERROR_CHECKSUM);</span><br><span class="line">            <span class="comment">// Wait until the responder sends back the response</span></span><br><span class="line">            <span class="comment">// and interrupt this thread.</span></span><br><span class="line">            Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (InterruptedException e) &#123; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Terminating due to a checksum error."</span> + ioe);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (needsChecksumTranslation) &#123;</span><br><span class="line">        <span class="comment">// overwrite the checksums in the packet buffer with the</span></span><br><span class="line">        <span class="comment">// appropriate polynomial for the disk storage.</span></span><br><span class="line">        translateChunks(dataBuf, checksumBuf);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// checksum在传输过程中丢失，则重新计算</span></span><br><span class="line">    <span class="keyword">if</span> (checksumReceivedLen == <span class="number">0</span> &amp;&amp; !streams.isTransientStorage()) &#123;</span><br><span class="line">      <span class="comment">// checksum is missing, need to calculate it</span></span><br><span class="line">      checksumBuf = ByteBuffer.allocate(checksumLen);</span><br><span class="line">      diskChecksum.calculateChunkedSums(dataBuf, checksumBuf);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// by this point, the data in the buffer uses the disk checksum</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">boolean</span> shouldNotWriteChecksum = checksumReceivedLen == <span class="number">0</span></span><br><span class="line">        &amp;&amp; streams.isTransientStorage();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 得到磁盘中当前block的长度</span></span><br><span class="line">      <span class="keyword">long</span> onDiskLen = replicaInfo.getBytesOnDisk();</span><br><span class="line">      <span class="keyword">if</span> (onDiskLen&lt;offsetInBlock) &#123;</span><br><span class="line">        <span class="comment">//finally write to the disk :</span></span><br><span class="line">        <span class="comment">// 当磁盘中已写入block的长度不是chunk的整数倍，则将最后一个checksum进行重写</span></span><br><span class="line">        <span class="keyword">if</span> (onDiskLen % bytesPerChecksum != <span class="number">0</span>) &#123; </span><br><span class="line">          <span class="comment">// prepare to overwrite last checksum</span></span><br><span class="line">          adjustCrcFilePosition();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// If this is a partial chunk, then read in pre-existing checksum</span></span><br><span class="line">        Checksum partialCrc = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (!shouldNotWriteChecksum &amp;&amp; firstByteInBlock % bytesPerChecksum != <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">            LOG.debug(<span class="string">"receivePacket for "</span> + block </span><br><span class="line">                + <span class="string">": bytesPerChecksum="</span> + bytesPerChecksum                  </span><br><span class="line">                + <span class="string">" does not divide firstByteInBlock="</span> + firstByteInBlock);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">long</span> offsetInChecksum = BlockMetadataHeader.getHeaderSize() +</span><br><span class="line">              onDiskLen / bytesPerChecksum * checksumSize;</span><br><span class="line">          partialCrc = computePartialChunkCrc(onDiskLen, offsetInChecksum);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> startByteToDisk = (<span class="keyword">int</span>)(onDiskLen-firstByteInBlock) </span><br><span class="line">            + dataBuf.arrayOffset() + dataBuf.position();</span><br><span class="line">        <span class="comment">// data的len</span></span><br><span class="line">        <span class="keyword">int</span> numBytesToDisk = (<span class="keyword">int</span>)(offsetInBlock-onDiskLen);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Write data to disk.</span></span><br><span class="line">        <span class="keyword">long</span> begin = Time.monotonicNow();</span><br><span class="line">        <span class="comment">// 将data写入磁盘</span></span><br><span class="line">        out.write(dataBuf.array(), startByteToDisk, numBytesToDisk);</span><br><span class="line">        <span class="keyword">long</span> duration = Time.monotonicNow() - begin;</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">byte</span>[] lastCrc;</span><br><span class="line">        <span class="keyword">if</span> (shouldNotWriteChecksum) &#123;</span><br><span class="line">          lastCrc = <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (partialCrc != <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// If this is a partial chunk, then verify that this is the only</span></span><br><span class="line">          <span class="comment">// chunk in the packet. Calculate new crc for this chunk.</span></span><br><span class="line">          <span class="keyword">if</span> (len &gt; bytesPerChecksum) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unexpected packet data length for "</span></span><br><span class="line">                +  block + <span class="string">" from "</span> + inAddr + <span class="string">": a partial chunk must be "</span></span><br><span class="line">                + <span class="string">" sent in an individual packet (data length = "</span> + len</span><br><span class="line">                +  <span class="string">" &gt; bytesPerChecksum = "</span> + bytesPerChecksum + <span class="string">")"</span>);</span><br><span class="line">          &#125;</span><br><span class="line">          partialCrc.update(dataBuf.array(), startByteToDisk, numBytesToDisk);</span><br><span class="line">          <span class="keyword">byte</span>[] buf = FSOutputSummer.convertToByteStream(partialCrc, checksumSize);</span><br><span class="line">          lastCrc = copyLastChunkChecksum(buf, checksumSize, buf.length);</span><br><span class="line">          checksumOut.write(buf);</span><br><span class="line">          <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">            LOG.debug(<span class="string">"Writing out partial crc for data len "</span> + len);</span><br><span class="line">          &#125;</span><br><span class="line">          partialCrc = <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// write checksum</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> offset = checksumBuf.arrayOffset() +</span><br><span class="line">              checksumBuf.position();</span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> end = offset + checksumLen;</span><br><span class="line">          lastCrc = copyLastChunkChecksum(checksumBuf.array(), checksumSize,</span><br><span class="line">              end);</span><br><span class="line">          <span class="comment">// 将checksum写入磁盘</span></span><br><span class="line">          checksumOut.write(checksumBuf.array(), offset, checksumLen);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/// flush entire packet, sync if requested</span></span><br><span class="line">        <span class="comment">// 将block data和metadata flush到磁盘</span></span><br><span class="line">        flushOrSync(syncBlock);       </span><br><span class="line">        replicaInfo.setLastChecksumAndDataLen(offsetInBlock, lastCrc);</span><br><span class="line">        datanode.metrics.incrBytesWritten(len);</span><br><span class="line">        manageWriterOsCache(offsetInBlock);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException iex) &#123;</span><br><span class="line">      datanode.checkDiskErrorAsync();</span><br><span class="line">      <span class="keyword">throw</span> iex;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> lastPacketInBlock?-<span class="number">1</span>:len;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="发送接收ACK"><a href="#发送接收ACK" class="headerlink" title="发送接收ACK"></a>发送接收ACK</h2><p><em>receivePacket从流中读出packet，在其向downstream发送时，先将packet当如ackQueue队列中，由PacketResponder线程等待接收此packet的ack，然后向downstream发送packet，最后将packet写入本地磁盘。</em></p>
<p>下面看下PacketResponder线程的run方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> lastPacketInBlock = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> startTime = ClientTraceLog.isInfoEnabled() ? System.nanoTime() : <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (isRunning() &amp;&amp; !lastPacketInBlock) &#123;</span><br><span class="line">    <span class="keyword">long</span> totalAckTimeNanos = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">boolean</span> isInterrupted = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Packet pkt = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">long</span> expected = -<span class="number">2</span>;</span><br><span class="line">      PipelineAck ack = <span class="keyword">new</span> PipelineAck();</span><br><span class="line">      <span class="keyword">long</span> seqno = PipelineAck.UNKOWN_SEQNO;</span><br><span class="line">      <span class="keyword">long</span> ackRecvNanoTime = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (type != PacketResponderType.LAST_IN_PIPELINE &amp;&amp; !mirrorError) &#123;</span><br><span class="line">          <span class="comment">// read an ack from downstream datanode</span></span><br><span class="line">          <span class="comment">// 读取ack</span></span><br><span class="line">          ack.readFields(downstreamIn);</span><br><span class="line">          ackRecvNanoTime = System.nanoTime();</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">            LOG.debug(myString + <span class="string">" got "</span> + ack);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// Process an OOB ACK.</span></span><br><span class="line">          Status oobStatus = ack.getOOBStatus();</span><br><span class="line">          <span class="keyword">if</span> (oobStatus != <span class="keyword">null</span>) &#123;</span><br><span class="line">            LOG.info(<span class="string">"Relaying an out of band ack of type "</span> + oobStatus);</span><br><span class="line">            sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, <span class="number">0L</span>, <span class="number">0L</span>,</span><br><span class="line">                Status.SUCCESS);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 新收到的ack的seqno</span></span><br><span class="line">          seqno = ack.getSeqno();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 获得一个ack</span></span><br><span class="line">        <span class="keyword">if</span> (seqno != PipelineAck.UNKOWN_SEQNO</span><br><span class="line">            || type == PacketResponderType.LAST_IN_PIPELINE) &#123;</span><br><span class="line">          <span class="comment">// 按照发送packet的顺序接收packet ack</span></span><br><span class="line">          pkt = waitForAckHead(seqno);</span><br><span class="line">          <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          expected = pkt.seqno;</span><br><span class="line">          ...</span><br><span class="line">          lastPacketInBlock = pkt.lastPacketInBlock;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ine) &#123;</span><br><span class="line">        isInterrupted = <span class="keyword">true</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">        <span class="keyword">if</span> (Thread.interrupted()) &#123;</span><br><span class="line">          isInterrupted = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// continue to run even if can not read from mirror</span></span><br><span class="line">          <span class="comment">// notify client of the error</span></span><br><span class="line">          <span class="comment">// and wait for the client to shut down the pipeline</span></span><br><span class="line">          mirrorError = <span class="keyword">true</span>;</span><br><span class="line">          LOG.info(myString, ioe);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (Thread.interrupted() || isInterrupted) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * The receiver thread cancelled this thread. We could also check</span></span><br><span class="line"><span class="comment">         * any other status updates from the receiver thread (e.g. if it is</span></span><br><span class="line"><span class="comment">         * ok to write to replyOut). It is prudent to not send any more</span></span><br><span class="line"><span class="comment">         * status back to the client because this datanode has a problem.</span></span><br><span class="line"><span class="comment">         * The upstream datanode will detect that this datanode is bad, and</span></span><br><span class="line"><span class="comment">         * rightly so.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * The receiver thread can also interrupt this thread for sending</span></span><br><span class="line"><span class="comment">         * an out-of-band response upstream.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        LOG.info(myString + <span class="string">": Thread is interrupted."</span>);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (lastPacketInBlock) &#123;</span><br><span class="line">        <span class="comment">// Finalize the block and close the block file</span></span><br><span class="line">        finalizeBlock(startTime);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 向upstream发送ack</span></span><br><span class="line">      sendAckUpstream(ack, expected, totalAckTimeNanos,</span><br><span class="line">          (pkt != <span class="keyword">null</span> ? pkt.offsetInBlock : <span class="number">0</span>), </span><br><span class="line">          (pkt != <span class="keyword">null</span> ? pkt.ackStatus : Status.SUCCESS));</span><br><span class="line">      <span class="keyword">if</span> (pkt != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// remove the packet from the ack queue</span></span><br><span class="line">        removeAckHead();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"IOException in BlockReceiver.run(): "</span>, e);</span><br><span class="line">      <span class="keyword">if</span> (running) &#123;</span><br><span class="line">        datanode.checkDiskErrorAsync();</span><br><span class="line">        LOG.info(myString, e);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (!Thread.interrupted()) &#123; <span class="comment">// failure not caused by interruption</span></span><br><span class="line">          receiverThread.interrupt();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (running) &#123;</span><br><span class="line">        LOG.info(myString, e);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        receiverThread.interrupt();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.info(myString + <span class="string">" terminating"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PacketResponder线程主要用来接收和发送packet ack，并且是按照packet的写入顺序发送ack。</p>
<p>如果packet的type为<em>LAST_IN_PIPELINE</em>时，不进入<code>if (type != PacketResponderType.LAST_IN_PIPELINE &amp;&amp; !mirrorError)</code>语句，直接进入<code>if (seqno != PipelineAck.UNKOWN_SEQNO || type == PacketResponderType.LAST_IN_PIPELINE)</code>，从ackQueue队列中拿出第一个packet，<code>sendAckUpstream</code>向upstream发送ack，发送结束之后从ackQueue中移除packet。因为ackQueue的里packet的顺序是packet的写入顺序，则这样就保证了ack也是有序的。</p>
<p>如果packet的type为<em>HAS_DOWNSTREAM_IN_PIPELINE</em>时，进入<code>if (type != PacketResponderType.LAST_IN_PIPELINE &amp;&amp; !mirrorError)</code>，从输入流中读取ack，再进入<code>if (seqno != PipelineAck.UNKOWN_SEQNO || type == PacketResponderType.LAST_IN_PIPELINE)</code>从ackQueue中读取expect的packet，进行一些列校验之后，想upstream发送ack<code>sendAckUpstream</code>(<em>此时发送的ack包括自己和downstream的ack</em>)，发送结束之后从ackQueue中移除packet。</p>
<p><em>PacketResponder线程负责dn上packet ack的发送和接收，ResponseProcessor线程负责client端packet ack的接收</em>，看下ResponseProcessor线程的run方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  PipelineAck ack = <span class="keyword">new</span> PipelineAck();</span><br><span class="line">  <span class="keyword">while</span> (!responderClosed &amp;&amp; dfsClient.clientRunning &amp;&amp; !isLastPacketInBlock) &#123;</span><br><span class="line">    <span class="comment">// process responses from datanodes.</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// read an ack from the pipeline</span></span><br><span class="line">      <span class="keyword">long</span> begin = Time.monotonicNow();</span><br><span class="line">      <span class="comment">// 读取ack</span></span><br><span class="line">      ack.readFields(blockReplyStream);</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">long</span> seqno = ack.getSeqno();</span><br><span class="line">      <span class="comment">// processes response status from datanodes.</span></span><br><span class="line">      <span class="comment">// 从pipeline的最后一个dn开始接收ack</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = ack.getNumOfReplies()-<span class="number">1</span>; i &gt;=<span class="number">0</span>  &amp;&amp; dfsClient.clientRunning; i--) &#123;</span><br><span class="line">        <span class="keyword">final</span> Status reply = ack.getReply(i);</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// node error</span></span><br><span class="line">        <span class="keyword">if</span> (reply != SUCCESS) &#123;</span><br><span class="line">          setErrorIndex(i); <span class="comment">// first bad datanode</span></span><br><span class="line">          <span class="comment">// throw 则跳出for循环，被catch捕获异常</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad response "</span> + reply +</span><br><span class="line">              <span class="string">" for block "</span> + block +</span><br><span class="line">              <span class="string">" from datanode "</span> + </span><br><span class="line">              targets[i]);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">assert</span> seqno != PipelineAck.UNKOWN_SEQNO : </span><br><span class="line">        <span class="string">"Ack for unknown seqno should be a failed ack: "</span> + ack;</span><br><span class="line">      <span class="keyword">if</span> (seqno == Packet.HEART_BEAT_SEQNO) &#123;  <span class="comment">// a heartbeat ack</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// a success ack for a data packet</span></span><br><span class="line">      Packet one;</span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        one = ackQueue.getFirst();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 从输入流中读取的ack的seqno与ackQueue中取得的seqno不一样则抛出异常</span></span><br><span class="line">      <span class="keyword">if</span> (one.seqno != seqno) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"ResponseProcessor: Expecting seqno "</span> +</span><br><span class="line">                              <span class="string">" for block "</span> + block +</span><br><span class="line">                              one.seqno + <span class="string">" but received "</span> + seqno);</span><br><span class="line">      &#125;</span><br><span class="line">      isLastPacketInBlock = one.lastPacketInBlock;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Fail the packet write for testing in order to force a</span></span><br><span class="line">      <span class="comment">// pipeline recovery.</span></span><br><span class="line">      <span class="keyword">if</span> (DFSClientFaultInjector.get().failPacket() &amp;&amp;</span><br><span class="line">          isLastPacketInBlock) &#123;</span><br><span class="line">        failPacket = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">              <span class="string">"Failing the last packet for testing."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">        </span><br><span class="line">      <span class="comment">// update bytesAcked</span></span><br><span class="line">      block.setNumBytes(one.getLastByteOffsetBlock());</span><br><span class="line">      <span class="comment">// 接收到ack后，从ackQueue中移除packet</span></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        lastAckedSeqno = seqno;</span><br><span class="line">        ackQueue.removeFirst();</span><br><span class="line">        dataQueue.notifyAll();</span><br><span class="line"></span><br><span class="line">        one.releaseBuffer(byteArrayManager);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!responderClosed) &#123;</span><br><span class="line">        <span class="keyword">if</span> (e <span class="keyword">instanceof</span> IOException) &#123;</span><br><span class="line">          setLastException((IOException)e);</span><br><span class="line">        &#125;</span><br><span class="line">        hasError = <span class="keyword">true</span>;</span><br><span class="line">        <span class="comment">// If no explicit error report was received, mark the primary</span></span><br><span class="line">        <span class="comment">// node as failed.</span></span><br><span class="line">        tryMarkPrimaryDatanodeFailed();</span><br><span class="line">        <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">          dataQueue.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">          DFSClient.LOG.warn(<span class="string">"DFSOutputStream ResponseProcessor exception "</span></span><br><span class="line">               + <span class="string">" for block "</span> + block, e);</span><br><span class="line">        &#125;</span><br><span class="line">        responderClosed = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ResponseProcessor线程读取ack，并从pipeline中的最后一个dn检查packet的状态，如果发现error则设置errorIndex为当前dn的索引，在catch中设置<code>hasError = true</code>；如果没有error则从ackQueue中移除packet。</p>
<h2 id="pipeline中写发送错误"><a href="#pipeline中写发送错误" class="headerlink" title="pipeline中写发送错误"></a>pipeline中写发送错误</h2><p>在写数据的过程中，如果Pipeline数据流管道中的一个DataNode节点写失败了会发生什问题、需要做哪些内部处理呢？下面从代码中寻找答案。</p>
<p>ResponseProcessor线程中从接收到的ack中发现error，则设置errorIndex为错误节点的index，hasError标识为true，在DataStreamer线程中发现属性的变化，进行错误处理，看下部分DataStreamer的run代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">while</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="comment">// if the Responder encountered an error, shutdown Responder</span></span><br><span class="line">    <span class="keyword">if</span> (hasError &amp;&amp; response != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        response.close();</span><br><span class="line">        response.join();</span><br><span class="line">        response = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    Packet one;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// process datanode IO errors if any</span></span><br><span class="line">      <span class="keyword">boolean</span> doSleep = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (hasError &amp;&amp; (errorIndex &gt;= <span class="number">0</span> || restartingNodeIndex &gt;= <span class="number">0</span>)) &#123;</span><br><span class="line">        <span class="comment">// 处理错误</span></span><br><span class="line">        doSleep = processDatanodeError();</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DataStreamer线程发现error之后调用<code>processDatanodeError</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">processDatanodeError</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (response != <span class="keyword">null</span>) &#123;</span><br><span class="line">    DFSClient.LOG.info(<span class="string">"Error Recovery for "</span> + block +</span><br><span class="line">    <span class="string">" waiting for responder to exit. "</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 关闭pipeline流</span></span><br><span class="line">  closeStream();</span><br><span class="line">  <span class="comment">// 将ackQueue中的packet移到dataQueue</span></span><br><span class="line">  <span class="comment">// move packets from ack queue to front of the data queue</span></span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">    dataQueue.addAll(<span class="number">0</span>, ackQueue);</span><br><span class="line">    ackQueue.clear();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Record the new pipeline failure recovery.</span></span><br><span class="line">  <span class="comment">// 创建新的pipeline可以进行重试</span></span><br><span class="line">  <span class="keyword">if</span> (lastAckedSeqnoBeforeFailure != lastAckedSeqno) &#123;</span><br><span class="line">     lastAckedSeqnoBeforeFailure = lastAckedSeqno;</span><br><span class="line">     pipelineRecoveryCount = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// If we had to recover the pipeline five times in a row for the</span></span><br><span class="line">    <span class="comment">// same packet, this client likely has corrupt data or corrupting</span></span><br><span class="line">    <span class="comment">// during transmission.</span></span><br><span class="line">    <span class="keyword">if</span> (++pipelineRecoveryCount &gt; <span class="number">5</span>) &#123;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">"Error recovering pipeline for writing "</span> +</span><br><span class="line">          block + <span class="string">". Already retried 5 times for the same packet."</span>);</span><br><span class="line">      lastException.set(<span class="keyword">new</span> IOException(<span class="string">"Failing write. Tried pipeline "</span> +</span><br><span class="line">          <span class="string">"recovery 5 times without success."</span>));</span><br><span class="line">      streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 重建pipeline</span></span><br><span class="line">  <span class="keyword">boolean</span> doSleep = setupPipelineForAppendOrRecovery();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_CLOSE) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// If we had an error while closing the pipeline, we go through a fast-path</span></span><br><span class="line">      <span class="comment">// where the BlockReceiver does not run. Instead, the DataNode just finalizes</span></span><br><span class="line">      <span class="comment">// the block immediately during the 'connect ack' process. So, we want to pull</span></span><br><span class="line">      <span class="comment">// the end-of-block packet from the dataQueue, since we don't actually have</span></span><br><span class="line">      <span class="comment">// a true pipeline to send it over.</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that</span></span><br><span class="line">      <span class="comment">// a client waiting on close() will be aware that the flush finished.</span></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        Packet endOfBlockPacket = dataQueue.remove();  <span class="comment">// remove the end of block packet</span></span><br><span class="line">        <span class="keyword">assert</span> endOfBlockPacket.lastPacketInBlock;</span><br><span class="line">        <span class="keyword">assert</span> lastAckedSeqno == endOfBlockPacket.seqno - <span class="number">1</span>;</span><br><span class="line">        lastAckedSeqno = endOfBlockPacket.seqno;</span><br><span class="line">        dataQueue.notifyAll();</span><br><span class="line">      &#125;</span><br><span class="line">      endBlock();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 启动ResponseProcess线程</span></span><br><span class="line">      initDataStreaming();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> doSleep;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>processDatanodeError方法中主要逻辑是<code>setupPipelineForAppendOrRecovery</code>，创建新的pipeline</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">setupPipelineForAppendOrRecovery</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// check number of datanodes</span></span><br><span class="line">  ...  </span><br><span class="line">  <span class="keyword">boolean</span> success = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">long</span> newGS = <span class="number">0L</span>;</span><br><span class="line">  <span class="keyword">while</span> (!success &amp;&amp; !streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="comment">// Sleep before reconnect if a dn is restarting.</span></span><br><span class="line">    <span class="comment">// This process will be repeated until the deadline or the datanode</span></span><br><span class="line">    <span class="comment">// starts back up.</span></span><br><span class="line">    <span class="keyword">if</span> (restartingNodeIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 4 seconds or the configured deadline period, whichever is shorter.</span></span><br><span class="line">      <span class="comment">// This is the retry interval and recovery will be retried in this</span></span><br><span class="line">      <span class="comment">// interval until timeout or success.</span></span><br><span class="line">      <span class="keyword">long</span> delay = Math.min(dfsClient.getConf().datanodeRestartTimeout,</span><br><span class="line">          <span class="number">4000L</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        Thread.sleep(delay);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">        lastException.set(<span class="keyword">new</span> IOException(<span class="string">"Interrupted while waiting for "</span> +</span><br><span class="line">            <span class="string">"datanode to restart. "</span> + nodes[restartingNodeIndex]));</span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">boolean</span> isRecovery = hasError;</span><br><span class="line">    <span class="comment">// remove bad datanode from list of datanodes.</span></span><br><span class="line">    <span class="comment">// If errorIndex was not set (i.e. appends), then do not remove </span></span><br><span class="line">    <span class="comment">// any datanodes</span></span><br><span class="line">    <span class="comment">// </span></span><br><span class="line">    <span class="keyword">if</span> (errorIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (nodes.length &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        lastException.set(<span class="keyword">new</span> IOException(<span class="string">"All datanodes "</span> + pipelineMsg</span><br><span class="line">            + <span class="string">" are bad. Aborting..."</span>));</span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 将错误的dn加入failed列表中</span></span><br><span class="line">      failed.add(nodes[errorIndex]);</span><br><span class="line">      DatanodeInfo[] newnodes = <span class="keyword">new</span> DatanodeInfo[nodes.length-<span class="number">1</span>];</span><br><span class="line">      <span class="comment">// 将正常的dn复制到新的数组newnodes里</span></span><br><span class="line">      arraycopy(nodes, newnodes, errorIndex);</span><br><span class="line">      <span class="keyword">final</span> StorageType[] newStorageTypes = <span class="keyword">new</span> StorageType[newnodes.length];</span><br><span class="line">      arraycopy(storageTypes, newStorageTypes, errorIndex);</span><br><span class="line">      <span class="keyword">final</span> String[] newStorageIDs = <span class="keyword">new</span> String[newnodes.length];</span><br><span class="line">      arraycopy(storageIDs, newStorageIDs, errorIndex);</span><br><span class="line">      <span class="comment">// 使用newnodes设置pipeline</span></span><br><span class="line">      setPipeline(newnodes, newStorageTypes, newStorageIDs);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Just took care of a node error while waiting for a node restart</span></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// If the error came from a node further away than the restarting</span></span><br><span class="line">        <span class="comment">// node, the restart must have been complete.</span></span><br><span class="line">        <span class="keyword">if</span> (errorIndex &gt; restartingNodeIndex) &#123;</span><br><span class="line">          restartingNodeIndex = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (errorIndex &lt; restartingNodeIndex) &#123;</span><br><span class="line">          <span class="comment">// the node index has shifted.</span></span><br><span class="line">          restartingNodeIndex--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// this shouldn't happen...</span></span><br><span class="line">          <span class="keyword">assert</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        hasError = <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      lastException.set(<span class="keyword">null</span>);</span><br><span class="line">      errorIndex = -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if replace-datanode policy is satisfied.</span></span><br><span class="line">    <span class="keyword">if</span> (dfsClient.dtpReplaceDatanodeOnFailure.satisfy(blockReplication,</span><br><span class="line">        nodes, isAppend, isHflushed)) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 补全pipeline的节点数量</span></span><br><span class="line">        addDatanode2ExistingPipeline();</span><br><span class="line">      &#125; <span class="keyword">catch</span>(IOException ioe) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get a new generation stamp and an access token</span></span><br><span class="line">    <span class="comment">// 生成一个新的stamp</span></span><br><span class="line">    LocatedBlock lb = dfsClient.namenode.updateBlockForPipeline(block, dfsClient.clientName);</span><br><span class="line">    newGS = lb.getBlock().getGenerationStamp();</span><br><span class="line">    accessToken = lb.getBlockToken();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// set up the pipeline again with the remaining nodes</span></span><br><span class="line">    <span class="keyword">if</span> (failPacket) &#123; <span class="comment">// for testing</span></span><br><span class="line">      success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);</span><br><span class="line">      failPacket = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Give DNs time to send in bad reports. In real situations,</span></span><br><span class="line">        <span class="comment">// good reports should follow bad ones, if client committed</span></span><br><span class="line">        <span class="comment">// with those nodes.</span></span><br><span class="line">        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;&#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 与pipeline中的第一个dn建立连接</span></span><br><span class="line">      success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="comment">// while</span></span><br><span class="line">  <span class="comment">// 更新block的stamp</span></span><br><span class="line">  <span class="keyword">if</span> (success) &#123;</span><br><span class="line">    <span class="comment">// update pipeline at the namenode</span></span><br><span class="line">    ExtendedBlock newBlock = <span class="keyword">new</span> ExtendedBlock(</span><br><span class="line">        block.getBlockPoolId(), block.getBlockId(), block.getNumBytes(), newGS);</span><br><span class="line">    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,</span><br><span class="line">        nodes, storageIDs);</span><br><span class="line">    <span class="comment">// update client side generation stamp</span></span><br><span class="line">    block = newBlock;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">// do not sleep, continue processing</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>setupPipelineForAppendOrRecovery从原pipeline中取出正常的dn，将错误dn排除，然后调用<code>addDatanode2ExistingPipeline</code>，加入一个新的dn与原来正常的两个dn组成一个新的pipeline(<em>在这个过程中会transfer之前传输成功的数据</em>)，并生成新的stamp和token，调用<code>createBlockOutputStream</code>与pipeline建立socket连接。使用stamp更新block标识，这样namenode可以删除以前发生错误的block。</p>
<p>下面主要看写<code>addDatanode2ExistingPipeline</code>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addDatanode2ExistingPipeline</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Is data transfer necessary?  We have the following cases.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * Case 1: Failure in Pipeline Setup</span></span><br><span class="line"><span class="comment">   * - Append</span></span><br><span class="line"><span class="comment">   *    + Transfer the stored replica, which may be a RBW or a finalized.</span></span><br><span class="line"><span class="comment">   * - Create</span></span><br><span class="line"><span class="comment">   *    + If no data, then no transfer is required.</span></span><br><span class="line"><span class="comment">   *    + If there are data written, transfer RBW. This case may happens </span></span><br><span class="line"><span class="comment">   *      when there are streaming failure earlier in this pipeline.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Case 2: Failure in Streaming</span></span><br><span class="line"><span class="comment">   * - Append/Create:</span></span><br><span class="line"><span class="comment">   *    + transfer RBW</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * Case 3: Failure in Close</span></span><br><span class="line"><span class="comment">   * - Append/Create:</span></span><br><span class="line"><span class="comment">   *    + no transfer, let NameNode replicates the block.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">//get a new datanode</span></span><br><span class="line">  <span class="keyword">final</span> DatanodeInfo[] original = nodes;</span><br><span class="line">  <span class="comment">// 从namenode得到一个新的dn</span></span><br><span class="line">  <span class="keyword">final</span> LocatedBlock lb = dfsClient.namenode.getAdditionalDatanode(</span><br><span class="line">      src, fileId, block, nodes, storageIDs,</span><br><span class="line">      failed.toArray(<span class="keyword">new</span> DatanodeInfo[failed.size()]),</span><br><span class="line">      <span class="number">1</span>, dfsClient.clientName);</span><br><span class="line">  <span class="comment">// 更新pipeline    </span></span><br><span class="line">  setPipeline(lb);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//find the new datanode</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> d = findNewDatanode(original);</span><br><span class="line">  <span class="comment">//transfer replica</span></span><br><span class="line">  <span class="keyword">final</span> DatanodeInfo src = d == <span class="number">0</span>? nodes[<span class="number">1</span>]: nodes[d - <span class="number">1</span>];</span><br><span class="line">  <span class="comment">// transfer的目标节点，也就是新添加的节点</span></span><br><span class="line">  <span class="keyword">final</span> DatanodeInfo[] targets = &#123;nodes[d]&#125;;</span><br><span class="line">  <span class="keyword">final</span> StorageType[] targetStorageTypes = &#123;storageTypes[d]&#125;;</span><br><span class="line">  <span class="comment">// tarnsfer</span></span><br><span class="line">  transfer(src, targets, targetStorageTypes, lb.getBlockToken());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>hdfs write的流程为：</p>
<ul>
<li>通过FileSystem.create创建一个FSDataOutputStream输出流，在此过程中client通过rpc向namenode添加一个文件记录，得到该文件的租约，启动一个DataStreamer线程(DataStreamer线程中维护dataQueue和ackQueue队列)，并持续更新租约</li>
<li>FSDataOutputStream输出流建好之后，就可以调用FSDataOutputStream.write方法进行数据的写入。在写入过程中先将数据写入client本地的buf中，此buf默认是9个chunk的大小，当本地buf写满之后(<em>如果要写入的数据长度大于本地buf的长度，则直接将buf长度的数据写入currentPacket中</em>)，计算这些数据的checksum，并写入currentPacket中，currentPacket写满之后放入dataQueue中排队并通知DataStreamer线程去dataQueue中消费数据。(<strong>数据先写入本地buf，然后写入packet，等packet满之后才向namenode申请blockId</strong>)</li>
<li>DataStreamer线程从dataQueue中取出packet，如果DataStreamer的stage为<em>PIPELINE_SETUP_CREATE</em>时，表示当前block的pipeline还没有建立，向namenode申请blockId和block的locations，将申请到的locations组成一个pipeline，与第一个dn建立socket连接，由Sender发送写请求。新启动ResponseProcessor线程接收dn返回的packet ack，并更新DataStreamer的stage，由<em>PIPELINE_SETUP_CREATE</em>变为<em>DATA_STREAMING</em></li>
<li>将要发送的packet从dataQueue中移到ackQueue中，然后向pipeline中发送packet</li>
</ul>
<p>以上的流程都发生在client端，下面的流程发生在dn端</p>
<ul>
<li>dn在client创建pipeline时，通过DataXceiverServer接收到client的socket请求，创建一个DataXceiver线程，由DataXceiver线程处理来自client的写请求。</li>
<li>DataXceiver线程会实例化一个BlockReceiver对象，并判断是否有downstream，如果有则创建一个downstream的socket，发送写请求。</li>
<li>与downstream建立连接之后，在blockReceiver.receiveBlock循环调用receivePacket接收packet，向downstream发送packet之前将packet放入ackQueue(当前ackQueue是PacketResponder线程维护的)中，然后将data和checksum写入磁盘</li>
<li>在blockReceiver.receiveBlock中还会启动一个PacketResponder线程，此线程负责接收downstream发送的packet ack，校验成功之后从ackQueue中移除，向upstream发送自己的ack和downstream的ack。</li>
<li>最终所有的ack都汇集到ResponseProcessor线程中，如果ack没有error则从ackQueue中移除；如果有error，先将ackQueue中的packet移到dataQueue中，然后将发生error的dn从pipeline中删除，从namenode中重新申请dn与原有的没有发生error的dn组成新的pipeline，在<code>addDatanode2ExistingPipeline</code>中判断是否要transfer已经发送的packet，<em>将已经发送成功的packet从之前正常的dn上transfer到新增加的dn上，并更新block是stamp</em>，这样发生故障的DataNode节点上的block数据会在节点恢复正常后被删除。</li>
</ul>
<h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p>在DataNode节点的流水复制过程中，如果一个DataNode节点发生错误，如接收到的packet出错了，那么该DataNode的BlockReceiver自动结束该线程，也不会向发送端发送确认帧，发送端就会迟迟收不到接收端的确认帧，这样的话，接受端就任务它以后的所有DataNode节点在接受该Block的packet是发生了错误，并把这个情况发送给发送端的发送端。</p>
<p>如果Pipeline中的多个节点在写数据是发生失败，那么只要写成功的block的数量达到dfs.replication.min(默认为1)，那么就任务是写成功的，然后NameNode后通过一步的方式将block复制到其他节点，最后事数据副本达到dfs.replication参数配置的个数。 </p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>您的肯定，是我装逼的最大的动力！</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/path/to/wechat-reward-image/wechatpay.png" alt="混绅士 WeChat Pay">
          <p>微信打赏</p>
        </div>
      
      
    </div>
  </div>


      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>本文作者：</strong>
      混绅士
    </li>
    
    <!--add wordcount and min2 read by szw-->
    <li class="post-copyright-author">
      <strong>本文字数：</strong>
      38,477
    </li>
    <li class="post-copyright-author">
      <strong>阅读时长：</strong>
      229
    </li>

    <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://bigdatadecode.club/HDFS write解析.html" title="HDFS write解析">http://bigdatadecode.club/HDFS write解析.html</a>
    </li>
    <li class="post-copyright-license">
      <strong>版权声明： </strong>
      本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          
            <a href="/tags/BigData/" rel="tag"># BigData</a>
          
            <a href="/tags/HDFS/" rel="tag"># HDFS</a>
          
            <a href="/tags/write/" rel="tag"># write</a>
          
        </div>
      

       
        <h3> 相关推荐：</h3><ul class="related-posts"><li><a href="/再议HDFS写流程之pipeline.html">再议HDFS写流程之pipeline</a></li><li><a href="/Hadoop-Ozone.html">Hadoop小文件利器Ozone调研</a></li><li><a href="/HDFS-little-file-action.html">HDFS小文件合并实战</a></li><li><a href="/HDFS中atime和mtime.html">HDFS中atime与mtime解析</a></li><li><a href="/HDFS权限.html">HDFS权限</a></li><li><a href="/Hadoop_get_NullPointerException.html">Hadoop get命令返回NullPointerException</a></li><li><a href="/Ozone感悟.html">Ozone感悟</a></li><li><a href="/[译]HDFS恢复过程2.html">HDFS恢复过程2</a></li><li><a href="/my-book.html">姗姗来迟的果实</a></li><li><a href="/常用Hadoop命令.html">常用Hadoop命令</a></li></ul> 
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/[译]Append Hflush Read设计文档.html" rel="next" title="Append/Hflush/Read设计文档">
                <i class="fa fa-chevron-left"></i> Append/Hflush/Read设计文档
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/再议HDFS写流程之pipeline.html" rel="prev" title="再议HDFS写流程之pipeline">
                再议HDFS写流程之pipeline <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        
  <div class="bdsharebuttonbox">
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>  
    <a href="#" class="bds_sqq" data-cmd="sqq" title="分享到QQ好友"></a>      
    <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
    <a href="#" class="bds_qzone" data-cmd="qzone" title="分享到QQ空间"></a>
    <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
    <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
    <a href="#" class="bds_more" data-cmd="more"></a>
    <a class="bds_count" data-cmd="count"></a>
  </div>
  <script>
    window._bd_share_config = {
      "common": {
        "bdText": "",
        "bdMini": "1",
        "bdMiniList": ["tsina", "weixin", "sqq", "douban", "qzone", "twi", "fbook"],
        "bdPic": ""
      },
      "image": {
        "viewList": ["tsina", "weixin", "sqq", "douban", "qzone", "twi", "fbook"],
        "viewText": "分享到：",
        "viewSize": "16"
      },
      "slide": {
        "bdImg": "5",
        "bdPos": "left",
        "bdTop": "100"
      }
    }
  </script>

<script>
  with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='//bdimg.share.baidu.com/static/api/js/share.js?cdnversion='+~(-new Date()/36e5)];
</script>

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>       
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/uploads/avatar.png" alt="混绅士">
          <p class="site-author-name" itemprop="name">混绅士</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
           
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">114</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">185</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <!-- <i class="fa  fa-fw fa-globe"></i> -->
              <!-- modify icon to fire by szw -->
              <i class="fa fa-fire fa-" aria-hidden="true"></i>
              热文推荐
            </div>
            <ul class="links-of-blogroll-list">
              
                <!-- delete li's class by szw -->
                <li>
                  <a href="http://bigdatadecode.club/Spark Streaming 消费kafka到HDFS.html" title="Spark Streaming 消费kafka到HDFS" target="_blank">Spark Streaming 消费kafka到HDFS</a>
                </li>
              
                <!-- delete li's class by szw -->
                <li>
                  <a href="http://bigdatadecode.club/HDFS write解析.html" title="HDFS write解析" target="_blank">HDFS write解析</a>
                </li>
              
                <!-- delete li's class by szw -->
                <li>
                  <a href="http://bigdatadecode.club/Spark编译与部署.html" title="Spark编译与部署" target="_blank">Spark编译与部署</a>
                </li>
              
                <!-- delete li's class by szw -->
                <li>
                  <a href="http://bigdatadecode.club/MapReduce源码解析--环形缓冲区.html" title="MapReduce源码解析--环形缓冲区" target="_blank">MapReduce源码解析--环形缓冲区</a>
                </li>
              
                <!-- delete li's class by szw -->
                <li>
                  <a href="http://bigdatadecode.club/Flume简介及初次使用.html" title="Flume简介及初次使用" target="_blank">Flume简介及初次使用</a>
                </li>
              
                <!-- delete li's class by szw -->
                <li>
                  <a href="http://bigdatadecode.club/实时抓取MySQL的更新数据到Hadoop.html" title="实时抓取MySQL的更新数据到Hadoop" target="_blank">实时抓取MySQL的更新数据到Hadoop</a>
                </li>
              
            </ul>
          </div>


        

        
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <!-- modify icon to fire by szw -->
                <i class="fa fa-history fa-" aria-hidden="true"></i>
                近期文章
              </div>
              <ul class="links-of-blogroll-list">
                
                
                  <li>
                    <a href="/Flink-standlone-Flinkx.html" title="Flink standlone模式下Flinkx测试" target="_blank">Flink standlone模式下Flinkx测试</a>
                  </li>
                
                  <li>
                    <a href="/openGauss-deploy.html" title="openGauss极简版安装使用" target="_blank">openGauss极简版安装使用</a>
                  </li>
                
                  <li>
                    <a href="/my-book.html" title="姗姗来迟的果实" target="_blank">姗姗来迟的果实</a>
                  </li>
                
                  <li>
                    <a href="/android-app-timeup.html" title="坑娃-防沉迷App" target="_blank">坑娃-防沉迷App</a>
                  </li>
                
                  <li>
                    <a href="/elasticsearch-op.html" title="elasticsearch运维踩坑" target="_blank">elasticsearch运维踩坑</a>
                  </li>
                
              </ul>
            </div>
          
 

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#创建一个输出流"><span class="nav-number">1.</span> <span class="nav-text">创建一个输出流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#DFSOutputStream实例"><span class="nav-number">1.1.</span> <span class="nav-text">DFSOutputStream实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#向输出流中写bytes数据流"><span class="nav-number">2.</span> <span class="nav-text">向输出流中写bytes数据流</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DFSOutputStream-DataStreamer发送packet"><span class="nav-number">3.</span> <span class="nav-text">DFSOutputStream.DataStreamer发送packet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DataXceiver线程写入DataNode"><span class="nav-number">4.</span> <span class="nav-text">DataXceiver线程写入DataNode</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#发送接收ACK"><span class="nav-number">5.</span> <span class="nav-text">发送接收ACK</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pipeline中写发送错误"><span class="nav-number">6.</span> <span class="nav-text">pipeline中写发送错误</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#总结"><span class="nav-number">7.</span> <span class="nav-text">总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#疑问"><span class="nav-number">8.</span> <span class="nav-text">疑问</span></a></li></ol></div>
            

          </div>

          <div class="post-toc-wrap sidebar-panel sidebar-panel-active" style="margin: 0 2px; text-align: left;">
            
              <div class="links-of-blogroll motion-element links-of-blogroll-inline">
                <div class="links-of-blogroll-title">
                  <!-- <i class="fa  fa-fw fa-globe"></i> -->
                  <!-- modify icon to fire by szw -->
                  <i class="fa fa-fire fa-" aria-hidden="true"></i>
                  热文推荐
                </div>
                <ul class="links-of-blogroll-list">
                  
                    <!-- delete li's class by szw -->
                    <li>
                      <a href="http://bigdatadecode.club/Spark Streaming 消费kafka到HDFS.html" title="Spark Streaming 消费kafka到HDFS" target="_blank">Spark Streaming 消费kafka到HDFS</a>
                    </li>
                  
                    <!-- delete li's class by szw -->
                    <li>
                      <a href="http://bigdatadecode.club/HDFS write解析.html" title="HDFS write解析" target="_blank">HDFS write解析</a>
                    </li>
                  
                    <!-- delete li's class by szw -->
                    <li>
                      <a href="http://bigdatadecode.club/Spark编译与部署.html" title="Spark编译与部署" target="_blank">Spark编译与部署</a>
                    </li>
                  
                    <!-- delete li's class by szw -->
                    <li>
                      <a href="http://bigdatadecode.club/MapReduce源码解析--环形缓冲区.html" title="MapReduce源码解析--环形缓冲区" target="_blank">MapReduce源码解析--环形缓冲区</a>
                    </li>
                  
                    <!-- delete li's class by szw -->
                    <li>
                      <a href="http://bigdatadecode.club/Flume简介及初次使用.html" title="Flume简介及初次使用" target="_blank">Flume简介及初次使用</a>
                    </li>
                  
                    <!-- delete li's class by szw -->
                    <li>
                      <a href="http://bigdatadecode.club/实时抓取MySQL的更新数据到Hadoop.html" title="实时抓取MySQL的更新数据到Hadoop" target="_blank">实时抓取MySQL的更新数据到Hadoop</a>
                    </li>
                  
                </ul>
              </div>
            
  
            
                <div class="links-of-blogroll motion-element links-of-blogroll-block">
                  <div class="links-of-blogroll-title">
                    <!-- modify icon to fire by szw -->
                    <i class="fa fa-history fa-" aria-hidden="true"></i>
                    近期文章
                  </div>
                  <ul class="links-of-blogroll-list">
                    
                    
                      <li>
                        <a href="/Flink-standlone-Flinkx.html" title="Flink standlone模式下Flinkx测试" target="_blank">Flink standlone模式下Flinkx测试</a>
                      </li>
                    
                      <li>
                        <a href="/openGauss-deploy.html" title="openGauss极简版安装使用" target="_blank">openGauss极简版安装使用</a>
                      </li>
                    
                      <li>
                        <a href="/my-book.html" title="姗姗来迟的果实" target="_blank">姗姗来迟的果实</a>
                      </li>
                    
                      <li>
                        <a href="/android-app-timeup.html" title="坑娃-防沉迷App" target="_blank">坑娃-防沉迷App</a>
                      </li>
                    
                      <li>
                        <a href="/elasticsearch-op.html" title="elasticsearch运维踩坑" target="_blank">elasticsearch运维踩坑</a>
                      </li>
                    
                  </ul>
                </div>
              
          </div>

        </section>
      <!--/noindex-->
      

      

    </div>

  </aside>



        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy;  2016 - 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">混绅士</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


<!--add total count by szw-->
<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">博客全站共689.9k字</span>
</div>
        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user">本站访客数</i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye">本站总访问量</i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  






  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("nP29Qpe35cHgQTQIFL94dGoW-gzGzoHsz", "eVPY9SfyVH11gSsbPBEcAQM0");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  

</body>
</html>
