<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>NameNode内存解析及大小评估 | big data decode club</title><meta name="keywords" content="Hadoop,BigData,HDFS,Memory,Size"><meta name="author" content="混绅士"><meta name="copyright" content="混绅士"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="HDFS由NameNode和DataNode组成，其中NameNode作为Master节点，负责维护整个集群的状态，为了提高响应速度其大部分数据都常驻内存，则NameNode内存的使用尤为重要，一旦NameNode出现故障，整个Hadoop集群就将处于不可服务的状态。 在解析NameNode内存之前先来回顾下HDFS整体架构。">
<meta property="og:type" content="article">
<meta property="og:title" content="NameNode内存解析及大小评估">
<meta property="og:url" content="http://bigdatadecode.club/NameNode%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%A4%A7%E5%B0%8F%E8%AF%84%E4%BC%B0.html">
<meta property="og:site_name" content="big data decode club">
<meta property="og:description" content="HDFS由NameNode和DataNode组成，其中NameNode作为Master节点，负责维护整个集群的状态，为了提高响应速度其大部分数据都常驻内存，则NameNode内存的使用尤为重要，一旦NameNode出现故障，整个Hadoop集群就将处于不可服务的状态。 在解析NameNode内存之前先来回顾下HDFS整体架构。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2016-11-10T15:07:00.000Z">
<meta property="article:modified_time" content="2016-11-10T15:07:00.000Z">
<meta property="article:author" content="混绅士">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="BigData">
<meta property="article:tag" content="HDFS">
<meta property="article:tag" content="Memory">
<meta property="article:tag" content="Size">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://bigdatadecode.club/NameNode%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%A4%A7%E5%B0%8F%E8%AF%84%E4%BC%B0"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="27E5EbutCm"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'NameNode内存解析及大小评估',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2016-11-10 23:07:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="big data decode club" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/uploads/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">117</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">191</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Timeline</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">big data decode club</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Timeline</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">NameNode内存解析及大小评估</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2016-11-10T15:07:00.000Z" title="发表于 2016-11-10 23:07:00">2016-11-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2016-11-10T15:07:00.000Z" title="更新于 2016-11-10 23:07:00">2016-11-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>13分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="NameNode内存解析及大小评估"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>HDFS由NameNode和DataNode组成，其中NameNode作为Master节点，负责维护整个集群的状态，为了提高响应速度其大部分数据都常驻内存，则NameNode内存的使用尤为重要，一旦NameNode出现故障，整个Hadoop集群就将处于不可服务的状态。</p>
<p>在解析NameNode内存之前先来回顾下HDFS整体架构。</p>
<span id="more"></span>

<h2 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h2><p><img src="/blogimgs/NameNode%E5%86%85%E5%AD%98%E8%AF%84%E4%BC%B0/HDFS-A.gif" alt="HDFS架构" title="HDFS架构"><br>从上图中可以看出HDFS可以分为两层，分别为NameSpace和Block Storage Service，其中Block Storage Service包含Block Management和Storage两部分。</p>
<p>NameSpace和Block Management在NameNode中，Storage在DataNode中。</p>
<p>NameSpace主要存储集群的目录结构和文件所对应的block映射(file-&gt;blocks的映射)，是HDFS文件系统实际执行的核心，提供各种增删改查文件操作接口。</p>
<p>Block Management</p>
<ul>
<li>通过注册和周期性的心跳提供dn集群成员</li>
<li>处理dn的block report，存储在BlocksMap中</li>
<li>提供block相关的操作，如create、delete、modif和get block location</li>
<li>管理replica的放置策略，不足副本因子的replica进行复制，超过副本因子的replica进行删除</li>
</ul>
<p>Storage<br>由DataNode提供，用于将replica存放在本地文件系统中并提供读写权限。</p>
<p>由上得知NameNode中主要由NameSpace和Block Management组成，其中NameSpace和BlocksMap是占内存的大户。</p>
<h2 id="NameNode内存概述"><a href="#NameNode内存概述" class="headerlink" title="NameNode内存概述"></a>NameNode内存概述</h2><p>NameNode的内存中除了上面提到的NameSpace和BlocksMap之外，还有维护整个集群拓扑结构的NetworkTopology、管理整个集群写租约的LeaseManager、管理集中式缓存的CacheManager和SnapshotManager。NameNode的内存结构如下图：<br><img src="/blogimgs/NameNode%E5%86%85%E5%AD%98%E8%AF%84%E4%BC%B0/namenodemem.png" alt="NameNode内存结构" title="NameNode内存结构"><br>Namespace：维护整个文件系统的目录树结构，及目录树上的状态变化；<br>BlocksManager：维护整个文件系统中与数据块相关的信息，及数据块的状态变化；<br>NetworkTopology：维护机架拓扑及DataNode信息，机架感知的基础；<br>LeaseManager：读写的互斥同步就是靠Lease实现，支持HDFS的Write-Once-Read-Many的核心数据结构；<br>CacheManager：<em>Hadoop 2.3.0引入的集中式缓存新特性</em>，支持集中式缓存的管理，实现memory-locality提升读性能；<br>SnapshotManager：<em>Hadoop 2.1.0引入的Snapshot新特性</em>，用于数据备份、回滚，以防止因用户误操作导致集群出现数据问题；<br>DelegationTokenSecretManager：管理HDFS的安全访问；<br>其他：临时数据信息、统计信息metrics等等。</p>
<p>NameNode常驻内存主要被Namespace和BlockManager使用，二者使用占比分别接近50%。其他部分内存开销较小且相对固定，与Namespace和BlockManager相比基本可以忽略。</p>
<h2 id="NameNode内存解析"><a href="#NameNode内存解析" class="headerlink" title="NameNode内存解析"></a>NameNode内存解析</h2><h3 id="NameSpace"><a href="#NameSpace" class="headerlink" title="NameSpace"></a>NameSpace</h3><p>与单机文件系统相似，HDFS对文件系统的目录结构也是按照树状结构维护，Namespace保存了目录树及每个目录/文件节点的属性。<em>除在内存常驻外，这部分数据会定期flush到持久化设备上，生成一个新的FsImage文件，方便NameNode发生重启时，从FsImage及时恢复整个Namespace</em>。</p>
<p>在整个Namespace目录树中存在两种不同类型的<em>INode</em>数据结构：INodeDirectory和INodeFile。其中<em>INodeDirectory标识的是目录树中的目录</em>，<em>INodeFile标识的是目录树中的文件</em>。由于二者均继承自INode，所以具备大部分相同的公共信息INodeWithAdditionalFields，除常用基础属性外，其中还提供了扩展属性features，如Quota，Snapshot等均通过Feature增加，如果以后出现新属性也可通过Feature方便扩展。不同的是，INodeFile特有的标识<em>副本数和数据块大小组合的header</em>（2.6.1之后又新增了标识存储策略ID的信息）及该文件包含的有序Blocks数组；INodeDirectory则特有子节点的列表children。这里需要特别说明children是默认大小为5的ArrayList，按照子节点name有序存储，虽然在插入时会损失一部分写性能，但是可以方便后续快速二分查找提高读性能，对一般存储系统，读操作比写操作占比要高。</p>
<h3 id="BlockManager"><a href="#BlockManager" class="headerlink" title="BlockManager"></a>BlockManager</h3><p>BlocksMap在NameNode的内存空间中占据很大的比例，由BlockManager统一管理。相比NameSpace，BlockManager管理的这部分数据要复杂的多。<em>Namespace与BlockManager之间通过前面提到的INodeFile有序Blocks数组关联到一起</em>。下图是BlockManager管理的内存结构。<br><img src="/blogimgs/NameNode%E5%86%85%E5%AD%98%E8%AF%84%E4%BC%B0/blockmanager.png" alt="BlockManager" title="BlockManager"></p>
<p>INodeFile是一个实体file在NameNode内存中的一个对象，包含一个存放block信息的BlockInfo数组，数组的大小为文件block的个数。如上图BlockInfo[A~K]所示。</p>
<p>BlockInfo继承自Block，维护的是Block的元数据，除基本信息外还包括一个*inode引用(<code>private BlockCollection bc</code>)<em>，表示该block所属的文件；以及一个记录replica到底存放在那些dn上的三元组数组<code>Object[] triplets</code>，大小为3</em>replicas，其中replicas是Block副本数量。triplets包含的信息：</p>
<p>triplets[3<em>i]：Block所在的DataNode A；(<em>DatanodeStorageInfo对象</em>)<br>triplets[3</em>i+1]：该DataNode A上前一个Block；(<em>指向前一个block的BlockInfo对象引用</em>)<br>triplets[3*i+2]：该DataNode A上后一个Block；(<em>指向后一个block的BlockInfo对象引用</em>)</p>
<p>其中i表示的是Block的第i个副本，i取值[0,replicas)。</p>
<p>从前面描述中通过BlockInfo可以得到以下几块重要信息：</p>
<ul>
<li>文件包含了哪些Block(由BlockInfo对该文件的引用可以得到该文件所有的block信息)</li>
<li>这些Block分别被实际存储在哪些DataNode上(通过BlockInfo的triplets数组可以得到该block的replica存储位置)</li>
<li>DataNode上所有Block前后链表关系(通过BlockInfo的triplets数组中pre)</li>
</ul>
<p>如果从信息完整度来看，以上数据足够支持所有关于HDFS文件系统的正常操作，但还存在一个使用场景较多的问题：<em>不能通过blockid快速定位Block</em>，所以引入了BlocksMap。</p>
<p>BlocksMap底层通过LightWeightGSet实现(关于LightWeightGSet的详细介绍可参考<a target="_blank" rel="noopener" href="http://bigdatadecode.top/HDFS%E4%B8%ADLightWeightGSet%E4%B8%8EHashMap%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90.html">这篇blog</a>)，本质是一个链式解决冲突的哈希表。为了避免rehash过程带来的性能开销，初始化时，索引空间直接给到了整个JVM可用内存的2%，并且不再变化。集群启动过程，<em>DataNode会进行BR(BlockReport)，根据BR的每一个Block计算其HashCode，之后将对应的BlockInfo插入到相应位置逐渐构建起来巨大的BlocksMap</em>。前面在INodeFile里也提到的BlockInfo集合，如果我们将BlocksMap里的BlockInfo与所有INodeFile里的BlockInfo分别收集起来，可以发现两个集合完全相同，事实上BlocksMap里所有的BlockInfo就是INodeFile中对应BlockInfo的引用；通过Block查找对应BlockInfo时，也是先对Block计算HashCode，根据结果快速定位到对应的BlockInfo信息。</p>
<p>前面提到部分都属于静态数据部分，NameNode内存中所有数据都要随读写情况发生变化，BlockManager当然也需要管理这部分动态数据。主要是当Block发生变化不符合预期时需要及时调整Blocks的分布。这里涉及几个核心的数据结构：</p>
<ul>
<li>excessReplicateMap：若某个Block实际存储的副本数多于预设副本数，这时候需要删除多余副本，这里多余副本会被置于excessReplicateMap中。<em>excessReplicateMap是从DataNode的StorageID到Block集合的映射集</em>。 </li>
<li>neededReplications：若某个Block实际存储的副本数少于预设副本数，这时候需要补充缺少副本，这里哪些Block缺少多少个副本都统一存在neededReplications里，<em>本质上neededReplications是一个优先级队列</em>，缺少副本数越多的Block之后越会被优先处理。</li>
<li>invalidateBlocks：若某个Block即将被删除，会被置于invalidateBlocks中。invalidateBlocks是从DataNode的StorageID到Block集合的映射集。如某个文件被客户端执行了删除操作，该文件所属的所有Block会先被置于invalidateBlocks中。 </li>
<li>corruptReplicas：有些场景Block由于时间戳/长度不匹配等等造成Block不可用，会被暂存在corruptReplicas中，之后再做处理。</li>
</ul>
<blockquote>
<p>关于这几个数据结构在维持副本平衡中的更多内容，可以移步到<a target="_blank" rel="noopener" href="http://bigdatadecode.top/HDFS%E7%BB%B4%E6%8C%81%E5%89%AF%E6%9C%AC%E5%B9%B3%E8%A1%A1%E7%9A%84%E6%B5%81%E7%A8%8B.html">这篇blog</a></p>
</blockquote>
<p>前面几个涉及到Block分布情况动态变化的核心数据结构，<em>这里的数据实际上是过渡性质的</em>，BlocksManager内部的ReplicationMonitor线程(关于ReplicationMonitor的内容可以查看[blog](<a target="_blank" rel="noopener" href="http://bigdatadecode.top/HDFS">http://bigdatadecode.top/HDFS</a> ReplicationMonitor副本监控线程解析.html)会持续从其中取出数据并通过逻辑处理后分发给具体的<em>DatanodeDescriptor对应数据结构</em>，当对应DataNode的心跳过来之后，NameNode会遍历DatanodeDescriptor里暂存的数据，将其转换成对应指令返回给DataNode，DataNode收到任务并执行完成后再反馈回NameNode，之后DatanodeDescriptor里对应信息被清除。如BlockB预设副本数为3，由于某种原因实际副本变成4(如之前下线的DataNode D重新上线，其中B正好有BlockB的一个副本数据)，BlockManager能及时发现副本变化，并将多余的DataNode D上BlockB副本放置到excessReplicateMap中，ReplicationMonitor线程定期检查时发现excessReplicateMap中数据后将其移到DataNode D对应DatanodeDescriptor中invalidateBlocks里，当DataNode D下次心跳过来后，随心跳返回删除Block B的指令，DataNode D收到指令实际删除其上的Block B数据并反馈回NameNode，此后BlockManager将DataNode D上的Block B从内存中清除，至此Block B的副本符合预期，整个流程如下所示。<br><img src="/blogimgs/NameNode%E5%86%85%E5%AD%98%E8%AF%84%E4%BC%B0/blockreplica.png" alt="删除多余副本流程图" title="删除多余副本流程图"></p>
<h3 id="NetworkTopology"><a href="#NetworkTopology" class="headerlink" title="NetworkTopology"></a>NetworkTopology</h3><p>前面多次提到Block与DataNode之间的关联关系，事实上NameNode确实还需要管理所有DataNode，不仅如此，由于数据写入前需要确定数据块写入位置，NameNode还维护着整个机架拓扑NetworkTopology。下图所示内存中机架拓扑图。<br><img src="/blogimgs/NameNode%E5%86%85%E5%AD%98%E8%AF%84%E4%BC%B0/networktopology.png" alt="NetworkTopology内存结构" title="NetworkTopology内存结构"></p>
<p>从图中可以看出这里包含两个部分：<em>机架拓扑结构NetworkTopology和DataNode节点信息</em>。其中树状的机架拓扑是根据机架感知(一般都是外部脚本计算得到)在集群启动完成后建立起来，整个机架的拓扑结构在NameNode的生命周期内一般不会发生变化；另一部分是比较关键的DataNode信息，BlockManager已经提到每一个DataNode上的Blocks集合都会形成一个双向链表，更准确的应该是DataNode的每一个存储单元DatanodeStorageInfo上的所有Blocks集合会形成一个双向链表，这个链表的入口就是机架拓扑结构叶子节点即DataNode管理的DatanodeStorageInfo。此外由于上层应用对数据的增删查随时发生变化，随之DatanodeStorageInfo上的Blocks也会动态变化，所以NetworkTopology上的DataNode对象还会管理这些动态变化的数据结构，如replicateBlocks/recoverBlocks/invalidateBlocks，这些数据结构正好和BlockManager管理的动态数据结构对应，实现了数据的动态变化由BlockManager传达到DataNode内存对象最后通过指令下达到物理DataNode实际执行的流动过程。</p>
<p>这里存在一个问题，为什么DatanodeStorageInfo下所有Block之间会以双向链表组织，而不是其他数据结构？如果结合实际场景就不难发现，对每一个DatanodeStorageInfo下Block的操作集中在快速增加/删除(Block动态增减变化)及顺序遍历(BlockReport期间)，所以双向链表是非常合适的数据结构。</p>
<h3 id="LeaseManager"><a href="#LeaseManager" class="headerlink" title="LeaseManager"></a>LeaseManager</h3><p>这里只简单介绍下Lease机制，更多内容请查看blog<a target="_blank" rel="noopener" href="http://bigdatadecode.top/HDFS%E7%A7%9F%E7%BA%A6%E8%A7%A3%E6%9E%90.html">HDFS租约解析</a></p>
<p>Lease机制是重要的分布式协议，广泛应用于各种实际的分布式系统中。HDFS支持Write-Once-Read-Many，对文件写操作的互斥同步靠Lease实现。Lease实际上是时间约束锁，其主要特点是排他性。客户端写文件时需要先申请一个Lease，一旦有客户端持有了某个文件的Lease，其他客户端就不可能再申请到该文件的Lease，这就保证了同一时刻对一个文件的写操作只能发生在一个客户端。NameNode的LeaseManager是Lease机制的核心，维护了文件与Lease、客户端与Lease的对应关系，这类信息会随写数据的变化实时发生对应改变。<br><img src="/blogimgs/NameNode%E5%86%85%E5%AD%98%E8%AF%84%E4%BC%B0/leasemanager.png" alt="LeaseManager内存结构" title="LeaseManager内存结构"></p>
<p>从上图中可以看出LeaseManager内存结构中主要包括以下三个核心数据结构：</p>
<ul>
<li>sortedLeases：Lease集合，按照时间先后进行排序，便于检查Lease是否超时(hardLimit)；</li>
<li>leases：客户端到Lease的映射关系；(一对一，一个clent对应一个lease)</li>
<li>sortedLeasesByPath：文件路径到Lease的映射关系；(多对一，多个path对应一个lease)</li>
</ul>
<p>其中每一个写数据的客户端会对应一个Lease，每个Lease里包含至少一个标识文件路径的Path。Lease本身已经维护了其持有者(客户端)及该Lease正在操作的文件路径集合，之所以增加了leases和sortedLeasesByPath为提高通过Lease持有者或文件路径快速索引到Lease的性能。</p>
<p>由于Lease本身的时间约束特性，当Lease发生超时后需要强制回收，内存中与该Lease相关的内容要被及时清除。超时检查及超时后的处理逻辑由LeaseManager.Monitor统一执行。LeaseManager中维护了两个与Lease相关的超时时间：软超时(softLimit)和硬超时(hardLimit)，使用场景稍有不同。</p>
<p>正常情况下，<em>客户端向集群写文件前需要向NameNode的LeaseManager申请Lease；写文件过程中定期更新Lease时间，以防Lease过期，周期与softLimit相关</em>；写完数据后申请释放Lease。整个过程可能发生两类问题：<br>1、写文件过程中客户端没有及时更新Lease时间；<br>2、写完文件后没有成功释放Lease。<br>两个问题分别对应为softLimit和hardLimit。两种场景都会触发LeaseManager对Lease超时强制回收。如果客户端写文件过程中没有及时更新Lease超过softLimit时间后，另一客户端尝试对同一文件进行写操作时触发Lease软超时强制回收；如果客户端写文件完成但是没有成功释放Lease，则会由LeaseManager的后台线程LeaseManager.Monitor检查是否硬超时后统一触发超时回收。不管是softLimit还是hardLimit超时触发的强制Lease回收，处理逻辑都一样：FSNamesystem.internalReleaseLease，逻辑本身比较复杂，这里不再展开(详细内容可以查看<a target="_blank" rel="noopener" href="http://bigdatadecode.top/HDFS%E7%A7%9F%E7%BA%A6%E8%A7%A3%E6%9E%90.html">blog</a>)，简单的说先对Lease过期前最后一次写入的Block进行检查和修复，之后释放超时持有的Lease，保证后面其他客户端的写入能够正常申请到该文件的Lease。</p>
<p>NameNode内存数据结构非常丰富，这里对几个重要的数据结构进行了简单的描述，除了前面罗列之外，其实还有如SnapShotManager/CacheManager等，由于其内存占用有限且有一些特性还尚未稳定，这里不再展开</p>
<h2 id="NameNode内存大小评估"><a href="#NameNode内存大小评估" class="headerlink" title="NameNode内存大小评估"></a>NameNode内存大小评估</h2><p>NameNode的内存主要由NameSpace和BlocksMap占用，其中NameSpace存储的主要是INodeFile和INodeDirectory对象，BlocksMap存储的主要是BlockInfo对象。则估算NameNode占用的内存大小也就是估算集群中INodeFile、INodeDirectory和BlockInfo这些对象占用的heap空间。</p>
<blockquote>
<p>Java中常见数据结构占用的内存大小<br>下面先列举下java中常见数据结构占用的内存大小(64bit的jvm)<br>int = 4 bytes<br>long = 8 bytes<br>Reference size(引用) = 8 bytes<br>Object header size(对象头) = 16 bytes<br>Array header size(数组头) = 24 bytes<br>ArrayList header size(list头) = 24(数组头) + 4(属性size的大小) = 28 bytes<br>TreeMap.Entry = 64 bytes. (Entry的属性中有5个引用)<br>HashMap.Entry = 48 bytes. (Entry的属性有3个引用)<br>String header = 64 bytes.</p>
</blockquote>
<p>则对INodeFile、INodeDirectory和BlockInfo对象进行大小评估还有一点疑惑，看了几篇资料还是有点不清晰，这里就不展开了，有兴趣的可以看文章末尾的资料，随后搞清楚了会进行更新。</p>
<p>但参考了很多资料如<em>Hadoop权威指南</em>、<em>HADOOP-1687</em>等，INodeFile、INodeDirectory和BlockInfo对象大小在150~200bytes之间，可以使用150bytes对其内存进行评估，</p>
<p>例子：<br>NameNode文件和block信息如下：<br>94115032 files and directories, 91722740 blocks = 185837772 total filesystem object(s).</p>
<p>memSum = 185837772 * 150 bytes = 27875665800bytes = 25.9612368g &lt; 26g</p>
<p>使用jmap命令查看此时NameNode的内存<br>命令<code>jmap -histo:live pid &gt; mem</code>，输出内存大小为24619484976(22.9286821g，大约23g)</p>
<blockquote>
<p>小插曲<br>使用命令<code>jmap -heap pid</code>查看nn所占的内存时，发现nn占的内存比估算的26g要大很多，随后使用<code>histo</code>命令之后才发现和估算的差不多，原因可能是使用<code>heap</code>查看的nn占用的内存，其中可能包括一些无用的对象(在等待gc)，而使用<code>histo</code>查看的是nn中存活的对象，能够更好的展示评估的结果。</p>
</blockquote>
<p><em>如果是2亿的FileSystem object则内存空间大约为30g(200M * 150 = 30000M，约等30G)</em></p>
<p>本篇文章大部分内容是从网上整理所得，只有少部分是原创，所涉及的资料在参考一节。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a target="_blank" rel="noopener" href="https://issues.apache.org/jira/browse/HADOOP-1687">https://issues.apache.org/jira/browse/HADOOP-1687</a><br><a target="_blank" rel="noopener" href="http://hexiaoqiao.github.io/blog/2016/07/06/namenode-memory-overview">http://hexiaoqiao.github.io/blog/2016/07/06/namenode-memory-overview</a><br><a target="_blank" rel="noopener" href="http://hexiaoqiao.github.io/blog/2016/07/21/namenode-memory-detail/">http://hexiaoqiao.github.io/blog/2016/07/21/namenode-memory-detail/</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">混绅士</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://bigdatadecode.club/NameNode%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%A4%A7%E5%B0%8F%E8%AF%84%E4%BC%B0.html">http://bigdatadecode.club/NameNode%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%A4%A7%E5%B0%8F%E8%AF%84%E4%BC%B0.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://bigdatadecode.club" target="_blank">big data decode club</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/BigData/">BigData</a><a class="post-meta__tags" href="/tags/HDFS/">HDFS</a><a class="post-meta__tags" href="/tags/Memory/">Memory</a><a class="post-meta__tags" href="/tags/Size/">Size</a></div><div class="post_share"></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/path/to/wechat-reward-image/wechatpay.png" target="_blank"><img class="post-qr-code-img" src="/path/to/wechat-reward-image/wechatpay.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/HDFS%20read%E8%A7%A3%E6%9E%902%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread.html"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">HDFS read解析2之从文件流中read</div></div></a></div><div class="next-post pull-right"><a href="/YARN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BFair%20Scheduler%20part2.html"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">YARN源码分析之Fair Scheduler part2</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/HDFS%20HA%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90.html" title="HDFS HA机制解析"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-07-14</div><div class="title">HDFS HA机制解析</div></div></a></div><div><a href="/HDFS%20HA%E7%9B%B8%E5%85%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%92%8C%E7%A4%BA%E4%BE%8B%E5%9C%BA%E6%99%AF.html" title="HDFS HA相关的几个问题和示例场景"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-11-19</div><div class="title">HDFS HA相关的几个问题和示例场景</div></div></a></div><div><a href="/HDFS%20ReplicationMonitor%E5%89%AF%E6%9C%AC%E7%9B%91%E6%8E%A7%E7%BA%BF%E7%A8%8B%E8%A7%A3%E6%9E%90.html" title="HDFS ReplicationMonitor副本监控线程解析"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-08-01</div><div class="title">HDFS ReplicationMonitor副本监控线程解析</div></div></a></div><div><a href="/HDFS%20read%E8%A7%A3%E6%9E%90.html" title="HDFS read解析(一)之Open文件流"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-11-21</div><div class="title">HDFS read解析(一)之Open文件流</div></div></a></div><div><a href="/HDFS%20read%E8%A7%A3%E6%9E%902%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread.html" title="HDFS read解析2之从文件流中read"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-11-15</div><div class="title">HDFS read解析2之从文件流中read</div></div></a></div><div><a href="/HDFS-little-file-action.html" title="HDFS小文件合并实战"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-01-30</div><div class="title">HDFS小文件合并实战</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/uploads/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">混绅士</div><div class="author-info__description">Any answers you can find in source code.</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">117</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">191</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS%E6%9E%B6%E6%9E%84"><span class="toc-number">1.</span> <span class="toc-text">HDFS架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NameNode%E5%86%85%E5%AD%98%E6%A6%82%E8%BF%B0"><span class="toc-number">2.</span> <span class="toc-text">NameNode内存概述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NameNode%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90"><span class="toc-number">3.</span> <span class="toc-text">NameNode内存解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#NameSpace"><span class="toc-number">3.1.</span> <span class="toc-text">NameSpace</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BlockManager"><span class="toc-number">3.2.</span> <span class="toc-text">BlockManager</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NetworkTopology"><span class="toc-number">3.3.</span> <span class="toc-text">NetworkTopology</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#LeaseManager"><span class="toc-number">3.4.</span> <span class="toc-text">LeaseManager</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#NameNode%E5%86%85%E5%AD%98%E5%A4%A7%E5%B0%8F%E8%AF%84%E4%BC%B0"><span class="toc-number">4.</span> <span class="toc-text">NameNode内存大小评估</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83"><span class="toc-number">5.</span> <span class="toc-text">参考</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/scratch-extensions-demo.html" title="scratch自定义扩展"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="scratch自定义扩展"/></a><div class="content"><a class="title" href="/scratch-extensions-demo.html" title="scratch自定义扩展">scratch自定义扩展</a><time datetime="2021-12-14T14:30:20.000Z" title="发表于 2021-12-14 22:30:20">2021-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/metabase-import-ide.html" title="metabase导入IDE调试"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="metabase导入IDE调试"/></a><div class="content"><a class="title" href="/metabase-import-ide.html" title="metabase导入IDE调试">metabase导入IDE调试</a><time datetime="2021-12-13T15:31:22.000Z" title="发表于 2021-12-13 23:31:22">2021-12-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/flink-connector-example.html" title="Flink Connector调研"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink Connector调研"/></a><div class="content"><a class="title" href="/flink-connector-example.html" title="Flink Connector调研">Flink Connector调研</a><time datetime="2021-11-10T14:30:20.000Z" title="发表于 2021-11-10 22:30:20">2021-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Flink-standlone-Flinkx.html" title="Flink standlone模式下Flinkx测试"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink standlone模式下Flinkx测试"/></a><div class="content"><a class="title" href="/Flink-standlone-Flinkx.html" title="Flink standlone模式下Flinkx测试">Flink standlone模式下Flinkx测试</a><time datetime="2021-11-06T15:05:20.000Z" title="发表于 2021-11-06 23:05:20">2021-11-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/openGauss-deploy.html" title="openGauss极简版安装使用"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="openGauss极简版安装使用"/></a><div class="content"><a class="title" href="/openGauss-deploy.html" title="openGauss极简版安装使用">openGauss极简版安装使用</a><time datetime="2021-05-13T14:35:20.000Z" title="发表于 2021-05-13 22:35:20">2021-05-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2022 By 混绅士</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>