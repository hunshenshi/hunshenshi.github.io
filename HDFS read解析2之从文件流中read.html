<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>HDFS read解析2之从文件流中read | big data decode club</title><meta name="keywords" content="Hadoop,BigData,HDFS,read"><meta name="author" content="混绅士"><meta name="copyright" content="混绅士"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="[上篇](http:&#x2F;&#x2F;bigdatadecode.top&#x2F;HDFS read解析.html)主要记录了HDFS read打开一个文件流的流程，该篇记录下从打开的文件流里read数据的流程。">
<meta property="og:type" content="article">
<meta property="og:title" content="HDFS read解析2之从文件流中read">
<meta property="og:url" content="http://bigdatadecode.club/HDFS%20read%E8%A7%A3%E6%9E%902%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread.html">
<meta property="og:site_name" content="big data decode club">
<meta property="og:description" content="[上篇](http:&#x2F;&#x2F;bigdatadecode.top&#x2F;HDFS read解析.html)主要记录了HDFS read打开一个文件流的流程，该篇记录下从打开的文件流里read数据的流程。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">
<meta property="article:published_time" content="2016-11-15T13:11:31.000Z">
<meta property="article:modified_time" content="2016-11-15T13:11:31.000Z">
<meta property="article:author" content="混绅士">
<meta property="article:tag" content="Hadoop">
<meta property="article:tag" content="BigData">
<meta property="article:tag" content="HDFS">
<meta property="article:tag" content="read">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://bigdatadecode.club/HDFS%20read%E8%A7%A3%E6%9E%902%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="baidu-site-verification" content="27E5EbutCm"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'HDFS read解析2之从文件流中read',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2016-11-15 21:11:31'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="big data decode club" type="application/atom+xml">
</head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/uploads/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">117</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">191</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Timeline</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">big data decode club</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Timeline</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">HDFS read解析2之从文件流中read</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2016-11-15T13:11:31.000Z" title="发表于 2016-11-15 21:11:31">2016-11-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2016-11-15T13:11:31.000Z" title="更新于 2016-11-15 21:11:31">2016-11-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.9k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>28分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="HDFS read解析2之从文件流中read"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>[上篇](<a target="_blank" rel="noopener" href="http://bigdatadecode.top/HDFS">http://bigdatadecode.top/HDFS</a> read解析.html)主要记录了HDFS read打开一个文件流的流程，该篇记录下从打开的文件流里read数据的流程。</p>
<span id="more"></span>

<h2 id="HDFS-Read之从文件流中read"><a href="#HDFS-Read之从文件流中read" class="headerlink" title="HDFS Read之从文件流中read"></a>HDFS Read之从文件流中read</h2><p>读取文件流中的数据通过文件流FSDataInputStream对象的read方法进行读取，最终调用了DFSInputStream的read方法(可以写个hdfs read file demo 进行debug下就会发现)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">final</span> <span class="keyword">byte</span> buf[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// ReaderStrategy 将不同的BlockReader进行了封装</span></span><br><span class="line">  <span class="comment">// 真正读数据的是BlockReader对象</span></span><br><span class="line">  ReaderStrategy byteArrayReader = <span class="keyword">new</span> ByteArrayStrategy(buf);</span><br><span class="line">  <span class="keyword">return</span> readWithStrategy(byteArrayReader, off, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">readWithStrategy</span><span class="params">(ReaderStrategy strategy, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  Map&lt;ExtendedBlock,Set&lt;DatanodeInfo&gt;&gt; corruptedBlockMap </span><br><span class="line">    = <span class="keyword">new</span> HashMap&lt;ExtendedBlock, Set&lt;DatanodeInfo&gt;&gt;();</span><br><span class="line">  failures = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (pos &lt; getFileLength()) &#123;</span><br><span class="line">    <span class="keyword">int</span> retries = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span> (retries &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// currentNode can be left as null if previous read had a checksum</span></span><br><span class="line">        <span class="comment">// error on the same block. See HDFS-3067</span></span><br><span class="line">        <span class="comment">// pos 和 blockEnd 会在blockSeekTo -&gt; getBlockAt 中赋值</span></span><br><span class="line">        <span class="keyword">if</span> (pos &gt; blockEnd || currentNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// 当前position所在的block</span></span><br><span class="line">          currentNode = blockSeekTo(pos);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> realLen = (<span class="keyword">int</span>) Math.min(len, (blockEnd - pos + <span class="number">1L</span>));</span><br><span class="line">        <span class="keyword">if</span> (locatedBlocks.isLastBlockComplete()) &#123;</span><br><span class="line">          realLen = (<span class="keyword">int</span>) Math.min(realLen, locatedBlocks.getFileLength());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 读取buffer</span></span><br><span class="line">        <span class="keyword">int</span> result = readBuffer(strategy, off, realLen, corruptedBlockMap);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (result &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">          pos += result;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// got a EOS from reader though we expect more data on it.</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;Unexpected EOS from the reader&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (dfsClient.stats != <span class="keyword">null</span>) &#123;</span><br><span class="line">          dfsClient.stats.incrementBytesRead(result);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">        <span class="comment">// 如果检测到ChecksumException 则只抛出异常，再次进行循环</span></span><br><span class="line">      &#125; <span class="keyword">catch</span> (ChecksumException ce) &#123;</span><br><span class="line">        <span class="keyword">throw</span> ce;    </span><br><span class="line">        <span class="comment">// 如果捕获到IO异常，则retries次数减1，进入下一次循环        </span></span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (retries == <span class="number">1</span>) &#123;</span><br><span class="line">          DFSClient.LOG.warn(<span class="string">&quot;DFS Read&quot;</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        blockEnd = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (currentNode != <span class="keyword">null</span>) &#123; addToDeadNodes(currentNode); &#125;</span><br><span class="line">        <span class="keyword">if</span> (--retries == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">throw</span> e;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// Check if need to report block replicas corruption either read</span></span><br><span class="line">        <span class="comment">// was successful or ChecksumException occured.</span></span><br><span class="line">        reportCheckSumFailure(corruptedBlockMap, </span><br><span class="line">            currentLocatedBlock.getLocations().length);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>readWithStrategy会重试2次进行读取，_如果捕获到<code>ChecksumException</code>则直接进行重试(本次尝试不计数)_，当捕获到<code>IOException</code>异常时会进行重试(尝试次数减1)，重新选择dn进行读取，并把有io异常的dn放入deadNodes map中。<strong>一个block一个deadNodes？？？</strong></p>
<p><strong>deadNodes是DFSInputStream的属性，则应该是一个DFSInputStream一个deadNodes，但是在读取一个block结束之后，deadNodes会不会被clear掉？？读取失败之后会clear deadNodes</strong></p>
<p>readWithStrategy中主要有两个方法，分别是<code>blockSeekTo</code>和<code>readBuffer</code>，blockSeekTo是找到当前pos的block，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> DatanodeInfo <span class="title">blockSeekTo</span><span class="params">(<span class="keyword">long</span> target)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Connect to best DataNode for desired Block, with potential offset</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  DatanodeInfo chosenNode = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">int</span> refetchToken = <span class="number">1</span>; <span class="comment">// only need to get a new access token once</span></span><br><span class="line">  <span class="keyword">int</span> refetchEncryptionKey = <span class="number">1</span>; <span class="comment">// only need to get a new encryption key once</span></span><br><span class="line">  <span class="keyword">boolean</span> connectFailedOnce = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Compute desired block</span></span><br><span class="line">    <span class="comment">//得到target所在的dn locations信息</span></span><br><span class="line">    LocatedBlock targetBlock = getBlockAt(target, <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">assert</span> (target==pos) : <span class="string">&quot;Wrong postion &quot;</span> + pos + <span class="string">&quot; expect &quot;</span> + target;</span><br><span class="line">    <span class="keyword">long</span> offsetIntoBlock = target - targetBlock.getStartOffset();</span><br><span class="line">    <span class="comment">// 从dn set中选出一个dn</span></span><br><span class="line">    DNAddrPair retval = chooseDataNode(targetBlock, <span class="keyword">null</span>);</span><br><span class="line">    chosenNode = retval.info;</span><br><span class="line">    InetSocketAddress targetAddr = retval.addr;</span><br><span class="line">    StorageType storageType = retval.storageType;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      ExtendedBlock blk = targetBlock.getBlock();</span><br><span class="line">      Token&lt;BlockTokenIdentifier&gt; accessToken = targetBlock.getBlockToken();</span><br><span class="line">      <span class="comment">// 使用 Builder模式 创建一个 blockReader</span></span><br><span class="line">      blockReader = <span class="keyword">new</span> BlockReaderFactory(dfsClient.getConf()).</span><br><span class="line">          setInetSocketAddress(targetAddr).</span><br><span class="line">          setRemotePeerFactory(dfsClient).</span><br><span class="line">          setDatanodeInfo(chosenNode).</span><br><span class="line">          setStorageType(storageType).</span><br><span class="line">          setFileName(src).</span><br><span class="line">          setBlock(blk).</span><br><span class="line">          setBlockToken(accessToken).</span><br><span class="line">          setStartOffset(offsetIntoBlock).</span><br><span class="line">          setVerifyChecksum(verifyChecksum).</span><br><span class="line">          setClientName(dfsClient.clientName).</span><br><span class="line">          setLength(blk.getNumBytes() - offsetIntoBlock).</span><br><span class="line">          setCachingStrategy(cachingStrategy).</span><br><span class="line">          setAllowShortCircuitLocalReads(!shortCircuitForbidden()).</span><br><span class="line">          setClientCacheContext(dfsClient.getClientContext()).</span><br><span class="line">          setUserGroupInformation(dfsClient.ugi).</span><br><span class="line">          setConfiguration(dfsClient.getConfiguration()).</span><br><span class="line">          build();</span><br><span class="line">      <span class="keyword">if</span>(connectFailedOnce) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">&quot;Successfully connected to &quot;</span> + targetAddr +</span><br><span class="line">                           <span class="string">&quot; for &quot;</span> + blk);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> chosenNode;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ex) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ex <span class="keyword">instanceof</span> InvalidEncryptionKeyException &amp;&amp; refetchEncryptionKey &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">&quot;Will fetch a new encryption key and retry, &quot;</span> </span><br><span class="line">            + <span class="string">&quot;encryption key was invalid when connecting to &quot;</span> + targetAddr</span><br><span class="line">            + <span class="string">&quot; : &quot;</span> + ex);</span><br><span class="line">        <span class="comment">// The encryption key used is invalid.</span></span><br><span class="line">        refetchEncryptionKey--;</span><br><span class="line">        dfsClient.clearDataEncryptionKey();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (refetchToken &gt; <span class="number">0</span> &amp;&amp; tokenRefetchNeeded(ex, targetAddr)) &#123;</span><br><span class="line">        refetchToken--;</span><br><span class="line">        <span class="comment">// Fetch a block from namenode and cache it ????</span></span><br><span class="line">        fetchBlockAt(target);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        connectFailedOnce = <span class="keyword">true</span>;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">&quot;Failed to connect to &quot;</span> + targetAddr + <span class="string">&quot; for block&quot;</span></span><br><span class="line">          + <span class="string">&quot;, add to deadNodes and continue. &quot;</span> + ex, ex);</span><br><span class="line">        <span class="comment">// Put chosen node into dead list, continue</span></span><br><span class="line">        addToDeadNodes(chosenNode);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>blockSeekTo主要包含两个方法和一个BlockReader的实例化对象，一个方法是<code>getBlockAt</code>，其作用是得到当前offset所在的block的dn locations信息，另一个方法是<code>chooseDataNode</code>，其作用是从<code>getBlockAt</code>得到的dn locations list中得到一个dn。getBlockAt的实现逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> LocatedBlock <span class="title">getBlockAt</span><span class="params">(<span class="keyword">long</span> offset,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">boolean</span> updatePosition)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> (locatedBlocks != <span class="keyword">null</span>) : <span class="string">&quot;locatedBlocks is null&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> LocatedBlock blk;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//check offset</span></span><br><span class="line">  <span class="keyword">if</span> (offset &lt; <span class="number">0</span> || offset &gt;= getFileLength()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;offset &lt; 0 || offset &gt;= getFileLength(), offset=&quot;</span></span><br><span class="line">        + offset</span><br><span class="line">        + <span class="string">&quot;, updatePosition=&quot;</span> + updatePosition</span><br><span class="line">        + <span class="string">&quot;, locatedBlocks=&quot;</span> + locatedBlocks);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (offset &gt;= locatedBlocks.getFileLength()) &#123;</span><br><span class="line">    <span class="comment">// offset to the portion of the last block,</span></span><br><span class="line">    <span class="comment">// which is not known to the name-node yet;</span></span><br><span class="line">    <span class="comment">// getting the last block </span></span><br><span class="line">    blk = locatedBlocks.getLastLocatedBlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// search cached blocks first</span></span><br><span class="line">    <span class="comment">// 使用二分查找从缓存的block中查找当前offset所在的block</span></span><br><span class="line">    <span class="keyword">int</span> targetBlockIdx = locatedBlocks.findBlock(offset);</span><br><span class="line">    <span class="comment">// 在缓存中没有找到</span></span><br><span class="line">    <span class="keyword">if</span> (targetBlockIdx &lt; <span class="number">0</span>) &#123; <span class="comment">// block is not cached</span></span><br><span class="line">      targetBlockIdx = LocatedBlocks.getInsertIndex(targetBlockIdx);</span><br><span class="line">      <span class="comment">// fetch more blocks</span></span><br><span class="line">      <span class="comment">// 再次抓取blocks，从当前offset处开始抓取</span></span><br><span class="line">      <span class="keyword">final</span> LocatedBlocks newBlocks = dfsClient.getLocatedBlocks(src, offset);</span><br><span class="line">      <span class="keyword">assert</span> (newBlocks != <span class="keyword">null</span>) : <span class="string">&quot;Could not find target position &quot;</span> + offset;</span><br><span class="line">      <span class="comment">// 将new block插入到缓存的targetBlockIdx位置中</span></span><br><span class="line">      locatedBlocks.insertRange(targetBlockIdx, newBlocks.getLocatedBlocks());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 得到offset所在的block  targetBlockIdx是block在缓存中的索引</span></span><br><span class="line">    blk = locatedBlocks.get(targetBlockIdx);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// update current position</span></span><br><span class="line">  <span class="comment">// 更新read的起始地址pos和结束地址blockEnd</span></span><br><span class="line">  <span class="keyword">if</span> (updatePosition) &#123;</span><br><span class="line">    pos = offset;</span><br><span class="line">    blockEnd = blk.getStartOffset() + blk.getBlockSize() - <span class="number">1</span>;</span><br><span class="line">    currentLocatedBlock = blk;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> blk;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getBlockAt主要是得到offset所在的block，其检索方法是先在缓存(这个缓存大小是由_dfs.client.read.prefetch.size_决定的)中进行二分查找，找到就返回其索引，如果没有找到则再次调用rpc进行重新抓取block，__此次抓取的block的是从offset所在block开始抓取的__。下面看下<code>findBlock</code>的代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public int findBlock(long offset) &#123;</span><br><span class="line">  <span class="comment">// create fake block of size 0 as a key</span></span><br><span class="line">  <span class="comment">// 创建一个LocatedBlock对象，便于和LocatedBlocks中的block进行比较</span></span><br><span class="line">  <span class="type">LocatedBlock</span> key = <span class="keyword">new</span> <span class="type">LocatedBlock</span>(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ExtendedBlock</span>(), <span class="keyword">new</span> <span class="type">DatanodeInfo</span>[<span class="number">0</span>], <span class="number">0</span>L, <span class="literal">false</span>);</span><br><span class="line">  key.setStartOffset(offset);</span><br><span class="line">  key.getBlock().setNumBytes(<span class="number">1</span>);</span><br><span class="line">  <span class="comment">// 重写comparator</span></span><br><span class="line">  <span class="type">Comparator</span>&lt;<span class="type">LocatedBlock</span>&gt; comp = </span><br><span class="line">    <span class="keyword">new</span> <span class="type">Comparator</span>&lt;<span class="type">LocatedBlock</span>&gt;() &#123;</span><br><span class="line">      <span class="comment">// Returns 0 iff a is inside b or b is inside a</span></span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      public int compare(<span class="type">LocatedBlock</span> a, <span class="type">LocatedBlock</span> b) &#123;</span><br><span class="line">        long aBeg = a.getStartOffset();</span><br><span class="line">        long bBeg = b.getStartOffset();</span><br><span class="line">        long aEnd = aBeg + a.getBlockSize();</span><br><span class="line">        long bEnd = bBeg + b.getBlockSize();</span><br><span class="line">        <span class="keyword">if</span>(aBeg &lt;= bBeg &amp;&amp; bEnd &lt;= aEnd </span><br><span class="line">            || bBeg &lt;= aBeg &amp;&amp; aEnd &lt;= bEnd)</span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>; <span class="comment">// one of the blocks is inside the other</span></span><br><span class="line">        <span class="keyword">if</span>(aBeg &lt; bBeg)</span><br><span class="line">          <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// a&#x27;s left bound is to the left of the b&#x27;s</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// 调用Collections的二分查找</span></span><br><span class="line">  <span class="keyword">return</span> <span class="type">Collections</span>.binarySearch(blocks, key, comp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>findBlock主要是利用Collections的二分查找进行查找offset所在的block，进行比较时先创建一个LocatedBlock对象，然后重写Comparator进行对象的比较。如果没有找到则调用<code>dfsClient.getLocatedBlocks</code>，从当前offset所在的block为起点进行再次抓取固定长度的block，并将newBlocks插入缓存中的blocks中。</p>
<p>抓取block是通过rpc调用dfsClient.getLocatedBlocks从FSNamesystem中获得blocks列表，然后通过<code>locatedBlocks.insertRange</code>插入到缓存中，locatedBlocks.insertRange代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insertRange</span><span class="params">(<span class="keyword">int</span> blockIdx, List&lt;LocatedBlock&gt; newBlocks)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 返回在缓存中查找失败返回的low处的索引</span></span><br><span class="line">  <span class="keyword">int</span> oldIdx = blockIdx;</span><br><span class="line">  <span class="keyword">int</span> insStart = <span class="number">0</span>, insEnd = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 如果缓存blocks的最后一个元素依然小于目标block的offset时(也就是low=len+1)</span></span><br><span class="line">  <span class="comment">// 则不进入for循环</span></span><br><span class="line">  <span class="comment">// 找到目标block在newBlocks中的索引</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> newIdx = <span class="number">0</span>; newIdx &lt; newBlocks.size() &amp;&amp; oldIdx &lt; blocks.size(); </span><br><span class="line">                                                      newIdx++) &#123;</span><br><span class="line">    <span class="keyword">long</span> newOff = newBlocks.get(newIdx).getStartOffset();</span><br><span class="line">    <span class="keyword">long</span> oldOff = blocks.get(oldIdx).getStartOffset();</span><br><span class="line">    <span class="comment">// 当newBlocks</span></span><br><span class="line">    <span class="keyword">if</span>(newOff &lt; oldOff) &#123;</span><br><span class="line">      insEnd++;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span>(newOff == oldOff) &#123;</span><br><span class="line">      <span class="comment">// replace old cached block by the new one</span></span><br><span class="line">      blocks.set(oldIdx, newBlocks.get(newIdx));</span><br><span class="line">      <span class="keyword">if</span>(insStart &lt; insEnd) &#123; <span class="comment">// insert new blocks</span></span><br><span class="line">        blocks.addAll(oldIdx, newBlocks.subList(insStart, insEnd));</span><br><span class="line">        oldIdx += insEnd - insStart;</span><br><span class="line">      &#125;</span><br><span class="line">      insStart = insEnd = newIdx+<span class="number">1</span>;</span><br><span class="line">      oldIdx++;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  <span class="comment">// newOff &gt; oldOff</span></span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">false</span> : <span class="string">&quot;List of LocatedBlock must be sorted by startOffset&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  insEnd = newBlocks.size();</span><br><span class="line">  <span class="comment">// 将大于目标block的blocks插入缓存中</span></span><br><span class="line">  <span class="keyword">if</span>(insStart &lt; insEnd) &#123; <span class="comment">// insert new blocks</span></span><br><span class="line">    blocks.addAll(oldIdx, newBlocks.subList(insStart, insEnd));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>insertRange将<em>newBlocks</em>中的block根据其在<em>blocks</em>中的顺序<em>分区间插入blocks中</em>。区间由insStart和insEnd控制，for循环中调整insEnd和insStart的值，分批次插入到blocks中。</p>
<p>此时就可以得到目标block的locations信息，通过<code>chooseDataNode</code>选择一个dn，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> DNAddrPair <span class="title">chooseDataNode</span><span class="params">(LocatedBlock block,</span></span></span><br><span class="line"><span class="params"><span class="function">    Collection&lt;DatanodeInfo&gt; ignoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> getBestNodeDNAddrPair(block, ignoredNodes);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">      <span class="comment">// 捕获到getBestNodeDNAddrPair中chosenNode为null的异常之后</span></span><br><span class="line">      <span class="comment">// 清空deadNodes，重新获取该block的信息</span></span><br><span class="line">      <span class="comment">// 尝试3次，抛出异常</span></span><br><span class="line">      String errMsg = getBestNodeDNAddrPairErrorString(block.getLocations(),</span><br><span class="line">        deadNodes, ignoredNodes);</span><br><span class="line">      String blockInfo = block.getBlock() + <span class="string">&quot; file=&quot;</span> + src;</span><br><span class="line">      <span class="comment">// dfs.client.max.block.acquire.failures 默认是3</span></span><br><span class="line">      <span class="comment">// 获取该block信息3次，注意与获取3次dn的区别</span></span><br><span class="line">      <span class="keyword">if</span> (failures &gt;= dfsClient.getMaxBlockAcquireFailures()) &#123;</span><br><span class="line">        String description = <span class="string">&quot;Could not obtain block: &quot;</span> + blockInfo;</span><br><span class="line">        DFSClient.LOG.warn(description + errMsg</span><br><span class="line">            + <span class="string">&quot;. Throwing a BlockMissingException&quot;</span>);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BlockMissingException(src, description,</span><br><span class="line">            block.getStartOffset());</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      DatanodeInfo[] nodes = block.getLocations();</span><br><span class="line">      <span class="keyword">if</span> (nodes == <span class="keyword">null</span> || nodes.length == <span class="number">0</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">&quot;No node available for &quot;</span> + blockInfo);</span><br><span class="line">      &#125;</span><br><span class="line">      DFSClient.LOG.info(<span class="string">&quot;Could not obtain &quot;</span> + block.getBlock()</span><br><span class="line">          + <span class="string">&quot; from any node: &quot;</span> + ie + errMsg</span><br><span class="line">          + <span class="string">&quot;. Will get new block locations from namenode and retry...&quot;</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Introducing a random factor to the wait time before another retry.</span></span><br><span class="line">        <span class="comment">// The wait time is dependent on # of failures and a random factor.</span></span><br><span class="line">        <span class="comment">// At the first time of getting a BlockMissingException, the wait time</span></span><br><span class="line">        <span class="comment">// is a random number between 0..3000 ms. If the first retry</span></span><br><span class="line">        <span class="comment">// still fails, we will wait 3000 ms grace period before the 2nd retry.</span></span><br><span class="line">        <span class="comment">// Also at the second retry, the waiting window is expanded to 6000 ms</span></span><br><span class="line">        <span class="comment">// alleviating the request rate from the server. Similarly the 3rd retry</span></span><br><span class="line">        <span class="comment">// will wait 6000ms grace period before retry and the waiting window is</span></span><br><span class="line">        <span class="comment">// expanded to 9000ms. </span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> timeWindow = dfsClient.getConf().timeWindow;</span><br><span class="line">        <span class="keyword">double</span> waitTime = timeWindow * failures +       <span class="comment">// grace period for the last round of attempt</span></span><br><span class="line">          timeWindow * (failures + <span class="number">1</span>) * DFSUtil.getRandom().nextDouble(); <span class="comment">// expanding time window for each failure</span></span><br><span class="line">        DFSClient.LOG.warn(<span class="string">&quot;DFS chooseDataNode: got # &quot;</span> + (failures + <span class="number">1</span>) + <span class="string">&quot; IOException, will wait for &quot;</span> + waitTime + <span class="string">&quot; msec.&quot;</span>);</span><br><span class="line">        Thread.sleep((<span class="keyword">long</span>)waitTime);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException iex) &#123;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 从block的所有dn中没有找到合适的dn，则将deadNodes清空，重新获取该block的信息</span></span><br><span class="line">      <span class="comment">// 一个block一个deadNodes</span></span><br><span class="line">      deadNodes.clear(); <span class="comment">//2nd option is to remove only nodes[blockId]</span></span><br><span class="line">      openInfo();</span><br><span class="line">      block = getBlockAt(block.getStartOffset(), <span class="keyword">false</span>);</span><br><span class="line">      failures++;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> DNAddrPair <span class="title">getBestNodeDNAddrPair</span><span class="params">(LocatedBlock block,</span></span></span><br><span class="line"><span class="params"><span class="function">    Collection&lt;DatanodeInfo&gt; ignoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  DatanodeInfo[] nodes = block.getLocations();</span><br><span class="line">  StorageType[] storageTypes = block.getStorageTypes();</span><br><span class="line">  DatanodeInfo chosenNode = <span class="keyword">null</span>;</span><br><span class="line">  StorageType storageType = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (nodes != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 遍历选出非deadNode节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nodes.length; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!deadNodes.containsKey(nodes[i])</span><br><span class="line">          &amp;&amp; (ignoredNodes == <span class="keyword">null</span> || !ignoredNodes.contains(nodes[i]))) &#123;</span><br><span class="line">        chosenNode = nodes[i];</span><br><span class="line">        <span class="comment">// Storage types are ordered to correspond with nodes, so use the same</span></span><br><span class="line">        <span class="comment">// index to get storage type.</span></span><br><span class="line">        <span class="keyword">if</span> (storageTypes != <span class="keyword">null</span> &amp;&amp; i &lt; storageTypes.length) &#123;</span><br><span class="line">          storageType = storageTypes[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 循环了一圈依然没有找到合适的dn</span></span><br><span class="line">  <span class="keyword">if</span> (chosenNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;No live nodes contain block &quot;</span> + block.getBlock() +</span><br><span class="line">        <span class="string">&quot; after checking nodes = &quot;</span> + Arrays.toString(nodes) +</span><br><span class="line">        <span class="string">&quot;, ignoredNodes = &quot;</span> + ignoredNodes);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">final</span> String dnAddr =</span><br><span class="line">      chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);</span><br><span class="line">  <span class="keyword">if</span> (DFSClient.LOG.isDebugEnabled()) &#123;</span><br><span class="line">    DFSClient.LOG.debug(<span class="string">&quot;Connecting to datanode &quot;</span> + dnAddr);</span><br><span class="line">  &#125;</span><br><span class="line">  InetSocketAddress targetAddr = NetUtils.createSocketAddr(dnAddr);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> DNAddrPair(chosenNode, targetAddr, storageType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>chooseDataNode调用<code>getBestNodeDNAddrPair</code>在<em>block的locations中选择一个dn</em>，如果没有找到则抛出一个<em>IOException异常</em>，在chooseDataNode中捕获，在catch中校验重试次数是否超过<code>dfs.client.max.block.acquire.failures</code>，没有则清空deadNodes再次去获取该block的locations。依然失败则抛出异常。</p>
<p>chooseDataNode结束返回到blockSeekTo中，由BlockReaderFactory创建BlockReader对象，这里创建的BlockReader对象会根据<em>short circuit local read</em>还是<em>远程读</em>创建不同的BlockReader。BlockReaderFactory使用了Builder设计模式，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> BlockReader <span class="title">build</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  BlockReader reader = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  Preconditions.checkNotNull(configuration);</span><br><span class="line">  <span class="comment">// 检查是否开启了short circuit local read</span></span><br><span class="line">  <span class="comment">// short circuit local read 使用的就是 Unix Domain Socket技术，</span></span><br><span class="line">  <span class="comment">// 那为什么还要将conf.domainSocketDataTraffic作为一个备选方案</span></span><br><span class="line">  <span class="keyword">if</span> (conf.shortCircuitLocalReads &amp;&amp; allowShortCircuitLocalReads) &#123;</span><br><span class="line">    <span class="keyword">if</span> (clientContext.getUseLegacyBlockReaderLocal()) &#123;</span><br><span class="line">      reader = getLegacyBlockReaderLocal();</span><br><span class="line">      <span class="keyword">if</span> (reader != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">          LOG.trace(<span class="keyword">this</span> + <span class="string">&quot;: returning new legacy block reader local.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> reader;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      reader = getBlockReaderLocal();</span><br><span class="line">      <span class="keyword">if</span> (reader != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">          LOG.trace(<span class="keyword">this</span> + <span class="string">&quot;: returning new block reader local.&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> reader;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 通过UNIX domain socket 得到一个remote block reader</span></span><br><span class="line">  <span class="comment">// 与short circuit local read 的区别？？？？</span></span><br><span class="line">  <span class="keyword">if</span> (conf.domainSocketDataTraffic) &#123;</span><br><span class="line">    reader = getRemoteBlockReaderFromDomain();</span><br><span class="line">    <span class="keyword">if</span> (reader != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">        LOG.trace(<span class="keyword">this</span> + <span class="string">&quot;: returning new remote block reader using &quot;</span> +</span><br><span class="line">            <span class="string">&quot;UNIX domain socket on &quot;</span> + pathInfo.getPath());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> reader;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  Preconditions.checkState(!DFSInputStream.tcpReadsDisabledForTesting,</span><br><span class="line">      <span class="string">&quot;TCP reads were disabled for testing, but we failed to &quot;</span> +</span><br><span class="line">      <span class="string">&quot;do a non-TCP read.&quot;</span>);</span><br><span class="line">  <span class="comment">// 返回远程BlockReader</span></span><br><span class="line">  <span class="keyword">return</span> getRemoteBlockReaderFromTcp();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>得到BlockReader之后代码回到<code>readWithStrategy</code>中，然后进行<code>readBuffer</code>操作，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// corruptedBlockMap在readWithStrategy中被实例化</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">readBuffer</span><span class="params">(ReaderStrategy reader, <span class="keyword">int</span> off, <span class="keyword">int</span> len,</span></span></span><br><span class="line"><span class="params"><span class="function">    Map&lt;ExtendedBlock, Set&lt;DatanodeInfo&gt;&gt; corruptedBlockMap)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  IOException ioe;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* we retry current node only once. So this is set to true only here.</span></span><br><span class="line"><span class="comment">   * Intention is to handle one common case of an error that is not a</span></span><br><span class="line"><span class="comment">   * failure on datanode or client : when DataNode closes the connection</span></span><br><span class="line"><span class="comment">   * since client is idle. If there are other cases of &quot;non-errors&quot; then</span></span><br><span class="line"><span class="comment">   * then a datanode might be retried by setting this to true again.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">boolean</span> retryCurrentNode = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">// retry as many times as seekToNewSource allows.</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> reader.doRead(blockReader, off, len, readStatistics);</span><br><span class="line">    &#125; <span class="keyword">catch</span> ( ChecksumException ce ) &#123;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">&quot;Found Checksum error for &quot;</span></span><br><span class="line">          + getCurrentBlock() + <span class="string">&quot; from &quot;</span> + currentNode</span><br><span class="line">          + <span class="string">&quot; at &quot;</span> + ce.getPos());        </span><br><span class="line">      ioe = ce;</span><br><span class="line">      retryCurrentNode = <span class="keyword">false</span>;</span><br><span class="line">      <span class="comment">// we want to remember which block replicas we have tried</span></span><br><span class="line">      addIntoCorruptedBlockMap(getCurrentBlock(), currentNode,</span><br><span class="line">          corruptedBlockMap);</span><br><span class="line">    &#125; <span class="keyword">catch</span> ( IOException e ) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!retryCurrentNode) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">&quot;Exception while reading from &quot;</span></span><br><span class="line">            + getCurrentBlock() + <span class="string">&quot; of &quot;</span> + src + <span class="string">&quot; from &quot;</span></span><br><span class="line">            + currentNode, e);</span><br><span class="line">      &#125;</span><br><span class="line">      ioe = e;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">boolean</span> sourceFound = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (retryCurrentNode) &#123;</span><br><span class="line">      <span class="comment">/* possibly retry the same node so that transient errors don&#x27;t</span></span><br><span class="line"><span class="comment">       * result in application level failures (e.g. Datanode could have</span></span><br><span class="line"><span class="comment">       * closed the connection because the client is idle for too long).</span></span><br><span class="line"><span class="comment">       */</span> </span><br><span class="line">      sourceFound = seekToBlockSource(pos);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      addToDeadNodes(currentNode);</span><br><span class="line">      sourceFound = seekToNewSource(pos);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!sourceFound) &#123;</span><br><span class="line">      <span class="keyword">throw</span> ioe;</span><br><span class="line">    &#125;</span><br><span class="line">    retryCurrentNode = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>readBuffer是通过调用ByteArrayStrategy重写的doRead方法来read的，而<code>ByteArrayStrategy.doRead</code>又是调用<code>BlockReader.read</code>来进行真正的读操作。</p>
<p>doRead时readBuffer会捕获到ChecksumException和IOException异常，</p>
<ul>
<li>如果检测到_ChecksumException_异常，retryCurrentNode 变为fasle，将当前节点加入deadNodes，然后进行seekToNewSource</li>
<li>如果检测到_IOException_异常，并且retryCurrentNode为true，则进行seekToBlockSource<pre><code>            如果retryCurrentNode为false，将当前节点加入deadNodes，然后进行seekToNewSource
</code></pre>
</li>
</ul>
<p>retryCurrentNode标识当前节点read失败之后是否进行重试，如果是ChecksumException失败，则不进行重试，如果是IOException失败，则进行重试，并且只重试一次。_因为可能存在由于client长时间没有任何动作，则dn关闭了连接导致IOException，此时进行重试_。__此处进行重试并不是马上对该节点进行重试，只是不该节点标为dead，可以在随后的choseNode时可以被再次选择__。</p>
<p>由seekToNewSource来选择再次read的节点，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">seekToNewSource</span><span class="params">(<span class="keyword">long</span> targetPos)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> markedDead = deadNodes.containsKey(currentNode);</span><br><span class="line">  addToDeadNodes(currentNode);</span><br><span class="line">  DatanodeInfo oldNode = currentNode;</span><br><span class="line">  DatanodeInfo newNode = blockSeekTo(targetPos);</span><br><span class="line">  <span class="keyword">if</span> (!markedDead) &#123;</span><br><span class="line">    <span class="comment">/* remove it from deadNodes. blockSeekTo could have cleared </span></span><br><span class="line"><span class="comment">     * deadNodes and added currentNode again. Thats ok. */</span></span><br><span class="line">    deadNodes.remove(oldNode);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!oldNode.getDatanodeUuid().equals(newNode.getDatanodeUuid())) &#123;</span><br><span class="line">    currentNode = newNode;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>真正的read操作是<code>BlockReader.read</code>，BlockReader是在blockSeekTo中实例化的，此处是_远程read_，其实现是<code>RemoteBlockReader2.read</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RemoteBlockReader2.read</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">byte</span>[] buf, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> </span></span><br><span class="line"><span class="function">                             <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">  UUID randomId = <span class="keyword">null</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (curDataSlice == <span class="keyword">null</span> || curDataSlice.remaining() == <span class="number">0</span> &amp;&amp; bytesNeededToFinish &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    readNextPacket();</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (curDataSlice.remaining() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// we&#x27;re at EOF now</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 如果buf的len小于curDataSlice的长度，剩下的内容怎么读</span></span><br><span class="line">  <span class="keyword">int</span> nRead = Math.min(curDataSlice.remaining(), len);</span><br><span class="line">  <span class="comment">// 从curDataSlice中读取数据到buf中</span></span><br><span class="line">  curDataSlice.get(buf, off, nRead);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> nRead;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readNextPacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">//Read packet headers.</span></span><br><span class="line">  packetReceiver.receiveNextPacket(in);</span><br><span class="line"></span><br><span class="line">  PacketHeader curHeader = packetReceiver.getHeader();</span><br><span class="line">  curDataSlice = packetReceiver.getDataSlice();</span><br><span class="line">  <span class="keyword">assert</span> curDataSlice.capacity() == curHeader.getDataLen();</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (curHeader.getDataLen() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// bytesPerChecksum 多少字节一个checkcum</span></span><br><span class="line">    <span class="comment">// curHeader.getDataLen得到数据data的长度，然后得出需要多少个chunks</span></span><br><span class="line">    <span class="keyword">int</span> chunks = <span class="number">1</span> + (curHeader.getDataLen() - <span class="number">1</span>) / bytesPerChecksum;</span><br><span class="line">    <span class="comment">// 得出checksum的长度</span></span><br><span class="line">    <span class="keyword">int</span> checksumsLen = chunks * checksumSize;</span><br><span class="line">    ...</span><br><span class="line">    lastSeqNo = curHeader.getSeqno();</span><br><span class="line">    <span class="keyword">if</span> (verifyChecksum &amp;&amp; curDataSlice.remaining() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// N.B.: the checksum error offset reported here is actually</span></span><br><span class="line">      <span class="comment">// relative to the start of the block, not the start of the file.</span></span><br><span class="line">      <span class="comment">// This is slightly misleading, but preserves the behavior from</span></span><br><span class="line">      <span class="comment">// the older BlockReader.</span></span><br><span class="line">      <span class="comment">// 利用checksum检查数据是否正确</span></span><br><span class="line">      checksum.verifyChunkedSums(curDataSlice,</span><br><span class="line">          packetReceiver.getChecksumSlice(),</span><br><span class="line">          filename, curHeader.getOffsetInBlock());</span><br><span class="line">    &#125;</span><br><span class="line">    bytesNeededToFinish -= curHeader.getDataLen();</span><br><span class="line">  &#125;    </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// First packet will include some data prior to the first byte</span></span><br><span class="line">  <span class="comment">// the user requested. Skip it.</span></span><br><span class="line">  <span class="keyword">if</span> (curHeader.getOffsetInBlock() &lt; startOffset) &#123;</span><br><span class="line">    <span class="keyword">int</span> newPos = (<span class="keyword">int</span>) (startOffset - curHeader.getOffsetInBlock());</span><br><span class="line">    curDataSlice.position(newPos);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If we&#x27;ve now satisfied the whole client read, read one last packet</span></span><br><span class="line">  <span class="comment">// header, which should be empty</span></span><br><span class="line">  <span class="comment">// bytesNeededToFinish是表示还需要读多少字节，</span></span><br><span class="line">  <span class="comment">// 这个是在哪赋值的？怎么知道还有多少字节要读</span></span><br><span class="line">  <span class="keyword">if</span> (bytesNeededToFinish &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 读取结束</span></span><br><span class="line">    readTrailingEmptyPacket();</span><br><span class="line">    <span class="keyword">if</span> (verifyChecksum) &#123;</span><br><span class="line">      sendReadResult(Status.CHECKSUM_OK);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      sendReadResult(Status.SUCCESS);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>read时packet是基本的传输单位，每个packet(默认每个packet为64K)由若干个chunk组成，每个chunk对应一个chunksum。</p>
<p>curDataSlice中存储这需要读取data的信息，初次读取packet时，curDataSlice为null，进行packet读取<code>readNextPacket</code>，对curDataSlice进行赋值（_也就是先把内容读取到packet中，此时curDataSlice就相当于一个packet_），并对packet中的数据调用<code>checksum.verifyChunkedSums</code>进行checksum检验。</p>
<p>最后由<code>curDataSlice.get(buf, off, nRead)</code>从curDataSlice读取一定长度的byte放入buf中。</p>
<p>则一次调用read流程结束，一次read只是从packet中读取一些byte，再次调用read会继续从curDataSlice中get一定长度的byte，直到<code>curDataSlice.remaining() == 0 &amp;&amp; bytesNeededToFinish &gt; 0</code>时，也就是当前packet内容读取完毕，然后再次调用readNextPacket进行读取block。</p>
<p>简单说下packet的数据结构</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Each packet looks like:</span></span><br><span class="line"><span class="comment">//   PLEN    HLEN      HEADER     CHECKSUMS  DATA</span></span><br><span class="line"><span class="comment">//   32-bit  16-bit   &lt;protobuf&gt;  &lt;variable length&gt;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// PLEN:      Payload length</span></span><br><span class="line"><span class="comment">//            = length(PLEN) + length(CHECKSUMS) + length(DATA)</span></span><br><span class="line"><span class="comment">//            This length includes its own encoded length in</span></span><br><span class="line"><span class="comment">//            the sum for historical reasons.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// HLEN:      Header length</span></span><br><span class="line"><span class="comment">//            = length(HEADER)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// HEADER:    the actual packet header fields, encoded in protobuf</span></span><br><span class="line"><span class="comment">// CHECKSUMS: the crcs for the data chunk. May be missing if</span></span><br><span class="line"><span class="comment">//            checksums were not requested</span></span><br><span class="line"><span class="comment">// DATA       the actual block data</span></span><br></pre></td></tr></table></figure>

<p>HDFS一个文件由多个block构成。HDFS在进行block读写的时候是以packet(默认每个packet为64K)为单位进行的。每一个packet由若干个chunk（默认512Byte）组成。Chunk是进行数据校验的基本单位，对每一个chunk生成一个校验和(默认4Byte)并将校验和进行存储。在读取一个block的时候，数据传输的基本单位是packet，每个packet由若干个chunk组成。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="getRemoteBlockReaderFromTcp代码跟读"><a href="#getRemoteBlockReaderFromTcp代码跟读" class="headerlink" title="getRemoteBlockReaderFromTcp代码跟读"></a>getRemoteBlockReaderFromTcp代码跟读</h3><p>getRemoteBlockReaderFromTcp得到一个远程BlockReader</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> BlockReader <span class="title">getRemoteBlockReaderFromTcp</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  BlockReader blockReader = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    BlockReaderPeer curPeer = <span class="keyword">null</span>;</span><br><span class="line">    Peer peer = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//Get the next TCP-based peer-- either from the cache or by creating it.</span></span><br><span class="line">      curPeer = nextTcpPeer();</span><br><span class="line">      <span class="keyword">if</span> (curPeer == <span class="keyword">null</span>) <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">if</span> (curPeer.fromCache) remainingCacheTries--;</span><br><span class="line">      peer = curPeer.peer;</span><br><span class="line">      <span class="comment">// 通过peer得到某个block的blockReader</span></span><br><span class="line">      blockReader = getRemoteBlockReader(peer);</span><br><span class="line">      <span class="keyword">return</span> blockReader;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (blockReader == <span class="keyword">null</span>) &#123;</span><br><span class="line">        IOUtils.cleanup(LOG, peer);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> BlockReader <span class="title">getRemoteBlockReader</span><span class="params">(Peer peer)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (conf.useLegacyBlockReader) &#123;</span><br><span class="line">    <span class="keyword">return</span> RemoteBlockReader.newBlockReader(fileName,</span><br><span class="line">        block, token, startOffset, length, conf.ioBufferSize,</span><br><span class="line">        verifyChecksum, clientName, peer, datanode,</span><br><span class="line">        clientContext.getPeerCache(), cachingStrategy);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> RemoteBlockReader2.newBlockReader(</span><br><span class="line">        fileName, block, token, startOffset, length,</span><br><span class="line">        verifyChecksum, clientName, peer, datanode,</span><br><span class="line">        clientContext.getPeerCache(), cachingStrategy);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// RemoteBlockReader2</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> BlockReader <span class="title">newBlockReader</span><span class="params">(String file,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   ExtendedBlock block,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   Token&lt;BlockTokenIdentifier&gt; blockToken,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   <span class="keyword">long</span> startOffset, <span class="keyword">long</span> len,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   <span class="keyword">boolean</span> verifyChecksum,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   String clientName,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   Peer peer, DatanodeID datanodeID,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   PeerCache peerCache,</span></span></span><br><span class="line"><span class="params"><span class="function">                                   CachingStrategy cachingStrategy)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// in and out will be closed when sock is closed (by the caller)</span></span><br><span class="line">  <span class="comment">// 使用Socket建立写入流，</span></span><br><span class="line">  <span class="keyword">final</span> DataOutputStream out = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(</span><br><span class="line">        peer.getOutputStream()));</span><br><span class="line">  <span class="comment">// 向DataNode发送读指令</span></span><br><span class="line">  <span class="comment">// 此处的readBlock与DataXceiver中的readBlock的区别是啥？这是一个rpc调用？？</span></span><br><span class="line">  <span class="comment">// Sender是client端，DataXceiver是Server端？？？</span></span><br><span class="line">  <span class="keyword">new</span> Sender(out).readBlock(block, blockToken, clientName, startOffset, len,</span><br><span class="line">      verifyChecksum, cachingStrategy);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Get bytes in block</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  DataInputStream in = <span class="keyword">new</span> DataInputStream(peer.getInputStream());</span><br><span class="line"></span><br><span class="line">  BlockOpResponseProto status = BlockOpResponseProto.parseFrom(</span><br><span class="line">      PBHelper.vintPrefixed(in));</span><br><span class="line">  checkSuccess(status, peer, block, file);</span><br><span class="line">  ReadOpChecksumInfoProto checksumInfo =</span><br><span class="line">    status.getReadOpChecksumInfo();</span><br><span class="line">  DataChecksum checksum = DataTransferProtoUtil.fromProto(</span><br><span class="line">      checksumInfo.getChecksum());</span><br><span class="line">  <span class="comment">//Warning when we get CHECKSUM_NULL?</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Read the first chunk offset.</span></span><br><span class="line">  <span class="keyword">long</span> firstChunkOffset = checksumInfo.getChunkOffset();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ( firstChunkOffset &lt; <span class="number">0</span> || firstChunkOffset &gt; startOffset ||</span><br><span class="line">      firstChunkOffset &lt;= (startOffset - checksum.getBytesPerChecksum())) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;BlockReader: error in first chunk offset (&quot;</span> +</span><br><span class="line">                          firstChunkOffset + <span class="string">&quot;) startOffset is &quot;</span> +</span><br><span class="line">                          startOffset + <span class="string">&quot; for file &quot;</span> + file);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> RemoteBlockReader2(file, block.getBlockPoolId(), block.getBlockId(),</span><br><span class="line">      checksum, verifyChecksum, startOffset, firstChunkOffset, len, peer,</span><br><span class="line">      datanodeID, peerCache);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="随机读"><a href="#随机读" class="headerlink" title="随机读"></a>随机读</h3><p>HDFS读文件包含两种，一种是最经常使用的顺序读，另一种是随机读。像MR任务，一般都会涉及到随机读。MR在提交作业时，已经确定了每个map和reduce要读取的文件，文件的偏移量，读取的长度，则只读取相应的split就行。</p>
<p>随机读的代码入口函数依然在<code>FSDataInputStream</code>中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSDataInputStream.read</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">byte</span>[] buffer, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> ((PositionedReadable)in).read(position, buffer, offset, length);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//DFSInputStream.read</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">byte</span>[] buffer, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// sanity checks</span></span><br><span class="line">  dfsClient.checkOpen();</span><br><span class="line">  <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">&quot;Stream closed&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  failures = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">long</span> filelen = getFileLength();</span><br><span class="line">  <span class="keyword">if</span> ((position &lt; <span class="number">0</span>) || (position &gt;= filelen)) &#123;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">int</span> realLen = length;</span><br><span class="line">  <span class="keyword">if</span> ((position + length) &gt; filelen) &#123;</span><br><span class="line">    realLen = (<span class="keyword">int</span>)(filelen - position);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// determine the block and byte range within the block</span></span><br><span class="line">  <span class="comment">// corresponding to position and realLen</span></span><br><span class="line">  List&lt;LocatedBlock&gt; blockRange = getBlockRange(position, realLen);</span><br><span class="line">  <span class="keyword">int</span> remaining = realLen;</span><br><span class="line">  Map&lt;ExtendedBlock,Set&lt;DatanodeInfo&gt;&gt; corruptedBlockMap </span><br><span class="line">    = <span class="keyword">new</span> HashMap&lt;ExtendedBlock, Set&lt;DatanodeInfo&gt;&gt;();</span><br><span class="line">  <span class="keyword">for</span> (LocatedBlock blk : blockRange) &#123;</span><br><span class="line">    <span class="keyword">long</span> targetStart = position - blk.getStartOffset();</span><br><span class="line">    <span class="keyword">long</span> bytesToRead = Math.min(remaining, blk.getBlockSize() - targetStart);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (dfsClient.isHedgedReadsEnabled()) &#123;</span><br><span class="line">        hedgedFetchBlockByteRange(blk, targetStart, targetStart + bytesToRead</span><br><span class="line">            - <span class="number">1</span>, buffer, offset, corruptedBlockMap);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        fetchBlockByteRange(blk, targetStart, targetStart + bytesToRead - <span class="number">1</span>,</span><br><span class="line">            buffer, offset, corruptedBlockMap);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="comment">// Check and report if any block replicas are corrupted.</span></span><br><span class="line">      <span class="comment">// BlockMissingException may be caught if all block replicas are</span></span><br><span class="line">      <span class="comment">// corrupted.</span></span><br><span class="line">      reportCheckSumFailure(corruptedBlockMap, blk.getLocations().length);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    remaining -= bytesToRead;</span><br><span class="line">    position += bytesToRead;</span><br><span class="line">    offset += bytesToRead;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">assert</span> remaining == <span class="number">0</span> : <span class="string">&quot;Wrong number of bytes read.&quot;</span>;</span><br><span class="line">  <span class="keyword">if</span> (dfsClient.stats != <span class="keyword">null</span>) &#123;</span><br><span class="line">    dfsClient.stats.incrementBytesRead(realLen);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> realLen;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这两篇文章主要介绍了hdfs读文件的流程，整个流程为：</p>
<ol>
<li>得到一个文件系统的实例，通过getFileSystem得到</li>
<li>open一个文件输入流，open时根据指定的path调用rpc打开一个FSDataInputStream，在初始化输入流时，会将一部分block的locations信息读入内存进行缓存，默认是10个block。将输入流的实例返回给client。<em>内存中缓存的block已经是按照各个dn到client的距离进行排序之后的结果</em></li>
<li>输入流实例化之后，调用read方法读取数据。(读分为顺序读和随机读)<ol>
<li>read时可以选择几种ReaderStrategy，本篇选择的是ByteArrayStrategy。</li>
<li>根据off和len进行读。通过off找到对应的block A(二分查找)，如果block A在之前的缓存中，则直接返回block A。如果block A不在之前的缓存中，则再次请求从nn请求一部分block，将新请求的blocks根据其中block在原缓存中的位置插入到缓存中，之后得到该off对应的block A。</li>
<li>通过block A选择离client最近的dn，*如果得到dn时发生IOException错误(当从locations中没有选择到合适的dn时，抛出IOException)*，则等待一段时间之后，进行重试，默认是重试3次。</li>
<li>得到dn之后，通过BlockRead进行读取数据，BlockRead根据是否short circuit local 和 remote实例化不同的BlockRead。</li>
<li><em>read数据时发生的错误为checksumException和IOException</em>，如果是ChecksumException则将dn放入deadNodes中，换个dn进行重读，如果是IOException则直接重读(<em>可能是连接断开了</em>)，不将dn放入deadNodes中。</li>
<li>本篇介绍的是RemoteBlockReader，读文件时是以packet为单位的，读取一个packet放入内存，对其中的chunk进行checksum校验。从内存中读取len的长度，如果读完则继续读取下一个packet。<em>读取完毕之后发送一个空packet。</em><strong>是block的最后一个packet还是？？</strong></li>
<li>读文件时还需要dn端的一些操作，主要类是DataXceiver，这个类随后再分析。</li>
</ol>
</li>
</ol>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>何种情况下block会丢失</li>
<li>读取速度慢，某个node读取失败</li>
<li>怎么判断需要创建远程BlockReader还是本地BlockReader(是否还有本地读的概念，都是通过remote吗？)<br>仅由此来判断是否开启本地读还是远程读？  setRemotePeerFactory<br>allowShortCircuitLocalReads 当 当前文件正在构建中则为false</li>
<li>read某个block的dn时，出错，怎么办<br>看在哪出错？是在get block dn时还是在得到dn进行read时出错，<br><em>如果在get block的dn时出错</em>，重复3次依然出错，则抛出异常。<br><em>如果在得到dn之后，read时出错</em>，此时又分两种情况，如果是checksum错，换个dn重读，如果是IOException，则直接重试。</li>
<li>发送，数据是怎么发送的？？？   读的过程中有send嘛？</li>
<li>读取某个dn的block时失败，将此dn加入哪？或者dn死掉，。。<br>  加入deadNodes</li>
<li>这个deadNodes是谁维护的？只是本次读？<br>读一个block，一个deadNodes</li>
<li>In HDFS, why corrupted block(s) happens?<br> dfs.datanode.scan.period.hours</li>
<li>Sender(out).readBlock与DataXceiver中的readBlock的区别是啥？这是一个rpc调用？？<br>// Sender是client端，DataXceiver是Server端？？？</li>
</ul>
<h2 id="相关配置属性"><a href="#相关配置属性" class="headerlink" title="相关配置属性"></a>相关配置属性</h2><ul>
<li><p>io.file.buffer.size(4096)<br> The size of buffer for use in sequence files. The size of this buffer should probably be a multiple of hardware page size (4096 on Intel x86), and it determines how much data is buffered during read and write operations.</p>
</li>
<li><p>dfs.client.read.prefetch.size</p>
</li>
</ul>
<p>prefetchSize = conf.getLong(DFS_CLIENT_READ_PREFETCH_SIZE_KEY,<br>          10 * defaultBlockSize);</p>
<ul>
<li><p>dfs.client.<em>cache.drop</em>.behind.reads (vs dfs.datanode.<em>drop.cache</em>.behind.reads)</p>
<p> Just like dfs.datanode.drop.cache.behind.reads, this setting causes the page cache to be dropped behind HDFS reads, potentially freeing up more memory for other uses. Unlike dfs.datanode.drop.cache.behind.reads, this is a client-side setting rather than a setting for the entire datanode. If present, this setting will override the DataNode default. If the native libraries are not available to the DataNode, this configuration has no effect.</p>
<p> In some workloads, the data read from HDFS is known to be significantly large enough that it is unlikely to be useful to cache it in the operating system buffer cache. In this case, the DataNode may be configured to automatically purge all data from the buffer cache after it is delivered to the client. This behavior is automatically disabled for workloads which read only short sections of a block (e.g HBase random-IO workloads). This may improve performance for some workloads by freeing buffer cache space usage for more cacheable data. If the Hadoop native libraries are not available, this configuration has no effect.</p>
</li>
</ul>
<ul>
<li><p>dfs.client.cache.drop.behind.writes</p>
</li>
<li><p>dfs.client.cache.readahead (vs dfs.datanode.readahead.bytes)</p>
<p> When using remote reads, this setting causes the datanode to read ahead in the block file using posix_fadvise, potentially decreasing I/O wait times. Unlike dfs.datanode.readahead.bytes, this is a client-side setting rather than a setting for the entire datanode. If present, this setting will override the DataNode default. When using local reads, this setting determines how much readahead we do in BlockReaderLocal. If the native libraries are not available to the DataNode, this configuration has no effect.</p>
</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">混绅士</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://bigdatadecode.club/HDFS%20read%E8%A7%A3%E6%9E%902%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread.html">http://bigdatadecode.club/HDFS%20read%E8%A7%A3%E6%9E%902%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://bigdatadecode.club" target="_blank">big data decode club</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a><a class="post-meta__tags" href="/tags/BigData/">BigData</a><a class="post-meta__tags" href="/tags/HDFS/">HDFS</a><a class="post-meta__tags" href="/tags/read/">read</a></div><div class="post_share"></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/path/to/wechat-reward-image/wechatpay.png" target="_blank"><img class="post-qr-code-img" src="/path/to/wechat-reward-image/wechatpay.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/%5B%E8%AF%91%5DHDFS%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B2.html"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">HDFS恢复过程2</div></div></a></div><div class="next-post pull-right"><a href="/NameNode%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%A4%A7%E5%B0%8F%E8%AF%84%E4%BC%B0.html"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">NameNode内存解析及大小评估</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/HDFS%20read%E8%A7%A3%E6%9E%90.html" title="HDFS read解析(一)之Open文件流"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-11-21</div><div class="title">HDFS read解析(一)之Open文件流</div></div></a></div><div><a href="/%E5%B8%B8%E7%94%A8Hadoop%E5%91%BD%E4%BB%A4.html" title="常用Hadoop命令"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-02-14</div><div class="title">常用Hadoop命令</div></div></a></div><div><a href="/HDFS%20HA%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90.html" title="HDFS HA机制解析"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-07-14</div><div class="title">HDFS HA机制解析</div></div></a></div><div><a href="/HDFS%20HA%E7%9B%B8%E5%85%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%92%8C%E7%A4%BA%E4%BE%8B%E5%9C%BA%E6%99%AF.html" title="HDFS HA相关的几个问题和示例场景"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-11-19</div><div class="title">HDFS HA相关的几个问题和示例场景</div></div></a></div><div><a href="/HDFS%20ReplicationMonitor%E5%89%AF%E6%9C%AC%E7%9B%91%E6%8E%A7%E7%BA%BF%E7%A8%8B%E8%A7%A3%E6%9E%90.html" title="HDFS ReplicationMonitor副本监控线程解析"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2016-08-01</div><div class="title">HDFS ReplicationMonitor副本监控线程解析</div></div></a></div><div><a href="/HDFS-little-file-action.html" title="HDFS小文件合并实战"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-01-30</div><div class="title">HDFS小文件合并实战</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/uploads/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">混绅士</div><div class="author-info__description">Any answers you can find in source code.</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">117</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">191</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">20</div></a></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#HDFS-Read%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread"><span class="toc-number">1.</span> <span class="toc-text">HDFS Read之从文件流中read</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A1%A5%E5%85%85"><span class="toc-number">2.</span> <span class="toc-text">补充</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#getRemoteBlockReaderFromTcp%E4%BB%A3%E7%A0%81%E8%B7%9F%E8%AF%BB"><span class="toc-number">2.1.</span> <span class="toc-text">getRemoteBlockReaderFromTcp代码跟读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E8%AF%BB"><span class="toc-number">2.2.</span> <span class="toc-text">随机读</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%97%AE%E9%A2%98"><span class="toc-number">4.</span> <span class="toc-text">问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E9%85%8D%E7%BD%AE%E5%B1%9E%E6%80%A7"><span class="toc-number">5.</span> <span class="toc-text">相关配置属性</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/scratch-extensions-demo.html" title="scratch自定义扩展"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="scratch自定义扩展"/></a><div class="content"><a class="title" href="/scratch-extensions-demo.html" title="scratch自定义扩展">scratch自定义扩展</a><time datetime="2021-12-14T14:30:20.000Z" title="发表于 2021-12-14 22:30:20">2021-12-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/metabase-import-ide.html" title="metabase导入IDE调试"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="metabase导入IDE调试"/></a><div class="content"><a class="title" href="/metabase-import-ide.html" title="metabase导入IDE调试">metabase导入IDE调试</a><time datetime="2021-12-13T15:31:22.000Z" title="发表于 2021-12-13 23:31:22">2021-12-13</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/flink-connector-example.html" title="Flink Connector调研"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink Connector调研"/></a><div class="content"><a class="title" href="/flink-connector-example.html" title="Flink Connector调研">Flink Connector调研</a><time datetime="2021-11-10T14:30:20.000Z" title="发表于 2021-11-10 22:30:20">2021-11-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/Flink-standlone-Flinkx.html" title="Flink standlone模式下Flinkx测试"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Flink standlone模式下Flinkx测试"/></a><div class="content"><a class="title" href="/Flink-standlone-Flinkx.html" title="Flink standlone模式下Flinkx测试">Flink standlone模式下Flinkx测试</a><time datetime="2021-11-06T15:05:20.000Z" title="发表于 2021-11-06 23:05:20">2021-11-06</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/openGauss-deploy.html" title="openGauss极简版安装使用"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="openGauss极简版安装使用"/></a><div class="content"><a class="title" href="/openGauss-deploy.html" title="openGauss极简版安装使用">openGauss极简版安装使用</a><time datetime="2021-05-13T14:35:20.000Z" title="发表于 2021-05-13 22:35:20">2021-05-13</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2016 - 2022 By 混绅士</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>