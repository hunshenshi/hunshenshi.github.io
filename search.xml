<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
    
    <entry>
      <title><![CDATA[cryptozombies源码解析二]]></title>
      <url>http://bigdatadecode.club/cryptozombies-src-parse-2.html</url>
      <content type="html"><![CDATA[<p><a href="">cryptozombies源码解析一</a>中对以太坊开发中的<em>事件</em>与<em>合约交互</em>进行了介绍，看过这篇文章的同学我相信对Dapp开发也有了一个初步的了解，下面我们继续学习一些智能合约开发中特性。</p>
<a id="more"></a>
<h2 id="如何减少gas"><a href="#如何减少gas" class="headerlink" title="如何减少gas"></a>如何减少gas</h2><p>gas是EVM中代码执行所消耗资源的计量单位，gas是需要用以太币购买的，现在你是不是已经get到了为什么要减少gas了，嘿嘿。。。</p>
<h3 id="使用合适的数据结构"><a href="#使用合适的数据结构" class="headerlink" title="使用合适的数据结构"></a>使用合适的数据结构</h3><p>这里以uint为例，在Solidity中除了有基本版的uint外，还有其他变种uint：uint8，uint16，uint32等。通常情况下我们不会考虑使用uint变种，<em>因为无论如何定义 uint的大小，Solidity为它保留256位的存储空间</em>。例如，使用uint8而不使用uint(uint256)，并不会为你节省任何gas，因为Solidity始终保留了256的空间。</p>
<p>那么为什么还要有其他uint的变种呢？<strong>是因为在struct里，可以通过声明具体的uint变种来节省存储空间</strong>。<br>在struct里，相同类型的uint要紧邻，例如uint8的变量要放在一起，uint16的要放在一起，这样可以将这些uint打包在一起，从而占用较少的存储空间。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">struct Zombie &#123;</span><br><span class="line">  string name;</span><br><span class="line">  uint dna;</span><br><span class="line">  uint32 level;</span><br><span class="line">  uint32 readyTime;</span><br><span class="line">  uint16 winCount;</span><br><span class="line">  uint16 lossCount;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="注意view和pure的使用场景"><a href="#注意view和pure的使用场景" class="headerlink" title="注意view和pure的使用场景"></a>注意view和pure的使用场景</h3><p>之所以要注意view和pure的使用场景，是<strong>因为从合约外部调用这两个修饰符修饰的函数的时候不花费任何gas</strong>，注意这里说的是在合约外部调用，<strong>它们在被内部其他函数调用的时候将会耗费gas</strong><!--，因为一个view函数在另一个函数的内部被调用，而调用函数与view函数的不属于同一个合约，也会产生调用成本。这是因为如果主调函数在以太坊创建了一个事务，它仍然需要逐个节点去验证。所以标记为view的函数只有在外部调用时才是免费的-->。</p>
<p>下面解释下为什么view和pure从合约外部调用不需要花费gas。<br>是因为<em>view修饰符的意思是不会改变区块链上的任何数据，只是从区块链上读取数据</em>。标记为view的函数，意味着告诉web3.js，运行这个函数只需要查询你的本地以太坊节点，而不需要在区块链上创建一个事务(事务需要运行在每个节点上，因此花费gas)。<br>所以在所有能只读的函数上标记上表示<code>只读</code>的<code>external view</code>声明，就能为你的玩家减少在DApp中gas用量。</p>
<p>pure与view类似，<em>pure修饰符的意思是不但不会往区块链写数据，它甚至不从区块链读取数据</em>，所以pure也不会消耗gas。</p>
<h3 id="尽可能的规避昂贵的操作"><a href="#尽可能的规避昂贵的操作" class="headerlink" title="尽可能的规避昂贵的操作"></a>尽可能的规避昂贵的操作</h3><p><strong>Solidity中使用storage(存储)是相当昂贵的，”写入”操作尤其贵</strong>。这是因为，无论是写入还是更改一段数据，这都将永久性地写入区块链。”永久性”啊！需要在全球数千个节点的硬盘上存入这些数据，随着区块链的增长，拷贝份数更多，存储量也就越大。这是需要成本的！</p>
<p>所以在开发中，为了降低成本，不到万不得已，避免将数据写入存储。虽然这样做会导致效率低下，但是在有些场景下还是可取的。</p>
<p>代码中有一个<code>getZombiesByOwner</code>的函数，功能是得到某个用户的僵尸军团，常规逻辑是在<code>ZombieFactory</code>中存入<em>owner</em>与<em>zombies</em>的映射<code>mapping (address =&gt; uint[]) public ownerToZombies</code>，然后我们每次创建新僵尸时，执行<code>ownerToZombies[owner].push(zombieId)</code>将其添加到主人的僵尸数组中。而 <code>getZombiesByOwner</code>函数也非常简单：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">getZombiesByOwner</span>(<span class="params">address _owner</span>) <span class="title">external</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">uint[]</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> ownerToZombies[_owner];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可是如果我们需要一个函数来把一头僵尸转移到另一个主人名下，又会发生什么？<br>这个”换主”函数要做到：</p>
<ol>
<li>将僵尸push到新主人的<code>ownerToZombies</code>映射中的数组， </li>
<li>从旧主的<code>ownerToZombies</code>数组中移除僵尸， </li>
<li>将旧主僵尸数组中”换主僵尸”之后的的每头僵尸都往前挪一位，把挪走”换主僵尸”后留下的”空槽”填上， </li>
<li>将数组长度减1。<br>但是<em>第三步实在是太贵了</em>！<em>因为每挪动一头僵尸，我们都要执行一次写操作</em>。如果一个主人有20头僵尸，而第一头被挪走了，那为了保持数组的顺序，我们得做19个写操作。<br>由于<em>写入存储是Solidity中最费gas的操作之一</em>，使得换主函数的每次调用都非常昂贵。更糟糕的是，每次调用的时候花费的gas都不同！具体还取决于用户在原主军团中的僵尸头数，以及移走的僵尸所在的位置。以至于用户都不知道应该支付多少gas。</li>
</ol>
<blockquote>
<p>注意：当然，我们也可以把数组中最后一个僵尸往前挪来填补空槽，并将数组长度减少一。但这样每做一笔交易，都会改变僵尸军团的秩序。</p>
</blockquote>
<p>此时我们就应该避免这种高昂的操作，使用另一种方案来解决。上面提到view修饰的函数从外部调用是免费的，而且我们也只是从区块链中读取数据，所以我们可以在<code>getZombiesByOwner</code>函数中一个for循环遍历整个僵尸数组<code>zombies</code>，把属于某个主人的僵尸挑出来构建出僵尸数组。那么我们的transfer函数将会便宜得多，因为我们不需要挪动存储里的僵尸数组重新排序，总体上这个方法会更便宜，就是有点反常。</p>
<blockquote>
<p>在大多数编程语言中，遍历大数据集合都是昂贵的。但是在Solidity中，使用一个标记了<code>external view</code>的函数，遍历比storage要便宜太多，因为view函数不会产生任何花销。 （gas可是真金白银啊！）。</p>
</blockquote>
<p>最后<code>getZombiesByOwner</code>的实现为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">function getZombiesByOwner(address _owner) external view returns(uint[]) &#123;</span><br><span class="line">  uint[] memory result = new uint[](ownerZombieCount[_owner]);</span><br><span class="line">  uint counter = 0;</span><br><span class="line">  for (uint i = 0; i &lt; zombies.length; i++) &#123;</span><br><span class="line">    if (zombieToOwner[i] == _owner) &#123;</span><br><span class="line">      result[counter] = i;</span><br><span class="line">      counter++;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  return result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="随机数"><a href="#随机数" class="headerlink" title="随机数"></a>随机数</h2><p>相信大家在日常开发中免不了用随机数，但是在区块链中如何使用随机数呢？区块链中的随机数与传统程序中的随机数不一样是因为，区块链是一个分布式执行环境，并且为了不可篡改性，需要n台机器在同一时刻的执行结果是一样的，也就是说在同一时刻随机数是一样的。</p>
<p>Solidity中最好的随机数生成器是<code>keccak256</code>哈希函数。<br>我们可以这样来生成一些随机数：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 生成一个0到100的随机数:</span></span><br><span class="line">uint randNonce = <span class="number">0</span>;</span><br><span class="line">uint random = uint(keccak256(now, msg.sender, randNonce)) % <span class="number">100</span>;</span><br><span class="line">randNonce++;</span><br><span class="line">uint random2 = uint(keccak256(now, msg.sender, randNonce)) % <span class="number">100</span>;</span><br></pre></td></tr></table></figure>
<p>这个方法首先拿到now的时间戳、msg.sender、以及一个自增数nonce(一个仅会被使用一次的数，这样我们就不会对相同的输入值调用一次以上哈希函数了)。<br>然后利用<code>keccak</code>把输入的值转变为一个哈希值, 再将哈希值转换为uint, 然后利用<code>%100</code>来取最后两位, 就生成了一个0到100之间随机数了。</p>
<blockquote>
<p>这个方法很容易被不诚实的节点攻击</p>
</blockquote>
<p>不诚实节点是利用随机函数进行攻击的，假设我们有一个硬币翻转合约–正面你赢双倍钱，反面你输掉所有的钱。假如它使用上面的方法来决定是正面还是反面(random&gt;=50算正面, random&lt;50算反面)。<br>此时如果我正运行一个节点，我可以只对我自己的节点发布一个事务，<em>且不分享它</em>。我可以运行硬币翻转方法来偷窥我的输赢。<br>如果我输了，我就不把这个事务包含进我要解决的下一个区块中去。我可以一直运行这个方法，直到我赢得了硬币翻转并解决了下一个区块，然后获利。</p>
<p>当然，因为网络上成千上万的以太坊节点都在竞争解决下一个区块，我能成功解决下一个区块的几率非常之低。这将花费我们巨大的计算资源来开发这个获利方法，但是如果奖励异常地高(比如我可以在硬币翻转函数中赢得1个亿)，那就很值得去攻击了。</p>
<p>所以尽管这个方法在以太坊上不安全，在实际中，除非我们的随机函数有一大笔钱在上面，你游戏的用户一般是没有足够的资源去攻击的。</p>
<p>因此我们决定接受这个不足之处，使用这个简单的随机数生成函数。但是要谨记它是不安全的。<br><!--
在以太坊上，当你在一个合约上调用函数的时候，你会把它广播给一个节点或者在网络上的transaction节点们。网络上的节点将收集很多事务，试着成为第一个解决计算密集型数学问题的人，作为"工作证明"，然后将"工作证明"(Proof of Work, PoW)和事务一起作为一个block发布在网络上。一旦一个节点解决了一个PoW, 其他节点就会停止尝试解决这个PoW，并验证其他节点的事务列表是有效的，然后接受这个节点转而尝试解决下一个节点。
--></p>
<p>游戏中的随机函数应用在与其它僵尸打架的场景上，用来决定是否取胜，代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.19</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"./zombiehelper.sol"</span>;</span><br><span class="line"></span><br><span class="line">contract ZombieBattle is ZombieHelper &#123;</span><br><span class="line">  uint randNonce = <span class="number">0</span>;</span><br><span class="line">  uint attackVictoryProbability = <span class="number">70</span>;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">randMod</span>(<span class="params">uint _modulus</span>) <span class="title">internal</span> <span class="title">returns</span>(<span class="params">uint</span>) </span>&#123;</span><br><span class="line">    randNonce++;</span><br><span class="line">    <span class="keyword">return</span> uint(keccak256(now, msg.sender, randNonce)) % _modulus;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">attack</span>(<span class="params">uint _zombieId, uint _targetId</span>) <span class="title">external</span> <span class="title">ownerOf</span>(<span class="params">_zombieId</span>) </span>&#123;</span><br><span class="line">    Zombie storage myZombie = zombies[_zombieId];</span><br><span class="line">    Zombie storage enemyZombie = zombies[_targetId];</span><br><span class="line">    uint rand = randMod(<span class="number">100</span>);</span><br><span class="line">    <span class="keyword">if</span> (rand &lt;= attackVictoryProbability) &#123;</span><br><span class="line">      myZombie.winCount++;</span><br><span class="line">      myZombie.level++;</span><br><span class="line">      enemyZombie.lossCount++;</span><br><span class="line">      feedAndMultiply(_zombieId, enemyZombie.dna, <span class="string">"zombie"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      myZombie.lossCount++;</span><br><span class="line">      enemyZombie.winCount++;</span><br><span class="line">      _triggerCooldown(myZombie);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="订阅事件"><a href="#订阅事件" class="headerlink" title="订阅事件"></a>订阅事件</h2><p>一个完整可用的DApp除了智能合约必然也会包括前端应用，这样才能够更方便的让用户使用，那么前端应用如何及时的感知合约上的变化呢？答案是通过<em>订阅事件</em>。</p>
<p><a href="">cryptozombies源码解析一</a>中zombiefactory.sol有个事件<code>NewZombie</code>，每次新建一个僵尸之后，都会触发这个时间，那么我们可以在前端中通过Web3.js订阅一个事件，这样Web3提供者就可以在每次事件发生后触发一些代码逻辑，如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cryptoZombies.events.NewZombie()</span><br><span class="line">.on(<span class="string">"data"</span>, <span class="function"><span class="keyword">function</span>(<span class="params">event</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> zombie = event.returnValues;</span><br><span class="line">  <span class="built_in">console</span>.log(<span class="string">"一个新僵尸诞生了！"</span>, zombie.zombieId, zombie.name, zombie.dna);</span><br><span class="line">&#125;).on(<span class="string">'error'</span>, <span class="built_in">console</span>.error);</span><br></pre></td></tr></table></figure>
<p><code>NewZombie</code>事件在每个新建僵尸的时候都会调用，而上述代码是监听<code>NewZombie</code>的每次触发，所以无论谁的僵尸新建我都会收到一次弹窗信息，这对我可很不友好，我只关心我当自己的僵尸军团增加成员时提醒我，这个怎么实现呢？</p>
<blockquote>
<p>indexed关键字可用于过滤event </p>
</blockquote>
<p>为了筛选仅和当前用户相关的事件，Solidity合约必须使用<code>indexed</code>关键字，就像我们在ERC721实现中的<code>Transfer</code>事件中那样：<br><code>event Transfer(address indexed _from, address indexed _to, uint256 _tokenId);</code><br>在这种情况下，因为_from和_to都是indexed，这就意味着我们可以在前端事件监听中过滤事件：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cryptoZombies.events.Transfer(&#123; <span class="attr">filter</span>: &#123; <span class="attr">_to</span>: userAccount &#125; &#125;)</span><br><span class="line">.on(<span class="string">"data"</span>, <span class="function"><span class="keyword">function</span>(<span class="params">event</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> data = event.returnValues;</span><br><span class="line">  <span class="comment">// 当前用户更新了一个僵尸！更新界面来显示</span></span><br><span class="line">&#125;).on(<span class="string">'error'</span>, <span class="built_in">console</span>.error);</span><br></pre></td></tr></table></figure>
<p>看到了吧，使用<code>event</code>和<code>indexed</code>字段对于监听合约中的更改并将其<em>反映到DApp的前端界面中是非常有用的做法</em>。</p>
<p>也可以查询过去的事件，查询过去事件使用<code>getPastEvents</code>方法，使用过滤器<code>fromBlock</code>和<code>toBlock</code>给Solidity一个事件日志的时间范围(“block” 在这里代表以太坊区块编号)：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cryptoZombies.getPastEvents(<span class="string">"NewZombie"</span>, &#123; <span class="attr">fromBlock</span>: <span class="number">0</span>, <span class="attr">toBlock</span>: <span class="string">'latest'</span> &#125;)</span><br><span class="line">.then(<span class="function"><span class="keyword">function</span>(<span class="params">events</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// events 是可以用来遍历的 `event` 对象 </span></span><br><span class="line">  <span class="comment">// 这段代码将返回给我们从开始以来创建的僵尸列表</span></span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>有些牛逼的同学看到这里可能就想到了一个非常有趣的用例：<em>用事件来作为一种更便宜的存储</em>。但是这里的短板是，<strong>事件不能从智能合约本身读取</strong>。但是，<strong>如果你有一些数据需要永久性地记录在区块链中以便可以在应用的前端中读取，这将是一个很好的用例</strong>。这些数据不会影响智能合约向前的状态。</p>
<p>僵尸游戏中就有这样一个场景，<em>用事件来作为僵尸战斗的历史纪录</em>–我们可以在每次僵尸攻击别人以及有一方胜出的时候产生一个事件。智能合约不需要这些数据来计算任何接下来的事情，但是这对我们在前端向用户展示来说是非常有用的东西。</p>
<p>上面的示例代码是针对Web3.js最新版1.0的，此版本使用了WebSockets来订阅事件。但是，MetaMask尚且不支持最新的事件API。<br>所以现在我们必须使用一个单独Web3提供者，它针对事件提供了WebSockets支持。 我们可以用Infura来像实例化第二份拷贝：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> web3Infura = <span class="keyword">new</span> Web3(<span class="keyword">new</span> Web3.providers.WebsocketProvider(<span class="string">"wss://mainnet.infura.io/ws"</span>));</span><br><span class="line"><span class="keyword">var</span> czEvents = <span class="keyword">new</span> web3Infura.eth.Contract(cryptoZombiesABI, cryptoZombiesAddress);</span><br></pre></td></tr></table></figure>
<p>然后我们将使用<code>czEvents.events.Transfer</code>来监听事件，而不再使用<code>cryptoZombies.events.Transfer</code>。</p>
<p>这是我跟完这个教程之后的一些总结吧，还有一些内容没有总结，随后有时间再总结下，项目的源代码可从<a href="https://github.com/hunshenshi/cryptozombies" target="_blank" rel="noopener">github</a>上浏览。</p>
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> Ethereum </tag>
            
            <tag> crypto </tag>
            
            <tag> cryptozombies </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[cryptozombies源码解析一]]></title>
      <url>http://bigdatadecode.club/cryptozombies-src-parse.html</url>
      <content type="html"><![CDATA[<p>学习区块链的朋友应该都了解去年又一款迷恋猫的爆款游戏，他是一款基于以太网的Dapp游戏。此游戏将区块链应用推向了高潮，网上各种解读接踵而来。<br>但对于学习区块链的技术人员肯定想从代码层次学习下，想借此掌握一些Dapp开发的技巧，我也是这么想的，但是不巧的是我的水平有限(虽然代码真的很简单，代码量也不多)，读了一遍源码发现脑子里没有留下什么。</p>
<p>于是就在网上各种找资料，无意中发现了<a href="https://cryptozombies.io/zh/course/" target="_blank" rel="noopener">Loom Network的一个游戏教程cryptozombies</a>，就尝试了下，发现停不下来，就把<em>Solidity 教程: 智能合约基础教程</em>给学完了。在学习的过程中发现很多知识也在迷恋猫的代码中出现了，瞬间感觉开朗了很多。</p>
<p>此篇博客算是学完课程之后的回顾和总结吧。</p>
<a id="more"></a>
<h2 id="僵尸工厂"><a href="#僵尸工厂" class="headerlink" title="僵尸工厂"></a>僵尸工厂</h2><p>这是个僵尸游戏，所以游戏的开始肯定得有个创造僵尸的地方，这里就是从僵尸工厂开始的。先贴下代码，相信有点代码基础的同学都可以看懂。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// zombiefactory.sol</span></span><br><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.19</span>;</span><br><span class="line"></span><br><span class="line">contract ZombieFactory &#123;</span><br><span class="line"></span><br><span class="line">    event NewZombie(uint zombieId, string name, uint dna);</span><br><span class="line"></span><br><span class="line">    uint dnaDigits = <span class="number">16</span>;</span><br><span class="line">    uint dnaModulus = <span class="number">10</span> ** dnaDigits;</span><br><span class="line"></span><br><span class="line">    struct Zombie &#123;</span><br><span class="line">        string name;</span><br><span class="line">        uint dna;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Zombie[] public zombies;</span><br><span class="line"></span><br><span class="line">    mapping (<span class="function"><span class="params">uint</span> =&gt;</span> address) public zombieToOwner;</span><br><span class="line">    mapping (<span class="function"><span class="params">address</span> =&gt;</span> uint) ownerZombieCount;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> _createZombie(<span class="params">string _name, uint _dna</span>) <span class="title">private</span> </span>&#123;</span><br><span class="line">        uint id = zombies.push(Zombie(_name, _dna)) - <span class="number">1</span>;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        zombieToOwner[id] = msg.sender;</span><br><span class="line">        ownerZombieCount[msg.sender]++;</span><br><span class="line">        NewZombie(id, _name, _dna);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> _generateRandomDna(<span class="params">string _str</span>) <span class="title">private</span> <span class="title">view</span> <span class="title">returns</span> (<span class="params">uint</span>) </span>&#123;</span><br><span class="line">        uint rand = uint(keccak256(_str));</span><br><span class="line">        <span class="keyword">return</span> rand % dnaModulus;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">createRandomZombie</span>(<span class="params">string _name</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="built_in">require</span>(ownerZombieCount[msg.sender] == <span class="number">0</span>);</span><br><span class="line">        uint randDna = _generateRandomDna(_name);</span><br><span class="line">        _createZombie(_name, randDna);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码中个人感觉需要重点掌握的应该是<code>event</code>，何为event呢？<strong>event是合约和区块链通讯的一种机制，最重要的是你的前端应用可以”监听”某些事件，并做出反应</strong>。<br><code>NewZombie</code>是一个event，在<code>_createZombie</code>的<em>最后一行代码</em>中调用，我们仔细观察下<code>_createZombie</code>函数的逻辑，新建了一个Zombie，并且push到了zombies的数组中，也对相应的映射进行的修改，至此新建zombie的逻辑已经写完，那么最后一行调用<code>NewZombie</code>事件有什么用呢？<br>也就是说调用event并不是业务逻辑需要，而是框架需要，是为了告诉区块链去做一件事。那么具体什么事呢？这里就得说说<strong>区块链的日志</strong>。<br>日志在区块层面，可以用一种特殊的<em>可索引的数据结构来存储数据</em>，所以说日志是区块链中存储数据的，而且还是<em>可以被检索</em>的。<strong>Solidity的event就是用日志实现的</strong>。<em>当event被调用时，会触发event的参数存储到交易的日志中</em>。<br><code>NewZombie</code>事件被调用的时候将新建zombie的id、name和dna信息存在了日志中，通过前端应用就可以将其读出。<br><!--合约创建之后就无法访问日志数 据，但是这些数据可以从区块链外高效的访问。因为部分日志数据被存储在布隆过滤器（Bloom filter) 中，我们可以高效并且安全的搜索日志，所以那些没有下载整个区块链的网络节点（轻客户端）也可以找到这些日志。--></p>
<p>最后看下官方给出的前端应用调用合约的代码，这里也展示了event的具体用法</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 下面是调用合约的方式:</span></span><br><span class="line"><span class="keyword">var</span> abi = <span class="comment">/* abi是由编译器生成的 */</span></span><br><span class="line"><span class="keyword">var</span> ZombieFactoryContract = web3.eth.contract(abi)</span><br><span class="line"><span class="keyword">var</span> contractAddress = <span class="comment">/* 发布之后在以太坊上生成的合约地址 */</span></span><br><span class="line"><span class="keyword">var</span> ZombieFactory = ZombieFactoryContract.at(contractAddress)</span><br><span class="line"><span class="comment">// `ZombieFactory` 能访问公共的函数以及事件</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 某个监听文本输入的监听器:</span></span><br><span class="line">$(<span class="string">"#ourButton"</span>).click(<span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">var</span> name = $(<span class="string">"#nameInput"</span>).val()</span><br><span class="line">  <span class="comment">//调用合约的 `createRandomZombie` 函数:</span></span><br><span class="line">  ZombieFactory.createRandomZombie(name)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 监听 `NewZombie` 事件, 并且更新UI</span></span><br><span class="line"><span class="keyword">var</span> event = ZombieFactory.NewZombie(<span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (error) <span class="keyword">return</span></span><br><span class="line">  generateZombie(result.zombieId, result.name, result.dna)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 获取 Zombie 的 dna, 更新图像</span></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">generateZombie</span>(<span class="params">id, name, dna</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">let</span> dnaStr = <span class="built_in">String</span>(dna)</span><br><span class="line">  <span class="comment">// 如果dna少于16位,在它前面用0补上</span></span><br><span class="line">  <span class="keyword">while</span> (dnaStr.length &lt; <span class="number">16</span>)</span><br><span class="line">    dnaStr = <span class="string">"0"</span> + dnaStr</span><br><span class="line"></span><br><span class="line">  <span class="keyword">let</span> zombieDetails = &#123;</span><br><span class="line">    <span class="comment">// 前两位数构成头部.我们可能有7种头部, 所以 % 7</span></span><br><span class="line">    <span class="comment">// 得到的数在0-6,再加上1,数的范围变成1-7</span></span><br><span class="line">    <span class="comment">// 通过这样计算：</span></span><br><span class="line">    headChoice: dnaStr.substring(<span class="number">0</span>, <span class="number">2</span>) % <span class="number">7</span> + <span class="number">1</span>，</span><br><span class="line">    <span class="comment">// 我们得到的图片名称从head1.png 到 head7.png</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 接下来的两位数构成眼睛, 眼睛变化就对11取模:</span></span><br><span class="line">    eyeChoice: dnaStr.substring(<span class="number">2</span>, <span class="number">4</span>) % <span class="number">11</span> + <span class="number">1</span>,</span><br><span class="line">    <span class="comment">// 再接下来的两位数构成衣服，衣服变化就对6取模:</span></span><br><span class="line">    shirtChoice: dnaStr.substring(<span class="number">4</span>, <span class="number">6</span>) % <span class="number">6</span> + <span class="number">1</span>,</span><br><span class="line">    <span class="comment">//最后6位控制颜色. 用css选择器: hue-rotate来更新</span></span><br><span class="line">    <span class="comment">// 其实迷恋猫的各种形态也是从它的dna中像这样解析出来的</span></span><br><span class="line">    <span class="comment">// 360度:</span></span><br><span class="line">    skinColorChoice: <span class="built_in">parseInt</span>(dnaStr.substring(<span class="number">6</span>, <span class="number">8</span>) / <span class="number">100</span> * <span class="number">360</span>),</span><br><span class="line">    eyeColorChoice: <span class="built_in">parseInt</span>(dnaStr.substring(<span class="number">8</span>, <span class="number">10</span>) / <span class="number">100</span> * <span class="number">360</span>),</span><br><span class="line">    clothesColorChoice: <span class="built_in">parseInt</span>(dnaStr.substring(<span class="number">10</span>, <span class="number">12</span>) / <span class="number">100</span> * <span class="number">360</span>),</span><br><span class="line">    zombieName: name,</span><br><span class="line">    zombieDescription: <span class="string">"A Level 1 CryptoZombie"</span>,</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> zombieDetails</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>msg.sender</p>
</blockquote>
<p>对于不了解智能合约开发的同学来说，看到<code>msg.sender</code>这个变量的时候，肯定一脸懵逼，这个从哪来的。。。其实<code>msg.sender</code>是一个全局变量，就像javascript一样也有很多全局变量。这些全局变量可以被所有函数调用，其中一个全局变量就是<code>msg.sender</code>，<strong>它指的是当前调用者（或智能合约）的address</strong>。    注意：在Solidity中，功能执行始终需要从外部调用者开始。 <em>一个合约只会在区块链上什么也不做，除非有人调用其中的函数</em>。所以msg.sender总是存在的。</p>
<h2 id="与其它合约交互"><a href="#与其它合约交互" class="headerlink" title="与其它合约交互"></a>与其它合约交互</h2><p>电影中的僵尸都是成群结队的去撕咬异类，需要寻找食物，那么刚刚新建的僵尸也需要去寻找食物，所以这里作者将迷恋猫作为了僵尸的食物，要想拿到迷恋猫的信息就得与迷恋猫交互，这就是本节的重点，与其他合约交互。照例先贴下代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span>.19;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">"./zombiefactory.sol"</span>;</span><br><span class="line"></span><br><span class="line">contract KittyInterface &#123;</span><br><span class="line">  <span class="function">function <span class="title">getKitty</span><span class="params">(uint256 _id)</span> external view <span class="title">returns</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    bool isGestating,</span></span></span><br><span class="line"><span class="function"><span class="params">    bool isReady,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 cooldownIndex,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 nextActionAt,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 siringWithId,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 birthTime,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 matronId,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 sireId,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 generation,</span></span></span><br><span class="line"><span class="function"><span class="params">    uint256 genes</span></span></span><br><span class="line"><span class="function"><span class="params">  )</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract ZombieFeeding is ZombieFactory &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 迷恋猫合约的地址</span></span><br><span class="line">  address ckAddress = <span class="number">0x06012c8cf97BEaD5deAe237070F9587f8E7A266d</span>;</span><br><span class="line">  <span class="comment">// 实现类，只是接口的实现类被别人实现了，并且已部署在的区块链中</span></span><br><span class="line">  KittyInterface kittyContract = KittyInterface(ckAddress);</span><br><span class="line"></span><br><span class="line">  <span class="function">function <span class="title">feedAndMultiply</span><span class="params">(uint _zombieId, uint _targetDna, string _species)</span> <span class="keyword">public</span> </span>&#123;</span><br><span class="line">    require(msg.sender == zombieToOwner[_zombieId]);</span><br><span class="line">    Zombie storage myZombie = zombies[_zombieId];</span><br><span class="line">    _targetDna = _targetDna % dnaModulus;</span><br><span class="line">    uint newDna = (myZombie.dna + _targetDna) / <span class="number">2</span>;</span><br><span class="line">    <span class="comment">// 这里增加一个 if 语句</span></span><br><span class="line">    <span class="keyword">if</span> (keccak256(_species) == keccak256(<span class="string">"kitty"</span>)) &#123;</span><br><span class="line">      newDna = newDna - newDna % <span class="number">100</span> + <span class="number">99</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 子类访问父类的内部方法注意private和internal的区别</span></span><br><span class="line">    _createZombie(<span class="string">"NoName"</span>, newDna);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">function <span class="title">feedOnKitty</span><span class="params">(uint _zombieId, uint _kittyId)</span> <span class="keyword">public</span> </span>&#123;</span><br><span class="line">    uint kittyDna;</span><br><span class="line">    (,,,,,,,,,kittyDna) = kittyContract.getKitty(_kittyId);</span><br><span class="line">    feedAndMultiply(_zombieId, kittyDna, <span class="string">"kitty"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>细心的同学在代码的开头就发现了solidity也可以像python那么import一个文件，接着有个<code>ZombieFeeding</code>的合约，此合约继承自<code>ZombieFactory</code>(继承的语法是使用is关键字)。<br>这里漏介绍了一段代码，那就是<code>KittyInterface</code>，这个看着像个合约，但仔细一看不是，这就是solidity中的接口，是不是有点java的感觉，有类名，方法名，只是没有方法具体的实现。</p>
<p><code>KittyInterface</code>只声明了迷恋猫的getKitty函数，其实迷恋猫合约里有很多函数，这里只声明使用到的函数，其它函数可以查看<a href="">合约地址</a>。使用这个接口，合约就知道其他合约的函数是怎样的，应该如何调用，以及可期待什么类型的返回值。</p>
<p>现在我们从java角度看下接口如何使用。在java中，我们先写一个接口类I，声明了个方法f。然后又写了个实现类Impl，并完成了f的具体逻辑。最后有个类O，调用了f，所以在O内有个对象I，并且被Impl初始化。上面的代码是不是也是这个套路，只不过<code>KittyInterface</code>的实现类被迷恋猫写好了，不在这个僵尸项目中。</p>
<p>到目前为止，我们已经写两个合约一个接口，我们只用编译和部署<code>ZombieFeeding</code>，就可以将这个合约部署到以太坊了。我们最终完成的这个合约继承自 ZombieFactory，因此它可以访问自己和父辈合约中的所有<code>public</code>方法。</p>
<p>说到访问权限上面<code>ZombieFactory</code>到代码有处需要改下，<code>_createZombie</code>方法是<code>private</code>，但是在<code>ZombieFeeding</code>中被调用了，此时会编译错误，因为<em>private</em>意味着它<strong>只能被合约内部调用</strong>；<em>internal</em>就像<strong>private但是也能被继承的合约调用</strong>，所以需要将<code>ZombieFactory._createZombie</code>改为<code>internal</code>。(顺便提下<em>external</em>只能从合约外部调用；最后<em>public</em> 可以在任何地方调用，不管是内部还是外部。)</p>
<p>最后我们来看一个与我们的刚部署的合约进行交互的例子， 这个例子使用了<code>JavaScript</code>和<code>web3.js</code>：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> abi = <span class="comment">/* abi generated by the compiler */</span></span><br><span class="line"><span class="keyword">var</span> ZombieFeedingContract = web3.eth.contract(abi)</span><br><span class="line"><span class="keyword">var</span> contractAddress = <span class="comment">/* our contract address on Ethereum after deploying */</span></span><br><span class="line"><span class="keyword">var</span> ZombieFeeding = ZombieFeedingContract.at(contractAddress)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 假设我们有我们的僵尸ID和要攻击的猫咪ID</span></span><br><span class="line"><span class="keyword">let</span> zombieId = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">let</span> kittyId = <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 要拿到猫咪的DNA，我们需要调用它的API。这些数据保存在它们的服务器上而不是区块链上。</span></span><br><span class="line"><span class="comment">// 如果一切都在区块链上，我们就不用担心它们的服务器挂了，或者它们修改了API，</span></span><br><span class="line"><span class="comment">// 或者因为不喜欢我们的僵尸游戏而封杀了我们</span></span><br><span class="line"><span class="keyword">let</span> apiUrl = <span class="string">"https://api.cryptokitties.co/kitties/"</span> + kittyId</span><br><span class="line">$.<span class="keyword">get</span>(apiUrl, function(data) &#123;</span><br><span class="line">  <span class="keyword">let</span> imgUrl = data.image_url</span><br><span class="line">  <span class="comment">// 一些显示图片的代码</span></span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 当用户点击一只猫咪的时候:</span></span><br><span class="line">$(<span class="string">".kittyImage"</span>).click(<span class="function"><span class="keyword">function</span>(<span class="params">e</span>) </span>&#123;</span><br><span class="line">  <span class="comment">// 调用我们合约的 `feedOnKitty` 函数</span></span><br><span class="line">  ZombieFeeding.feedOnKitty(zombieId, kittyId)</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 侦听来自我们合约的新僵尸事件好来处理</span></span><br><span class="line">ZombieFactory.NewZombie(<span class="function"><span class="keyword">function</span>(<span class="params">error, result</span>) </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (error) <span class="keyword">return</span></span><br><span class="line">  <span class="comment">// 这个函数用来显示僵尸:</span></span><br><span class="line">  generateZombie(result.zombieId, result.name, result.dna)</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>后续内容将在下一篇中继续介绍。</p>
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> Ethereum </tag>
            
            <tag> crypto </tag>
            
            <tag> cryptozombies </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ozone感悟]]></title>
      <url>http://bigdatadecode.club/Ozone%E6%84%9F%E6%82%9F.html</url>
      <content type="html"><![CDATA[<p>前面提到Ozone的原创团队对大规模Hadoop集群运维和优化有着丰富的经验，所以Ozone的设计中也体现了很多HDFS的优点，并屏蔽了一些HDFS的性能瓶颈。</p>
<p>HDFS目前的瓶颈主要在NN上，NN内存中维护着两个大对象，一个是NameSpace，另一个是BlocksMap，这两个是常驻内存而且随着集群存储的文件数和规模成线性增长，这就造成NN的内存占比越来越大，成为HDFS扩展的瓶颈。</p>
<p>那么Ozone是如何解决这些瓶颈呢？</p>
<a id="more"></a> 
<blockquote>
<p>NameSpace扩展性</p>
</blockquote>
<p>Ozone使用Ozone Manager的服务来管理namespace，其并不会把整个namespace存储在一个节点的内存中，而是只将一些正在使用的集合存储在内存中。(因为namespace具有本地引用性，所以可以这么搞)<!-- The key insight is that the namespace has locality of reference so we can store just the working set in memory. --></p>
<blockquote>
<p>Block Map扩展性</p>
</blockquote>
<p>这部分解决起来比较难，因为其不像namespace一样具有本地引用性，因为block map是dn周期性的把每个块的信息汇报给nn而来的。<em>Ozone将此问题委托给名为Hadoop Distributed DataStore(HDDS)的共享通用存储层来解决</em></p>
<p>接下来主要谈下Ozone中的container，全称为Storage Container。<em>Container类似于HDFS中block的概念，都是最小的容错单元，但Container并不是最小的写入单元，Container中包含若干个block，block为最小的写入单元。</em><br>有点像在block上又加了一层索引，<em>由原来的file-&gt;blocks变为file-&gt;containers-&gt;blocks</em>，这样blocks map就会少了一个量级，更方便维护，而且Ozone还为Container提供了一个专门的服务用与管理，这个服务是Storage Container Manager(SCM)。(SCM与Container两者的关系是Container对外提供块服务，SCM由底层存储向外提供服务，可以支持不同的上层系统。)</p>
<p>上面提到Container是最小的容错单元，是因为Ozone是把Container利用Raft进行3副本达到容错的效果，这样的话HDFS原先block副本的代码可以复用，基于pipeline方式进行写入。</p>
<p>个人感觉如果HDFS Federation是HDFS的2.0时代的话，我感觉Ozone就是HDFS的3.0时代，是对HDFS的又一次扩展。<br><!--
https://issues.apache.org/jira/secure/attachment/12895963/HDFS%20Scalability%20and%20Ozone.pdf”
--></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> Ozone </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop小文件利器Ozone调研]]></title>
      <url>http://bigdatadecode.club/Hadoop-Ozone.html</url>
      <content type="html"><![CDATA[<p>之前一篇文章介绍了在小文件合并方面的一些心得，<em>本篇介绍下Hadoop解决小文件的最新利器Ozone(本篇基于0.3.0-alpha版本)</em>。</p>
<h2 id="Ozone诞生的背景"><a href="#Ozone诞生的背景" class="headerlink" title="Ozone诞生的背景"></a>Ozone诞生的背景</h2><p>众所周知，HDFS是大数据存储系统，并在业界得到了广泛的使用。但是无论大集群还是小集群其扩展性都受NN的限制，<em>虽然HDFS可以通过Federation进行扩展，但是依然深受小文件和4亿个文件的困扰</em>。</p>
<p>于是分布式key-value存储系统Ozone诞生了，Ozone能够轻松管理小文件和大文件。(HDFS提供了类似POSIX的语义，Ozone的外观和行为更像一个Object存储系统。)</p>
<a id="more"></a>
<h2 id="Ozone"><a href="#Ozone" class="headerlink" title="Ozone"></a>Ozone</h2><p>Ozone是专门为Hadoop设计的可扩展的分布式对象存储系统。Hadoop生态中的其它组件如Spark、Hive和Yarn不需要任何修改就可以直接运行在Ozone之上。<em>Ozone的使用方式也较为丰富，可以通过命令行直接使用也有java客户端接口，而且接口支持RPC和REST。</em></p>
<p>Ozone由<em>volumes、buckets和Keys</em>组成，其中<br>Volumes只有管理员能够创建和删除，类似账号的概念，管理员一般都是给某个团队或者组织创建一个Volume。<br>Buckets有点像目录，<em>不过这个只能有一层，因为Buckets中不能包含其它Buckets</em>。Buckets是在Volume下，一个Volume可以包含n个Buckets，<em>但是Buckets下面只能是Keys</em>。<br>Keys就是具体的对象，在Buckets中是唯一的，其名字可以是任意字符串，其值就是需要存储的数据，也就是具体的文件。目前ozone对key的大小没有限制，bucket可以包含n个keys。</p>
<blockquote>
<p>有个小疑问–key就是对象，没有目录的概念，那么原hdfs某个目录下的n个小文件对应n个key？如何一次读取所有相关的key呢？比如hive加载某个分区呢？</p>
</blockquote>
<h2 id="设计原则"><a href="#设计原则" class="headerlink" title="设计原则"></a>设计原则</h2><p>Ozone是由一群对大规模Hadoop集群有着丰富运维和管理经验的工程师设计开发的，因此HDFS在实践中的优缺点深刻的影响着Ozone的设计和优化。</p>
<ol>
<li>Strongly Consistent</li>
<li>Architectural Simplicity<br>当系统出现问题时，一个简单的架构更容易定位，也容易调试。Ozone尽可能的将架构进行简单化，即使牺牲掉一些可扩展性，但是在扩展性上Ozone并不逊色。Ozone目前在单个集群上可以存储10亿个对象。</li>
<li>Layered Architecture<br>为了提高Ozone的扩展性，Ozone采用<em>分层的文件系统</em>。Ozone将<strong>namespace management与块和节点管理层分开</strong>，允许用户分别对其进行扩展。</li>
<li>Painless Recovery</li>
<li>Open Source in Apache</li>
<li>Interoperability with Hadoop Ecosystem<br>Ozone可以被现存的Hadoop生态和相关的应用(如 apache hive、apache spark 和传统的 mapreduce)使用，因此Ozone支持:</li>
</ol>
<blockquote>
<p>Hadoop Compatible FileSystem API(也叫OzoneFS) – hive、spark等可以使用OzoneFS API将Ozone作为存储层，而不需要做任务修改</p>
</blockquote>
<blockquote>
<p>Data Locality – Ozone像HDFS那样对上层应用支持数据本地性。</p>
</blockquote>
<blockquote>
<p>与HDFS并行部署 – Ozone可以部署在现有的Hadoop集群中, 并且可以与HDFS共享存储磁盘。</p>
</blockquote>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>在架构上Ozone由三部分组成，分别为<code>Ozone Manager</code>、<code>Storage Container Manager</code>和<code>Datanodes</code><!--，在目前的版本中还有一个组件`Hadoop Distributed Data Store`-->。架构图如下:<br><img src="/blogimgs/ozone调研/OzoneOverview.png" alt="OzoneOverview" title="OzoneOverview"></p>
<blockquote>
<p>Ozone Manager(OM) </p>
</blockquote>
<p>OzoneManager是一个server服务，<em>主要负责Ozone的namespace，记录所有的volume, bucket和key操作</em>。<strong>有点类似HDFS的namenode</strong><br>Ozone由<em>volumes、buckets和Keys</em>组成，其中每个volume是一个namespace的根节点(<em>与HDFS不同，HDFS只提供了一个根节点</em>)，所以<em>整个Ozone的namespace是一个volumes的集合或者是一个由类似HDFS那样的树节点组成的森林</em>。这使得OM可以轻松的扩展为多个OM(此功能正在开发)。<br>OM中也存储了Ozone的一些元数据信息，这些元数据信息包括volumes、buckets和keys，<em>底层通过Ratis扩展元数据的副本数来实现HA</em>。</p>
<blockquote>
<p>Storage Container Manager(SCM) </p>
</blockquote>
<p>类似HDFS中的block manager，是Ozone中一个非常重要的组件，用来管理container的，<em>为OM提供基于block和container的服务</em>。<br><strong>container是由一些block组成的集合</strong>，这些block相互之间没有关系。<br>SCM和数据节点协同工作以维护群集所需的复制级别</p>
<p>关于SCM的作用通过一个使用实例来说明下 – 由客户端调用<code>putKey(keyName, data, pipeline type, replication count)</code>发起一个putKey操作</p>
<p><strong>参数说明</strong><br>keyName是指文件的名字。data是指要写入的数据。pipeline type指block的副本策略，Ozone目前支持Stand Alone和Ratis两种策略。replication count是指block有多少个副本<br>一般情况下pipeline type和replication count不用指定，直接使用模式的就行。</p>
<p><em>整个流程为OM收到putKey请求，向SCM发送一个请求，请求一个包含特定属性的pipeline实例。例如客户端要求Ratis存储策略并且副本数是3，则OM请求SCM返回一个满足此特性的datanode set。如果SCM能够实例化这样一个pipeline(也就是一个datanode set)，则将这些dn返回给OM。OM则存储这些信息并将此信息包装成一个元组{BlockID, ContainerName, and Pipeline}。**</em>这里也有点类似HDFS写流程<strong><br>如果SCM并没有找到一组datanode set来满足clinet的要求，</strong>则SCM创建一个逻辑管道，然后返回它**</p>
<p>从上面的调用过程中可以看出OM与SCM的关系，SCM作为block manager。当client向OM请求datanode set写数据数据时，OM需要向SCM请求block。block从SCM以pipeline的形式返回，此时pipeline是由参与block副本的一组datanode。<br><!-- So OM is dependent on SCM for reading and writing of Keys. However, OM is independent of SCM while doing metadata operations like ozone volume or bucket operations. --><br>SCM主要用来管理blocks、containers和pipelines，为了返回正常可用的pipelines，SCM必须找到node的健康状态，所以SCM也会监听datanode发来的心态，扮演着datanode manager的角色。</p>
<p>SCM内部结构为:<br><img src="/blogimgs/ozone调研/SCMBlockDiagram.png" alt="SCM" title="SCM"></p>
<p>Block：block数据块对象，真实存储数据的对象，可以拥有多个副本块。<br>Container：在逻辑上存储的是Block块对象集合。<br>Pipeline：SCM允许2种Pipeline方式实现多副本：单副本的Standaline模式和多副本的Ratis方式。<br>Pool：一组特定的数据节点称为一个pool。将节点按pool分组是为了方便日常的维护升级操作，也是为了扩展性的考虑。<br>Node：物理存储数据的地方。</p>
<blockquote>
<p>Datanodes</p>
</blockquote>
<p>如果是基于HDFS部署的Ozone也就是Ozone数据节点功能以插件的功能运行在HDFS的datanode中，则就指HDFS的datanode。Ozone也可以单独部署，此时指运行Ozone数据节点的守护进程。<strong>DataNode中以Container基本存储单元</strong></p>
<blockquote>
<p>Ozone Client</p>
</blockquote>
<p>Ozone client在Ozone内部是一个对外开放使用的模块，比如说Ozone相关的shell命令会触发到ozone client，这就是图中显示的Ozone Cli。<br>Rest Handler是一个钩子，能够做到RPC和Restful通信方式的一键切换。<em>Ozone client能够支持2种方式的通信：RPC方式和Restful接口的方式。</em><br>Freon是Ozone内部的性能测试工具。</p>
<blockquote>
<p>OzoneFileSysyem</p>
</blockquote>
<p>Ozone为了兼容其它框架体系，根据自身独特的数据特点，实现了文件系统接口，称为OzoneFileSystem。这样的话，用户可以以通用的方式来使用Ozone内部的文件对象。在程序上无需做兼容性的改动。</p>
<blockquote>
<p>Hadoop Distributed Data Store</p>
</blockquote>
<p>上面的架构图中只剩下Hadoop Distributed Data Store没有介绍了，其实<em>Hadoop Distributed Data Store(HDDS)是由Containers、Ratis和SCM组成的，是一个没有全局命名空间的分布式块存储层</em>。</p>
<p>DataNodes3个组成一组，每组都是一个Ratis副本链，每个链都可以打开多个containers进行操作。</p>
<p>SCM定期从datanode上接受报告，通知每个节点上打开和关闭的容器副本。基于每次报告的内容制定一些决定，例如如何分配新container、关闭打开的containers和在磁盘/数据丢失时重新复制封闭容器。</p>
<p>SCM Clients可以向SCM请求新块的分配节点，然后将块数据写入分配的容器中。Clients还可以读取open/closed状态的容器，并且可以删除块。<em>关键的一点是, HDDS 并不关心单个容器的内容。内容完全由SCM管理</em>。</p>
<p>HDDS细节图如下:<br><img src="/blogimgs/ozone调研/HDDS.png" alt="HDDS" title="HDDS"></p>
<h2 id="部署及测试"><a href="#部署及测试" class="headerlink" title="部署及测试"></a>部署及测试</h2><p>Ozone与HDFS结合的话需要基于Hadoop3.0，所以需要先部署Hadoop3.0，具体部署细节在此略去不表。</p>
<p>从官方下载Hadoop3.0和Ozone的安装包(由于官方build的Hadoop3.0中并没有Ozone相关的内容，所以需要单独下载Ozone的安装包)，将Ozone的相关内容复制到Hadoop的home目录。命令如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在Ozone的home目录下执行</span></span><br><span class="line">cp libexec/ozone-config.sh /opt/soft/hadoop/libexec</span><br><span class="line">cp -r share/ozone /opt/soft/hadoop/share</span><br><span class="line">cp -r share/hadoop/ozoneplugin /opt/soft/hadoop/share/hadoop/</span><br></pre></td></tr></table></figure>
<p>利用Ozone的命令生成conf文件，<code>ozone genconf etc/hadoop</code>，此命令会生成ozone-site.xml文件，修改配置之后复制到Hadoop3.0的conf目录中。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ozone.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tag</span>&gt;</span>OZONE, REQUIRED<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      Status of the Ozone Object Storage service is enabled.</span><br><span class="line">      Set to true to enable Ozone.</span><br><span class="line">      Set to false to disable Ozone.</span><br><span class="line">      Unless this value is set to true, Ozone services will not be started in</span><br><span class="line">      the cluster.</span><br><span class="line"></span><br><span class="line">      Please note: By default ozone is disabled on a hadoop cluster.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ozone.om.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tag</span>&gt;</span>OM, REQUIRED<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The address of the Ozone OM service. This allows clients to discover</span><br><span class="line">      the address of the OM.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ozone.metadata.dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/opt/hadoop/ozone<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tag</span>&gt;</span>OZONE, OM, SCM, CONTAINER, REQUIRED, STORAGE<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      Ozone metadata is shared among OM, which acts as the namespace</span><br><span class="line">      manager for ozone, SCM which acts as the block manager and data nodes</span><br><span class="line">      which maintain the name of the key(Key Name and BlockIDs). This</span><br><span class="line">      replicated and distributed metadata store is maintained under the</span><br><span class="line">      directory pointed by this key. Since metadata can be I/O intensive, at</span><br><span class="line">      least on OM and SCM we recommend having SSDs. If you have the luxury</span><br><span class="line">      of mapping this path to SSDs on all machines in the cluster, that will</span><br><span class="line">      be excellent.</span><br><span class="line"></span><br><span class="line">      If Ratis metadata directories are not specified, Ratis server will emit a</span><br><span class="line">      warning and use this path for storing its metadata too.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ozone.scm.client.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tag</span>&gt;</span>OZONE, SCM, REQUIRED<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The address of the Ozone SCM client service. This is a required setting.</span><br><span class="line"></span><br><span class="line">      It is a string in the host:port format. The port number is optional</span><br><span class="line">      and defaults to 9860.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ozone.scm.names<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>localhost<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tag</span>&gt;</span>OZONE, REQUIRED<span class="tag">&lt;/<span class="name">tag</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span></span><br><span class="line">      The value of this property is a set of DNS | DNS:PORT | IP</span><br><span class="line">      Address | IP:PORT. Written as a comma separated string. e.g. scm1,</span><br><span class="line">      scm2:8020, 7.7.7.7:7777.</span><br><span class="line">      This property allows datanodes to discover where SCM is, so that</span><br><span class="line">      datanodes can send heartbeat to SCM.</span><br><span class="line">    <span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>ozone.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>需要将ozone相关的jar引入到classpath中，在user home目录下增加.hadooprc文件</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim ~/.hadooprc</span><br><span class="line">HADOOP_CLASSPATH=/opt/soft/hadoop/share/hadoop/yarn/*.jar:/opt/soft/hadoop/share/hadoop/tools/*.jar:/opt/soft/hadoop/share/hadoop/ozoneplugin/*.jar:/opt/soft/hadoop/share/hadoop/ozone/*.jar:/opt/soft/hadoop/share/hadoop/mapreduce/*.jar:/opt/soft/hadoop/share/hadoop/hdfs/*.jar:/opt/soft/hadoop/share/hadoop/common/*.jar:/opt/soft/hadoop/share/hadoop/client/*.jar:/opt/soft/hadoop/share/hadoop/yarn/lib/*.jar:/opt/soft/hadoop/share/hadoop/tools/lib/*.jar:/opt/soft/hadoop/share/hadoop/ozoneplugin/lib/*.jar:/opt/soft/hadoop/share/hadoop/ozone/lib/*.jar:/opt/soft/hadoop/share/hadoop/mapreduce/lib/*.jar:/opt/soft/hadoop/share/hadoop/hdfs/lib/*.jar:/opt/soft/hadoop/share/hadoop/common/lib/*.jar:/opt/soft/hadoop/share/hadoop/client/lib/*.jar</span><br></pre></td></tr></table></figure>
<p>如果将Ozone运行在HDFS之上的话，需要在hdfs-site.xml中添加如下内容:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;dfs.datanode.plugins&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;org.apache.hadoop.ozone.HddsDatanodeService&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>此时就可以启动相关的服务了，首先启动namenode和datanode，命令为<code>hdfs --daemon start namenode</code>和<code>hdfs --daemon start datanode</code><br>其次启动scm和om，<em>要先启动scm再启动om，而且在第一次启动的时候要先初始化</em>，命令如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ozone scm --init</span><br><span class="line">ozone --daemon start scm</span><br><span class="line">ozone om --init</span><br><span class="line">ozone --daemon start om</span><br></pre></td></tr></table></figure>
<p><em>一切正常就可以在OM的UI上查看信息，OM默认端口上9874，地址为<a href="http://omserver:9874/" target="_blank" rel="noopener">http://omserver:9874/</a></em></p>
<p>我们可以运行一些命令来感受下Ozone，<br>创建一个volume并且查看</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">ozone sh volume create --user=work /hive-ozone</span><br><span class="line"></span><br><span class="line">ozone sh volume list --user work</span><br><span class="line">SLF4J: Class path contains multiple SLF4J bindings.</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:<span class="regexp">/opt/</span>soft/hadoop<span class="number">-3.2</span><span class="number">.0</span>/share/hadoop/common/lib/slf4j-log4j12<span class="number">-1.7</span><span class="number">.25</span>.jar!<span class="regexp">/org/</span>slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:<span class="regexp">/opt/</span>soft/hadoop<span class="number">-3.2</span><span class="number">.0</span>/share/ozone/lib/slf4j-log4j12<span class="number">-1.7</span><span class="number">.25</span>.jar!<span class="regexp">/org/</span>slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: Found binding <span class="keyword">in</span> [jar:file:<span class="regexp">/opt/</span>soft/hadoop<span class="number">-3.2</span><span class="number">.0</span>/share/hadoop/ozone/lib/slf4j-log4j12<span class="number">-1.7</span><span class="number">.25</span>.jar!<span class="regexp">/org/</span>slf4j/impl/StaticLoggerBinder.class]</span><br><span class="line">SLF4J: See http:<span class="comment">//www.slf4j.org/codes.html#multiple_bindings for an explanation.</span></span><br><span class="line">SLF4J: Actual binding is <span class="keyword">of</span> type [org.slf4j.impl.Log4jLoggerFactory]</span><br><span class="line"><span class="number">2019</span><span class="number">-01</span><span class="number">-29</span> <span class="number">15</span>:<span class="number">33</span>:<span class="number">52</span>,<span class="number">786</span> WARN util.NativeCodeLoader: Unable to load native-hadoop library <span class="keyword">for</span> your platform... using builtin-java classes where applicable</span><br><span class="line">[ &#123;</span><br><span class="line">  <span class="string">"owner"</span> : &#123;</span><br><span class="line">    <span class="string">"name"</span> : <span class="string">"work"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"quota"</span> : &#123;</span><br><span class="line">    <span class="string">"unit"</span> : <span class="string">"TB"</span>,</span><br><span class="line">    <span class="string">"size"</span> : <span class="number">1048576</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="string">"volumeName"</span> : <span class="string">"hive-ozone"</span>,</span><br><span class="line">  <span class="string">"createdOn"</span> : <span class="string">"星期二, 29 一月 2019 07:32:27 GMT"</span>,</span><br><span class="line">  <span class="string">"createdBy"</span> : <span class="string">"work"</span></span><br><span class="line">&#125; ]</span><br></pre></td></tr></table></figure>
<p>再来创建一个bucket，<code>ozone sh bucket create /hive-ozone/bucket-test</code></p>
<p>创建完volume和bucket，就可以上传文件了，也就是创建一个key，Ozone命令为<code>ozone sh key put /hive-ozone/bucket-test/hadoop.log logs/hadoop.log</code>，<br>也可以像hdfs shell那样上传key，命令为<code>ozone fs -put logs/hadoop.log o3fs://bucket-test.hive-ozone/t.log</code></p>
<!--
各用户之间如何共享数据
Ozone如何自动识别小文件？
-->
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://cwiki.apache.org/confluence/display/HADOOP/Building+Ozone" target="_blank" rel="noopener">https://cwiki.apache.org/confluence/display/HADOOP/Building+Ozone</a><br><a href="https://hortonworks.com/blog/introducing-apache-hadoop-ozone-object-store-apache-hadoop/" target="_blank" rel="noopener">https://hortonworks.com/blog/introducing-apache-hadoop-ozone-object-store-apache-hadoop/</a><br><a href="https://hortonworks.com/blog/apache-hadoop-ozone-object-store-overview/" target="_blank" rel="noopener">https://hortonworks.com/blog/apache-hadoop-ozone-object-store-overview/</a><br><a href="https://hadoop.apache.org/ozone/docs/0.3.0-alpha/index.html" target="_blank" rel="noopener">https://hadoop.apache.org/ozone/docs/0.3.0-alpha/index.html</a><br><a href="https://hortonworks.com/blog/apache-hadoop-ozone-object-store-architecture/" target="_blank" rel="noopener">https://hortonworks.com/blog/apache-hadoop-ozone-object-store-architecture/</a><br><a href="https://blog.csdn.net/Androidlushangderen/article/details/78168479" target="_blank" rel="noopener">https://blog.csdn.net/Androidlushangderen/article/details/78168479</a></p>
<!--

To scale Ozone to billions of files, we needed to solve two bottlenecks that exist in HDFS.

2.1. NAMESPACE SCALABILITY
We can no longer store the entire namespace in the memory of a single node. The key insight is that the namespace has locality of reference so we can store just the working set in memory. The namespace is managed by a service called the Ozone Manager.

2.2. BLOCK MAP SCALABILITY
This is a harder problem to solve. Unlike the namespace, the block map does not have locality of reference since storage nodes (DataNodes) periodically send block reports about each block in the system. Ozone delegates this problem to a shared generic storage layer called Hadoop Distributed DataStore (HDDS).
-->
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> 小文件 </tag>
            
            <tag> Ozone </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS小文件合并实战]]></title>
      <url>http://bigdatadecode.club/HDFS-little-file-action.html</url>
      <content type="html"><![CDATA[<p>HDFS是一个大数据存储系统，主要面向的场景是一次写入多次读取，大文件。但是在实际使用过程中由于各种原因集群中总是充斥着各种小文件，而且数据惊人。无论社区还是公司都在积极解决这个问题。(为什么要解决小文件，这个问题我想看到这篇文章的人应该都知道啊!)</p>
<p>无论你怎么优化集群，指定各种规范，让业务方优化程序，小文件总是无法避免的。</p>
<a id="more"></a>
<p>都说解决一个问题，不能只从表面去解决，需要从根上彻底解决，需要根据产生问题的n个原因去解决，但是这种方式对目前小文件这个问题上确实不好办。即使你知道小文件产生过多的原因很大一部分归结于用户的应用程度在执行的时候没有很好的预估写出数据量的规模，导致写出过多的小文件。你依然无法从根上解决这个问题，因为你要想从根上解决这个问题需要用户对自己程序的逻辑和数据有较高的了解，而且用户的水平也参差不齐，<em>最最重要的是用户认为这是尼玛平台该优化的事，干毛浪费我的时间给你搞</em>。所以种种原因造成收益较少。</p>
<p>不能从根上解决这个问题，那就只能从面上解决这个问题了。怎么解决？那就是定期对小文件进行合并(是不是比较low，嘿嘿)。</p>
<h2 id="合并方案"><a href="#合并方案" class="headerlink" title="合并方案"></a>合并方案</h2><ol>
<li>Hadoop Archives<br>很早提出的一种解决方案，把历史数据进行归档。<em>个人感觉比较鸡肋，不怎么好用</em>。</li>
<li>SequenceFile<br>SequenceFile是hadoop的一种二进制文件，随着Hadoop的问世就出现了，当时主要用来存储一些mr的中间结果。因为其也是key/value形式存储的，所以现在也有很多公司使用SequenceFile来存储小文件，key是文件名，value是内容。<em>这种方式较依赖使用的场景，感觉不是一个普适的解决方案</em>。</li>
<li>业务方优化代码<br>业务方在代码中根据数据量控制分区的个数，直接从源头解决小文件问题。<em>这种方案太理想，进度无法把控，而且小文件总会在新上线的程序中复现</em></li>
<li>平台定期合并<br>编写合并小文件的小工具，对集群中小文件top的目录进行定期自动合并。<em>实现方式较简单，而且容易把控，主动权在平台手里</em></li>
<li>黑科技<br>实时关注业界动态，期待社区提供黑科技完美解决小文件问题。<em>目前社区提供了一个Ozone对象存储系统，还不太完善，持续关注中，随后写个简单的调研结果</em>。</li>
</ol>
<h2 id="合并实践"><a href="#合并实践" class="headerlink" title="合并实践"></a>合并实践</h2><p>利用工具合并小文件时，需要注意的是不同文件类型的合并方式不一样，所以在合并之前需要知道文件的类型从而选择合适的方法去合并。</p>
<p>目前平台中的文件类型主要为3中，分别为普通文本、lzo压缩文件和parquet列存储文件，所以自动识别文件类型也就是自动文件的编码格式。</p>
<blockquote>
<p>自动识别文件类型</p>
</blockquote>
<ol>
<li>根据压缩格式中序列化的特殊信息识别压缩格式，如parquet文件的头为’PAR1’</li>
<li>根据文件的后缀名进行识别，如lzo的文件都有后缀 </li>
</ol>
<p><strong>个人感觉识别文件类型最好的方法是通过后缀名，通过改Hadoop和Hive的代码，对普通文本增加后缀.txt，parquet文件增加后缀.parquet</strong>，目前暂时使用的通过读取文件头信息的方式来识别文件类型，只所以没有使用增加后缀的方式是因为这种方式需要进行较全面的测试，为了快速验证合并小文件的可行性选择了识别文件头的方式。</p>
<blockquote>
<p>合并方式</p>
</blockquote>
<ol>
<li>普通文本和lzo文件利用<code>CombineFileInputFormat</code>将同一目录下的小文件合并读取，然后调用<code>CombineTextInputFormat.setMaxInputSplitSize</code>根据读取文件的大小进行切分，然后直接通过map输出，达到小文件根据期望输出文件的大小进行合并的效果。</li>
<li>parquet列存储文件有点特殊，目前最好的方法是使用spark api进行读取，然后通过<code>repartition</code>进行合并。repartition的个数可以通过输入文件的总大小和期望输出文件的大小进行预计算而得。</li>
</ol>
<p>这样初期由平台统一进行合并(<em>这里合并只能对历史文件进行合并</em>)，随后可以慢慢督促各个业务进行优化，先解决燃眉之急。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> 小文件 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Merkle Patricia Tree(MPT)]]></title>
      <url>http://bigdatadecode.club/Merkle-Patricia-Tree.html</url>
      <content type="html"><![CDATA[<p>区块链一个重要的亮点就是防篡改，那么它是怎么做到防篡改的呢？其中一个重要的知识点就是Merkle Patricia Tree(MPT)，本篇就来解析下何为MPT。</p>
<p>MPT是一种加密认证的数据结构，它融合了Merkle树和Patricia Trie树(基数树/压缩前缀树)两种数据类型的优点。</p>
<p>则在介绍MPT树之前先介绍下Merkle树(默克尔树)、Trie树(前缀树)和Patricia Trie(基数树/压缩前缀树)，介绍Trie树是因为Patricia Trie是基于Trie树衍化来的。</p>
<a id="more"></a>
<h2 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h2><p>Trie树又称前缀树或字典树，是一种检索树，使用一个有序的树结构存储一个动态数据集或者关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙相对于当前节点都有相同的前缀，而根节点为空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。</p>
<p>Trie树中，key是从树根到对应value得真实的路径。即从根节点开始，key中的每个字符会标识走那个子节点从而到达相应value。Value被存储在叶子节点，是每条路径的终止。假如key来自一个包含N个字符的字母表，那么树中的每个节点都可能会有多达N个孩子，树的最大深度是key的最大长度。看个例子画个图就了然了。<br>例子：关键字集合{“a”, “to”, “tea”, “ted”, “i”, “in”, “inn”}，此集合转为Trie树为<br><img src="/blogimgs/MPT/trie.png" alt="tire" title="Trie树"></p>
<p>不理想情况下，数据集中存在一个很长的key，而这个key与其它key又没有太多的公共前缀，这就造成整个树的深度会加大，需要存储多个节点，存储比较稀疏而且极不平衡。<br>例子：关键字集合{“algori”, “to”, “tea”, “ted”, “i”, “in”, “inn”}，此集合转为Trie树为<br><img src="/blogimgs/MPT/trie1.png" alt="稀疏Trie树" title="稀疏Trie树"></p>
<h2 id="Patricia-Trie树"><a href="#Patricia-Trie树" class="headerlink" title="Patricia Trie树"></a>Patricia Trie树</h2><p>既然Trie树在某些情况下存储空间利用率不高，那就给压缩下，然后就出现了Patricia Trie树。</p>
<p>Patricia Trie树是一种空间使用率经过优化的Trie树。与Trie树不同的是，Patricia Trie 里如果存在一个父节点只有一个子节点，那么这个父节点将与其子节点合并。这样压缩存储可以减少Trie树中不必要的深度，大大加快搜索节点速度。<br>如下图所示<br><img src="/blogimgs/MPT/patricia.png" alt="Patricia Trie树" title="Patricia Trie树"></p>
<h2 id="Merkle树"><a href="#Merkle树" class="headerlink" title="Merkle树"></a>Merkle树</h2><p>Merkle树是由计算机科学家Ralph Merkle在很多年前提出的，并以他本人的名字来命名，是一种树形数据结构，可以是二叉树，也可以是多叉树。<br>它由若干叶节点、中间节点和一个根节点构成。最下面的叶节点包含基础数据，每个中间节点是它子节点的散列，根节点是它的子节点的散列，代表了Merkle树的根部。</p>
<p>由于Merkle树是自底向上构建的，而且除叶子结点之外的其它节点都是其子节点的散列，这样每个节点的值发生变化都会一层一层的向上反映，最终在根节点上表现出来。也就是说只要对比两个Merkle树的根节点是否相等就能得到两份数据集是否一样，而且还可以验证Merkle树的某个分支。</p>
<p>比特币使用Merkle树存储一个区块中的所有交易信息，一是为了防篡改，因为散列是向上的，伪造任何一个节点都会引起上层节点的改动，最终导致根节点的变化。二是为了允许区块的数据可以零散的传送，即节点可以从一个节点下载区块头，从另外的源下载与其相关的树的其他部分，而依然能够确认所有的数据都是正确的。</p>
<p>看下图的例子，首先将L1-L4四个单元数据散列化，然后将散列值存储至相应的叶子节点。这些节点是Hash0-0, Hash0-1, Hash1-0, Hash1-1，然后将相邻两个节点的散列值合并成一个字符串，然后计算这个字符串的散列，得到的就是这两个节点的父节点的散列值。<br><img src="/blogimgs/MPT/merkle.png" alt="merkle树" title="merkle树"></p>
<p>在比特币网络中，merkle树被用来归纳一个区块中的所有交易，同时生成整个交易集合的数字指纹。此外，由于merkle树的存在，使得在比特币这种公链的场景下，扩展一种“轻节点”实现简单支付验证变成可能。</p>
<p>知道了Merkle树在比特币中的应用，那么他是怎么构成呢？现在就简单看下其构成。<em>它由一组叶节点、一组中间节点和一个根节点构成</em>。最下面的叶节点包含基础数据，每个中间节点是它的子节点的散列，根节点是它的子节点的散列，代表了Merkle树的根部 。</p>
<blockquote>
<p>Merkle树具有下列特性:</p>
<ol>
<li>每个数据集对应一个唯一合法的根散列值。</li>
<li>很容易更新、添加或者删除树节点，以及生成新的根散列值 。 </li>
<li>不改变根散列值的话就没有办法修改树的任何部分，所以如果根散列值被包括在签名的文档或有效区块中，就可以保证这棵树的正确性。</li>
<li>任何人可以只提供一个到特定节点的分支，并通过密码学方法证明拥有对应内容的节点确实在树里 。</li>
</ol>
</blockquote>
<h2 id="Merkle-Patricia-Tree"><a href="#Merkle-Patricia-Tree" class="headerlink" title="Merkle Patricia Tree"></a>Merkle Patricia Tree</h2><p>叨叨了那么多，本篇的主角终于出来了。<br>Merkle Patricia Tree结合了Merkle树和Patricia树的特点，并针对以太坊的使用场景进行了一些改进。</p>
<p>首先，为了保证树的加密安全，<em>每个节点通过它的散列值被引用</em>，则根节点是一层一层散列向上收敛而得，被称为整棵树的加密签名，如果一棵给定 Trie树的根散列值是公开的，那么所有人都可以提供一种证明，即通过提供每步向上的路径证明特定的key是否含有特定的值。<em>在当前的以太坊版本中，MPT存储在LevelDB数据库中</em>。</p>
<p>其次，MPT树引人了很多节点类型来提高效率。包括以下4种:</p>
<ol>
<li><p>空节点(NULL) – represented as the empty string</p>
<blockquote>
<p>简单的表示空，在代码中是一个空串。</p>
</blockquote>
</li>
<li><p>叶子节点(leaf) – a 2-item node [encodedPath, value]</p>
<blockquote>
<p>表示为[key,value]的一个键值对，<strong>其中key是key的一种特殊十六进制编码(MP编码)， value是value的RLP编码</strong>。</p>
</blockquote>
</li>
<li><p>分支节点(branch) – a 17-item node [v0 … v15, vt]</p>
<blockquote>
<p>因为MPT树中的key被编码成一种特殊的16进制的表示，再加上最后的value，所以<strong>分支节点是一个长度为17的list</strong>，前16个元素对应着key中的16个可能的十六进制字符，<strong>如果有一个[key,value]对在这个分支节点终止，最后一个元素代表这个值value</strong>，即分支节点既可以是搜索路径的终止也可以是路径的中间节点。</p>
</blockquote>
</li>
<li><p>扩展节点(extension) – a 2-item node [encodedPath, key]<br>也是[key，value]的一个键值对，但是这里的value是其他节点的hash值，这个hash可以被用来查询数据库中的节点。也就是说通过hash链接到其他节点。</p>
</li>
</ol>
<p>下面看个以太坊中MPT树的官方示例<br><img src="/blogimgs/MPT/e-mpt.png" alt="MPT实例" title="MPT实例"></p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>看到这里你肯定依然是一脸懵逼，(不要问我我是怎么知道的。。。。)，接下来我们就来根据一批数据构造一个MPT树，这样你会理解一些。<br>但是在讲例子之前，还得先介绍几种编码方式，要不看例子的时候对key的取值会比较懵。</p>
<h4 id="key编码"><a href="#key编码" class="headerlink" title="key编码"></a>key编码</h4><p>在以太坊中，MPT树的key值共有三种不同的编码方式，分别为:</p>
<ol>
<li>Raw编码(原生的字符)</li>
<li>Hex编码(扩展的16进制编码)</li>
<li>Hex-Prefix编码(16进制前缀编码)</li>
</ol>
<blockquote>
<p>Raw编码</p>
</blockquote>
<p>Raw编码就是原生的key值，不做任何改变。这种编码方式的key，是MPT对外提供接口的默认编码方式。<br>例如key为”dog”，value为”puppy”的数据项，其key的Raw编码就是[‘d’, ‘o’, ‘g’]，换成ASCII表示方式就是[64, 6f, 67] : dog =&gt; ‘puppy’</p>
<blockquote>
<p>Hex编码</p>
</blockquote>
<p>Hex编码就是把一个8位的字节数据根据高4位和低4位拆解为两个4位的数字，然后两个数字的高4位都补0，最后将补完之后的两个字节编码为16进制。<br>这里需要注意的是<em>key对应的值为真实的数据项</em>，即是一个有意义的kv对，比如dog-&gt;puppy(也就是叶子结点)，而不是key-&gt;节点hash(也就是分支节点)，则在末尾添加一个ASCII值为16(十六进制为0x10)的字符串作为terminator。如果是<em>分支节点则不加任何字符</em>。<br>例如key为”dog”，value为”puppy”的数据项，其key中d(100)的二进制编码为01100100，拆解为两个4位的数字为0110和0100，高位补0之后的二进制为00000110和00000100，16进制为6和4，依次编码o和g。又因为dog对应的value是真实的数据项，则在末尾添加16。最后最终的Hex编码为[ 6, 4, 6, 15, 6, 7, 16 ] : dog =&gt; ‘puppy’</p>
<blockquote>
<p>Hex-Prefix编码</p>
</blockquote>
<p>首先根据名字得知这是一个前缀编码，是在原key的基础上加上一些标识作为前缀，其次我们看下这种编码方式的目的：</p>
<ol>
<li>区分leaf和extension</li>
<li>把奇数路径变成偶数路径</li>
</ol>
<p>则这个前缀的生成肯定与leaf、extension和key的奇偶相关了，下面看下编码步骤为:</p>
<ol>
<li>先按Hex对key进行编码</li>
<li>key的结尾如果是0x10(也就是16)，则去掉这个终止符</li>
<li>key之前补一个四元组，这个四元组<em>第0位区分奇偶信息，第1位区分节点类型</em>，表格表示如下</li>
</ol>
<table>
<thead>
<tr>
<th>node type</th>
<th>path length</th>
<th>prefix</th>
<th>hexchar</th>
</tr>
</thead>
<tbody>
<tr>
<td>extension</td>
<td>even</td>
<td>0000</td>
<td>0x0</td>
</tr>
<tr>
<td>extension</td>
<td>odd</td>
<td>0001</td>
<td>0x1</td>
</tr>
<tr>
<td>leaf</td>
<td>even</td>
<td>0010</td>
<td>0x2</td>
</tr>
<tr>
<td>leaf</td>
<td>odd</td>
<td>0011</td>
<td>0x3</td>
</tr>
</tbody>
</table>
<ol start="4">
<li><em>如果输入key的长度是偶数</em>，则在之前的四元组后再添加一个四元组0x0</li>
<li>将原来的key内容压缩，将分离的两个byte以高四位低四位进行合并</li>
</ol>
<blockquote>
<p>这里有个名词解释下，四元组是四个bit位的组合(例如二进制表达的0010就是一个四元组)，其中Nibble就是一个四元组，是key的基本单元。</p>
</blockquote>
<p>例如key为”dog”，value为”puppy”的数据项，则首先对dog进行Hex编码[ 6, 4, 6, 15, 6, 7, 16 ]，然后按照上面的步骤进行编码，dog的Hex编码末尾是16，去掉终止符为[ 6, 4, 6, 15, 6, 7 ]，准备在key前补四元组，dog为叶子节点并且编码之后的长度为6是偶数，所以四元组为0010(0x2)，此时到了第4步，key编码之后的长度是偶数，则在<em>前一个四元组(0x2)之后再添加一个四元组0x0</em>，最终的前缀为0x20。最后将原来的key内容进行高低四位合并，最终的Hex-Prefix编码是[ 0x20, 0x64, 0x6f, 0x67 ]</p>
<blockquote>
<p>以上三种编码方式的转换关系为：</p>
</blockquote>
<p>Raw编码: 原生的key编码，是MPT对外提供接口中使用的编码方式，当数据项被插入到树中时，Raw编码被转换成Hex编码<br>Hex编码: 16进制扩展编码，用于对内存中树节点key进行编码，当树节点被持久化到数据库时，Hex编码被转换成HP编码<br>HP编码: 16进制前缀编码，用于对数据库中树节点key进行编码，当树节点被加载到内存时，HP编码被转换成Hex编码</p>
<h4 id="构造过程"><a href="#构造过程" class="headerlink" title="构造过程"></a>构造过程</h4><p>接下来我们就实际操作下：<br>假设我们有一个树有这样一些kv对(‘dog’, ‘puppy’), (‘horse’, ‘stallion’), (‘do’, ‘verb’), (‘doge’, ‘coin’)。<br>首先，我们将key转成Hex编码，如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 64 6f</span></span><br><span class="line">[ 6, 4, 6, 15, 16 ] : <span class="keyword">do</span> =&gt; <span class="string">'verb'</span></span><br><span class="line"><span class="comment">#64 6f 67</span></span><br><span class="line">[ 6, 4, 6, 15, 6, 7, 16 ] : dog =&gt; <span class="string">'puppy'</span></span><br><span class="line"><span class="comment">#64 6f 67 65</span></span><br><span class="line">[ 6, 4, 6, 15, 6, 7, 6, 5, 16 ] : doge =&gt; <span class="string">'coin'</span></span><br><span class="line"><span class="comment">#68 6f 72 73 65</span></span><br><span class="line">[ 6, 8, 6, 15, 7, 2, 7, 3, 6, 5, 16 ] : horse =&gt; <span class="string">'stallion'</span></span><br></pre></td></tr></table></figure>
<p>其构造MPT树如图：<br><img src="/blogimgs/MPT/mpt.png" alt="MPT" title="MPT"></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">rootHash: [ &lt;16&gt;, hashA ]</span><br><span class="line">hashA:    [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashB, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashC, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt; ]</span><br><span class="line">hashC:    [ &lt;20 6f 72 73 65&gt;, <span class="string">'stallion'</span> ]</span><br><span class="line">hashB:    [ &lt;00 6f&gt;, hashD ]</span><br><span class="line">hashD:    [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashE, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, <span class="string">'verb'</span> ]</span><br><span class="line">hashE:    [ &lt;17&gt;, hashF ]</span><br><span class="line">hashF:    [ &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, hashG, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, <span class="string">'puppy'</span> ]</span><br><span class="line">hashG:    [ &lt;35&gt;, <span class="string">'coin'</span> ]</span><br></pre></td></tr></table></figure>
<!-- 若当前节点为分支节点，若搜索路径为空，则返回分支节点的存储内容 -->
<p>构造过程为</p>
<ol>
<li>假设插入第一个kv对是do-&gt;verb，key根据Hex-Prefix编码为[‘0x20’, ‘0x64’, ‘0x6f’]，MPT树为：<br><img src="/blogimgs/MPT/leafA.png" alt="叶子结点" title="叶子结点"></li>
<li>接着插入第二个kv对dog-&gt;puppy，dog和do的公共前缀为[‘64’, ‘6f’]，do是叶子结点A，将<em>叶子结点替换成扩展节点A</em>，并将新key与叶子节点A的公共前缀(646f)作为扩展节点的key，<em>扩展节点的value是新分支节点B的hash值</em>，然后将do和dog剩余的key插入到分支节点中，由于do没有剩余的key，则将对应的value写入分支节点B的value中，dog剩余的key为67，则分支节点B中的路径为6，指向叶子结点C。7为dog剩下的最后一个key值，是奇数叶子结点则前缀为3，所有最终的MPT树为：<br><img src="/blogimgs/MPT/two.png" alt="叶子结点插入" title="叶子结点插入"></li>
<li>再插入第三个kv对doge-&gt;coin，按照上面的步骤生成的MPT树是：<br><img src="/blogimgs/MPT/three.png" alt=""></li>
<li>最后插入第四个kv对horse-&gt;stallion，horse与其它key的公共前缀只有6，则将扩展节点A新增一个分支节点F作为其孩子节点，将新key与扩展节点A的公共前缀6作为扩展节点A的key，A是扩展节点并且key为奇数，所以前缀为1，value为新增分支节点F的hash。原扩展节点A变成新扩展节点之后剩余的key，与新key剩下的key，插入到分支节点F中，分别放入4和8中，4指向新的扩展节点G，8指向叶子节点H。最终的MPT树为：<br><img src="/blogimgs/MPT/four.png" alt=""></li>
</ol>
<!--
剩余的搜索路径与当前节点的key不完全一致，则将叶子／扩展节点的孩子节点替换成分支节点，将新节点与当前节点key的共同前缀作为当前节点的key，将新节点与当前节点的孩子节点作为两个孩子插入到分支节点的孩子列表中，同时当前节点转换成了一个扩展节点（若新节点与当前节点没有共同前缀，则直接用生成的分支节点替换当前节点）；
-->
<!--
树的构造逻辑是root结点，要构造一个指向下一个结点的kv节点。先对键编码，由于当前节点不是结束结点，存值的键为奇数字符数，所以前导值为1，又由于奇数不补位，最终存键为0x16。它指向的是一个全节点A。下一层级，要编码的是d和h的第二个半字节，4和6。所以在A节点的第五个位置（从零开始）和第七个位置，我们可以看到分别被指向到了B和C两个节点。对于B节点往后do，dog，doge来说。他们紧接着的都是一个编码为6f的o字符。所以这里，B节点被编码为指向D的kv结点，数据是指向D节点的。其中键值存6f，由于是指向另一个节点的kv节点，不包含结束标记，且是偶数，需要补位0，得到00，最终的编码结果是006f。后续节点也以此类推。
-->
<h2 id="MPT在以太坊中的应用"><a href="#MPT在以太坊中的应用" class="headerlink" title="MPT在以太坊中的应用"></a>MPT在以太坊中的应用</h2><p>Merkle数据结构在区块链领域中使用比较广泛，比特币和以太坊都是用了Merkle树，其中以太坊中保留了三颗MPT，分别是<em>状态树、交易树和收据树</em>，这三种树可以帮助以太坊客户端做一些简易的查询，如查询某个账户的余额、某笔交易是否被包含在区块中等。</p>
<p>需要注意的是在以太坊中对MPT再进行了一次封装，对<em>数据项的key进行了一次哈希计算sha3(key)</em>，value进行了RLP(Recursive length prefix encoding,递归长度前缀编码)编码，数据库中存储额外的sha3(key)与key之间的对应关系。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://ethfans.org/toya/articles/588" target="_blank" rel="noopener">https://ethfans.org/toya/articles/588</a><br><a href="https://ethfans.org/toya/articles/588" target="_blank" rel="noopener">https://github.com/ethereum/wiki/wiki/Patricia-Tree</a><br><a href="https://stackoverflow.com/questions/14708134/what-is-the-difference-between-trie-and-radix-trie-data-structures" target="_blank" rel="noopener">https://stackoverflow.com/questions/14708134/what-is-the-difference-between-trie-and-radix-trie-data-structures</a><br><a href="https://cs.stackexchange.com/questions/63048/what-is-the-difference-between-radix-trees-and-patricia-tries" target="_blank" rel="noopener">https://cs.stackexchange.com/questions/63048/what-is-the-difference-between-radix-trees-and-patricia-tries</a></p>
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> Ethereum </tag>
            
            <tag> MPT </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker容器log采集实践]]></title>
      <url>http://bigdatadecode.club/Docker-Log-Action.html</url>
      <content type="html"><![CDATA[<p>随着容器和编排技术持续发展，各个公司都已陆续在容器云领域有了相关实践，转转也不例外，也在进行一些积极探索与实践。<br>本文以日志采集为切入点，介绍下转转容器云平台中的业务日志是如何自动化采集的。</p>
<a id="more"></a>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在微服务和docker大火的当下，各个公司都在积极主推容器化，最大化的利用资源并减少运维成本，希望各个业务方能尽早接入云平台。</p>
<p>而做为数据团队的我们却遇到了一个问题，我们的数据源绝大多数都来自于业务程序的埋点日志，如果业务方迁移到云平台，埋点日志将无法采集，所以我们急需一套云平台日志采集方案。</p>
<p>先看下容器日志采集与传统日志采集的区别</p>
<h3 id="容器日志采集与传统日志采集区别"><a href="#容器日志采集与传统日志采集区别" class="headerlink" title="容器日志采集与传统日志采集区别"></a>容器日志采集与传统日志采集区别</h3><p>容器云平台的最大的特点就是能够最大化的利用资源，并且利用编排工具可以做到弹性伸缩，所以容器云与传统日志采集的最大区别有如下两点：</p>
<ol>
<li>采集日志的实例较多，且数据量较大。</li>
<li>采集日志分布不固定，无法像传统日志采集方案那样配置固定的采集目录。</li>
</ol>
<h2 id="调研"><a href="#调研" class="headerlink" title="调研"></a>调研</h2><ol>
<li>最简单粗暴的方法就是让业务方将埋点日志直接打入kafka或者redis等中间件，这种方式对业务侵入性较大，无法做到对业务无感知，要<em>保证日志传输的可靠性也比较困难</em>。</li>
<li>使用容器推荐的方法将日志写到标准输出中，然后使用Docker Engine采集。这种方式也是对业务方有一定的侵入性。</li>
<li>在每个容器内部署一个日志采集服务，如flume、filebeat，通过采集工具将日志传输到下一环节。这种方案对业务方无感知，但是依然对业务程序有一定的侵入性，因为存在采集程序异常导致容器崩溃的可能性，而且容器的启动和停止是一个常态，如果采集有延迟的话，容器停止之后将会丢失一部分数据，所以这种方案也不合理。</li>
<li>容器在启动时，指定日志的挂载目录，这样日志就保存到了宿主机里，而且日志也可以做到不随容器的消亡和消失。但是这样的话需要保证挂载目录唯一，而且最致命的是需要根据容器的状态更新宿主机上采集服务的配置文件。</li>
</ol>
<h2 id="架构方案"><a href="#架构方案" class="headerlink" title="架构方案"></a>架构方案</h2><p>调研之后我们倾向使用第4种方法，在此基础上制定的容器云采集方案希望能解决如下问题：</p>
<ol>
<li>业务无感知</li>
<li>能够采集容器内业务日志，并且支持同一容器内多份日志采集</li>
<li>断点续传</li>
<li>从日志中区分来源</li>
<li>动态发现</li>
<li>支持扩展</li>
<li>日志灵活归档</li>
</ol>
<blockquote>
<p>整个背景调研结束之后发现一个关键点，那就是如何动态感知容器的启停，从而决定采集哪些日志。</p>
</blockquote>
<p>阿里云开源了一款日志采集工具<a href="https://github.com/AliyunContainerService/log-pilot" target="_blank" rel="noopener">log-pilot</a>，此工具最大的特色是能够动态地发现和采集容器内部的日志文件。</p>
<h3 id="log-pilot架构与原理"><a href="#log-pilot架构与原理" class="headerlink" title="log-pilot架构与原理"></a>log-pilot架构与原理</h3><p>log-pilot是用golang开发的，本身架构比较简单，代码量也不大，主要分为三部分，其中一部分就是<em>容器事件管理</em>，它能够动态地监听容器的事件变化，然后依据容器的标签来进行解析，生成日志采集配置文件，然后交由采集插件来进行日志采集。</p>
<p><img src="/blogimgs/dockerLogAction/log-pilot采集流.png" alt="log-pilot采集流图" title="log-pilot采集流图"><br>简单介绍下log-pilot日志采集的流程，log-pilot容器事件管理模块监听到容器启动之后，从容器的env中解析特定标签，然后根据log-pilot配置的采集插件通过配置文件管理生成对应的配置文件，启动采集工具对日志进行采集。</p>
<p>log-pilot对采集后端支持的也比较丰富，具体如下图，不过我们为了与现有传统日志采集流程进行兼容，我们使用了file模式，即将日志从容器内采集到宿主机，然后再进行日志收集。<br><img src="/blogimgs/dockerLogAction/采集后端.png" alt="log-pilot采集后端" title="log-pilot采集后端"></p>
<p>log-pilot也没有使用特别复杂的架构，但是功能还是比较全的，我们使用主要功能是服务发现和动态更新配置的功能，其它功能这里不展开，有兴趣的可以参考<a href="https://github.com/AliyunContainerService/log-pilot" target="_blank" rel="noopener">github主页</a>。</p>
<h2 id="采集实践"><a href="#采集实践" class="headerlink" title="采集实践"></a>采集实践</h2><p>通过一些测试发现此工具能够最大化的满足目前的需求，只需要与目前已存在的采集流程和日志采集工单系统进行下兼容就可以快速上线。</p>
<h3 id="log-pilot部署"><a href="#log-pilot部署" class="headerlink" title="log-pilot部署"></a>log-pilot部署</h3><p>起初我们使用fluentd采集日志，针对fluentd的配置模版并没有太大的改动，只是调整了一些参数，相关改动如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;buffer tag,time,docker_app,docker_service,docker_container&gt;</span><br><span class="line">  @<span class="built_in">type</span> <span class="variable">$&#123;FILE_BUFFER_TYPE:=file&#125;</span></span><br><span class="line">  path <span class="variable">$FILE_PATH</span>/.buffer</span><br><span class="line">  chunk_limit_size 8MB</span><br><span class="line">  chunk_limit_records 1000</span><br><span class="line">  flush_thread_count 20</span><br><span class="line">  flush_at_shutdown <span class="literal">true</span></span><br><span class="line">  timekey <span class="variable">$&#123;FILE_BUFFER_TIME_KEY:=1d&#125;</span></span><br><span class="line">  timekey_wait <span class="variable">$&#123;FILE_BUFFER_TIME_KEY_WAIT:=2m&#125;</span></span><br><span class="line">  timekey_use_utc <span class="variable">$&#123;FILE_BUFFER_TIME_KEY_USE_UTC:=false&#125;</span></span><br><span class="line">  $(bufferd_output)</span><br><span class="line">&lt;/buffer&gt;</span><br></pre></td></tr></table></figure>
<p>这个配置主要目的是尽可能的减少数据延迟，并实现按照时间归档日志。但是由于fluentd本身的一些机制和与我们现有采集流程的融合性不高，在线上运行一段时间之后最终放弃了该插件，使用flume进行采集(具体内容在下一节会介绍)。</p>
<p>更多fluentd相关的内容可以参考<a href="https://docs.fluentd.org/v1.0/articles/buffer-section" target="_blank" rel="noopener">官网</a></p>
<p>log-pilot的部署我们采用的是每台宿主机上启动一个log-pilot容器，用来监听整个宿主机上所有的容器。</p>
<h3 id="关键功能代码解析"><a href="#关键功能代码解析" class="headerlink" title="关键功能代码解析"></a>关键功能代码解析</h3><p>上文中提到架构比较简单，一起看下关键功能的实现。</p>
<ol>
<li>容器事件管理</li>
</ol>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 时刻监听</span></span><br><span class="line">msgs, errs := p.client().Events(ctx, options)</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">  <span class="keyword">select</span> &#123;</span><br><span class="line">  <span class="keyword">case</span> msg := &lt;-msgs:</span><br><span class="line">    <span class="keyword">if</span> err := p.processEvent(msg); err != <span class="literal">nil</span> &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="keyword">case</span> err := &lt;-errs:</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 事件处理function</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(p *Pilot)</span> <span class="title">processEvent</span><span class="params">(msg events.Message)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">  containerId := msg.Actor.ID</span><br><span class="line">  ctx := context.Background()</span><br><span class="line">  <span class="keyword">switch</span> msg.Action &#123;</span><br><span class="line">  <span class="keyword">case</span> <span class="string">"start"</span>, <span class="string">"restart"</span>:</span><br><span class="line">    ...</span><br><span class="line">    containerJSON, err := p.client().ContainerInspect(ctx, containerId)</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> p.newContainer(&amp;containerJSON)</span><br><span class="line">  <span class="keyword">case</span> <span class="string">"destroy"</span>:</span><br><span class="line">    ...</span><br><span class="line">    err := p.delContainer(containerId)</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过调用docker的api拿到事件信息，然后教由<code>processEvent</code>进行处理，这里主要监听<code>start</code>、<code>restart</code>和<code>destroy</code>事件。<br>监听到<code>start</code>和<code>restart</code>事件之后，通过<code>inspect</code>拿到容器的相关信息，由<code>newContainer</code>去check是否由日志采集标识，然后生成具体到配置文件，进行采集。</p>
<ol start="2">
<li>生成配置文件<br>各个采集工具的配置文件相对固定，具有一定的规律性，可以提出一个统一的模版，所以这里使用了<code>template</code>功能来生成配置文件，具体代码不做展开，只展示下flume的配置模版，<strong>这个模版解决了k8s环境下容器重启之后日志重复采集的问题</strong>。</li>
</ol>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#123;<span class="keyword">range</span> .configList&#125;&#125;</span><br><span class="line"></span><br><span class="line">a1.sources.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_source.<span class="keyword">type</span> = TAILDIR</span><br><span class="line">a1.sources.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_source.channels = &#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_channel</span><br><span class="line">a1.sources.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_source.positionFile = /flume/log_meta/source/&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;/&#123;&#123; .Name &#125;&#125;/taildir_position.json</span><br><span class="line">a1.sources.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_source.filegroups = f1</span><br><span class="line">a1.sources.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_source.filegroups.f1 = &#123;&#123; .HostDir &#125;&#125;/&#123;&#123; .File &#125;&#125;</span><br><span class="line"></span><br><span class="line">a1.channels.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_channel.<span class="keyword">type</span> = file</span><br><span class="line">a1.channels.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_channel.checkpointDir = /flume/log_meta/channel/&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;/&#123;&#123; .Name &#125;&#125;/checkpoint</span><br><span class="line">a1.channels.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_channel.dataDirs = /flume/log_meta/channel/&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;/&#123;&#123; .Name &#125;&#125;/buffer</span><br><span class="line"></span><br><span class="line">a1.sinks.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_sink.<span class="keyword">type</span> = file_roll</span><br><span class="line">a1.sinks.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_sink.channel = &#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_channel</span><br><span class="line">a1.sinks.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_sink.sink.directory = &#123;&#123; $.output &#125;&#125;/&#123;&#123; index $.container <span class="string">"docker_container_subname"</span> &#125;&#125;</span><br><span class="line">a1.sinks.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_sink.sink.rollInterval = <span class="number">3600000</span></span><br><span class="line">a1.sinks.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_sink.sink.pathManager.prefix = &#123;&#123; .Name &#125;&#125;</span><br><span class="line">a1.sinks.&#123;&#123;<span class="keyword">if</span> index $.container <span class="string">"k8s_pod"</span>&#125;&#125;&#123;&#123; index $.container <span class="string">"k8s_pod"</span> &#125;&#125;&#123;&#123;<span class="keyword">else</span>&#125;&#125;&#123;&#123; $.containerId &#125;&#125;&#123;&#123;end&#125;&#125;_&#123;&#123; .Name &#125;&#125;_sink.sink.pathManager.extension = log</span><br><span class="line"></span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>
<p>整个项目用了很多golang的特性，比如channel、协程等等，而且也比较简单，对一些golang小白也比较友好，可以作为glang语言的入门项目好好钻研下。</p>
<h3 id="排雷"><a href="#排雷" class="headerlink" title="排雷"></a>排雷</h3><ol>
<li>时区问题<br><code>timekey_use_utc</code>参数不生效，总是慢8小时，发现是fluentd的bug，更新fluentd版本到1.2.6解决。</li>
<li>数据延迟<br>随着业务量的增长，采集延迟较大，发现大量的日志在buffer中无法进行归档，增加线程池<code>flush_thread_count</code>为20(按照一份日志一个线程)，并增加<code>chunk_limit_size</code>和<code>chunk_limit_records</code>，延迟得到缓解，但是零点依然会有延迟。</li>
<li>数据重复采集<br>docker中需要采集日志的offset记录在以containerId命名的目录中，但在k8s环境下，容器重启之后，由于容器所在的pod没有消失，所以容器日志的挂载目录没有发生变化(也就是说之前产生的日志还在)，但是容器的containerId发生了变化，当log-pilot去采集重启之后的容器时，发现并没有记录offset于是从新采集，于是就造成了日志重复采集。</li>
</ol>
<h3 id="二次开发与优化"><a href="#二次开发与优化" class="headerlink" title="二次开发与优化"></a>二次开发与优化</h3><p>在调研期间，发现log-pilot并不能完全满足我们的场景，于是对log-pilot进行了定制化的开发和优化。</p>
<ol>
<li><p>扩展动态配置<br>首先为了与现有传统日志采集流程进行兼容，我们使用的采集后端模式是file，则宿主机上的原有采集服务也需要根据容器的启停动态的更新配置，所以我们针对这个需求我们对log-pilot进行定制开发，使原有对采集服务能够动态的采集日志。</p>
</li>
<li><p>日志漏采<br>其次在线上运行期间发现fluentd有延迟，而且如果采用时间归档日志的话，fluentd是按照日志进入buffer的时间进行归档的，这就造成buffer中数据需要立即消费到sink中进行规档，以便后续流程进行采集，如果有延迟将会造成数据漏采。为了尽量减少漏采事件的发生，我们按照天来归档日志。但是随后发现有的业务日志特别庞大，单个能达到80G+，进行日常grep较困难，而且在零点的时候依然会有漏采的可能性。于是决定要对log-pilot的插件进行扩展，采用了比较大众的flume，而且团队对flume也有一定的技术积累。</p>
</li>
<li><p>重复采集<br>决定增加flume之后，我们对flume也进行了一些调整，比如支持严格意义的按照时间进行归档(此功能没有贡献给社区，因为这个功能相对个性化)。使用的flume组件为<code>Taildir Source</code> + <code>File Channel</code> + <code>File Roll Sink</code>，针对<em>数据重复采集</em>的问题，我们将相关的offset放在了以podName命名的目录中，这样可以保证容器重启offset不会丢失。</p>
</li>
</ol>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然现在看下整个方案并没有什么难点，但是从调研到上线再到后来的改进，整个过程还是比较曲折的。通过对log-pilot定制化开发我们将云平台日志采集流程集成到了传统日志采集流程中，对业务方做到最大的透明化，整个采集流程依然是业务方发起工单，我们进行审批然后就是自动化的采集流程，不需要由于容器的启停而要人工介入修改配置，最大化的释放了人力成本。</p>
<p>最后还是要感谢阿里云开源了这么棒的工具，让我们得以站在巨人的肩膀上看世界。转转本着拥抱开源，回馈开源的理念，将我们遇到的问题和扩展也反馈到了社区，相关PR见附件。</p>
<h2 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h2><p><a href="https://issues.apache.org/jira/browse/FLUME-3306" target="_blank" rel="noopener">FLUME-3306</a><br><a href="https://github.com/AliyunContainerService/log-pilot/pull/142" target="_blank" rel="noopener">log-pilot#142</a><br><a href="https://github.com/AliyunContainerService/log-pilot/pull/155" target="_blank" rel="noopener">log-pilot#155</a><br><a href="https://github.com/AliyunContainerService/log-pilot/pull/167" target="_blank" rel="noopener">log-pilot#167</a></p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://yq.aliyun.com/articles/674327" target="_blank" rel="noopener">容器日志采集利器Log-Pilot</a></p>
<!--
现有采集工具缺陷
缺乏动态配置的能力
目前的采集工具都需要我们事先手动配置好日志采集方式和路径等信息，由于它无法能够自动感知到容器的生命周期变化或者动态漂移，所以它无法动态地去配置。
日志采集重复或丢失
现有的一些采集工具基本上是通过 tail 的方式来进行日志采集的，那么这里就可能存在两个方面的问题：一个是可能导致日志丢失，比如采集工具在重启的过程中，而应用依然在写日志，那么就有可能导致这个窗口期的日志丢失；而对于这种情况一般保守的做法就是，默认往前多采集 1M 日志或 2M 的日志，那么这就又会可能引起日志采集重复的问题。
未明确标记日志源
一个应用可能有很多个容器，输出的应用日志也是一样的，那么当我们将所有应用日志收集到统一日志存储后端时，在搜索日志的时候，我们就无法明确这条日志具体是哪一个节点上的哪一个应用容器产生的。
-->]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
            <tag> BigData </tag>
            
            <tag> log </tag>
            
            <tag> log-pilot </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[函数式编程之闭包]]></title>
      <url>http://bigdatadecode.club/Func-Closure.html</url>
      <content type="html"><![CDATA[<p><a href="https://zh.wikipedia.org/wiki/闭包_\(计算机科学\" target="_blank" rel="noopener">维基百科</a>)中是这样定义闭包的：<br>在计算机科学中，闭包（英语：Closure），又称词法闭包（Lexical Closure）或函数闭包（function closures），是<strong>引用了自由变量的函数</strong>。<em>这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外</em>。</p>
<p>这里有两点需要把握，<strong>自由变量和函数</strong>。则判断是不是闭包首先判断是不是函数，如果都不是函数那么肯定不是闭包，是函数再继续判断是否有自由变量。<br>自由变量就是这里的重点了。。。</p>
<a id="more"></a>
<p>个人简单粗暴的将<em>自由变量</em>理解为<strong>当前函数引用的外部变量</strong>。</p>
<p>这里先举个例子简单感受下，看个golang代码：</p>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">f</span><span class="params">(i <span class="keyword">int</span>)</span> <span class="title">func</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">int</span></span> &#123;</span><br><span class="line">        i++</span><br><span class="line">        <span class="keyword">return</span> i</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>f是个function，此方法是返回一个function(由于f返回的function无法在外部访问，没有必要给他起名字，所以就直接返回一个匿名函数)。<br>其中变量i是f的参数，是f的局部变量，匿名函数在f的命名空间内，可以引用变量i，这个匿名函数就是一个闭包。</p>
<p>我们根据闭包的定义理解下这个f的返回值。</p>
<blockquote>
<p>变量i是f的局部变量，正常情况下f执行结束之后i会被回收，会随着f的结束而消失。但是这里f返回的匿名函数引用了i，这个i就作为了这个匿名函数的外部变量，也就成了一个自由变量，此自由变量会与匿名函数一同存在，即使已经离开了创造它的环境也不例外，形成了一个实体，也就是闭包。</p>
</blockquote>
<p>再看个代码，我们把定义扩展下，代码如下：</p>
<figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">c1 := f(<span class="number">0</span>)</span><br><span class="line">c2 := f(<span class="number">0</span>)</span><br><span class="line">fmt.Println(c1())    <span class="comment">// reference to i, i = 0, return 1</span></span><br><span class="line">fmt.Println(c1())    <span class="comment">// reference to i, i = 1, return 2</span></span><br><span class="line">fmt.Println(c2())    <span class="comment">// reference to another i, i = 0, return 1</span></span><br></pre></td></tr></table></figure>
<p>如果你看过其它关于闭包的资料，你可能有这个印象，<em>闭包运行时可以有多个实例</em>。<br>根据上面的代码解释下，<br>f是一个函数，<strong>函数是一些可执行的代码，这些代码在函数被定义后就确定了，不会在执行时发生变化，所以一个函数只有一个实例</strong>。f(0)返回一个闭包，c1和c2引用的i是f(0)传进去的0，c1和c2第一次执行时，自由变量都为0，执行结束在匿名函数内递增变为1，引用环境发生了变化，第二次执行c1时，闭包中的引用环境已经由i=0变为了i=1，所以经过递增变为了2。这里两次调用c1得到不通的结果，这也就是说闭包在运行时会根据不同的引用环境产生不通的实例。</p>
<p>所谓引用环境是指在程序执行中的某个点所处于活跃状态的约束所组成的集合。其中的约束是指一个变量的名字和其所代表的对象之间的联系。</p>
<!-- 变量i是函数f中的局部变量，假设这个变量是在函数f的栈中分配的，是不可以的。因为函数f返回以后，对应的栈就失效了，f返回的那个函数中变量i就引用一个失效的位置了。所以闭包的环境中引用的变量不能够在栈上分配。所以将i分配到heap上，这也就是说闭包容易造成内存泄漏-->
<!--
## 闭包的用途
一个显而易见的用途就是--**简化代码**，再者就是容易**模块化，代码能够高度复用**，假如有这样一个场景，需要对列表中的数据进行累加和累积时

nums = [10,3,22,34,17]
sum = 0
nums.each{|n| sum += n}
print sum

那么为什么要把引用环境与函数组合起来呢？这主要是因为在支持嵌套作用域的语言中，有时不能简单直接地确定函数的引用环境。

而且闭包是只有被调用的时候才会被执行。

闭包不是私有，闭的意思不是"封闭内部状态",而是"封闭外部状态"。一个函数如何能封闭外部状态呢？当外部状态的scope失效的时候，还有一份留在内部状态里。

闭包，常指有权访问其外部作用域中变量和参数的函数

[](https://www.zhihu.com/question/34210214)
-->
<p><a href="https://tiancaiamao.gitbooks.io/go-internals/content/zh/03.6.html" target="_blank" rel="noopener">参考1</a><br><a href="https://www.ibm.com/developerworks/cn/linux/l-cn-closure/index.html" target="_blank" rel="noopener">参考2</a></p>
]]></content>
      
        <categories>
            
            <category> Language </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 函数式 </tag>
            
            <tag> 闭包 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[全栈Voting Dapp Demo]]></title>
      <url>http://bigdatadecode.club/Voting-Dapp-Demo.html</url>
      <content type="html"><![CDATA[<p>本篇其实算是一篇译文，但不是直译，而是神译。(意会一下就ok了。。)<br><a href="https://medium.com/@mvmurthy/full-stack-hello-world-voting-ethereum-dapp-tutorial-part-1-40d2d0d807c2" target="_blank" rel="noopener">原文地址</a></p>
<p><a href="http://bigdatadecode.club/Solidity_Voting解析.html">上一篇</a>详细介绍了官方Voting例子，<br>本篇趁热打铁，介绍下这样的一个Voting在实际中怎么使用。</p>
<a id="more"></a>
<p>本篇所要介绍的是一个简单的web应用，首先初始化一批候选人，然后所有登录页面的人都可以为这些候选人投票，并展示每个候选人的得票数。</p>
<p>先来看下整个Application的架构图：<br><img src="/blogimgs/VotingDappDemo/VotingApp.png" alt="Voting App" title="Voting App"></p>
<h2 id="部署开发环境"><a href="#部署开发环境" class="headerlink" title="部署开发环境"></a>部署开发环境</h2><p>开发都离不开测试，更离不开测试环境，尤其是区块链相关的开发，如果直接在公网上测试，那损失的可真的是真金白银。<br>所以我们先搞个开发环境，这个测试环境比较简单，也容易安装。它就是ganache，是一个基于内存的区块链测试工具。<br><!-- Ganache 的前 身是 test叩C，现在已 经被整合 到 Ganache 项目 中 。 Ganache 是一个本 地内存执行的轻量级客户端，有良好的交互界面 --></p>
<p>ganache是nodejs的一个模块，安装命令为<code>cnpm install ganache-cli web3@0.20.2</code></p>
<blockquote>
<p>这里使用cnpm，是安装了淘宝的nodejs源，访问国外的太慢</p>
</blockquote>
<p>执行<code>node_modules/.bin/ganache-cli</code>开启测试区块链，此命令为默认生成10测试账号，每个账号有100ETH，如下：<br><img src="/blogimgs/VotingDappDemo/ganache-cli.png" alt="ganache-cli" title="ganache-cli"></p>
<h2 id="Voting合约代码"><a href="#Voting合约代码" class="headerlink" title="Voting合约代码"></a>Voting合约代码</h2><p>此代码与<a href="http://bigdatadecode.club/Solidity_Voting解析.html">上一篇</a>中的代码不一样，没有那个复杂，本篇重点在整个全流程，有兴趣的朋友可以把上一篇的代码迁移到这里。</p>
<p>代码内容就不过多的累赘了，请看代码：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.25</span>;</span><br><span class="line"><span class="comment">// We have to specify what version of compiler this code will compile with</span></span><br><span class="line"></span><br><span class="line">contract Voting &#123;</span><br><span class="line">  <span class="comment">/* mapping field below is equivalent to an associative array or hash.</span></span><br><span class="line"><span class="comment">  The key of the mapping is candidate name stored as type bytes32 and value is</span></span><br><span class="line"><span class="comment">  an unsigned integer to store the vote count</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"></span><br><span class="line">  mapping (<span class="function"><span class="params">bytes32</span> =&gt;</span> uint8) public votesReceived;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Solidity doesn't let you pass in an array of strings in the constructor (yet).</span></span><br><span class="line"><span class="comment">  We will use an array of bytes32 instead to store the list of candidates</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"></span><br><span class="line">  bytes32[] public candidateList;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* This is the constructor which will be called once when you</span></span><br><span class="line"><span class="comment">  deploy the contract to the blockchain. When we deploy the contract,</span></span><br><span class="line"><span class="comment">  we will pass an array of candidates who will be contesting in the election</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">constructor</span>(bytes32[] candidateNames) public &#123;</span><br><span class="line">    candidateList = candidateNames;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// This function returns the total votes a candidate has received so far</span></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">totalVotesFor</span>(<span class="params">bytes32 candidate</span>) <span class="title">view</span> <span class="title">public</span> <span class="title">returns</span> (<span class="params">uint8</span>) </span>&#123;</span><br><span class="line">    <span class="built_in">require</span>(validCandidate(candidate));</span><br><span class="line">    <span class="keyword">return</span> votesReceived[candidate];</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// This function increments the vote count for the specified candidate. This</span></span><br><span class="line">  <span class="comment">// is equivalent to casting a vote</span></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">voteForCandidate</span>(<span class="params">bytes32 candidate</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">    <span class="built_in">require</span>(validCandidate(candidate));</span><br><span class="line">    votesReceived[candidate] += <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">function</span> <span class="title">validCandidate</span>(<span class="params">bytes32 candidate</span>) <span class="title">view</span> <span class="title">public</span> <span class="title">returns</span> (<span class="params">bool</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(uint i = <span class="number">0</span>; i &lt; candidateList.length; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (candidateList[i] == candidate) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>把上面的代码写入Voting.sol文件，然后编译合约并部署到ganache blockchain中。</p>
<h2 id="命令行部署调用合约"><a href="#命令行部署调用合约" class="headerlink" title="命令行部署调用合约"></a>命令行部署调用合约</h2><p>这里是在node命令行中编译合约代码，所以需要安装solc依赖包，命令<code>cnpm install solc</code></p>
<p>首先在node命令行中初始化<code>web3</code>对象，代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hadoop@ubuntu:~<span class="regexp">/blockchain/</span>ethereum/project/voting-app$ node</span><br><span class="line">&gt; Web3 = <span class="built_in">require</span>(<span class="string">'web3'</span>)</span><br><span class="line">&#123; [<span class="built_in">Function</span>: Web3]</span><br><span class="line">  providers:</span><br><span class="line">   &#123; <span class="attr">HttpProvider</span>: [<span class="built_in">Function</span>: HttpProvider],</span><br><span class="line">     IpcProvider: [<span class="built_in">Function</span>: IpcProvider] &#125; &#125;</span><br><span class="line">&gt; web3 = <span class="keyword">new</span> Web3(<span class="keyword">new</span> Web3.providers.HttpProvider(<span class="string">"http://localhost:8545"</span>));</span><br></pre></td></tr></table></figure>
<p>web3对象初始化之后，就可以与ganache blockchain的测试环境进行交互，执行以下命令check下是否成功：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; web3.eth.accounts</span><br><span class="line">[ <span class="string">'0xc8d9d73906b06412f3768c5e09efe04704ac5f49'</span>,</span><br><span class="line">  <span class="string">'0x6b0a0169df2e5e5c576ae92cbe1a173a12662e97'</span>,</span><br><span class="line">  <span class="string">'0x0aef426a8dfc5627a6a16cd2118e2b10fdba9644'</span>,</span><br><span class="line">  <span class="string">'0x11dc712466b7dd60af4ccc82bcb273853338337b'</span>,</span><br><span class="line">  <span class="string">'0xc2c9f86b94d6e64dd60e8c1cf8f87355b7a05eb1'</span>,</span><br><span class="line">  <span class="string">'0xf851f0b2a52024ceedee6d33d9331e6f628c4525'</span>,</span><br><span class="line">  <span class="string">'0x06b0ab24104065384026f938a627c5183d477a47'</span>,</span><br><span class="line">  <span class="string">'0xffcc3f6b4747e922b61fb49d9e1608a28c0523fd'</span>,</span><br><span class="line">  <span class="string">'0x3847f4b5bc251da9bfc7050e51a8e33cae78080a'</span>,</span><br><span class="line">  <span class="string">'0x6c67bb1596e56cc5054296e4bf05a6e42d4fba04'</span> ]</span><br></pre></td></tr></table></figure>
<p>成功之后，开始编译合约。调用fs方法从Voting.sol文件中读取代码并编译。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; code = fs.readFileSync(<span class="string">'Voting.sol'</span>).toString()</span><br><span class="line">&gt; solc = <span class="built_in">require</span>(<span class="string">'solc'</span>)</span><br><span class="line">&gt; compiledCode = solc.compile(code)</span><br></pre></td></tr></table></figure>
<p>上述代码运行成功之后，Voting合约就算编译成功了。其中有两个值比较重要，一个是btyecode另一个是ABI。<br>通过<code>compiledCode.contracts[&#39;:Voting&#39;].bytecode</code>得到合约的bytecode，此值是合约编译之后的二进制码，将会部署到区块链中。<br>通过<code>compiledCode.contracts[&#39;:Voting&#39;].interface</code>得到合约的ABI，此值是在合约调用中起作用，用来告诉合约用户哪些方法可以使用。</p>
<p>下面我们开始部署吧。<br>第一步 创建合约对象，代码如下：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; abiDefinition = <span class="built_in">JSON</span>.parse(compiledCode.contracts[<span class="string">':Voting'</span>].interface)</span><br><span class="line">&gt; VotingContract = web3.eth.contract(abiDefinition)</span><br><span class="line">&gt; byteCode = compiledCode.contracts[<span class="string">':Voting'</span>].bytecode</span><br><span class="line">&gt; deployedContract = VotingContract.new([<span class="string">'Rama'</span>,<span class="string">'Nick'</span>,<span class="string">'Jose'</span>],&#123;<span class="attr">data</span>: byteCode, <span class="attr">from</span>: web3.eth.accounts[<span class="number">0</span>], <span class="attr">gas</span>: <span class="number">4700000</span>&#125;)</span><br><span class="line">&gt; deployedContract.address</span><br><span class="line">&gt; contractInstance = VotingContract.at(deployedContract.address)</span><br></pre></td></tr></table></figure>
<p>部署合约到区块链的关键代码是<code>VotingContract.new</code>，但是在部署合约之前，要先声明一个合约对象<code>web3.eth.contract(abiDefinition)</code>，传入的参数是ABI。<br><code>VotingContract.new</code>的第一个参数是合约构造函数传入的候选者数组，<br>第二个函数是一个json，json中data是合约编译之后的二进制码，from代表的是合约是又谁部署的，gas就代表要消耗多少钱。</p>
<p>执行完上述代码，就代表着我们已经部署了一个合约实例，并且我们可以与合约进行交互了。<br>交互时是使用<code>deployedContract.address</code>进行区分，执行以下命令，感受下与合约的交互。</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; contractInstance.totalVotesFor.call(<span class="string">'Rama'</span>)</span><br><span class="line">BigNumber &#123; <span class="attr">s</span>: <span class="number">1</span>, <span class="attr">e</span>: <span class="number">0</span>, <span class="attr">c</span>: [ <span class="number">0</span> ] &#125;</span><br><span class="line">&gt; contractInstance.voteForCandidate(<span class="string">'Rama'</span>, &#123;<span class="attr">from</span>: web3.eth.accounts[<span class="number">0</span>]&#125;)</span><br><span class="line"><span class="string">'0x718a9b2bfdb301a838ab39d8926e5881ff6c0da775eb933f944203c3353b1cfa'</span></span><br><span class="line">&gt; contractInstance.voteForCandidate(<span class="string">'Rama'</span>, &#123;<span class="attr">from</span>: web3.eth.accounts[<span class="number">0</span>]&#125;)</span><br><span class="line"><span class="string">'0x6c2e893552f316a4d37046baa2d030751db21bf7580559df5c051b10e71c0248'</span></span><br><span class="line">&gt; contractInstance.voteForCandidate(<span class="string">'Rama'</span>, &#123;<span class="attr">from</span>: web3.eth.accounts[<span class="number">0</span>]&#125;)</span><br><span class="line"><span class="string">'0xf211d536961f58fcca70d4b199bb814debdb445c3fff255eefb828008b0d9aa5'</span></span><br><span class="line">&gt; contractInstance.totalVotesFor.call(<span class="string">'Rama'</span>).toLocaleString()</span><br><span class="line"><span class="string">'3'</span></span><br></pre></td></tr></table></figure>
<p>我们给<em>Rama</em>投了3张票，可以看到Rama的票数确实增加了，而且每次投票都会返回一个字符串，这个字符串是transaction id。</p>
<h2 id="web操作合约"><a href="#web操作合约" class="headerlink" title="web操作合约"></a>web操作合约</h2><p>现在我们写个简单的html来把整个与合约交互的流程可视化。页面包括候选者的名字和票数，以及投票功能。<br>这里有一个index.html和一个index.js文件，代码分别如下:</p>
<p>index.html<br><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE html&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">title</span>&gt;</span>Hello World DApp<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">'https://fonts.googleapis.com/css?family=Open+Sans:400,700'</span> <span class="attr">rel</span>=<span class="string">'stylesheet'</span> <span class="attr">type</span>=<span class="string">'text/css'</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">link</span> <span class="attr">href</span>=<span class="string">'https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css'</span> <span class="attr">rel</span>=<span class="string">'stylesheet'</span> <span class="attr">type</span>=<span class="string">'text/css'</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span> <span class="attr">class</span>=<span class="string">"container"</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">h1</span>&gt;</span>A Simple Hello World Voting Application<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"table-responsive"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">table</span> <span class="attr">class</span>=<span class="string">"table table-bordered"</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">thead</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">th</span>&gt;</span>Candidate<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">th</span>&gt;</span>Votes<span class="tag">&lt;/<span class="name">th</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">thead</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">tbody</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">td</span>&gt;</span>Rama<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">"candidate-1"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">td</span>&gt;</span>Nick<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">"candidate-2"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">tr</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">td</span>&gt;</span>Jose<span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">td</span> <span class="attr">id</span>=<span class="string">"candidate-3"</span>&gt;</span><span class="tag">&lt;/<span class="name">td</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">tr</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">tbody</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">table</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">input</span> <span class="attr">type</span>=<span class="string">"text"</span> <span class="attr">id</span>=<span class="string">"candidate"</span> /&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"#"</span> <span class="attr">onclick</span>=<span class="string">"voteForCandidate()"</span> <span class="attr">class</span>=<span class="string">"btn btn-primary"</span>&gt;</span>Vote<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 国内这源可能访问不了，换成本地的web3.js文件 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;script src="https://cdn.rawgit.com/ethereum/web3.js/develop/dist/web3.js"&gt;&lt;/script&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"https://code.jquery.com/jquery-3.1.1.slim.min.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"./node_modules/web3/dist/web3.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">script</span> <span class="attr">src</span>=<span class="string">"./index.js"</span>&gt;</span><span class="undefined"></span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>index.js<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">Web3 = <span class="built_in">require</span>(<span class="string">'web3'</span>);</span><br><span class="line">web3 = <span class="keyword">new</span> Web3(<span class="keyword">new</span> Web3.providers.HttpProvider(<span class="string">"http://localhost:8545"</span>));</span><br><span class="line">abi = <span class="built_in">JSON</span>.parse(<span class="string">'[&#123;"constant":true,"inputs":[&#123;"name":"candidate","type":"bytes32"&#125;],"name":"totalVotesFor","outputs":[&#123;"name":"","type":"uint8"&#125;],"payable":false,"stateMutability":"view","type":"function"&#125;,&#123;"constant":true,"inputs":[&#123;"name":"candidate","type":"bytes32"&#125;],"name":"validCandidate","outputs":[&#123;"name":"","type":"bool"&#125;],"payable":false,"stateMutability":"view","type":"function"&#125;,&#123;"constant":true,"inputs":[&#123;"name":"","type":"bytes32"&#125;],"name":"votesReceived","outputs":[&#123;"name":"","type":"uint8"&#125;],"payable":false,"stateMutability":"view","type":"function"&#125;,&#123;"constant":true,"inputs":[&#123;"name":"","type":"uint256"&#125;],"name":"candidateList","outputs":[&#123;"name":"","type":"bytes32"&#125;],"payable":false,"stateMutability":"view","type":"function"&#125;,&#123;"constant":false,"inputs":[&#123;"name":"candidate","type":"bytes32"&#125;],"name":"voteForCandidate","outputs":[],"payable":false,"stateMutability":"nonpayable","type":"function"&#125;,&#123;"inputs":[&#123;"name":"candidateNames","type":"bytes32[]"&#125;],"payable":false,"stateMutability":"nonpayable","type":"constructor"&#125;]'</span>)</span><br><span class="line">VotingContract = web3.eth.contract(abi);</span><br><span class="line"><span class="comment">// In your nodejs console, execute contractInstance.address to get the address at which the contract is deployed and change the line below to use your deployed address</span></span><br><span class="line">contractInstance = VotingContract.at(<span class="string">'0xd018d4ed72e54fc3d66f254dfead8965577403dd'</span>);</span><br><span class="line">candidates = &#123;<span class="string">"Rama"</span>: <span class="string">"candidate-1"</span>, <span class="string">"Nick"</span>: <span class="string">"candidate-2"</span>, <span class="string">"Jose"</span>: <span class="string">"candidate-3"</span>&#125;</span><br><span class="line"><span class="keyword">var</span> account;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">voteForCandidate</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  candidateName = $(<span class="string">"#candidate"</span>).val();</span><br><span class="line">  contractInstance.voteForCandidate(candidateName, &#123;<span class="attr">from</span>: account&#125;, <span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">let</span> div_id = candidates[candidateName];</span><br><span class="line">    $(<span class="string">"#"</span> + div_id).html(contractInstance.totalVotesFor.call(candidateName).toString());</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">$(<span class="built_in">document</span>).ready(<span class="function"><span class="keyword">function</span>(<span class="params"></span>) </span>&#123;</span><br><span class="line">  web3.eth.getAccounts(<span class="function"><span class="keyword">function</span> (<span class="params">err, accs</span>) </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (err != <span class="literal">null</span>) &#123;</span><br><span class="line">        alert(<span class="string">'There was an error fetching your accounts.'</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (accs.length === <span class="number">0</span>) &#123;</span><br><span class="line">        alert(<span class="string">"Couldn't get any accounts! Make sure your Ethereum client is configured correctly."</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      account = accs[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">  candidateNames = <span class="built_in">Object</span>.keys(candidates);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">var</span> i = <span class="number">0</span>; i &lt; candidateNames.length; i++) &#123;</span><br><span class="line">    <span class="keyword">let</span> name = candidateNames[i];</span><br><span class="line">    <span class="keyword">let</span> val = contractInstance.totalVotesFor.call(name).toString()</span><br><span class="line">    $(<span class="string">"#"</span> + candidates[name]).html(val);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure></p>
<p>这里注意下index.js文件，这里展示了如何使用ABI和address与合约进行交互。</p>
<p>代码搞好之后，安装一个web server，这里安装http-server，命令<code>cnpm install -g http-server</code><br>安装成功之后，在项目目录下运行<code>http-server</code>启动程序，输出如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Starting up http-server, serving ./</span><br><span class="line">Available on:</span><br><span class="line">  http://127.0.0.1:8080</span><br><span class="line">  http://192.168.234.138:8080</span><br><span class="line">Hit CTRL-C to stop the server</span><br></pre></td></tr></table></figure>
<p>访问上述的网址，可见如下页面：<br><img src="/blogimgs/VotingDappDemo/webDapp.png" alt="web页面" title="web页面"><br>在文本框中输入候选人的名字，然后点击<strong>Vote</strong>提交，就可以在看见对应候选人的票数加1。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>一个完整的Dapp Demo结束了，是不是感觉也没有想象中的神秘，但我想说这只是上层的使用，真正神秘的东西是底层的技术支撑，慢慢探秘吧。</p>
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> Ethereum </tag>
            
            <tag> Solidity </tag>
            
            <tag> Dapp </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Application运行失败导致RM主备切换]]></title>
      <url>http://bigdatadecode.club/Application-fail-RM-change.html</url>
      <content type="html"><![CDATA[<p>先说故障现象:<br>某天收到RM主备切换报警，正常切换并不会有什么影响，但我当时还是出于警觉想去服务器上check下为什么切，check的时候发现集群无法提交任务，所以的任务都被挂起了。<br>第一反应是原standby节点有问题，于是手动又触发了一次切换，但任务依然无法运行。主备RM都重启过了但问题依然无法解决，那只能使用终极杀手锏了，重启了整个yarn集群。<br>集群重启之后任务恢复了，心里舒了一口气，去查RM的log吧，看下是什么原因导致了这次故障，log还没有细看，只看到一些<code>KeeperErrorCode = ConnectionLoss</code>，此时悲剧发生了，又收到了RM切换的报警，任务又被挂起了。。。</p>
<p>毫无头绪，只能再次重启集群，<em>这次重点关注了下集群上运行任务，估计是哪个任务把集群给干瘫了</em>，观察到有个任务运行失败的时候集群就会被瘫，看了下该任务的<strong>报错信息特别特别的长</strong>，于是告诉任务的负责人暂时把任务停掉，观察下集群是不是因为这个任务导致的。</p>
<p>该任务停掉之后集群正常运行了一段时间，在这段时间内在查RM的log并没有发现太多有价值的东西，全是与zk的连接丢失，连接丢失确实是会触发主备切换，但关键是为什么连接会丢失呢？没有头绪，只好去zk server端看下log，发现报<code>2018-11-27 15:54:30,208 [myid:1] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@373] - Exception causing close of session 0x36753e378030000 due to java.io.IOException: Len error 8603591</code></p>
<a id="more"></a>
<p>对这个error进行了搜索之后，有人说是zk的一个bug，在某个版本中已经修复，而我用的这个版本我看了下代码也已经修复了，后来手里有其它事再忙，就又另一个同事跟这个故障，调整了个zk的参数<code>jute.maxbuffer</code>搞定，这个参数控制着写入node的数据量。</p>
<blockquote>
<p>整个故障的原因是app在失败的时候会写入一些信息到zk，这些信息超过了zk的默认配置，导致写失败，链接就丢失了，主备就切换了，切换成功之后依然再尝试去写，总是写失败，所以整个集群就被卡住了。</p>
</blockquote>
<h2 id="Root-Cause"><a href="#Root-Cause" class="headerlink" title="Root Cause"></a>Root Cause</h2><p>这次并没有什么关键字可以让我们迅速找到关键代码处，此时你对源码的熟悉程度就能帮你迅速的定位了，这也就是为什么我们要熟悉源码的原因。</p>
<p>我们先来梳理下整个故障的全流程，流程如下：<br><img src="/blogimgs/Application-RM-change/state.png" alt="故障流程" title="故障流程"></p>
<p>是不是有点Application状态机的样子，那我们就从这里入手。</p>
<p>Application状态是从<code>RUNNING</code>状态又事件<code>ATTEMPT_FAILED</code>触发，将状态进行改变的，看下对应状态转化的处理类<code>AttemptFailedTransition</code>。<br>在<code>transition</code>方法中找到关键方法<code>rememberTargetTransitionsAndStoreState</code>，看下代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">rememberTargetTransitionsAndStoreState</span><span class="params">(RMAppEvent event,</span></span></span><br><span class="line"><span class="function"><span class="params">    Object transitionToDo, RMAppState targetFinalState,</span></span></span><br><span class="line"><span class="function"><span class="params">    RMAppState stateToBeStored)</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">  String diags = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">switch</span> (event.getType()) &#123;</span><br><span class="line">  <span class="keyword">case</span> APP_REJECTED:</span><br><span class="line">  <span class="keyword">case</span> ATTEMPT_FINISHED:</span><br><span class="line">  <span class="keyword">case</span> ATTEMPT_KILLED:</span><br><span class="line">    diags = event.getDiagnosticMsg();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> ATTEMPT_FAILED:</span><br><span class="line">    RMAppFailedAttemptEvent failedEvent = (RMAppFailedAttemptEvent) event;</span><br><span class="line">    diags = getAppAttemptFailedDiagnostics(failedEvent);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//      add by sunzhiwei for zk jute.maxbuffer</span></span><br><span class="line">  <span class="keyword">if</span> (diags.length() &gt; zkMaxBuffer) &#123;</span><br><span class="line">    diags = diags.substring(<span class="number">0</span>, zkMaxBuffer);</span><br><span class="line">    LOG.warn(<span class="string">"The diags is too long, so it needs to be intercepted : "</span> + diags);</span><br><span class="line">  &#125;</span><br><span class="line">  ApplicationStateData appState =</span><br><span class="line">      ApplicationStateData.newInstance(<span class="keyword">this</span>.submitTime, <span class="keyword">this</span>.startTime,</span><br><span class="line">          <span class="keyword">this</span>.user, <span class="keyword">this</span>.submissionContext,</span><br><span class="line">          stateToBeStored, diags, <span class="keyword">this</span>.storedFinishTime);</span><br><span class="line">  <span class="keyword">this</span>.rmContext.getStateStore().updateApplicationState(appState);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里把diags进行封装，通过<code>updateApplicationState</code>将app相关的信息写入zk中。(与写入zk相关的代码在<code>ZKRMStateStore.updateApplicationStateInternal</code>中)</p>
<p>知道了原因就好办了，我在这里将diags的长度进行了截取，并将其截取的长度进行了可配置化。<br>之所以这么改是因为我们不能一味的调整zk的<code>jute.maxbuffer</code>参数，这始终是个雷，我们应该从根处解决问题。</p>
<p>目前此代码已提交给社区，jira地址是<a href="https://issues.apache.org/jira/browse/YARN-9065" target="_blank" rel="noopener">YARN-9065</a></p>
<p>但是提交到社区之后，相关人员反馈了另一个patch，他修复的方式比我的方法优雅，感觉自己还是太简单粗暴了，嘿嘿。。。贴下jira地址可以参考下<a href="https://issues.apache.org/jira/browse/YARN-6125" target="_blank" rel="noopener">YARN-6125</a></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> ZK </tag>
            
            <tag> Len error </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Solidity Voting解析]]></title>
      <url>http://bigdatadecode.club/Solidity_Voting%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p>最近一直在学习BlockChain相关的知识，Ethereum网上也没有太好的资料，就先拿官网的一些example学习下吧。</p>
<p>本篇解析下使用智能合约编写的投票合约。</p>
<a id="more"></a>
<p>先看下代码，注释给的也比较清楚，虽然是一门新的语言，但读懂应该没有什么难度</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line">pragma solidity ^<span class="number">0.4</span><span class="number">.22</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/// @title 委托投票</span></span><br><span class="line">contract Ballot &#123;</span><br><span class="line">    <span class="comment">// 这里声明了一个新的复合类型用于稍后的变量</span></span><br><span class="line">    <span class="comment">// 它用来表示一个选民</span></span><br><span class="line">    struct Voter &#123;</span><br><span class="line">        uint weight; <span class="comment">// 计票的权重，也就是票数</span></span><br><span class="line">        bool voted;  <span class="comment">// 若为真，代表该人已投票</span></span><br><span class="line">        address delegate; <span class="comment">// 被委托人</span></span><br><span class="line">        uint vote;   <span class="comment">// 投票提案的索引</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 提案的类型</span></span><br><span class="line">    struct Proposal &#123;</span><br><span class="line">        bytes32 name;   <span class="comment">// 简称（最长32个字节）</span></span><br><span class="line">        uint voteCount; <span class="comment">// 得票数</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    address public chairperson;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 这声明了一个状态变量，为每个可能的地址存储一个 `Voter`。</span></span><br><span class="line">    <span class="comment">// 有权利投票的用户map</span></span><br><span class="line">    mapping(<span class="function"><span class="params">address</span> =&gt;</span> Voter) public voters;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 一个 `Proposal` 结构类型的动态数组</span></span><br><span class="line">    <span class="comment">// 投票提案数组</span></span><br><span class="line">    Proposal[] public proposals;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 为 `proposalNames` 中的每个提案，创建一个提案对象</span></span><br><span class="line">    <span class="comment">// 合约的构造函数，用constructor标识</span></span><br><span class="line">    <span class="keyword">constructor</span>(bytes32[] proposalNames) public &#123;</span><br><span class="line">        <span class="comment">// 合约的构造者为chairperson</span></span><br><span class="line">        chairperson = msg.sender;</span><br><span class="line">        <span class="comment">// 赋予投票的权利</span></span><br><span class="line">        voters[chairperson].weight = <span class="number">1</span>;</span><br><span class="line">        <span class="comment">//对于提供的每个提案名称，</span></span><br><span class="line">        <span class="comment">//创建一个新的 Proposal 对象并把它添加到数组的末尾。</span></span><br><span class="line">        <span class="keyword">for</span> (uint i = <span class="number">0</span>; i &lt; proposalNames.length; i++) &#123;</span><br><span class="line">            <span class="comment">// `Proposal(&#123;...&#125;)` 创建一个临时 Proposal 对象，</span></span><br><span class="line">            <span class="comment">// `proposals.push(...)` 将其添加到 `proposals` 的末尾</span></span><br><span class="line">            proposals.push(Proposal(&#123;</span><br><span class="line">                name: proposalNames[i],</span><br><span class="line">                voteCount: <span class="number">0</span></span><br><span class="line">            &#125;));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 授权 `voter` 投票的权利</span></span><br><span class="line">    <span class="comment">// 只有 `chairperson` 可以调用该函数。</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">giveRightToVote</span>(<span class="params">address voter</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 若 `require` 的第一个参数的计算结果为 `false`，</span></span><br><span class="line">        <span class="comment">// 则终止执行，撤销所有对状态和以太币余额的改动。</span></span><br><span class="line">        <span class="comment">// 在旧版的 EVM 中这曾经会消耗所有 gas，但现在不会了。</span></span><br><span class="line">        <span class="comment">// 使用 require 来检查函数是否被正确地调用，是一个好习惯。</span></span><br><span class="line">        <span class="comment">// 你也可以在 require 的第二个参数中提供一个对错误情况的解释。</span></span><br><span class="line">        <span class="built_in">require</span>(</span><br><span class="line">            msg.sender == chairperson,</span><br><span class="line">            <span class="string">"Only chairperson can give right to vote."</span></span><br><span class="line">        );</span><br><span class="line">        <span class="built_in">require</span>(</span><br><span class="line">            !voters[voter].voted,</span><br><span class="line">            <span class="string">"The voter already voted."</span></span><br><span class="line">        );</span><br><span class="line">        <span class="built_in">require</span>(voters[voter].weight == <span class="number">0</span>);</span><br><span class="line">        voters[voter].weight = <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// 把你的投票权利委托给 `to`。</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">delegate</span>(<span class="params">address to</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 传引用 (为什么这里传的是引用？？？？？？？)</span></span><br><span class="line">        Voter storage sender = voters[msg.sender];</span><br><span class="line">        <span class="built_in">require</span>(!sender.voted, <span class="string">"You already voted."</span>);</span><br><span class="line"></span><br><span class="line">        <span class="built_in">require</span>(to != msg.sender, <span class="string">"Self-delegation is disallowed."</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 委托是可以传递的，只要被委托者 `to` 也设置了委托。</span></span><br><span class="line">        <span class="comment">// 一般来说，这种循环委托是危险的。因为，如果传递的链条太长，</span></span><br><span class="line">        <span class="comment">// 则可能需消耗的gas要多于区块中剩余的（大于区块设置的gasLimit），</span></span><br><span class="line">        <span class="comment">// 这种情况下，委托不会被执行。</span></span><br><span class="line">        <span class="comment">// 而在另一些情况下，如果形成闭环，则会让合约完全卡住。</span></span><br><span class="line">        <span class="comment">// A委托给B，B的权利已经委托了C，那A的权利直接委托给C</span></span><br><span class="line">        <span class="keyword">while</span> (voters[to].delegate != address(<span class="number">0</span>)) &#123;</span><br><span class="line">            to = voters[to].delegate;</span><br><span class="line">            <span class="comment">// 不允许闭环委托</span></span><br><span class="line">            <span class="built_in">require</span>(to != msg.sender, <span class="string">"Found loop in delegation."</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// `sender` 是一个引用, 相当于对 `voters[msg.sender].voted` 进行修改</span></span><br><span class="line">        sender.voted = <span class="literal">true</span>;</span><br><span class="line">        sender.delegate = to;</span><br><span class="line">        <span class="comment">// 这也是引用？？？？？</span></span><br><span class="line">        Voter storage delegate_ = voters[to];</span><br><span class="line">        <span class="keyword">if</span> (delegate_.voted) &#123;</span><br><span class="line">            <span class="comment">// 若被委托者已经投过票了，直接增加得票数</span></span><br><span class="line">            proposals[delegate_.vote].voteCount += sender.weight;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 若被委托者还没投票，增加委托者的权重</span></span><br><span class="line">            delegate_.weight += sender.weight;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/// 把你的票(包括委托给你的票)，</span></span><br><span class="line">    <span class="comment">/// 投给提案 `proposals[proposal].name`.</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">vote</span>(<span class="params">uint proposal</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        Voter storage sender = voters[msg.sender];</span><br><span class="line">        <span class="built_in">require</span>(!sender.voted, <span class="string">"Already voted."</span>);</span><br><span class="line">        sender.voted = <span class="literal">true</span>;</span><br><span class="line">        sender.vote = proposal</span><br><span class="line">        <span class="comment">// 如果 `proposal` 超过了数组的范围，则会自动抛出异常，并恢复所有的改动</span></span><br><span class="line">        proposals[proposal].voteCount += sender.weight;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 结合之前所有的投票，计算出最终胜出的提案</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">winningProposal</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span></span></span><br><span class="line"><span class="function">            <span class="title">returns</span> (<span class="params">uint winningProposal_</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        uint winningVoteCount = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (uint p = <span class="number">0</span>; p &lt; proposals.length; p++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (proposals[p].voteCount &gt; winningVoteCount) &#123;</span><br><span class="line">                winningVoteCount = proposals[p].voteCount;</span><br><span class="line">                winningProposal_ = p;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 调用 winningProposal() 函数以获取提案数组中获胜者的索引，并以此返回获胜者的名称</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">winnerName</span>(<span class="params"></span>) <span class="title">public</span> <span class="title">view</span></span></span><br><span class="line"><span class="function">            <span class="title">returns</span> (<span class="params">bytes32 winnerName_</span>)</span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        winnerName_ = proposals[winningProposal()].name;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>合约测试可以在Solidity IDE中测试，也可以在geth中执行，先来看个简单一点的，使用remix在线IDE进行合约部署。</p>
<h2 id="Remix-IDE运行合约"><a href="#Remix-IDE运行合约" class="headerlink" title="Remix IDE运行合约"></a>Remix IDE运行合约</h2><p>Remix IDE可以使用在线的，也可能本地安装。(在线的IDE有时会比较慢，我就安装了个本地的，结果发现本地的也比较慢，不知道是不是我虚拟机的问题。。。)</p>
<p>这里先使用在线版的，随后写个本地安装Remix的教程。</p>
<p>在<a href="https://remix.ethereum.org" target="_blank" rel="noopener">Remix IDE</a>的左上角有个”+”的图标，点击新建一个文件，将上述代码copy进去。<br>文件创建成功之后就是选择Solidity的版本，编译代码，如图：<br><img src="/blogimgs/SolidityVoting/compile.png" alt="编译合约" title="编译合约"></p>
<p>编译成功之后就是部署合约，这里点击<code>Deploy</code>之后会帮你将合约部署到以太坊的测试环境中，部署流程如图：<br><img src="/blogimgs/SolidityVoting/deploy.png" alt="部署合约" title="部署合约"></p>
<blockquote>
<p>因为合约的构造函数需要输入参数，所以在deploy的时候，需要传入参数。<br>这里参数是一个bytes32的数组，在有的版本中string可以转成bytes32，但在<code>0.4.22</code>中无法直接转，<br>所以这里我们要直接输入byte32的一个数组<code>[&quot;0x616263&quot;, &quot;0x646566&quot;, &quot;0x676869&quot;]</code>，<br>转化成字符串为<code>[&quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;]</code></p>
</blockquote>
<p>合约部署好之后，就可以调用合约的一些方法了，比如<em>vote</em>和<em>giveRightToVote</em><br>vote方法需要传入的参数是uint，是<code>proposals</code>数组的索引，这里注意不要越界。<br>giveRightToVote方法传入的参数是address，意思是给某个地址授权，使其能够进行投票，<br>这个address可以在<em>Account</em>中选择(remix会默认创建5个账号)，如图：<br><img src="/blogimgs/SolidityVoting/accounts.png" alt="账号" title="账号"><br>将选择好的address粘贴到参数栏中调用该方法给address授权，<br>然后依然在<em>Account</em>选项中切换到该address，就可以以该账号进行操作了，比如调用vote给某个提案投票。</p>
<p>其它的方法也可以尝试着调用下，加深对代码的理解。</p>
<p>这是用Remix IDE进行测试开发，还可以使用geth命令行模式进行开发测试，geth相对于Remix IDE就比较繁琐，具体流程下次再续。。。</p>
<!--
将此代码写入`voting.sol`文件中，编译sol文件生成`bytecode`和`ABI`，执行命令如下：
1、`solc --bin voting.sol` 生成bytecode如下：


2、`solc --abi voting.sol` 生成ABI如下：

## 部署合约
### 使用ABI生成合约对象
在geth中执行如下命令

### 使用合约对象部署合约
在geth中执行如下命令


## 运行合约
运行合约之前先生成一个块  注释掉的(生成块有什么用呢)，执行挖矿命令，生成新块之后停止挖矿。

管理员执行
先调用voter.constructor()给投票增加提案
voter.giveRightToVote()给选民赋投票权
voter.winnerName()查看投票结果
选民执行
voter.vote()给喜欢的提案投票
voter.delegate()委托别的选民帮自己投票

-->
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> Ethereum </tag>
            
            <tag> Solidity </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS中atime与mtime解析]]></title>
      <url>http://bigdatadecode.club/HDFS%E4%B8%ADatime%E5%92%8Cmtime.html</url>
      <content type="html"><![CDATA[<p>先来了解下Linux中atime和mtime区别：<br>atime：access time即访问时间<br>mtime：modify time即修改时间，这里指文件内容的修改。(经常和atime与mtime一起谈到的还有ctime，这里不展开，有兴趣的可以goolge)</p>
<blockquote>
<p>这里需要注意的是有的系统可能为了性能上的优化，atime并不是实时更新，此时查看atime并没有得到想要的效果。</p>
</blockquote>
<a id="more"></a>
<p>Linux atime修改策略与mount有关，可选的值有<code>noatime</code>、<code>relatime</code>和<code>strictatime</code>。</p>
<ul>
<li>noatime<br>atime不会被更新，即使修改了文件内容</li>
<li>relatime</li>
</ul>
<ol>
<li>如果一个文件的atime比ctime或mtime更早，此时你去读取了该文件，atime才会被更新为当前时间。</li>
<li>atime比现在早一天，那么atime在文件读取时会被更新</li>
</ol>
<ul>
<li>strictatime<br>atime在文件每次被读取时，都能够被更新</li>
</ul>
<h2 id="HDFS中atime和mtime"><a href="#HDFS中atime和mtime" class="headerlink" title="HDFS中atime和mtime"></a>HDFS中atime和mtime</h2><p>了解了Linux中的atime与mtime，我们来了解下HDFS中的这两个值的变化规则。</p>
<p>在看代码之前，先想下atime和mtime有可能在哪些地方会修改，</p>
<p>hdfs底层api对文件都有哪些操作？无非就是读写两种操作，读肯定修改的是atime，写修改的是mtime，是否修改atime还得确认。<br>这里我们还漏掉一种操作，那就是mv。</p>
<p>先来看下atime</p>
<h3 id="atime"><a href="#atime" class="headerlink" title="atime"></a>atime</h3><p>去年写过一篇文章<a href="http://bigdatadecode.club/HDFS read解析.html">HDFS read解析(一)之Open文件流</a>介绍HDFS读操作流程，这里就不再累赘了，直接贴出关键代码。(有兴趣的同学可以自行查看)</p>
<blockquote>
<p>这里还是简单说下读的流程：<em>客户端向NN发起一个读请求，NN将相关的block信息返回给客户端，客户端再与对应的DN建立连接读取信息</em>。<br>在这个过程中，先与NN交互然后再与DN交互，那么每个文件的atime相关元数据信息都存在NN中，那么atime相关的修改也肯定发生在与NN交互的这个过程中。</p>
</blockquote>
<p>从之前的文章中可知入口函数是<code>FSNamesystem.getBlockLocations</code>，关键代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LocatedBlocks <span class="title">getBlockLocations</span><span class="params">(String clientMachine, String srcArg,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">long</span> offset, <span class="keyword">long</span> length)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">if</span> (res.updateAccessTime()) &#123;</span><br><span class="line">    String src = srcArg;</span><br><span class="line">    writeLock();</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> now = now();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">final</span> INodesInPath iip = dir.resolvePath(pc, src);</span><br><span class="line">      src = iip.getPath();</span><br><span class="line">      INode inode = iip.getLastINode();</span><br><span class="line">      <span class="comment">// 再次判断是否可以更新atime</span></span><br><span class="line">      <span class="keyword">boolean</span> updateAccessTime = inode != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">          now &gt; inode.getAccessTime() + getAccessTimePrecision();</span><br><span class="line">      <span class="keyword">if</span> (!isInSafeMode() &amp;&amp; updateAccessTime) &#123;</span><br><span class="line">        <span class="comment">// 设置atime</span></span><br><span class="line">        <span class="keyword">boolean</span> changed = FSDirAttrOp.setTimes(dir,</span><br><span class="line">            inode, -<span class="number">1</span>, now, <span class="keyword">false</span>, iip.getLatestSnapshotId());</span><br><span class="line">        <span class="keyword">if</span> (changed) &#123;</span><br><span class="line">          getEditLog().logTimes(src, -<span class="number">1</span>, now);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"Failed to update the access time of "</span> + src, e);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      writeUnlock(operationName);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>res.updateAccessTime()</code>决定了是否更新atime，其值是在<code>getBlockLocationsInt</code>中赋值的，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> updateAccessTime = isAccessTimeSupported() &amp;&amp; !isInSafeMode()</span><br><span class="line">        &amp;&amp; !iip.isSnapshot()</span><br><span class="line">        &amp;&amp; now &gt; inode.getAccessTime() + getAccessTimePrecision();</span><br></pre></td></tr></table></figure>
<p>其中关键的因素是<code>isAccessTimeSupported()</code>和<code>getAccessTimePrecision()</code>，这个两个方法都与<code>accessTimePrecision</code>有关，此值是由<code>dfs.namenode.accesstime.precision</code>设置的，默认是3600000。<br>当此值大于0，<code>isAccessTimeSupported()</code>返回true，<code>getAccessTimePrecision()</code>得到的值是<code>dfs.namenode.accesstime.precision</code>的值。</p>
<p>从上述代码中可以看出更新atime的一个条件是<strong>两次读取间隔相隔dfs.namenode.accesstime.precision秒，默认是1小时。</strong></p>
<p>这里遗留两个问题<br>1、新建文件时atime如何赋值<br>2、修改文件内容时atime如何赋值</p>
<p>关于这个两个问题我在下一节在写流程中解答。请继续向下看</p>
<h3 id="mtime"><a href="#mtime" class="headerlink" title="mtime"></a>mtime</h3><p>同样去年也写过一篇关于写的文章<a href="http://bigdatadecode.club/HDFS write解析.html">HDFS write解析</a>介绍HDFS读操作流程，这里就不再累赘了，直接贴出关键代码。(有兴趣的同学可以自行查看)</p>
<p>写相关的操作包括create、close和append<br>写文件有两种方式，一种是调用<code>create(Path)</code>方法，另一种是调用<code>append(Path)</code>方法</p>
<h3 id="create"><a href="#create" class="headerlink" title="create"></a>create</h3><p>通过调用<code>create(Path)</code>，最终会调用<code>FSDirectory.addFile</code>方法，在此方法中会new一个<code>INodeFile</code>，此时<em>会设置mtime和atime为同一个值</em>，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">INodesInPath <span class="title">addFile</span><span class="params">(INodesInPath existing, String localName, PermissionStatus</span></span></span><br><span class="line"><span class="function"><span class="params">    permissions, <span class="keyword">short</span> replication, <span class="keyword">long</span> preferredBlockSize,</span></span></span><br><span class="line"><span class="function"><span class="params">    String clientName, String clientMachine)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> FileAlreadyExistsException, QuotaExceededException,</span></span><br><span class="line"><span class="function">    UnresolvedLinkException, SnapshotAccessControlException, AclException </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> modTime = now();</span><br><span class="line">  INodeFile newNode = newINodeFile(allocateNewInodeId(), permissions, modTime,</span><br><span class="line">      modTime, replication, preferredBlockSize);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有打开一个文件就有关闭一个文件，接下来看下关闭文件时atime和mtime会有什么变化。</p>
<h3 id="close"><a href="#close" class="headerlink" title="close"></a>close</h3><p><code>closeFile()</code>在<code>finalizeINodeFileUnderConstruction</code>中调用，在此方法中会设置mtime，看下代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">finalizeINodeFileUnderConstruction</span><span class="params">(String src,</span></span></span><br><span class="line"><span class="function"><span class="params">    INodeFile pendingFile, <span class="keyword">int</span> latestSnapshot)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">...</span><br><span class="line">  pendingFile.toCompleteFile(now());</span><br><span class="line">...</span><br><span class="line">  closeFile(src, pendingFile);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// INodeFile.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> INodeFile <span class="title">toCompleteFile</span><span class="params">(<span class="keyword">long</span> mtime)</span> </span>&#123;</span><br><span class="line">  Preconditions.checkState(isUnderConstruction(),</span><br><span class="line">      <span class="string">"file is no longer under construction"</span>);</span><br><span class="line">  FileUnderConstructionFeature uc = getFileUnderConstructionFeature();</span><br><span class="line">  <span class="keyword">if</span> (uc != <span class="keyword">null</span>) &#123;</span><br><span class="line">    assertAllBlocksComplete();</span><br><span class="line">    removeFeature(uc);</span><br><span class="line">    <span class="keyword">this</span>.setModificationTime(mtime);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">this</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从代码中可以看出，close文件时只对mtime进行了修改。</p>
<h3 id="append"><a href="#append" class="headerlink" title="append"></a>append</h3><p>append只是打开一个文件流，并不会修改mtime或者atime，只是在close的时候修改mtime</p>
<!--

  public final void setModificationTime(long modificationTime) {
    referred.setModificationTime(modificationTime);
  }



  public final void setAccessTime(long accessTime) {
    referred.setAccessTime(accessTime);
  }  

INodeWithAdditionalFields.modificationTime accessTime

-->
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><blockquote>
<p>atime</p>
</blockquote>
<p>1、两次读间隔大于默认的1小时时，更新atime。默认间隔通过<code>dfs.namenode.accesstime.precision</code>控制。<br>2、新建一个文件时atime赋值为当前时间(<em>注意，当关闭一个文件时atime不会修改</em>)</p>
<blockquote>
<p>mtime</p>
</blockquote>
<p>1、新建一个文件时mtime赋值为当前时间(同时会修改atime)<br>2、关闭一个文件时mtime赋值为当前时间(此时并不会修改atime)</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> atime </tag>
            
            <tag> mtime </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN Lost Node显示异常]]></title>
      <url>http://bigdatadecode.club/YARN-Lost-Node%E6%98%BE%E7%A4%BA%E5%BC%82%E5%B8%B8.html</url>
      <content type="html"><![CDATA[<p>先说现象，在yarn的web页面，Lost Nodes指标显示的数据异常，如下：<br><img src="/blogimgs/lostnode/lostnode1.png" alt=""><br>我的集群一共有5台节点，这里显示有一台节点为<code>Lost Nodes</code>，但依然有5台<code>Active Nodes</code>，细心观察发现或有某个节点即存在Active Nodes中也存在Lost Nodes中，只是端口不一样。</p>
<p>这种情况如何解决呢？<br>在<code>yarn-site.xml</code>中添加<code>yarn.nodemanager.address</code>配置项，如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="variable">$&#123;yarn.nodemanager.hostname&#125;</span>:65033&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>
<p>需要重启集群，让参数生效。</p>
<p>现在你可以去修改你集群的配置，是不是瞬间心情愉快了很多，那是不是可以继续读下去，看下我们如何解决这种问题。</p>
<a id="more"></a>
<h2 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h2><p>首先利用搜索引擎，看下是否有没有前人帮你埋坑。(当你搜到这篇blog，说明你已经具有了这种能力)</p>
<h2 id="镇定"><a href="#镇定" class="headerlink" title="镇定"></a>镇定</h2><p>没有前人埋坑，怎么办？有的同学就慌了，解决不了了，怎么办？先重启解决吧。。。<br>重启是可以解决遇到的问题，但我们不能遇到问题就重启。在重启之前，我们也要进行一些评估，评估下这个问题是不是很严重，是不是需要立马解决。</p>
<p>目前我们遇到的这个问题很明显不是那种需要立马重启服务来解决的问题，那我们应该怎么解决这个问题呢？最好的答案就是<strong>看源码</strong>。</p>
<p>一个项目代码那么多，在你不熟悉每一行代码的时候如何快速定位关键代码并找到问题所在呢？<br>我认为很简单，就两步，<code>首先全文检索找到表象，然后逆向跟踪代码并找到答案</code>。</p>
<h3 id="定位关键代码入口"><a href="#定位关键代码入口" class="headerlink" title="定位关键代码入口"></a>定位关键代码入口</h3><p>全文检索关键字<code>Lost Nodes</code>，结果如下：<br><img src="/blogimgs/lostnode/find.png" alt=""><br>从结果中我们可以根据经验定位到关键入口应该在webapp包中，点击进<code>MetricsOverviewTable</code>中的相关代码位置<br>代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">th().<span class="variable">$class</span>(<span class="string">"ui-state-default"</span>)._(<span class="string">"Lost Nodes"</span>)._()</span><br><span class="line"></span><br><span class="line">// 这里只是一个页面样式，并没有涉及到赋值，看下上下文有没有取值的相关代码</span><br><span class="line">// 发现代码如下</span><br><span class="line">td().a(url(<span class="string">"nodes/lost"</span>),String.valueOf(clusterMetrics.getLostNodes()))._()</span><br></pre></td></tr></table></figure>
<p>是不是找到了，<code>clusterMetrics</code>是一个<code>ClusterMetricsInfo</code>的对象。</p>
<p>ClusterMetricsInfo存储了整个集群的metrics信息，其中有个属性<code>lostNodes</code>，然后根据这个属性跟踪到<code>ClusterMetrics.numLostNMs</code>，该属性存在三个方法，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Lost NMs</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getNumLostNMs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> numLostNMs.value();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">incrNumLostNMs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  numLostNMs.incr();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">decrNumLostNMs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  numLostNMs.decr();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码跟到这里，你就可以随所欲为了。。。</p>
<p>LostNode显示异常，不是增加的时候有问题就是减少的时候有问题，无非这两种情况，我们先看下incr的逻辑</p>
<h3 id="Lost-Node-incr"><a href="#Lost-Node-incr" class="headerlink" title="Lost Node incr"></a>Lost Node incr</h3><p>根据<code>incrNumLostNMs</code>方法我们反跟踪到NM的状态机相关的代码，这里我按照顺序的逻辑来梳理代码</p>
<p>先看下一个正常RUNNING的节点是怎么变为Lost Node节点的</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.addTransition(NodeState.RUNNING, NodeState.LOST,</span><br><span class="line">    RMNodeEventType.EXPIRE,</span><br><span class="line">    <span class="keyword">new</span> DeactivateNodeTransition(NodeState.LOST))</span><br></pre></td></tr></table></figure>
<p>NM状态的变化是由<code>RMNodeEventType.EXPIRE</code>事件触发的，NM5分钟没有与RM进行心跳会触发这个事件，这个时间是在代码里写死的<code>public static final int DEFAULT_EXPIRE = 5*60*1000;//5 mins</code>。</p>
<p>我们看下<code>DeactivateNodeTransition</code>这个handle的实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(RMNodeImpl rmNode, RMNodeEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//check for UnknownNodeId</span></span><br><span class="line">  <span class="keyword">if</span> (rmNode.getNodeID().getPort() == -<span class="number">1</span>) &#123;</span><br><span class="line">    rmNode.updateMetricsForDeactivatedNode(rmNode.getState(), finalState);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br><span class="line">  <span class="comment">// Deactivate the node</span></span><br><span class="line">  <span class="comment">// 从RUNNING中移除当前节点</span></span><br><span class="line">  rmNode.context.getRMNodes().remove(rmNode.nodeId);</span><br><span class="line">  LOG.info(<span class="string">"Deactivating Node "</span> + rmNode.nodeId + <span class="string">" as it is now "</span></span><br><span class="line">      + finalState);</span><br><span class="line">  <span class="comment">// 将当前节点放入inactive队列中</span></span><br><span class="line">  rmNode.context.getInactiveRMNodes().put(rmNode.nodeId.getHost(), rmNode);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//Update the metrics</span></span><br><span class="line">  rmNode.updateMetricsForDeactivatedNode(initialState, finalState);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>metrics信息是在<code>updateMetricsForDeactivatedNode</code>中增加的，查看其具体逻辑没有什么异常逻辑，就是简单的根据具体的状态对其进行incr和decr。<br>这里我们需要注意在更新metrics之前的一个put操作，这里将当前节点put到一个inactive队列中，LostNode的具体节点信息存储在这里，这里会不会有问题呢？</p>
<p>inactive是<code>ConcurrentMap&lt;String, RMNode&gt; inactiveNodes = new ConcurrentHashMap&lt;String, RMNode&gt;()</code>是一个线程安全的，看下这里的kv到底存的是什么，查其源码可以看出这里key是主机host，不与端口绑定，重启NM时可以从inactive中取出对应的host。</p>
<p>incr的逻辑并没有发现什么问题，那继续看下decr相关的代码</p>
<h3 id="Lost-Node-decr"><a href="#Lost-Node-decr" class="headerlink" title="Lost Node decr"></a>Lost Node decr</h3><p>根据<code>decrNumLostNMs</code>方法我们反跟踪到NM在启动的时候会触发这部分代码，大体流程是<code>RMNodeEventType.STARTED</code>事件触发，由<code>AddNodeTransition</code>进行捕获处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 事件触发状态转换</span></span><br><span class="line">.addTransition(NodeState.NEW, NodeState.RUNNING,</span><br><span class="line">    RMNodeEventType.STARTED, <span class="keyword">new</span> AddNodeTransition())</span><br><span class="line"></span><br><span class="line"><span class="comment">// AddNodeTransition.transition</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(RMNodeImpl rmNode, RMNodeEvent event)</span> </span>&#123;</span><br><span class="line">...</span><br><span class="line">  String host = rmNode.nodeId.getHost();</span><br><span class="line">  <span class="comment">// 根据当前节点的host从inactive中移除该节点信息并返回相关信息</span></span><br><span class="line">  RMNode previousRMNode = rmNode.context.getInactiveRMNodes().remove(host);</span><br><span class="line">  <span class="comment">// previousRMNode为null，说明inactive队列中没有该host的信息，</span></span><br><span class="line">  <span class="comment">// 当作一个新的节点进行处理，Lost Nodes信息不发生变化</span></span><br><span class="line">  <span class="comment">// 如果previousRMNode不为null，则更新Lost Nodes的信息</span></span><br><span class="line">  <span class="keyword">if</span> (previousRMNode != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (previousRMNode.getNodeID().getPort() != -<span class="number">1</span>) &#123;</span><br><span class="line">      <span class="comment">// Old node rejoining</span></span><br><span class="line">      rmNode.updateMetricsForRejoinedNode(previousRMNode.getState());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// An old excluded node rejoining</span></span><br><span class="line">      ClusterMetrics.getMetrics().decrDecommisionedNMs();</span><br><span class="line">      containers = updateNewNodeMetricsAndContainers(rmNode, startEvent);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Increment activeNodes explicitly because this is a new node.</span></span><br><span class="line">    containers = updateNewNodeMetricsAndContainers(rmNode, startEvent);</span><br><span class="line">  &#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从上面的代码得知，新启动一个节点回去inactive队列中check下是否存在，存在则更新下Lost Nodes的metrics计数信息，不存在则不更新Lost Nodes metrics的计数信息。</p>
<p>看到这里是不是感觉incr和decr的逻辑都正常，不存在Lost Nodes的metrics更新异常的问题，但是根据故障的想象仔细分析会发现肯定是新启动的NM没有从Lost Nodes中正常减少，那么什么情况会不正常呢？</p>
<blockquote>
<p>新启动一个节点需要去inactive中check下当前节点是否存在，那么如果当前节点<strong>之前启动的信息</strong>还没有放入inactive那这次新启动时就无法check成功，那就当成一个新的节点启动了。因为从incr的代码中分析可以得知NM在<code>RMNodeEventType.EXPIRE</code>事件之后才会放入inactive中，这个事件需要超时5分钟，这个时间差就导致了Active Nodes与Lost Nodes总数与集群的规模不匹配的原因，我们验证下，<strong>把一个节点停掉然后立马启动，会发现Active Nodes增加了一个，待5分钟之后，Lost Nodes中增加一个，Active Nodes减少一个，此时Active Nodes正常，但Lost Nodes显示异常，与开篇的现象一致</strong>。</p>
</blockquote>
<h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>明白了故障出现的原因，就离解决方案不远了。这个显示异常其实是因为每个NM启动的时候端口是随机的，如果某个NM停止和启动间隔时间较短(小于5分钟)，<em>则之前启动的NM进程在超时之后状态转换为Lost状态</em>，但当前host上的新NM进程已经启动，无法触发Lost的更新操作。</p>
<p>关键环节出现在<em>检查超时</em>这里，超时是通过NM与RM之间的心跳来维护的，心跳是由<code>host+port</code>来识别的，把NM对应的port固定就可以解决这个问题了。</p>
<p>那么我们就找下这个端口是在哪生成的。</p>
<p>我们从decr处的代码作为入口进行反跟踪。<br><code>AddNodeTransition.transition</code>中inactive的key是从<code>rmNode.nodeId.getHost()</code>中得到的，rmNode是RMNodeImpl类的一个实例，我们来看下RMNodeImpl中nodeId属性是如何赋值的，发现是在构造函数中赋值的，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">RMNodeImpl</span><span class="params">(NodeId nodeId, RMContext context, String hostName,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> cmPort, <span class="keyword">int</span> httpPort, Node node, Resource capability, String nodeManagerVersion)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.nodeId = nodeId;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那这个对象又是在哪实例化的呢？继续跟踪到<code>ResourceTrackerService.registerNodeManager</code>方法，发现port信息是从request请求中取的，request是在<code>NodeStatusUpdaterImpl.registerWithRM</code>实例化，而实例化使用的nodeId是<code>NMContext</code>的一个属性且通过<code>setNodeId</code>进行赋值的，这个赋值操作发生在<code>ContainerManagerImpl.serviceStart</code>中，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceStart</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="keyword">final</span> InetSocketAddress initialAddress = conf.getSocketAddr(</span><br><span class="line">      YarnConfiguration.NM_BIND_HOST,</span><br><span class="line">      YarnConfiguration.NM_ADDRESS,</span><br><span class="line">      YarnConfiguration.DEFAULT_NM_ADDRESS,</span><br><span class="line">      YarnConfiguration.DEFAULT_NM_PORT);</span><br><span class="line"> ...</span><br><span class="line">  <span class="comment">// setup node ID</span></span><br><span class="line">  InetSocketAddress connectAddress;</span><br><span class="line">  <span class="keyword">if</span> (delayedRpcServerStart) &#123;</span><br><span class="line">    connectAddress = NetUtils.getConnectAddress(initialAddress);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    server.start();</span><br><span class="line">    connectAddress = NetUtils.getConnectAddress(server);</span><br><span class="line">  &#125;</span><br><span class="line">  NodeId nodeId = buildNodeId(connectAddress, hostOverride);</span><br><span class="line">  ((NodeManager.NMContext)context).setNodeId(nodeId);</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看上面的代码发生nodeId是通过<code>connectAddress</code>实例化的，而<code>connectAddress</code>又是<code>initialAddress</code>得到的，initialAddress就是我们要找的终极目标。</p>
<p>这里的主要是两个变量<code>YarnConfiguration.NM_BIND_HOST</code>和<code>YarnConfiguration.NM_ADDRESS</code>对应的配置项是<code>yarn.nodemanager.bind-host</code>和<code>yarn.nodemanager.address</code>。</p>
<p>显而易见<code>yarn.nodemanager.address</code>的默认值是<code>${yarn.nodemanager.hostname}:0</code>控制了NM的端口，<strong>在这里指定端口来固定NM的心跳端口，在NM重启的时候可以继续之前的心跳端口，来避免重启的时候导致Lost Nodes显示异常</strong>。</p>
<h2 id="事后诸葛"><a href="#事后诸葛" class="headerlink" title="事后诸葛"></a>事后诸葛</h2><p>其实如果你熟悉Hadoop的状态机的话，很容易直接定位到Lost Nodes的变化是在NM状态变化的时候触发的，这就直接定位到关键类<code>RMNodeImpl</code></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> LostNode </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[以太坊测试环境部署]]></title>
      <url>http://bigdatadecode.club/Ethereum-private-chain.html</url>
      <content type="html"><![CDATA[<p>上篇介绍了以太坊开发环境，本篇介绍下如何使用私有链。</p>
<a id="more"></a>
<p>使用私有链之前，先要创建创世块genesis。</p>
<h2 id="初始化私有链"><a href="#初始化私有链" class="headerlink" title="初始化私有链"></a>初始化私有链</h2><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"> <span class="attr">"nonce"</span>: <span class="string">"0x0000000000000042"</span>,</span><br><span class="line"> <span class="attr">"timestamp"</span>: <span class="string">"0x0"</span>,</span><br><span class="line"> <span class="attr">"parentHash"</span>: <span class="string">"0x0000000000000000000000000000000000000000000000000000000000000000"</span>,</span><br><span class="line"> <span class="attr">"mixhash"</span>: <span class="string">"0x0000000000000000000000000000000000000000000000000000000000000000"</span>,</span><br><span class="line"> <span class="attr">"extraData"</span>: <span class="string">"0x"</span>,</span><br><span class="line"> <span class="attr">"gasLimit"</span>: <span class="string">"0x80000000"</span>,</span><br><span class="line"> <span class="attr">"difficulty"</span>: <span class="string">"0x3"</span>,</span><br><span class="line"> <span class="attr">"coinbase"</span>: <span class="string">"0x3333333333333333333333333333333333333333"</span>,</span><br><span class="line"> <span class="attr">"config"</span>:&#123;</span><br><span class="line">    <span class="attr">"chainId"</span>: <span class="number">55</span>,</span><br><span class="line">    <span class="attr">"homesteadBlock"</span>: <span class="number">0</span>,</span><br><span class="line">    <span class="attr">"eip155Block"</span>: <span class="number">0</span></span><br><span class="line"> &#125;,</span><br><span class="line"> <span class="attr">"alloc"</span>: &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将上述内容写入文件<code>genesis.json</code>中，字段的解释如下:</p>
<p>nonce：64位随机数，用于挖矿<br>timestamp：创世块的时间戳<br>parentHash：上一个区块的hash值，因为是创世块，所以这个值是0<br>mixhash：与 nonce 配合用于挖矿，由上一个区块的一部分生成的 hash。(<strong>这个在bitcoin中没有，具体是干什么用的呢？？？</strong>)<br>extraData：附加信息，任意填写<br>gasLimit ：对GAS的消耗总量限制，用来限制区块能包含的交易信息总和，因为我们就测试链，所以随意填写。<br>difficulty：难度值，越大越难 (<strong>bitcoin是难度值越小越难，注意下不同，随后抽空看下以太坊的难度值</strong>)<br>coinbase：矿工账号，第一个区块挖出后将给这个矿工账号发送奖励的以太币。(<strong>感觉貌似没用？？？也可能使用的方式不对，待测</strong>)<br>alloc： 预设账号以及账号的以太币数量，测试链挖矿比较容易可以不配置<br>chainId 指定了独立的区块链网络 ID，不同 ID 网络的节点无法互相连接。</p>
<p>创建了genesis文件之后，初始化私有链，命令为<code>geth --datadir=data0 init genesis.json</code><br>执行结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">hadoop@ubuntu:~/blockchain/ethereum$ geth --datadir data0 init genesis.json</span><br><span class="line">WARN [08-23|08:39:07.353] Sanitizing cache to Go<span class="string">'s GC limits       provided=1024 updated=662</span></span><br><span class="line"><span class="string">INFO [08-23|08:39:07.355] Maximum peer count                       ETH=25 LES=0 total=25</span></span><br><span class="line"><span class="string">INFO [08-23|08:39:07.357] Allocated cache and file handles         database=/home/hadoop/blockchain/ethereum/data0/geth/chaindata cache=16 handles=16</span></span><br><span class="line"><span class="string">INFO [08-23|08:39:07.400] Persisted trie from memory database      nodes=0 size=0.00B time=14.163µs gcnodes=0 gcsize=0.00B gctime=0s livenodes=1 livesize=0.00B</span></span><br><span class="line"><span class="string">INFO [08-23|08:39:07.405] Successfully wrote genesis state         database=chaindata                                             hash=4a306e…543a63</span></span><br><span class="line"><span class="string">INFO [08-23|08:39:07.405] Allocated cache and file handles         database=/home/hadoop/blockchain/ethereum/data0/geth/lightchaindata cache=16 handles=16</span></span><br><span class="line"><span class="string">INFO [08-23|08:39:07.420] Persisted trie from memory database      nodes=0 size=0.00B time=3.02µs   gcnodes=0 gcsize=0.00B gctime=0s livenodes=1 livesize=0.00B</span></span><br><span class="line"><span class="string">INFO [08-23|08:39:07.420] Successfully wrote genesis state         database=lightchaindata                                             hash=4a306e…543a63</span></span><br></pre></td></tr></table></figure>
<p>如上则初始化成功，下面开始使用私有链</p>
<h2 id="使用私有链"><a href="#使用私有链" class="headerlink" title="使用私有链"></a>使用私有链</h2><p>执行命令<code>geth --datadir data0 --networkid 1108 console</code>进入geth的终端，此时就和上篇的开发环境一样了，同样的挖矿流程来一套就ok了。</p>
<!--
geth --rpc --rpcaddr="0.0.0.0" --rpccorsdomain="*" --unlock '0' --password ~/Library/Ethereum/password   --nodiscover --maxpeers '5' --networkid '1234574' --datadir '~/Library/Ethereum'  consol

geth --identity "TestNode" --rpc --rpcport "8545" --datadir=/data0/eth-test --port "30303" --nodiscover console
-->
<p>别的命令不累赘了，有需要可以翻翻之前的文章，只记录下执行<code>miner.start()</code>命令之后的输出</p>
<p>miner.start()之后，先生成DAG，会展示进度，输出的关键字为<code>Generating DAG in progress</code><br>随后在这个过程中会伴随块的产生，输出的关键字为<code>Successfully sealed new block</code><br>具体输出如下:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> miner.start(2)</span></span><br><span class="line">INFO [08-22|09:10:31.066] Updated mining threads                   threads=2</span><br><span class="line">INFO [08-22|09:10:31.067] Transaction pool price threshold updated price=18000000000</span><br><span class="line">null</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> INFO [08-22|09:10:31.109] Starting mining operation</span></span><br><span class="line">INFO [08-22|09:10:31.109] Commit new mining work                   number=1 txs=0 uncles=0 elapsed=118.785µs</span><br><span class="line">INFO [08-22|09:10:31.369] Generating DAG in progress               epoch=1 percentage=19 elapsed=2m3.630s</span><br><span class="line">INFO [08-22|09:10:37.935] Generating DAG in progress               epoch=1 percentage=20 elapsed=2m10.196s</span><br><span class="line">INFO [08-22|09:10:44.781] Generating DAG in progress               epoch=1 percentage=21 elapsed=2m17.043s</span><br><span class="line">INFO [08-22|09:10:52.263] Generating DAG in progress               epoch=1 percentage=22 elapsed=2m24.524s</span><br><span class="line">INFO [08-22|09:10:59.633] Generating DAG in progress               epoch=1 percentage=23 elapsed=2m31.895s</span><br><span class="line">INFO [08-22|09:11:06.632] Generating DAG in progress               epoch=1 percentage=24 elapsed=2m38.894s</span><br><span class="line">INFO [08-22|09:11:13.379] Generating DAG in progress               epoch=1 percentage=25 elapsed=2m45.641s</span><br><span class="line">INFO [08-22|09:11:20.101] Generating DAG in progress               epoch=1 percentage=26 elapsed=2m52.362s</span><br><span class="line">INFO [08-22|09:11:26.798] Generating DAG in progress               epoch=1 percentage=27 elapsed=2m59.059s</span><br><span class="line">INFO [08-22|09:11:34.509] Generating DAG in progress               epoch=1 percentage=28 elapsed=3m6.770s</span><br><span class="line">INFO [08-22|09:11:41.806] Generating DAG in progress               epoch=1 percentage=29 elapsed=3m14.068s</span><br><span class="line">INFO [08-22|09:11:49.068] Generating DAG in progress               epoch=1 percentage=30 elapsed=3m21.329s</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> eth.accounts.INFO [08-22|09:11:56.419] Generating DAG <span class="keyword">in</span> progress               epoch=1 percentage=31 elapsed=3m28.680s</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> eth.accounts</span></span><br><span class="line">["0x729ef979ace85837425a46055e9b7264c32c21e6", "0xf5727a89f2b4dfb58ac199755823a22935fb9fbf"]</span><br><span class="line"><span class="meta">&gt;</span><span class="bash"> INFO [08-22|09:12:03.486] Generating DAG <span class="keyword">in</span> progress               epoch=1 percentage=32 elapsed=3m35.747s</span></span><br><span class="line">INFO [08-22|09:12:10.594] Generating DAG in progress               epoch=1 percentage=33 elapsed=3m42.855s</span><br><span class="line">INFO [08-22|09:12:17.769] Generating DAG in progress               epoch=1 percentage=34 elapsed=3m50.031s</span><br><span class="line">INFO [08-22|09:12:24.648] Generating DAG in progress               epoch=1 percentage=35 elapsed=3m56.910s</span><br><span class="line">INFO [08-22|09:12:31.965] Generating DAG in progress               epoch=1 percentage=36 elapsed=4m4.226s</span><br><span class="line">INFO [08-22|09:12:38.996] Generating DAG in progress               epoch=1 percentage=37 elapsed=4m11.257s</span><br><span class="line">INFO [08-22|09:12:46.210] Generating DAG in progress               epoch=1 percentage=38 elapsed=4m18.472s</span><br><span class="line">INFO [08-22|09:12:52.898] Generating DAG in progress               epoch=1 percentage=39 elapsed=4m25.159s</span><br><span class="line">INFO [08-22|09:12:59.072] Generating DAG in progress               epoch=1 percentage=40 elapsed=4m31.333s</span><br><span class="line">INFO [08-22|09:13:03.176] Successfully sealed new block            number=1 hash=5b2050…9754cd</span><br><span class="line">INFO [08-22|09:13:03.234] 🔨 mined potential block                  number=1 hash=5b2050…9754cd</span><br><span class="line">INFO [08-22|09:13:03.237] Commit new mining work                   number=2 txs=0 uncles=0 elapsed=2.910ms</span><br><span class="line">INFO [08-22|09:13:06.398] Successfully sealed new block            number=2 hash=ecb729…78a768</span><br><span class="line">INFO [08-22|09:13:06.399] 🔨 mined potential block                  number=2 hash=ecb729…78a768</span><br><span class="line">INFO [08-22|09:13:06.399] Commit new mining work                   number=3 txs=0 uncles=0 elapsed=123.882µs</span><br><span class="line">INFO [08-22|09:13:07.162] Generating DAG in progress               epoch=1 percentage=41 elapsed=4m39.423s</span><br><span class="line">INFO [08-22|09:13:08.005] Successfully sealed new block            number=3 hash=265505…2113c3</span><br><span class="line">INFO [08-22|09:13:08.005] 🔨 mined potential block                  number=3 hash=265505…2113c3</span><br><span class="line">INFO [08-22|09:13:08.005] Commit new mining work                   number=4 txs=0 uncles=0 elapsed=93.513µs</span><br><span class="line">INFO [08-22|09:13:10.197] Successfully sealed new block            number=4 hash=07a7f2…9c3877</span><br><span class="line">INFO [08-22|09:13:10.197] 🔨 mined potential block                  number=4 hash=07a7f2…9c3877</span><br><span class="line">INFO [08-22|09:13:10.218] Commit new mining work                   number=5 txs=0 uncles=0 elapsed=118.561µs</span><br><span class="line">INFO [08-22|09:13:11.572] Successfully sealed new block            number=5 hash=80c62e…229bb9</span><br><span class="line">INFO [08-22|09:13:11.573] 🔨 mined potential block                  number=5 hash=80c62e…229bb9</span><br><span class="line">INFO [08-22|09:13:11.573] Commit new mining work                   number=6 txs=0 uncles=0 elapsed=134.57µs</span><br><span class="line">INFO [08-22|09:13:13.347] Generating DAG in progress               epoch=1 percentage=42 elapsed=4m45.609s</span><br><span class="line">INFO [08-22|09:13:19.373] Generating DAG in progress               epoch=1 percentage=43 elapsed=4m51.634s</span><br><span class="line">INFO [08-22|09:13:26.582] Generating DAG in progress               epoch=1 percentage=44 elapsed=4m58.844s</span><br><span class="line">INFO [08-22|09:13:30.189] Successfully sealed new block            number=6 hash=c8e518…fbad3c</span><br><span class="line">INFO [08-22|09:13:30.190] 🔗 block reached canonical chain          number=1 hash=5b2050…9754cd</span><br><span class="line">INFO [08-22|09:13:30.192] 🔨 mined potential block                  number=6 hash=c8e518…fbad3c</span><br><span class="line">INFO [08-22|09:13:30.203] Commit new mining work                   number=7 txs=0 uncles=0 elapsed=152.206µs</span><br><span class="line">INFO [08-22|09:13:32.481] Generating DAG in progress               epoch=1 percentage=45 elapsed=5m4.743s</span><br><span class="line">INFO [08-22|09:13:34.301] Successfully sealed new block            number=7 hash=b286af…979418</span><br><span class="line">INFO [08-22|09:13:34.302] 🔗 block reached canonical chain          number=2 hash=ecb729…78a768</span><br><span class="line">INFO [08-22|09:13:34.302] 🔨 mined potential block                  number=7 hash=b286af…979418</span><br><span class="line">INFO [08-22|09:13:34.302] Commit new mining work                   number=8 txs=0 uncles=0 elapsed=135.716µs</span><br><span class="line">INFO [08-22|09:13:35.776] Successfully sealed new block            number=8 hash=1496cd…e06258</span><br><span class="line">INFO [08-22|09:13:35.778] 🔗 block reached canonical chain          number=3 hash=265505…2113c3</span><br><span class="line">INFO [08-22|09:13:35.778] 🔨 mined potential block                  number=8 hash=1496cd…e06258</span><br><span class="line">INFO [08-22|09:13:35.796] Commit new mining work                   number=9 txs=0 uncles=0 elapsed=905.496µs</span><br><span class="line">INFO [08-22|09:13:38.655] Generating DAG in progress               epoch=1 percentage=46 elapsed=5m10.916s</span><br><span class="line">INFO [08-22|09:13:40.374] Successfully sealed new block            number=9 hash=8d7fa0…676de1</span><br><span class="line">INFO [08-22|09:13:40.375] 🔗 block reached canonical chain          number=4 hash=07a7f2…9c3877</span><br><span class="line">INFO [08-22|09:13:40.375] 🔨 mined potential block                  number=9 hash=8d7fa0…676de1</span><br><span class="line">INFO [08-22|09:13:40.386] Commit new mining work                   number=10 txs=0 uncles=0 elapsed=11.551ms</span><br><span class="line">INFO [08-22|09:13:44.547] Generating DAG in progress               epoch=1 percentage=47 elapsed=5m16.809s</span><br><span class="line">INFO [08-22|09:13:52.465] Generating DAG in progress               epoch=1 percentage=48 elapsed=5m24.726s</span><br><span class="line">INFO [08-22|09:13:52.692] Successfully sealed new block            number=10 hash=687e93…116aa7</span><br><span class="line">INFO [08-22|09:13:52.693] 🔗 block reached canonical chain          number=5  hash=80c62e…229bb9</span><br><span class="line">INFO [08-22|09:13:52.693] 🔨 mined potential block                  number=10 hash=687e93…116aa7</span><br><span class="line">INFO [08-22|09:13:52.693] Commit new mining work                   number=11 txs=0 uncles=0 elapsed=112.383µs</span><br><span class="line">INFO [08-22|09:13:55.432] Successfully sealed new block            number=11 hash=09a872…2054a1</span><br><span class="line">INFO [08-22|09:13:55.432] 🔗 block reached canonical chain          number=6  hash=c8e518…fbad3c</span><br><span class="line">INFO [08-22|09:13:55.432] 🔨 mined potential block                  number=11 hash=09a872…2054a1</span><br><span class="line">INFO [08-22|09:13:55.432] Commit new mining work                   number=12 txs=0 uncles=0 elapsed=124.793µs</span><br><span class="line">INFO [08-22|09:13:57.145] Successfully sealed new block            number=12 hash=e9f8d3…e1c6ee</span><br><span class="line">INFO [08-22|09:13:57.145] 🔗 block reached canonical chain          number=7  hash=b286af…979418</span><br><span class="line">INFO [08-22|09:13:57.145] 🔨 mined potential block                  number=12 hash=e9f8d3…e1c6ee</span><br><span class="line">INFO [08-22|09:13:57.145] Commit new mining work                   number=13 txs=0 uncles=0 elapsed=111.673µs</span><br><span class="line">INFO [08-22|09:13:59.277] Generating DAG in progress               epoch=1 percentage=49 elapsed=5m31.538s</span><br></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> Ethereum </tag>
            
            <tag> Test </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[以太坊环境部署]]></title>
      <url>http://bigdatadecode.club/Ethereum-deploy.html</url>
      <content type="html"><![CDATA[<p>以太坊的环境容易部署，执行一些命令就OK了。<br>那就开始搞吧。。。</p>
<a id="more"></a>
<h2 id="以太坊环境部署"><a href="#以太坊环境部署" class="headerlink" title="以太坊环境部署"></a>以太坊环境部署</h2><p>在安装以太坊之前要先安装下go，go的安装类似jdk，下载tar包，解压然后配置下环境变量。</p>
<p>安装以太坊：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">sudo add-apt-repository -y ppa:ethereum/ethereum</span><br><span class="line">sudo add-apt-repository -y ppa:ethereum/ethereum-dev</span><br><span class="line">sudo add-apt-repository ppa:ethereum/ethereum-qt</span><br><span class="line">sudo apt-get update</span><br><span class="line"><span class="comment"># 安装以太坊</span></span><br><span class="line">sudo apt-get install ethereum</span><br><span class="line"><span class="comment"># 安装solc编译器</span></span><br><span class="line">sudo apt-get install cpp-ethereum  <span class="comment"># 并没有solc命令</span></span><br><span class="line">sudo apt-get install solc  <span class="comment"># 安装solc，进行本地编译合约</span></span><br></pre></td></tr></table></figure>
<p>安装结束之后的版本是<code>Geth/v1.8.13-stable-225171a4/linux-amd64/go1.10</code></p>
<h2 id="认识以太坊"><a href="#认识以太坊" class="headerlink" title="认识以太坊"></a>认识以太坊</h2><p>完成以上操作之后，就可以操作以太坊了，可以进行挖矿了。这里先来熟悉下以太坊的客户端geth。</p>
<p>geth的全称是go-ethereum,是一个以太坊客户端，用go语言编写。</p>
<p>进入geth客户端有两种比较方式，一种是<em>以开发方式登录</em>,另一种是以<em>私链方式登录</em>。其中以开发方式登录相对比较简单，我们先来简单的。</p>
<p>输入命令<code>geth --dev --dev.period 1  console 2&gt;&gt; geth-log</code>(<strong>此命令，默认就会挖矿，执行miner.stop()停止</strong>)进入客户端。</p>
<p>执行上述命令会在当前目录生成一个geth-log的文件，可在其中查看运行情况。</p>
<h3 id="挖矿"><a href="#挖矿" class="headerlink" title="挖矿"></a>挖矿</h3><p>我们接触到以太坊或者比特币的第一想法就是，自己在测试环境挖个矿，感受下，对这些虚拟的东西来个直观的认识。</p>
<p>在挖矿之前我们先熟悉几个常用的命令，感受下geth。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">eth <span class="comment"># 全局环境变量</span></span><br><span class="line">eth.accounts <span class="comment"># 查看系统已有的用户</span></span><br><span class="line">personal.newAccount(<span class="string">'bigdatadecode'</span>) <span class="comment"># 新增用户，bigdatadecode为密码</span></span><br><span class="line">personal.newAccount(<span class="string">'bigdatadecode.club'</span>) <span class="comment"># 可以多建几个，观察下效果</span></span><br><span class="line">eth.accounts <span class="comment"># 建完之后，再查看系统已有的用户</span></span><br><span class="line"><span class="comment"># 对用户赋值，方便使用</span></span><br><span class="line">user1 =  eth.accounts[0]</span><br><span class="line">user2 =  eth.accounts[1]</span><br><span class="line">eth.getBalance(user1) <span class="comment"># 账户余额</span></span><br></pre></td></tr></table></figure>
<p>发现这些账户的余额是0，那么重点就来了，开始挖矿了，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">miner.start() <span class="comment"># 开始挖矿</span></span><br><span class="line">miner.stop() <span class="comment"># 停止挖矿</span></span><br><span class="line">eth.getBalcance(user1) <span class="comment"># 挖矿一段时间，观察下账户余额</span></span><br><span class="line">eth.sendTransaction(&#123;from:user1,to:user2,value:8&#125;) <span class="comment"># 转账</span></span><br><span class="line">eth.getBalance(user2)  <span class="comment"># 此时为0，还没有被确认， 需重新开启挖矿，然后再查看余额，此时为8</span></span><br><span class="line">web3.fromWei(eth.getBalance(eth.accounts[0]), <span class="string">"ether"</span>)</span><br><span class="line">personal.unlockAccount(user3, <span class="string">'bigdatadecode.club'</span>) <span class="comment"># 解锁</span></span><br><span class="line">eth.blockNumber <span class="comment"># 查看区块高度</span></span><br><span class="line">eth.getBlock(8) <span class="comment"># 得到区块8的信息</span></span><br><span class="line"></span><br><span class="line">eth.coinbase  <span class="comment"># 查看coinbase</span></span><br><span class="line">miner.setEtherbase(eth.coinbase) <span class="comment"># 设置miner账号</span></span><br><span class="line">eth.blockNumber <span class="comment"># 查看区块高度</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>Note: 如果你进入geth的命令是<code>geth --dev console 2&gt;&gt; geth-log</code>，当执行<code>miner.start()</code>时，会返回null，<br>原因在于geth版本更新之后，–dev模式下新增了一个参数项，加上<code>--dev.period 1</code></p>
</blockquote>
<p><a href="https://blog.csdn.net/wo541075754/article/details/79260040" target="_blank" rel="noopener">返回null，解决方案原文</a></p>
<h2 id="HelloWorld"><a href="#HelloWorld" class="headerlink" title="HelloWorld"></a>HelloWorld</h2><p>上一节操作了挖矿转账等流程，这节整个智能合约的HelloWorld。直接上合约代码：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">contract Mortal &#123;</span><br><span class="line">    <span class="comment">/* Define variable owner of the type address */</span></span><br><span class="line">    address owner;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* This function is executed at initialization and sets the owner of the contract */</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">Mortal</span>(<span class="params"></span>) </span>&#123; owner = msg.sender; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Function to recover the funds on the contract */</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">kill</span>(<span class="params"></span>) </span>&#123; <span class="keyword">if</span> (msg.sender == owner) selfdestruct(owner); &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">contract Greeter is Mortal &#123;</span><br><span class="line">    <span class="comment">/* Define variable greeting of the type string */</span></span><br><span class="line">    string greeting;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* This runs when the contract is executed */</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">Greeter</span>(<span class="params">string _greeting</span>) <span class="title">public</span> </span>&#123;</span><br><span class="line">        greeting = _greeting;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Main function */</span></span><br><span class="line">    <span class="function"><span class="keyword">function</span> <span class="title">greet</span>(<span class="params"></span>) <span class="title">constant</span> <span class="title">returns</span> (<span class="params">string</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> greeting;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>合约greeter是一个简单的智能合约，你可以使用这个合约来和其他人交流，它的回复会同你的输入完全一样，当输入为“Hello World!”的时候，合约也会回复“Hello World!”。</p>
<p>将上述代码写入greeter.sol中。</p>
<h3 id="编译智能合约"><a href="#编译智能合约" class="headerlink" title="编译智能合约"></a>编译智能合约</h3><p>编译智能合约可以使用<a href="https://ethereum.github.io/browser-solidity" target="_blank" rel="noopener">Browser-Solidity</a>在线编译，也可以使用solc命令本地编译，此处使用solc命令本地编译。<br>1、生成bytecode<br>执行<code>solc --bin greeter.sol</code>生成code，如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">======= greeter.sol:Greeter =======</span><br><span class="line">Binary:</span><br><span class="line">608060405234801561001057600080fd5b5060405161039b38038061039b83398101806040528101908080518201929190505050336000806101000a81548173ffffffffffffffffffffffffffffffffffffffff021916908373ffffffffffffffffffffffffffffffffffffffff1602179055508060019080519060200190610089929190610090565b5050610135565b828054600181600116156101000203166002900490600052602060002090601f016020900481019282601f106100d157805160ff19168380011785556100ff565b828001600101855582156100ff579182015b828111156100fe5782518255916020019190600101906100e3565b5b50905061010c9190610110565b5090565b61013291905b8082111561012e576000816000905550600101610116565b5090565b90565b610257806101446000396000f30060806040526004361061004c576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806341c0e1b514610051578063cfae321714610068575b600080fd5b34801561005d57600080fd5b506100666100f8565b005b34801561007457600080fd5b5061007d610189565b6040518080602001828103825283818151815260200191508051906020019080838360005b838110156100bd5780820151818401526020810190506100a2565b50505050905090810190601f1680156100ea5780820380516001836020036101000a031916815260200191505b509250505060405180910390f35b6000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff163373ffffffffffffffffffffffffffffffffffffffff161415610187576000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16ff5b565b606060018054600181600116156101000203166002900480601f0160208091040260200160405190810160405280929190818152602001828054600181600116156101000203166002900480156102215780601f106101f657610100808354040283529160200191610221565b820191906000526020600020905b81548152906001019060200180831161020457829003601f168201915b50505050509050905600a165627a7a723058203f4430a961037d5e7c4870ac4cc8f97d329171e862ae297fd0046255bec602490029</span><br><span class="line"></span><br><span class="line">======= greeter.sol:Mortal =======</span><br><span class="line">Binary:</span><br><span class="line">608060405234801561001057600080fd5b50336000806101000a81548173ffffffffffffffffffffffffffffffffffffffff021916908373ffffffffffffffffffffffffffffffffffffffff160217905550610114806100606000396000f300608060405260043610603f576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806341c0e1b5146044575b600080fd5b348015604f57600080fd5b5060566058565b005b6000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff163373ffffffffffffffffffffffffffffffffffffffff16141560e6576000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16ff5b5600a165627a7a723058206554007d7824c95b6473134490ff9f84381627c8c29d43da39ce468e740abeda0029</span><br></pre></td></tr></table></figure></p>
<p>2、生成ABI<br>执行<code>solc --abi greeter.sol</code>生成ABI，如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">======= greeter.sol:Greeter =======</span><br><span class="line">Contract JSON ABI</span><br><span class="line">[&#123;<span class="string">"constant"</span>:<span class="literal">false</span>,<span class="string">"inputs"</span>:[],<span class="string">"name"</span>:<span class="string">"kill"</span>,<span class="string">"outputs"</span>:[],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"nonpayable"</span>,<span class="string">"type"</span>:<span class="string">"function"</span>&#125;,&#123;<span class="string">"constant"</span>:<span class="literal">true</span>,<span class="string">"inputs"</span>:[],<span class="string">"name"</span>:<span class="string">"greet"</span>,<span class="string">"outputs"</span>:[&#123;<span class="string">"name"</span>:<span class="string">""</span>,<span class="string">"type"</span>:<span class="string">"string"</span>&#125;],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"view"</span>,<span class="string">"type"</span>:<span class="string">"function"</span>&#125;,&#123;<span class="string">"inputs"</span>:[&#123;<span class="string">"name"</span>:<span class="string">"_greeting"</span>,<span class="string">"type"</span>:<span class="string">"string"</span>&#125;],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"nonpayable"</span>,<span class="string">"type"</span>:<span class="string">"constructor"</span>&#125;]</span><br><span class="line"></span><br><span class="line">======= greeter.sol:Mortal =======</span><br><span class="line">Contract JSON ABI</span><br><span class="line">[&#123;<span class="string">"constant"</span>:<span class="literal">false</span>,<span class="string">"inputs"</span>:[],<span class="string">"name"</span>:<span class="string">"kill"</span>,<span class="string">"outputs"</span>:[],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"nonpayable"</span>,<span class="string">"type"</span>:<span class="string">"function"</span>&#125;,&#123;<span class="string">"inputs"</span>:[],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"nonpayable"</span>,<span class="string">"type"</span>:<span class="string">"constructor"</span>&#125;]</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>ABI(Application Binary Interface)其实就是一个有序的用户手册，描述了所有方法的名字和如何调用它们</p>
</blockquote>
<!-- solc --combined-json abi,bin sample.sol > sample.json -->
<h3 id="设置希望返回的字符串"><a href="#设置希望返回的字符串" class="headerlink" title="设置希望返回的字符串"></a>设置希望返回的字符串</h3><p>进入geth命令行，执行<code>var _greeting = &quot;Hello World!&quot;</code></p>
<h3 id="部署合约"><a href="#部署合约" class="headerlink" title="部署合约"></a>部署合约</h3><p>1、用ABI来创建一个javascript环境中的合约对象<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> greeterContract = web3.eth.contract([&#123;<span class="string">"constant"</span>:<span class="literal">false</span>,<span class="string">"inputs"</span>:[],<span class="string">"name"</span>:<span class="string">"kill"</span>,<span class="string">"outputs"</span>:[],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"nonpayable"</span>,<span class="string">"type"</span>:<span class="string">"function"</span>&#125;,&#123;<span class="string">"constant"</span>:<span class="literal">true</span>,<span class="string">"inputs"</span>:[],<span class="string">"name"</span>:<span class="string">"greet"</span>,<span class="string">"outputs"</span>:[&#123;<span class="string">"name"</span>:<span class="string">""</span>,<span class="string">"type"</span>:<span class="string">"string"</span>&#125;],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"view"</span>,<span class="string">"type"</span>:<span class="string">"function"</span>&#125;,&#123;<span class="string">"inputs"</span>:[&#123;<span class="string">"name"</span>:<span class="string">"_greeting"</span>,<span class="string">"type"</span>:<span class="string">"string"</span>&#125;],<span class="string">"payable"</span>:<span class="literal">false</span>,<span class="string">"stateMutability"</span>:<span class="string">"nonpayable"</span>,<span class="string">"type"</span>:<span class="string">"constructor"</span>&#125;]);</span><br></pre></td></tr></table></figure></p>
<p>2、通过合约对象来部署合约<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> greeter = greeterContract.new(</span><br><span class="line">   _greeting,</span><br><span class="line">   &#123;</span><br><span class="line">     <span class="keyword">from</span>: web3.eth.accounts[<span class="number">0</span>],</span><br><span class="line">     data: <span class="string">'0x608060405234801561001057600080fd5b5060405161039b38038061039b83398101806040528101908080518201929190505050336000806101000a81548173ffffffffffffffffffffffffffffffffffffffff021916908373ffffffffffffffffffffffffffffffffffffffff1602179055508060019080519060200190610089929190610090565b5050610135565b828054600181600116156101000203166002900490600052602060002090601f016020900481019282601f106100d157805160ff19168380011785556100ff565b828001600101855582156100ff579182015b828111156100fe5782518255916020019190600101906100e3565b5b50905061010c9190610110565b5090565b61013291905b8082111561012e576000816000905550600101610116565b5090565b90565b610257806101446000396000f30060806040526004361061004c576000357c0100000000000000000000000000000000000000000000000000000000900463ffffffff16806341c0e1b514610051578063cfae321714610068575b600080fd5b34801561005d57600080fd5b506100666100f8565b005b34801561007457600080fd5b5061007d610189565b6040518080602001828103825283818151815260200191508051906020019080838360005b838110156100bd5780820151818401526020810190506100a2565b50505050905090810190601f1680156100ea5780820380516001836020036101000a031916815260200191505b509250505060405180910390f35b6000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff163373ffffffffffffffffffffffffffffffffffffffff161415610187576000809054906101000a900473ffffffffffffffffffffffffffffffffffffffff1673ffffffffffffffffffffffffffffffffffffffff16ff5b565b606060018054600181600116156101000203166002900480601f0160208091040260200160405190810160405280929190818152602001828054600181600116156101000203166002900480156102215780601f106101f657610100808354040283529160200191610221565b820191906000526020600020905b81548152906001019060200180831161020457829003601f168201915b50505050509050905600a165627a7a723058203f4430a961037d5e7c4870ac4cc8f97d329171e862ae297fd0046255bec602490029'</span>,</span><br><span class="line">     gas: <span class="string">'4700000'</span></span><br><span class="line">   &#125;, <span class="function"><span class="keyword">function</span> (<span class="params">e, contract</span>)</span>&#123;</span><br><span class="line">    <span class="built_in">console</span>.log(e, contract);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">typeof</span> contract.address !== <span class="string">'undefined'</span>) &#123;</span><br><span class="line">         <span class="built_in">console</span>.log(<span class="string">'Contract mined! address: '</span> + contract.address + <span class="string">' transactionHash: '</span> + contract.transactionHash);</span><br><span class="line">    &#125;</span><br><span class="line"> &#125;)</span><br></pre></td></tr></table></figure></p>
<h3 id="挖矿-1"><a href="#挖矿-1" class="headerlink" title="挖矿"></a>挖矿</h3><p>1、执行<code>miner.start(1)</code>开启挖矿<br>2、有块产生之后，执行<code>miner.stop()</code>停止挖矿</p>
<h3 id="运行合约"><a href="#运行合约" class="headerlink" title="运行合约"></a>运行合约</h3><p>执行命令<code>greeter.greet();</code>，正常命令行上会出现如下返回结果:<code>Hello World!</code></p>
<p>OK，我们的第一个智能合约程序 “Hello World!” 已经完成了,但是目前它只有一个节点!</p>
<h3 id="部署在其它节点"><a href="#部署在其它节点" class="headerlink" title="部署在其它节点"></a>部署在其它节点</h3><p>为了使得其他人可以运行你的智能合约，你需要两个信息：</p>
<ol>
<li>智能合约地址Address</li>
<li>智能合约ABI</li>
</ol>
<p>ABI在上文中已得到，智能合约的地址可以执行<code>greeter.address</code>得到。</p>
<p>然后你可以实例化一个JavaScript对象，该对象可以用来在任意联网机器上调用该合约，此处ABI和Address是上述代码返回值。<br><code>var greeter = eth.contract(ABI).at(Address);</code></p>
<h3 id="自毁程序"><a href="#自毁程序" class="headerlink" title="自毁程序"></a>自毁程序</h3><p>一个交易需要被发送到网络需要支付费用，自毁程序是对网络的补充，花费的费用远小于一次常用交易。<br>你可以通过以下代码来检验是否成功，如果自毁程序运行成功以下代码会返回0：<br><code>greeter.kill.sendTransaction({from:eth.accounts[0]})</code></p>
<p>我执行完上述命令返回的貌似是一个地址，如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; greeter.kill.sendTransaction(&#123;from:eth.accounts[0]&#125;)</span><br><span class="line"><span class="string">"0x117d2066fae468a16077286573b0e3470b20e9ac5bb87291f7733dd453027441"</span></span><br></pre></td></tr></table></figure></p>
<p>此时再次执行<code>greeter.greet();</code>依然能返回<code>Hello World!</code>，我再次开启挖矿，一段时间后停止挖矿，再执行<code>greeter.greet();</code>，报错<br><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&gt; greeter.greet()</span><br><span class="line"><span class="built_in">Error</span>: <span class="keyword">new</span> BigNumber() not a base <span class="number">16</span> number:</span><br><span class="line">    at L (bignumber.js:<span class="number">3</span>:<span class="number">2876</span>)</span><br><span class="line">    at bignumber.js:<span class="number">3</span>:<span class="number">8435</span></span><br><span class="line">    at a (bignumber.js:<span class="number">3</span>:<span class="number">389</span>)</span><br><span class="line">    at web3.js:<span class="number">1110</span>:<span class="number">23</span></span><br><span class="line">    at web3.js:<span class="number">1634</span>:<span class="number">20</span></span><br><span class="line">    at web3.js:<span class="number">826</span>:<span class="number">16</span></span><br><span class="line">    at map (<span class="xml"><span class="tag">&lt;<span class="name">native</span> <span class="attr">code</span>&gt;</span>)</span></span><br><span class="line"><span class="xml">    at web3.js:825:12</span></span><br><span class="line"><span class="xml">    at web3.js:4080:18</span></span><br></pre></td></tr></table></figure></p>
<!--
##
是否设置miner地址
启动节点挖矿之前，需要查看当前节点中是否已经存在账号，可执行以下命令，查看当前节点下面是否有账号存在。

>personal.listAccounts

["0xc040cbd8a189d36f580fa83c2ffe3a26fb3e6a7e", "0xe0d1de6c934049fe4847b64becff5885bdb83fa4"]

当确认账户已经存在时，可以设置Etherbase。先查看以下coinbase账户：

>eth.coinbase

"0xc040cbd8a189d36f580fa83c2ffe3a26fb3e6a7e"

通过上面的命令，可以看到coinbase的账户地址，也就是上面查看地址查到第一个地址。

执行设置miner地址：

>miner.setEtherbase(eth.coinbase)
true

也可以执行执行以下命令进行设置：

>miner.setEtherbase(eth.accounts[0])
true

然后，可以再执行挖矿命令，查看是否问题是否解决。

节点误报
另外一种情况就是其实miner.start()命令已经执行成功，只不过节点返回null。如果是dev模式，可以使用eth.blockNumber查看一下区块高度是否增加。

节点版本问题
本人安装的geth-1.7.3版本的节点，在dev环境下验证发现，当执行miner.start()时，返回null。但其实miner已经执行，只不过它在等待你发送交易之后才会生成新的区块。也就是说执行了miner.start(),它一直在等待，这是发送一笔交易，再查看区块高度发现已经增加一块。
-->
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> Ethereum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop get命令返回NullPointerException]]></title>
      <url>http://bigdatadecode.club/Hadoop_get_NullPointerException.html</url>
      <content type="html"><![CDATA[<p>昨天Hadoop的get命令突然无法使用，返回NullPointerException异常，无法从hdfs pull数据，其它命令正常，并且最近也无任务修改配置的操作。<br>这下捉急了，捉急也没用，还是滚回去看日志吧，在日志中也没发现什么具体的报错信息，只发现NN的状态发生了变化，变成了standby。<br>但按照以往的经验NN切换并不会导致Hadoop相关命令返回空指针异常，难道是当初配置有什么问题？<br>先把NN切回来吧，先保证线上任务正常运行吧。切回回来之后一切正常，剩下一脸懵逼的我。。。。</p>
<a id="more"></a>
<p>先贴下异常现象：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop dfs -get /<span class="built_in">test</span>/test_1527672887521.sh .</span><br><span class="line">DEPRECATED: Use of this script to execute hdfs <span class="built_in">command</span> is deprecated.</span><br><span class="line">Instead use the hdfs <span class="built_in">command</span> <span class="keyword">for</span> it.</span><br><span class="line"></span><br><span class="line">get: java.lang.NullPointerException</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>问题恢复了，那就是找到问题的原因，而彻底解决到问题。那就开始搞吧。</p>
</blockquote>
<ol>
<li>首先在测试环境测试下NN切换，会不会导致get命令返回NullPointerException，此问题没有在测试环境复现。</li>
<li>把NN1上的Hadoop包打包重新搭建了一套Hadoop环境，进行测试，问题依然没有复现</li>
<li>把线上NN重启之后，再次手动触发切换，使用get命令依然返回NullPointerException</li>
<li>查看下NN2的log(<strong>终于想起NN2的log了</strong>)，定位到发生故障的时间点，搜下NullPointerException，发现报错信息，如下：</li>
</ol>
<pre><code class="bash">18/07/31 11:53:32 WARN net.ScriptBasedMapping: Exception running <span class="variable">${HADOOP_HOME}</span>/etc/hadoop/rack_awareness.py 127.0.0.1
java.io.IOException: Cannot run program <span class="string">"<span class="variable">${HADOOP_HOME}</span>/etc/hadoop/rack_awareness.py"</span> (<span class="keyword">in</span> directory <span class="string">"<span class="variable">${HADOOP_HOME}</span>"</span>): error=13, Permission denied
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:1048)
        at org.apache.hadoop.util.Shell.runCommand(Shell.java:526)
        at org.apache.hadoop.util.Shell.run(Shell.java:482)
        at org.apache.hadoop.util.Shell<span class="variable">$ShellCommandExecutor</span>.execute(Shell.java:776)
        at org.apache.hadoop.net.ScriptBasedMapping<span class="variable">$RawScriptBasedMapping</span>.runResolveCommand(ScriptBasedMapping.java:251)
        at org.apache.hadoop.net.ScriptBasedMapping<span class="variable">$RawScriptBasedMapping</span>.resolve(ScriptBasedMapping.java:188)
        at org.apache.hadoop.net.CachedDNSToSwitchMapping.resolve(CachedDNSToSwitchMapping.java:119)
        at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.resolveNetworkLocation(DatanodeManager.java:751)
        at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.resolveNetworkLocation(DatanodeManager.java:731)
        at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.resolveNetworkLocationWithFallBackToDefaultLocation(DatanodeManager.java:705)
        at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.registerDatanode(DatanodeManager.java:958)
        at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.registerDatanode(FSNamesystem.java:4481)
        at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.registerDatanode(NameNodeRpcServer.java:1286)
        at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.registerDatanode(DatanodeProtocolServerSideTranslatorPB.java:96)
        at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos<span class="variable">$DatanodeProtocolService</span><span class="variable">$2</span>.callBlockingMethod(DatanodeProtocolProtos.java:28752)
        at org.apache.hadoop.ipc.ProtobufRpcEngine<span class="variable">$Server</span><span class="variable">$ProtoBufRpcInvoker</span>.call(ProtobufRpcEngine.java:616)
        at org.apache.hadoop.ipc.RPC<span class="variable">$Server</span>.call(RPC.java:982)
        at org.apache.hadoop.ipc.Server<span class="variable">$Handler</span><span class="variable">$1</span>.run(Server.java:2217)
        at org.apache.hadoop.ipc.Server<span class="variable">$Handler</span><span class="variable">$1</span>.run(Server.java:2213)
        at java.security.AccessController.doPrivileged(Native Method)
        at javax.security.auth.Subject.doAs(Subject.java:422)
        at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1754)
        at org.apache.hadoop.ipc.Server<span class="variable">$Handler</span>.run(Server.java:2213)
Caused by: java.io.IOException: error=13, Permission denied
        at java.lang.UNIXProcess.forkAndExec(Native Method)
        at java.lang.UNIXProcess.&lt;init&gt;(UNIXProcess.java:247)
        at java.lang.ProcessImpl.start(ProcessImpl.java:134)
        at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
        ... 22 more
18/07/31 11:53:32 ERROR blockmanagement.DatanodeManager: The resolve call returned null!
18/07/31 11:53:32 ERROR blockmanagement.DatanodeManager: Unresolved topology mapping. Using /default-rack <span class="keyword">for</span> host 127.0.0.1
</code></pre>
<p>是不是很清晰，有没有</p>
<p>原来是NN2上的机器感知脚本没有执行权限，加上可执行权限之后，NN切换之后一切命令正常。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> get </tag>
            
            <tag> NullPointerException </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Docker进程log和应用log采集调研]]></title>
      <url>http://bigdatadecode.club/Docker_log_collect.html</url>
      <content type="html"><![CDATA[<p>Docker容器化已是一个相对成熟的理念，但是在实际使用中还是有很多挑战，目前我们遇到的一个问题是<strong>Docker中的log如何采集</strong>。<br>这些log包括Docker容器进程本身的log和容器内运行应用的业务log，两份log都比较重要，尤其业务log，因为一些埋点数据和统计指标都在业务log中也包括一些程序异常log。</p>
<a id="more"></a>
<p>针对这些log采集，我们面对的一些问题有：</p>
<ol>
<li>容器标准输出日志采集</li>
<li>容器内业务log采集 (是否要支持同时采集多个文件或多个业务log)</li>
<li>断点续传</li>
<li>异常日志合并与拼接 (要想合并异常日志，则日志必须<em>标准化</em>)</li>
<li>日志采集的完整性</li>
<li>日志乱序</li>
<li>从日志中区分来源</li>
<li>支持热插拔</li>
<li>对业务的侵入性</li>
<li>故障重传</li>
</ol>
<blockquote>
<p>目前主流两种方案，一种是log在容器内通过采集工具直接传输给log聚合服务，另一种是将容器内的log传输到宿主机，然后再通过日志采集工具进行采集。</p>
</blockquote>
<h2 id="方案1"><a href="#方案1" class="headerlink" title="方案1"></a>方案1</h2><p>在容器内直接将log传输给log聚合服务，可以通过业务方调整业务逻辑将日志直接打入kafka或者redis等缓存组件中，这种方式对业务侵入性较大，无法做到对业务无感知，也无法解决docker容器本身的log传输。<br>在容器内直接将log传输给log聚合服务也可以做到对业务无感知，那就是在容器中部署一个日志采集服务，如flume，通过flume将log采集到kafka，这样貌似结果了问题，对业务无感知，而且flume在日志采集领域也比较成熟。<br>这种方案看似合理，但是这种方案依然不符合上生产的条件。因为容器的启动和停止是一个常态，容器在停止之后，容器内的log也将随之消失，那就存在flume采集日志不完整，或者由于kafka等受网络或者其它原因导致数据没有写入成功，这就造成log丢失，而且这种丢失还是永久性的丢失，无法追回的丢失，这对一些指标的统计是不允许的。</p>
<h2 id="方案2"><a href="#方案2" class="headerlink" title="方案2"></a>方案2</h2><p>针对方案1中的痛点<em>采集不完整数据永久丢失</em>和<em>依赖kafka等服务的稳定性</em>，提出是否可以将容器中的log落地到宿主磁盘，容器与宿主之间的网络延迟可以忽略也不会受外界网络的影响，这样后续流程就跟传统的日志采集服务一样了。</p>
<p>有了方向查阅资料就方便很多，阿里开源了一款日志采集工具<a href="https://github.com/AliyunContainerService/log-pilot/?spm=a2c4e.11153940.blogcont69382.19.65b278fcpbOK9h" target="_blank" rel="noopener">log-pilot</a>，此工具支持容器标准输出和业务log文件采集，还可以表识log来源，方便后续对日志进行归档。</p>
<p>docker容器日志输出的工具很多，而且docker本身也有一些功能可以实现，如log driver，但是这些只能将docker容器的标准输出与错误输出采集到宿主机上，而无法将业务log文件中的内容也采集到宿主机，如果非要用log driver之类的工具就得让业务方更改log的规则，这样就对业务有侵入了，所以感觉log-pilot还是比较符合预期的，虽然不是太完美，需要对其进行定制开发。</p>
<p>log-pilot最主要的一个定制功能就是可以支持<strong>断点续传</strong>和<strong>HA</strong>，具体的功能还需进一步的测试使用。</p>
<p>对于<em>异常日志合并与拼接</em>的功能可以通过更改flume的source代码实现，因为log-pilot是顺序的读取业务log并且顺序的写入宿主磁盘的某个文件中，不会出现乱序，所以我们把日志合并放在flume端进行处理。</p>
<h3 id="存在的隐患"><a href="#存在的隐患" class="headerlink" title="存在的隐患"></a>存在的隐患</h3><ol>
<li>flume对配置文件的更新在大数据量的情况下会更新异常，要对其进行调优</li>
<li>log-pilot断点续传与迟延</li>
<li>log-pilot部署方式，docker容器内还是宿主机</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Docker </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Docker </tag>
            
            <tag> BigData </tag>
            
            <tag> log </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[shell嵌套变量]]></title>
      <url>http://bigdatadecode.club/shell%E5%B5%8C%E5%A5%97%E5%8F%98%E9%87%8F.html</url>
      <content type="html"><![CDATA[<p>今天在批量生成命令的时候，需要使用一个类似嵌套变量的东西，(注意这个嵌套变量，一开始并不知道shell中有这个东东)</p>
<p>具体场景是这样的：</p>
<a id="more"></a>
<p>有一堆命名比较规则的变量，例如conf_1、conf_2、conf_3…<br>这些变量需要在一个循环中根据循环的次数输出，伪代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">conf_1=<span class="string">'conf1'</span></span><br><span class="line">conf_2=<span class="string">'conf2'</span></span><br><span class="line">conf_3=<span class="string">'conf3'</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;1..3&#125;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">	<span class="comment"># 想要的效果是当i=1时，echo $conf_1</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="variable">$&#123;conf_$&#123;i&#125;</span>&#125;</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>
<p>上面的代码会报语法错误。</p>
<p>于是就尴尬了，这要怎么搞，硬编码？这不符合前人的思维呀，于是google之。</p>
<p>既然要google就要给人家一个关键词，这看效果是变量里嵌套了变量，那关键字就是<code>嵌套变量</code>吧。<br>果然顺利搜出结果。demo如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">title3=<span class="string">'查找固件中的⼝令⽂件'</span></span><br><span class="line">i=3</span><br><span class="line">title=title<span class="variable">$&#123;i&#125;</span></span><br><span class="line"><span class="built_in">eval</span> temp=$(<span class="built_in">echo</span> \$<span class="variable">$title</span>)</span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$temp</span></span><br></pre></td></tr></table></figure>
<p>顺利结果问题。。。</p>
<p>果真是只有你想不到的，没有前人实现不了的。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://blog.csdn.net/u010801696/article/details/78847873" target="_blank" rel="noopener">https://blog.csdn.net/u010801696/article/details/78847873</a></p>
]]></content>
      
        <categories>
            
            <category> Tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Shell </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Ubuntu搭建Bitcoin源码阅读环境]]></title>
      <url>http://bigdatadecode.club/bitcoin%E6%BA%90%E7%A0%81%E7%8E%AF%E5%A2%83.html</url>
      <content type="html"><![CDATA[<p>这是区块链系列的开篇文章，随后会陆续写一些blog。<br>看了两本区块链的书，有了一些初步的了解，最近打算实践下，就想着先弄个读代码的环境，本以为挺简单但也折腾了好久，所以就打算备注下。</p>
<blockquote>
<p>两本区块链相关的书分别是区块链开发指南和精通比特币，随后会写些读后感</p>
</blockquote>
<p>虽然网上也有很多相关的文章但大都比较笼统或者记录的比较含糊，导致像我这样的新手得花大量的时间去摸索去踩坑。下面就开始流水账了。。。</p>
<a id="more"></a>
<h2 id="build-bitcoin"><a href="#build-bitcoin" class="headerlink" title="build bitcoin"></a>build bitcoin</h2><ul>
<li>从github上clone源码，<code>git clone https://github.com/bitcoin/bitcoin.git</code></li>
<li>clone到本地的代码是最新的代码也就是master分支上的，前人一般都推荐阅读0.12版本的代码，所以在build代码之前要切换下tag，命令<code>git checkout v0.12.0</code></li>
</ul>
<blockquote>
<p>选择tag为v0.12.0进行build之后，在qt文件中并不出会出现<strong>bitcoin-qt</strong>这个文件，随后切换到branch为<strong>remotes/origin/0.12</strong>的版本进行build成功出现，所以这里应该切换的代码版本是<code>git checkout remotes/origin/0.12</code></p>
</blockquote>
<ul>
<li>按照代码目录doc文件中build相关的文件(<em>build-*.md</em>)中介绍的步骤进行build</li>
</ul>
<blockquote>
<p>我用的系统是ubuntu-14.04-desktop-amd64.iso</p>
</blockquote>
<p>按照build-unix.md中的步骤去build代码，build之前需要安装一些依赖的软件，如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install build-essential libtool autotools-dev automake pkg-config libssl-dev libevent-dev bsdmainutils</span><br><span class="line"></span><br><span class="line">sudo apt-get install libboost-system-dev libboost-filesystem-dev libboost-chrono-dev libboost-program-options-dev libboost-test-dev libboost-thread-dev</span><br><span class="line"><span class="comment"># 如果上面安装boost的命令没有成功，则使用下面的命令进行安装</span></span><br><span class="line">sudo apt-get install libboost-all-dev</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下面三条命令是安装BerkeleyDB，wallet需要用到</span></span><br><span class="line">sudo add-apt-repository ppa:bitcoin/bitcoin</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install libdb4.8-dev libdb4.8++-dev</span><br><span class="line"></span><br><span class="line">sudo apt-get install libminiupnpc-dev</span><br><span class="line">sudo apt-get install libzmq3-dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#我安装QT的大版本是4，所以执行下面的命令(QT后面会进行介绍)</span></span><br><span class="line">sudo apt-get install libqt4-dev libprotobuf-dev protobuf-compiler</span><br><span class="line"></span><br><span class="line">sudo apt-get install libqrencode-dev</span><br></pre></td></tr></table></figure>
<p>OK，依赖的lib基本安装结束了，可以执行build命令了</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在bitcoin源码根目录下</span></span><br><span class="line">./autogen.sh</span><br><span class="line">./configure <span class="comment"># autogen.sh 执行成功之后会生成此文件</span></span><br><span class="line">make        <span class="comment"># configure 执行成功之后，会乘车MakeFile文件，供make使用</span></span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<p>上述命令不出错就说明build成功了，可以运行代码了。</p>
<blockquote>
<p>build成功之后会出现6个可执行文件，分别为bitcoin-cli、bitcoind、bitcoin-tx、bitcoin-qt和两个test文件test_bitcoin、test_bitcoin-qt</p>
</blockquote>
<p>此时你就想如果有个IDE就好了，我就可以Debug代码了。那我们就安装个吧，IDE一般用QT Creator，因为比特币钱包是用这个开发的。</p>
<h2 id="IDE踩坑"><a href="#IDE踩坑" class="headerlink" title="IDE踩坑"></a>IDE踩坑</h2><p>关于QT Creator比较坑，完全是一脸的懵逼呀，只知道这个是跨平台的，Linux下开发c++用这个，还可以用来开发界面。一开始安装了个<em>4.6</em>版本的，将bitcoin导入后就不知道要干啥了，于是就想着新建个c++的demo项目熟悉下这个IDE吧，当我在创建c++项目的时候就真的懵逼了，完全不知道怎么回事，具体就不在这丢人了。</p>
<p>懵逼就只好各种google了，看到一篇文章说QT Creator要结合QT来使用，原来QT和QT Creator不是一个东西，我一直以为QT是QT Creator的简称。。。。</p>
<p>下载了<a href="http://download.qt.io/archive/qt/4.8/4.8.1/" target="_blank" rel="noopener">QT 4.8.1 qt-everywhere-opensource-src-4.8.1.tar.gz</a>，不过在Linux下是源码包，不是安装包，得需要进行编译安装。</p>
<p>解压进入目录之后执行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make   <span class="comment"># 次过程较长</span></span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<p>安装成功之后需要配置环境变量</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PATH=/usr/<span class="built_in">local</span>/Trolltech/Qt-%VERSION%/bin:<span class="variable">$PATH</span></span><br><span class="line"><span class="built_in">export</span> PATH</span><br></pre></td></tr></table></figure>
<p>QT准备就绪之后再次打开QT Creator还是不知道怎么创建c++程序，不知道怎么运行，又是一通google，一些文章中的IDE和我的界面有所不同，C++的教程也比较少。</p>
<p>搜了很多文章虽然没有明确的教程单对QT Creator有了更新的认识，就只能使出杀手锏–换IDE的版本，从新下载了个<a href="https://download.qt.io/official_releases/qtcreator/2.8/2.8.1/" target="_blank" rel="noopener">2.8</a>的版本，再次打开IDE，瞬间感觉春天来了，2.8.1的界面是这样的<br><img src="/blogimgs/bitcoin-ide/ide.png" alt="" title="主界面"></p>
<h2 id="C-Demo"><a href="#C-Demo" class="headerlink" title="C++ Demo"></a>C++ Demo</h2><p>新建项目和大多IDE步骤类似，点击 File -&gt; New File or Project，然后出现如下页面：<br><img src="/blogimgs/bitcoin-ide/c++1.png" alt="" title="选择项目类型"><br>安装图中的选项进行选择就ok，接下来进行第二步<br><img src="/blogimgs/bitcoin-ide/c++2.png" alt="" title="选择项目地址"><br>选择项目名称和存放的目录，继续Next<br><img src="/blogimgs/bitcoin-ide/c++3.png" alt="" title="编译文件目录"><br>这里不能使用默认生成的目录，会有问题，需要将目录改成常规目录名，如下图：<br><img src="/blogimgs/bitcoin-ide/c++4.png" alt=""><br>继续Next，这里选下版本管理工具，随性来就好<br><img src="/blogimgs/bitcoin-ide/c++5.png" alt="" title="版本管理"><br>点击Finish，就可以进入项目界面，查看编辑新建的项目了：<br><img src="/blogimgs/bitcoin-ide/c++6.png" alt="" title="查看编辑项目"><br>IDE默认会生成一个Hello World的文件，点击运行看下效果<br><img src="/blogimgs/bitcoin-ide/c++7.png" alt="" title="运行效果"></p>
<h2 id="QT-Creator运行Bitcoin"><a href="#QT-Creator运行Bitcoin" class="headerlink" title="QT Creator运行Bitcoin"></a>QT Creator运行Bitcoin</h2><p>将bitcoin导入IDE并运行bitcoin钱包。<br>点击 File -&gt; New File or Project，选择Import project中的Import Existing Project，如下图：<br><img src="/blogimgs/bitcoin-ide/import1.png" alt="" title="导入bitcoin1"><br>点击Choose，选择源码所在目录，我的目录信息如下:<br><img src="/blogimgs/bitcoin-ide/import2.png" alt="" title="导入bitcoin2"><br>继续Next，默认Next就好，界面如图:<br><img src="/blogimgs/bitcoin-ide/import3.png" alt="" title="导入bitcoin3"><br>还有一步Summary，主要选下版本管理工具，点击Finish就导入成功了。</p>
<p>导入成功之后，首先运行个bitcoin-qt验证下，<br>点击IDE左侧的<em>Project</em>按钮，在<em>Desktop</em>选项中点击<em>run</em>标签，如下图：<br><img src="/blogimgs/bitcoin-ide/run-qt.png" alt="" title="运行bitcoin-qt"><br>配好之后点击运行就会出现钱包页面，如图:<br><img src="/blogimgs/bitcoin-ide/bitcoin-qt.png" alt="" title="运行bitcoin-qt.png"></p>
<h2 id="附加"><a href="#附加" class="headerlink" title="附加"></a>附加</h2><p>有人比较悲催的话，并没有顺利执行成功，可能Kits有问题，Kits是在<em>编辑文件目录</em>中选择的<em>Desktop</em>，我的Desktop的配置如图：<br><img src="/blogimgs/bitcoin-ide/desktop.png" alt="" title="Desktop配置"></p>
<blockquote>
<p>最后祝大家六一快乐。。。。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> BlockChain </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BlockChain </tag>
            
            <tag> BitCoin </tag>
            
            <tag> Src </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS权限]]></title>
      <url>http://bigdatadecode.club/HDFS%E6%9D%83%E9%99%90.html</url>
      <content type="html"><![CDATA[<p>之前对HDFS更或者说是对Linux中文件的权限没有进行一个完整的学习，只是知道有所有者、所属组和其它权限，具体到某个人的权限有读(r)、写(w)和可执行(x)。<br>遇到没有权限的问题就<em>chmod</em>加个权限，加完之后如果还有问题就给父目录也加一样的权限，如果还不行就给777。<br>这其中应该给什么权限，给什么权限最合适都是一头雾水。<br><strong>今天就说说文件和目录权限的那些事</strong>。。。。</p>
<a id="more"></a>
<h2 id="HDFS基于Linux的POSIX-model"><a href="#HDFS基于Linux的POSIX-model" class="headerlink" title="HDFS基于Linux的POSIX model"></a>HDFS基于Linux的POSIX model</h2><blockquote>
<p>HDFS的权限虽然是基于Linux的POSIX model，但是HDFS中其实并没有真正的用户和组的概念，只是从主机上拿到用户的信息然后对其存储的文件权限进行检查。</p>
</blockquote>
<p>HDFS中每个文件和目录都有一个owner和group，并对owner、owner同一个组的user和其它user的权限进行了分离，权限分为<em>rwx</em>。对于文件来说，有<em>r</em>权限则可对此文件<em>可读</em>，有<em>w</em>权限则可对文件进行<em>写和追加</em>，<strong>x权限对文件来说没有实际的意义</strong>。对于目录来说，拥有<em>r</em>权限可以<em>查看目录中内容</em>，比如此目录下的文件或者子目录，拥有<em>w</em>权限可以在此目录中<em>新建或者删除文件和子目录，但不可以改变此目录的名字，因为改变此目录的信息是需要其上层目录的写权限</em>，对于目录来说，个人感觉最重要的应该是<em>x</em>权限，拥有<em>x</em>权限，才可以进入当前目录进行其它操作。</p>
<blockquote>
<p>如果没有目录的<em>x</em>权限，你拥有的其它权限并不能发挥相应的作用，因为<em>rw</em>权限都是针对目录中的内容的，当你没有进入目录的权限时，其它权限都是虚无。</p>
</blockquote>
<h3 id="sticky-bit"><a href="#sticky-bit" class="headerlink" title="sticky bit"></a>sticky bit</h3><p>HDFS中还有一个sticky bit，此功能只针对目录有效，是一个防删除位。防止<em>除管理员、目录或者文件的所有者之外的其它人(即使其它用户对该文件夹有rwx权限)</em>对文件或者目录进行删除。<br>命令如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#即在第一位添加数字1</span></span><br><span class="line">hadoop fs -chmod 1777 /tmp</span><br><span class="line">hadoop fs -chmod 1777 /spark-history</span><br><span class="line">hadoop fs -chmod 1777 /user/hive/warehouse</span><br></pre></td></tr></table></figure>
<h2 id="HDFS-ACL"><a href="#HDFS-ACL" class="headerlink" title="HDFS ACL"></a>HDFS ACL</h2><p>HDFS ACL(Access Control Lists)是对POSIX permissions model的一个补充。传统的权限是针对用户和组的组织架构来设置的，但当你<em>只想给特定的用户或者组</em>(<strong>而不是只针对文件的所有者和所属组</strong>)来开权限时，我们就可以使用ACL来控制。</p>
<p>默认情况下，HDFS ACL功能是关闭的，因为开启ACL之后，NN中会对开启ACL的inode存储一份额外的数据，会带来额外的内存开销，如果有需要可以在<code>hdfs-site.xml</code>中设置<code>dfs.namenode.acls.enabled</code>为true。</p>
<blockquote>
<p>新建一个文件或者目录时，会继承父目录的ACL，但改变父目录的ACL时，在此目录中已经存在的内容不会发生改变。</p>
</blockquote>
<p>一个文件或者目录的ACL由一组ACL entry组成。每个Entry标识一个用户或者组的rwx权限，如下一个文件的一个ACL：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">user::rw-</span><br><span class="line">user:bruce:rwx                  <span class="comment">#effective:r--</span></span><br><span class="line">group::r-x                      <span class="comment">#effective:r--</span></span><br><span class="line">group:sales:rwx                 <span class="comment">#effective:r--</span></span><br><span class="line">mask::r--</span><br><span class="line">other::r--</span><br></pre></td></tr></table></figure>
<p>文件的所有者具有rw权限，所属组具有rx权限，其它用户具有r权限，但是用户bruce具有该文件的rwx权限，sales组也具有该文件的rwx权限。但是bruce和sales就真的具有rwx权限了？这里还有最后一道防线<em>mask</em>，mask决定了一个用户或者组能够得到的最大的权限。上面的例子中，bruce和sales的权限会与mask的权限进行与运算，最终的结果才是bruce和sales的权限，也就是注释中的内容。</p>
<h3 id="权限检查流程"><a href="#权限检查流程" class="headerlink" title="权限检查流程"></a>权限检查流程</h3><p>当一个文件有ACL时，权限检查的流程为：</p>
<ul>
<li>判断该用户是否为owner</li>
<li>判断该用户是否包含在ACL entry的user中，如果在，则通过mask过滤权限</li>
<li>判断该用户的所属组是否包含在组中，包含则也要通过mask来过滤权限(因为在使用了ACL的情况下，group的权限显示的就是当前的mask)</li>
<li>判断该用户的所属组是否包含在ACL entry的group中，如果在，则通过mask来过滤权限</li>
</ul>
<h3 id="ACL命令"><a href="#ACL命令" class="headerlink" title="ACL命令"></a>ACL命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加用户acl</span></span><br><span class="line">hdfs dfs -setfacl -m user:xx:rwx path</span><br><span class="line"><span class="comment"># 删除一个用户的acl</span></span><br><span class="line">hdfs dfs -setfacl -x user:xx path</span><br><span class="line"><span class="comment"># 删除所有的acl</span></span><br><span class="line">hdfs dfs -setfacl -d path</span><br><span class="line"><span class="comment"># 查看acl</span></span><br><span class="line">hdfs dfs -getfacl path</span><br></pre></td></tr></table></figure>
<blockquote>
<p>目录或者文件添加了ACL之后，ll命令查看，会有一个<code>+</code>标识</p>
</blockquote>
<h2 id="umask"><a href="#umask" class="headerlink" title="umask"></a>umask</h2><p>一个文件或者目录新建之后就有一个默认的权限，这个默认的权限是怎么控制的呢？是由<code>umask</code>控制的。</p>
<p>文件创建之后的默认权限是<code>0666 &amp; ^umask</code>，目录创建之后的默认权限是<code>0777 &amp; ^umask</code>，umask在<code>core-site.xml</code>中由<code>fs.permissions.umask-mode</code>设置，默认是022。</p>
<h2 id="HDFS-开启权限"><a href="#HDFS-开启权限" class="headerlink" title="HDFS 开启权限"></a>HDFS 开启权限</h2><p>HDFS中与权限相关的配置在<code>core-site.xml</code>和<code>hdfs-site.xml</code>中。</p>
<h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><p>core-site中主要是设置umask，由fs.permissions.umask-mode控制，默认是022</p>
<h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><p>hfds-site中控制着权限的开启，参数如下：</p>
<ul>
<li><p>dfs.permissions.enabled = true<br>是否开启权限检查，默认是true</p>
</li>
<li><p>dfs.permissions.superusergroup = supergroup<br>设置hdfs管理员的组名称，模式名字是<em>supergroup</em>，一般改为与管理员相同的名字，如管理员是hdfs，则改为hdfs</p>
</li>
<li><p>dfs.namenode.acls.enabled = true<br>控制ACL是否开启，默认为false。</p>
</li>
</ul>
<blockquote>
<p>Tips<br>HDFS权限设置最好是以传统的权限进行控制，只针对个别权限要求高的文件进行ACL控制。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> ACL </tag>
            
            <tag> permission </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Zookeeper session过期和connection超时]]></title>
      <url>http://bigdatadecode.club/Zookeeper%20session%E8%BF%87%E6%9C%9F%E5%92%8Cconnection%E8%B6%85%E6%97%B6.html</url>
      <content type="html"><![CDATA[<p>首先来看一张官方的状态转换图：<br><img src="/blogimgs/zk_timeout/state_dia.jpg" alt="zk状态图" title="zk状态图"><br>首先zk客户端会创建一个连接请求，此时会创建一个session，用于标识此次与服务器进行连接的一次生命周期。session创建之后，客户端的连接状态变为connecting，当与服务器建立成功之后变为connected状态。<br><a id="more"></a></p>
<p>由上面的状态图可以看出客户端会接受到服务端返回的两个错误码，分别为<em>CONNECTION_LOSS</em>和<em>SESSION_EXPIRED</em>，收到这两个错误码，客户端是怎么处理的呢？先看下CONNECTION_LOSS。</p>
<h2 id="CONNECTION-LOSS"><a href="#CONNECTION-LOSS" class="headerlink" title="CONNECTION_LOSS"></a>CONNECTION_LOSS</h2><p>当客户端与服务端的连接发生异常时，会返回CONNECTION_LOSS。<strong>当客户端收到此返回码时，并不能盲目的认为是网络连接失败还是服务端挂了</strong>。<br>因为返回CONNECTION_LOSS的情况可能有如下几种：</p>
<ul>
<li>客户端创建了一个请求，并且服务端已正常接收到了该请求，只是在返回时发生了异常(可能是网络异常)</li>
<li>客户端创建了一个请求，服务端根本没有收到(可能是网络也可能是服务端挂了)</li>
</ul>
<p>因此在客户端收到这样的返回码时，不能新建一个session。假如客户端与服务端A正常连接时，发生了异常，此时应该尝试与服务端B建立连接，如果此时新建session就会导致之前客户端与服务端A建立的一些watcher什么的就会消失，因为zk是以session来标识客户端与服务端连接的生命周期的。</p>
<p>当客户端收到这样的返回码之后，要做的事是根据服务器列表进行重连，如果在session过期之前，连接成功，则会话恢复，之前创建的watcher和临时节点什么的都依然存在<!--客户端会收到一个SyncConnection事件-->。如果在session过期之后，则收到Session Expired事件。</p>
<!--Zookeeper的读写操作都是原子操作，因此可以保证不会部分读取和部分写入的情况，这就保证了数据一致性。-->
<h2 id="SESSION-EXPIRED"><a href="#SESSION-EXPIRED" class="headerlink" title="SESSION_EXPIRED"></a>SESSION_EXPIRED</h2><p>当客户端收到SESSION_EXPIRED返回码时，会关闭与服务端的连接。</p>
<p>客户端与服务端第一次建立连接时，会生成一个session，在session超时之后客户端与服务端的连接才会跟换session。session是否过期是由服务端控制的。</p>
<p>当zk服务端超过一定的时间没有收到来自zk客户端的心跳，<strong>zk服务端就把这个session标记为过期，然后删除这个session创建的所有临时节点，并且马上通知所有监听了这些节点的其他session</strong>。此时，客户端由于处于断开连接的状态，并不知道当前session已经过期，只有在它与服务端重新建立连接之后，才会收到服务端发出的session过期通知。</p>
<p>这个流程是这样的：</p>
<ul>
<li>客户端1与服务端建立连接，此时session1被创建，连接正常；客户端2与服务端建立连接，此时session2被创建，连接正常(connected状态)</li>
<li>客户端1与服务端连接异常，并尝试与服务器列表中的其它服务端建立连接(connecting状态)</li>
<li>尝试与其它服务端建立连接的同时，时间也在一分一秒的流逝，超过了session1的超时时间</li>
<li>服务端检测到session1已过超时时间，则通知session2，session1已超时。</li>
<li>一段时间之后，可能是网络恢复也可能是客户端1程序恢复，已服务端建立的连接，但之前的session1已过期，收到了服务端的过期事件。(closed状态)</li>
<li>重新创建session建立连接。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://wiki.apache.org/hadoop/ZooKeeper/FAQ#A2" target="_blank" rel="noopener">https://wiki.apache.org/hadoop/ZooKeeper/FAQ#A2</a></p>
]]></content>
      
        <categories>
            
            <category> Zookeeper </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Zookeeper </tag>
            
            <tag> session </tag>
            
            <tag> connection </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Druid调研]]></title>
      <url>http://bigdatadecode.club/Druid%E8%B0%83%E7%A0%94.html</url>
      <content type="html"><![CDATA[<p>Druid初期是由metamarkets的技术人员开发，用于向买家、卖家、广告主进行广告展示的底层实时分析平台，为OLAP的事件查询而设计。目前已发展成一个开源的实时数据库。</p>
<blockquote>
<p>时序数据库（TSDB）是一种特定类型的数据库，主要用来存储时序数据。</p>
</blockquote>
<a id="more"></a>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>Druid的架构比较灵活，是一个集群模式，由多个不同类型的节点组成，并且各个节点也能组成自己的小集群以增加可用性和扩展性。</p>
<p>Druid中每类节点都只完成一小部分事情，节点分类如下：</p>
<ul>
<li>Historical节点<br>Historical节点是Druid集群的骨干，用于负责存储和查询历史数据。它从Deep Storage下载segments到本地，响应从broker节点上分发到查询请求，并将结果数据返回给broker节点。Historical节点采用shared nothing的架构，所以每个节点能够独自加载segments、删除segments、以及为segments提供查询服务。</li>
</ul>
<p><em>Historical节点与Zookeeper进行通信(Historical节点之间并不通信)，将该节点上已加载的segments和正在提供服务的segments记录在zk上，zk会通知Historical节点进行segments的加载和删除</em>。</p>
<ul>
<li><p>Broker节点<br>Broker节点是客户端和应用程序从Druid查询数据的入口。Broker节点负责分发查询，将查询请求分发给实时节点和历史节点，以及收集和合并来自实时节点和历史节点的结果。<em>Broker节点通过Zookeeper确定segments是在实时节点还是历史节点存活</em>。</p>
</li>
<li><p>Coordinator节点<br><em>Coordinator节点通过Metadata Storage和zk管理集群中historical节点上的segments</em>。Coordinator从Metadata Storage中获取segments的元数据信息，来决定哪些segments需要加载到历史节点集群中，利用zk判断历史节点集群中某些节点是否存在。当Historical需要加载或者删除一些segments时会在zk上创建一些entries。</p>
</li>
</ul>
<p><strong>Coordinator不与Historical通信，直接与zk进行通信</strong></p>
<ul>
<li><p>Realtime节点<br>实时节点负责加载实时的数据到系统中。</p>
</li>
<li><p>Indexing Service节点<br>索引服务节点由多个worker组成的集群，负责为加载批量的和实时的数据创建索引，并且允许对已经存在的数据进行修改。</p>
</li>
</ul>
<blockquote>
<p><strong>Real-time处理</strong>目前可以<em>通过独立的realtime节点，或者通过indexing service节点实现</em>，这两种方式都很常见。 Real-time处理包括加载数据、创建数据索引(创建segments)、以及交接segments给historical节点。实时处理逻辑加载之后数据立马可查。数据交接的过程也是安全的，数据在整个流程中都保持可查。</p>
</blockquote>
<!-- Realtime节点 和 Indexing Service节点 的区别 http://dj1211.com/?p=702-->
<p>Druid集群还会依赖一些外部组件：</p>
<ul>
<li><p>Zookeeper<br>Zookeeper主要作用是帮助群集服务发现和维护当前数据的拓扑结构，Druid依赖Zookeeper来保证集群内的信息一致。</p>
</li>
<li><p>Metadata Storage<br>Druid依赖metadata storage存储segments的元数据和配置。创建segments的服务在元数据中记录信息，coordinator监听着元数据以便了解什么时候需要下载新数据或者删除旧数据。 元数据的存储不涉及查询的路径。<em>MySQL和PostgreSQL非常有利于生产环境下元数据的存储</em>。</p>
</li>
<li><p>Deep Storage<br>Deep storage是segments的永久备份。创建segments的服务(实时或者离线)上传segments到Deep storage，然后historical节点下载。Deep storage不涉及查询路径。 <em>S3和HDFS是比较推荐的deep storages</em>。</p>
</li>
</ul>
<p>Druid集群整体架构图如下：<br><img src="/blogimgs/Druid/DruidArc.png" alt="Druid架构图" title="Druid架构图"><br>上面Druid架构图中展示了Druid集群中内部组件和外部依赖组件的整体架构，下面再来一张官方的架构图，和上面的架构图大体一样，我感觉两个图结合起来看就比较完美了。嘿嘿。。<br><img src="/blogimgs/Druid/druid-manage-1.png" alt="Druid架构图-官方" title="Druid架构图-官方"></p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><blockquote>
<p>高可用性<br>由于Druid使用的是shared noting架构，所以其内部并无单点故障，不同类型的节点失败也不会影响到其他类型节点的正常服务。 </p>
</blockquote>
<blockquote>
<p>可扩展性<br>Druid中的每类节点都可部署为集群模式，使Druid处理能力能够水平扩展。</p>
</blockquote>
<blockquote>
<p>亚秒级响应<br>官网说10亿量级下做到亚秒响应，能够做到实时导入，导入即可查询。</p>
</blockquote>
<blockquote>
<p>Roll-up<br>在数据接入时对原始数据选定一系列维度之后进行第一级聚合，减少数据量，提高查询速度和减少存储空间。</p>
</blockquote>
<h2 id="数据源"><a href="#数据源" class="headerlink" title="数据源"></a>数据源</h2><p>Druid数据源支持多种格式，比如json、csv或者是用特殊字符分割的数据。<br>数据来源主要分为批量数据和实时数据。接入方式主要有3种：</p>
<ul>
<li>从文件中批量加载，数据文件可以存放在本地、HDFS和S3等文件存储系统。</li>
<li>实时推送数据，是使用<em>Tranquility</em>通过HTTP推送数据到Druid。Tranquility是一个单独的工具包，并没有和Druid做集成，需要单独下载，Tranquility启动一个server进程，通过HTTP将数据发送给Druid，而不需要启动一个JVM之类的进程。</li>
</ul>
<blockquote>
<p>Tranquility是用scala编写的，主要是通过Druid indexing service来实时抽取数据，弥补Druid indexing service API的不足</p>
</blockquote>
<ul>
<li>实时拉取数据，是使用<em>Firehose</em>与要读取的数据进行连接，然后Realtime节点实时从中抽取数据。</li>
</ul>
<blockquote>
<p>Firehose是一个可插拔的组件，是Druid中的消费实时数据模型，可以有不同的实现，Druid自带了一个基于Kafka High Level API实现的对于Kafka的数据消费（druid-kafka-eight Firehose）</p>
</blockquote>
<p>数据接入时需要注意一下几点：</p>
<ul>
<li>数据集应该被什么调用？由”dataSchema”的”dataSource”字段设置</li>
<li>数据集位于什么位置？文件路径在”inputSpec”的”paths”。如果加载多个文件，将字符串以逗号分隔。</li>
<li>什么字段作为时间戳？由”timestampSpec”的”column”字段设置。</li>
<li>什么字段作为维度？由”dimensionsSpec”的”dimensions”字段设置。</li>
<li>什么字段作为度量？由”metricsSpec”控制。</li>
<li>什么时间范围（时间间隔）被加载？由”granularitySpec”的”intervals”字段设置。</li>
</ul>
<h3 id="数据格式"><a href="#数据格式" class="headerlink" title="数据格式"></a>数据格式</h3><p>Druid的数据集有三部分组成。分别为</p>
<ul>
<li><p>Timestamp列: 将timestamp区别开是因为Druid是一个时间序列的olap工具，其中的查询都以时间为中心。</p>
</li>
<li><p>Dimension列: Dimensions对应事件的维度，通常用于筛选过滤数据。</p>
</li>
<li><p>Metric列: Metrics是用于<em>聚合和计算的列</em>。在OLAP的术语中也被叫做measures。</p>
</li>
</ul>
<h3 id="数据源配置"><a href="#数据源配置" class="headerlink" title="数据源配置"></a>数据源配置</h3><p>接入数据不需要代码的开发，只需要进行一些配置。<br>下面看个从HDFS接入数据的demo：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"type"</span> : <span class="string">"index_hadoop"</span>,</span><br><span class="line">  <span class="attr">"spec"</span> : &#123;</span><br><span class="line">    <span class="attr">"dataSchema"</span> : &#123;</span><br><span class="line">      <span class="attr">"dataSource"</span> : <span class="string">"wikipedia"</span>,</span><br><span class="line">      <span class="attr">"parser"</span> : &#123;</span><br><span class="line">        <span class="attr">"type"</span> : <span class="string">"hadoopyString"</span>,</span><br><span class="line">        <span class="attr">"parseSpec"</span> : &#123;</span><br><span class="line">          <span class="attr">"format"</span> : <span class="string">"json"</span>,</span><br><span class="line">          <span class="attr">"timestampSpec"</span> : &#123;</span><br><span class="line">            <span class="attr">"column"</span> : <span class="string">"timestamp"</span>,</span><br><span class="line">            <span class="attr">"format"</span> : <span class="string">"auto"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"dimensionsSpec"</span> : &#123;</span><br><span class="line">            <span class="attr">"dimensions"</span>: [<span class="string">"page"</span>,<span class="string">"language"</span>,<span class="string">"user"</span>,<span class="string">"unpatrolled"</span>,<span class="string">"newPage"</span>,<span class="string">"robot"</span>,<span class="string">"anonymous"</span>,<span class="string">"namespace"</span>,<span class="string">"continent"</span>,<span class="string">"country"</span>,<span class="string">"region"</span>,<span class="string">"city"</span>],</span><br><span class="line">            <span class="attr">"dimensionExclusions"</span> : [],</span><br><span class="line">            <span class="attr">"spatialDimensions"</span> : []</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"metricsSpec"</span> : [</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"count"</span>,</span><br><span class="line">          <span class="attr">"name"</span> : <span class="string">"count"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"doubleSum"</span>,</span><br><span class="line">          <span class="attr">"name"</span> : <span class="string">"added"</span>,</span><br><span class="line">          <span class="attr">"fieldName"</span> : <span class="string">"added"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"doubleSum"</span>,</span><br><span class="line">          <span class="attr">"name"</span> : <span class="string">"deleted"</span>,</span><br><span class="line">          <span class="attr">"fieldName"</span> : <span class="string">"deleted"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="attr">"type"</span> : <span class="string">"doubleSum"</span>,</span><br><span class="line">          <span class="attr">"name"</span> : <span class="string">"delta"</span>,</span><br><span class="line">          <span class="attr">"fieldName"</span> : <span class="string">"delta"</span></span><br><span class="line">        &#125;</span><br><span class="line">      ],</span><br><span class="line">      <span class="attr">"granularitySpec"</span> : &#123;</span><br><span class="line">        <span class="attr">"type"</span> : <span class="string">"uniform"</span>,</span><br><span class="line">        <span class="attr">"segmentGranularity"</span> : <span class="string">"DAY"</span>,</span><br><span class="line">        <span class="attr">"queryGranularity"</span> : <span class="string">"NONE"</span>,</span><br><span class="line">        <span class="attr">"intervals"</span> : [ <span class="string">"2013-08-31/2013-09-01"</span> ]</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"ioConfig"</span> : &#123;</span><br><span class="line">      <span class="attr">"type"</span> : <span class="string">"hadoop"</span>,</span><br><span class="line">      <span class="attr">"inputSpec"</span> : &#123;</span><br><span class="line">        <span class="attr">"type"</span> : <span class="string">"static"</span>,</span><br><span class="line">        <span class="attr">"paths"</span> : <span class="string">"/MyDirectory/example/wikipedia_data.json"</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"tuningConfig"</span> : &#123;</span><br><span class="line">      <span class="attr">"type"</span>: <span class="string">"hadoop"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"hadoopDependencyCoordinates"</span>: <span class="string">"my_hadoop_version"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>简单解释下这些配置项：<br>json中最外层有3个key，分别为type、spec和hadoopDependencyCoordinates，前两个是必须的。<br>如果从HDFS中加载数据，<code>type</code>始终是<code>index_hadoop</code>，<code>spec</code>的value是数据的一些信息，也是一个json。<br>spec value就是DataSchema，由dataSchema、ioConfig和tuningConfig，如果tuningConfig不设置将提供默认值。<br>dataSchema描述了数据源的具体信息，包括数据的格式、Timestamp、维度和度量。<br>ioConfig描述了数据从何而来，和最终去向哪里。</p>
<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><p>Druid的查询语言是json，通过HTTP REST提交给可查询的节点(Broker, Historical, or Realtime)。官方目前暂不支持sql查询，有第三方的插件可以支持sql，但支持度不是太完美。</p>
<p>Druid支持的查询包括聚合查询、搜索查询(类似模糊匹配)和选择查询。</p>
<p>下面简单看几个json查询语句。</p>
<ul>
<li>聚合查询json语句<br>聚合查询比较复杂，又分为3个小类，分别为timeseries、topN和groupBy。<br>这里展示一个timeseries的json语句：</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"queryType"</span>: <span class="string">"timeseries"</span>,</span><br><span class="line">  <span class="attr">"dataSource"</span>: <span class="string">"sample_datasource"</span>,</span><br><span class="line">  <span class="attr">"granularity"</span>: <span class="string">"day"</span>,</span><br><span class="line">  <span class="attr">"descending"</span>: <span class="string">"true"</span>,</span><br><span class="line">  <span class="attr">"filter"</span>: &#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"and"</span>,</span><br><span class="line">    <span class="attr">"fields"</span>: [</span><br><span class="line">      &#123; <span class="attr">"type"</span>: <span class="string">"selector"</span>, <span class="attr">"dimension"</span>: <span class="string">"sample_dimension1"</span>, <span class="attr">"value"</span>: <span class="string">"sample_value1"</span> &#125;,</span><br><span class="line">      &#123; <span class="attr">"type"</span>: <span class="string">"or"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: [</span><br><span class="line">          &#123; <span class="attr">"type"</span>: <span class="string">"selector"</span>, <span class="attr">"dimension"</span>: <span class="string">"sample_dimension2"</span>, <span class="attr">"value"</span>: <span class="string">"sample_value2"</span> &#125;,</span><br><span class="line">          &#123; <span class="attr">"type"</span>: <span class="string">"selector"</span>, <span class="attr">"dimension"</span>: <span class="string">"sample_dimension3"</span>, <span class="attr">"value"</span>: <span class="string">"sample_value3"</span> &#125;</span><br><span class="line">        ]</span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"aggregations"</span>: [</span><br><span class="line">    &#123; <span class="attr">"type"</span>: <span class="string">"longSum"</span>, <span class="attr">"name"</span>: <span class="string">"sample_name1"</span>, <span class="attr">"fieldName"</span>: <span class="string">"sample_fieldName1"</span> &#125;,</span><br><span class="line">    &#123; <span class="attr">"type"</span>: <span class="string">"doubleSum"</span>, <span class="attr">"name"</span>: <span class="string">"sample_name2"</span>, <span class="attr">"fieldName"</span>: <span class="string">"sample_fieldName2"</span> &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"postAggregations"</span>: [</span><br><span class="line">    &#123; <span class="attr">"type"</span>: <span class="string">"arithmetic"</span>,</span><br><span class="line">      <span class="attr">"name"</span>: <span class="string">"sample_divide"</span>,</span><br><span class="line">      <span class="attr">"fn"</span>: <span class="string">"/"</span>,</span><br><span class="line">      <span class="attr">"fields"</span>: [</span><br><span class="line">        &#123; <span class="attr">"type"</span>: <span class="string">"fieldAccess"</span>, <span class="attr">"name"</span>: <span class="string">"sample_name1"</span>, <span class="attr">"fieldName"</span>: <span class="string">"sample_fieldName1"</span> &#125;,</span><br><span class="line">        &#123; <span class="attr">"type"</span>: <span class="string">"fieldAccess"</span>, <span class="attr">"name"</span>: <span class="string">"sample_name2"</span>, <span class="attr">"fieldName"</span>: <span class="string">"sample_fieldName2"</span> &#125;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"intervals"</span>: [ <span class="string">"2012-01-01T00:00:00.000/2012-01-03T00:00:00.000"</span> ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>timeseries是按照某段时间区间作为数据查询区间的，这里使用的是2012-01-01到2012-01-03的数据，分别对sample_fieldName1和sample_fieldName2进行聚合，最后两个聚合指标相除。结果如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="string">"2012-01-01T00:00:00.000Z"</span>,</span><br><span class="line">    <span class="attr">"result"</span>: &#123; <span class="attr">"sample_name1"</span>: <span class="string">"some_value"</span>, <span class="attr">"sample_name2"</span>: <span class="string">"some_value"</span>, <span class="attr">"sample_divide"</span>: <span class="string">"some_value"</span> &#125; </span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="string">"2012-01-02T00:00:00.000Z"</span>,</span><br><span class="line">    <span class="attr">"result"</span>: &#123; <span class="attr">"sample_name1"</span>: <span class="string">"some_value"</span>, <span class="attr">"sample_name2"</span>: <span class="string">"some_value"</span>, <span class="attr">"sample_divide"</span>: <span class="string">"some_value"</span> &#125;</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<ul>
<li>搜索查询json语句</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"queryType"</span>: <span class="string">"search"</span>,</span><br><span class="line">  <span class="attr">"dataSource"</span>: <span class="string">"sample_datasource"</span>,</span><br><span class="line">  <span class="attr">"granularity"</span>: <span class="string">"day"</span>,</span><br><span class="line">  <span class="attr">"searchDimensions"</span>: [</span><br><span class="line">    <span class="string">"dim1"</span>,</span><br><span class="line">    <span class="string">"dim2"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"query"</span>: &#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"insensitive_contains"</span>,</span><br><span class="line">    <span class="attr">"value"</span>: <span class="string">"Ke"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"sort"</span> : &#123;</span><br><span class="line">    <span class="attr">"type"</span>: <span class="string">"lexicographic"</span></span><br><span class="line">  &#125;,</span><br><span class="line">  <span class="attr">"intervals"</span>: [</span><br><span class="line">    <span class="string">"2013-01-01T00:00:00.000/2013-01-03T00:00:00.000"</span></span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>searchDimensions定义了要在哪些维度中进行搜索，query定义了搜索方式(本语句中的意思是包含Ke的维度值)，结果为：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="string">"2012-01-01T00:00:00.000Z"</span>,</span><br><span class="line">    <span class="attr">"result"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"dimension"</span>: <span class="string">"dim1"</span>,</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"Ke$ha"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"dimension"</span>: <span class="string">"dim2"</span>,</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"Ke$haForPresident"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"timestamp"</span>: <span class="string">"2012-01-02T00:00:00.000Z"</span>,</span><br><span class="line">    <span class="attr">"result"</span>: [</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"dimension"</span>: <span class="string">"dim1"</span>,</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"SomethingThatContainsKe"</span></span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">        <span class="attr">"dimension"</span>: <span class="string">"dim2"</span>,</span><br><span class="line">        <span class="attr">"value"</span>: <span class="string">"SomethingElseThatContainsKe"</span></span><br><span class="line">      &#125;</span><br><span class="line">    ]</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<ul>
<li>选择查询json语句</li>
</ul>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"queryType"</span>: <span class="string">"select"</span>,</span><br><span class="line">  <span class="attr">"dataSource"</span>: <span class="string">"wikipedia"</span>,</span><br><span class="line">  <span class="attr">"descending"</span>: <span class="string">"false"</span>,</span><br><span class="line">  <span class="attr">"dimensions"</span>:[],</span><br><span class="line">  <span class="attr">"metrics"</span>:[],</span><br><span class="line">  <span class="attr">"granularity"</span>: <span class="string">"all"</span>,</span><br><span class="line">  <span class="attr">"intervals"</span>: [</span><br><span class="line">    <span class="string">"2013-01-01/2013-01-02"</span></span><br><span class="line">  ],</span><br><span class="line">  <span class="attr">"pagingSpec"</span>:&#123;<span class="attr">"pagingIdentifiers"</span>: &#123;&#125;, <span class="attr">"threshold"</span>:<span class="number">5</span>&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>select查询支持分页显示，pagingSpec定义了分页的信息，这里只显示前5个，结果显示如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line">[&#123;</span><br><span class="line">  <span class="attr">"timestamp"</span> : <span class="string">"2013-01-01T00:00:00.000Z"</span>,</span><br><span class="line">  <span class="attr">"result"</span> : &#123;</span><br><span class="line">    <span class="attr">"pagingIdentifiers"</span> : &#123;</span><br><span class="line">      <span class="attr">"wikipedia_2012-12-29T00:00:00.000Z_2013-01-10T08:00:00.000Z_2013-01-10T08:13:47.830Z_v9"</span> : <span class="number">4</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"events"</span> : [ &#123;</span><br><span class="line">      <span class="attr">"segmentId"</span> : <span class="string">"wikipedia_editstream_2012-12-29T00:00:00.000Z_2013-01-10T08:00:00.000Z_2013-01-10T08:13:47.830Z_v9"</span>,</span><br><span class="line">      <span class="attr">"offset"</span> : <span class="number">0</span>,</span><br><span class="line">      <span class="attr">"event"</span> : &#123;</span><br><span class="line">        <span class="attr">"timestamp"</span> : <span class="string">"2013-01-01T00:00:00.000Z"</span>,</span><br><span class="line">        <span class="attr">"robot"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"namespace"</span> : <span class="string">"article"</span>,</span><br><span class="line">        <span class="attr">"anonymous"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"unpatrolled"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"page"</span> : <span class="string">"11._korpus_(NOVJ)"</span>,</span><br><span class="line">        <span class="attr">"language"</span> : <span class="string">"sl"</span>,</span><br><span class="line">        <span class="attr">"newpage"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"user"</span> : <span class="string">"EmausBot"</span>,</span><br><span class="line">        <span class="attr">"count"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"added"</span> : <span class="number">39.0</span>,</span><br><span class="line">        <span class="attr">"delta"</span> : <span class="number">39.0</span>,</span><br><span class="line">        <span class="attr">"variation"</span> : <span class="number">39.0</span>,</span><br><span class="line">        <span class="attr">"deleted"</span> : <span class="number">0.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">      <span class="attr">"segmentId"</span> : <span class="string">"wikipedia_2012-12-29T00:00:00.000Z_2013-01-10T08:00:00.000Z_2013-01-10T08:13:47.830Z_v9"</span>,</span><br><span class="line">      <span class="attr">"offset"</span> : <span class="number">1</span>,</span><br><span class="line">      <span class="attr">"event"</span> : &#123;</span><br><span class="line">        <span class="attr">"timestamp"</span> : <span class="string">"2013-01-01T00:00:00.000Z"</span>,</span><br><span class="line">        <span class="attr">"robot"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"namespace"</span> : <span class="string">"article"</span>,</span><br><span class="line">        <span class="attr">"anonymous"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"unpatrolled"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"page"</span> : <span class="string">"112_U.S._580"</span>,</span><br><span class="line">        <span class="attr">"language"</span> : <span class="string">"en"</span>,</span><br><span class="line">        <span class="attr">"newpage"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"user"</span> : <span class="string">"MZMcBride"</span>,</span><br><span class="line">        <span class="attr">"count"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"added"</span> : <span class="number">70.0</span>,</span><br><span class="line">        <span class="attr">"delta"</span> : <span class="number">70.0</span>,</span><br><span class="line">        <span class="attr">"variation"</span> : <span class="number">70.0</span>,</span><br><span class="line">        <span class="attr">"deleted"</span> : <span class="number">0.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">      <span class="attr">"segmentId"</span> : <span class="string">"wikipedia_2012-12-29T00:00:00.000Z_2013-01-10T08:00:00.000Z_2013-01-10T08:13:47.830Z_v9"</span>,</span><br><span class="line">      <span class="attr">"offset"</span> : <span class="number">2</span>,</span><br><span class="line">      <span class="attr">"event"</span> : &#123;</span><br><span class="line">        <span class="attr">"timestamp"</span> : <span class="string">"2013-01-01T00:00:00.000Z"</span>,</span><br><span class="line">        <span class="attr">"robot"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"namespace"</span> : <span class="string">"article"</span>,</span><br><span class="line">        <span class="attr">"anonymous"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"unpatrolled"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"page"</span> : <span class="string">"113_U.S._243"</span>,</span><br><span class="line">        <span class="attr">"language"</span> : <span class="string">"en"</span>,</span><br><span class="line">        <span class="attr">"newpage"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"user"</span> : <span class="string">"MZMcBride"</span>,</span><br><span class="line">        <span class="attr">"count"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"added"</span> : <span class="number">77.0</span>,</span><br><span class="line">        <span class="attr">"delta"</span> : <span class="number">77.0</span>,</span><br><span class="line">        <span class="attr">"variation"</span> : <span class="number">77.0</span>,</span><br><span class="line">        <span class="attr">"deleted"</span> : <span class="number">0.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">      <span class="attr">"segmentId"</span> : <span class="string">"wikipedia_2012-12-29T00:00:00.000Z_2013-01-10T08:00:00.000Z_2013-01-10T08:13:47.830Z_v9"</span>,</span><br><span class="line">      <span class="attr">"offset"</span> : <span class="number">3</span>,</span><br><span class="line">      <span class="attr">"event"</span> : &#123;</span><br><span class="line">        <span class="attr">"timestamp"</span> : <span class="string">"2013-01-01T00:00:00.000Z"</span>,</span><br><span class="line">        <span class="attr">"robot"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"namespace"</span> : <span class="string">"article"</span>,</span><br><span class="line">        <span class="attr">"anonymous"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"unpatrolled"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"page"</span> : <span class="string">"113_U.S._73"</span>,</span><br><span class="line">        <span class="attr">"language"</span> : <span class="string">"en"</span>,</span><br><span class="line">        <span class="attr">"newpage"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"user"</span> : <span class="string">"MZMcBride"</span>,</span><br><span class="line">        <span class="attr">"count"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"added"</span> : <span class="number">70.0</span>,</span><br><span class="line">        <span class="attr">"delta"</span> : <span class="number">70.0</span>,</span><br><span class="line">        <span class="attr">"variation"</span> : <span class="number">70.0</span>,</span><br><span class="line">        <span class="attr">"deleted"</span> : <span class="number">0.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125;, &#123;</span><br><span class="line">      <span class="attr">"segmentId"</span> : <span class="string">"wikipedia_2012-12-29T00:00:00.000Z_2013-01-10T08:00:00.000Z_2013-01-10T08:13:47.830Z_v9"</span>,</span><br><span class="line">      <span class="attr">"offset"</span> : <span class="number">4</span>,</span><br><span class="line">      <span class="attr">"event"</span> : &#123;</span><br><span class="line">        <span class="attr">"timestamp"</span> : <span class="string">"2013-01-01T00:00:00.000Z"</span>,</span><br><span class="line">        <span class="attr">"robot"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"namespace"</span> : <span class="string">"article"</span>,</span><br><span class="line">        <span class="attr">"anonymous"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"unpatrolled"</span> : <span class="string">"0"</span>,</span><br><span class="line">        <span class="attr">"page"</span> : <span class="string">"113_U.S._756"</span>,</span><br><span class="line">        <span class="attr">"language"</span> : <span class="string">"en"</span>,</span><br><span class="line">        <span class="attr">"newpage"</span> : <span class="string">"1"</span>,</span><br><span class="line">        <span class="attr">"user"</span> : <span class="string">"MZMcBride"</span>,</span><br><span class="line">        <span class="attr">"count"</span> : <span class="number">1.0</span>,</span><br><span class="line">        <span class="attr">"added"</span> : <span class="number">68.0</span>,</span><br><span class="line">        <span class="attr">"delta"</span> : <span class="number">68.0</span>,</span><br><span class="line">        <span class="attr">"variation"</span> : <span class="number">68.0</span>,</span><br><span class="line">        <span class="attr">"deleted"</span> : <span class="number">0.0</span></span><br><span class="line">      &#125;</span><br><span class="line">    &#125; ]</span><br><span class="line">  &#125;</span><br><span class="line">&#125; ]</span><br></pre></td></tr></table></figure>
<h2 id="数据生命周期"><a href="#数据生命周期" class="headerlink" title="数据生命周期"></a>数据生命周期</h2><p>如果数据来源于Kafka，则Realtime节点从kafka消费数据，实时数据在Realtime节点中创建索引，存入节点内存，内存数据量超过阈值时(或者定期)时，将内存数据写到外存形成外存索引。 内存数据加上多个外存索引， Realtime节点以这种方式支持亚秒级数据可见性。<br>但是Realtime节点的容量和查询能力是有限的， 所以它会定期合并多个外存索引生成segment，(segment对应一段时间范围内的进入druid的数据)。segment生成之后马上被上传到deep storage，很快就会有Historical节点下载该segment，并替代Realtime节点提供查询服务。<br>Historcial节点从DeepStorage下载segment之后，由Coordinator节点通过Zookeeper来通知Historcial节点加载或者删除segment。</p>
]]></content>
      
        <categories>
            
            <category> Druid </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Druid </tag>
            
            <tag> 调研 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java Synchronized实现原理]]></title>
      <url>http://bigdatadecode.club/JavaSynchronizedTheory.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/Java同步锁解析.html">之前一篇文章</a>介绍了Synchronized的用法，本篇从实现原理上更进一步了解下。</p>
<p>查看带有<em>Synchronized语句块</em>的class文件可以看到在同步代码块的起始位置插入了<code>moniterenter</code>指令，在同步代码块结束的位置插入了<code>monitorexit</code>指令。(JVM需要保证每一个monitorenter都有一个monitorexit与之相对应，但每个monitorexit不一定都有一个monitorenter)<br>但是查看同步方法的class文件时，同步方法并没有通过指令monitorenter和monitorexit来完成，而被翻译成普通的方法调用和返回指令，只是在其<strong>常量池中多了ACC_SYNCHRONIZED标示符</strong>。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。 <em>其实本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成</em>。</p>
<p>moniterenter和moniterexit指令是通过monitor对象实现的。<br>Synchronized的实现不仅与monitor对象有关，还与另一个东西密切相关，那就是<strong>对象头</strong>。</p>
<a id="more"></a>
<p>下面我们就来看下Java对象头和monitor对象与Synchronized的实现有着怎样的关系。</p>
<p>JVM规范中对monitorenter和monitorexit指令的描述如下：<br>monitorenter ：<br>Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:<br>• If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.<br>• If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.<br>• If another thread already owns the monitor associated with objectref, the thread blocks until the monitor’s entry count is zero, then tries again to gain ownership.</p>
<p>这段话的大概意思为：<br>每个对象都有一个监视器锁(monitor)与之对应。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：<br>1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。<br>2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.<br>3.如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。</p>
<p>monitorexit：　<br>The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.<br>The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so.</p>
<p>这段话的大概意思为：<br>执行monitorexit的线程必须是objectref所对应的monitor的所有者。<br>指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权。 </p>
<ul>
<li>通过这两个指令我们应该能很清楚的看出Synchronized的实现原理，<strong>Synchronized的语义底层是通过一个monitor的对象来完成</strong>，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。</li>
</ul>
<h2 id="Java对象头"><a href="#Java对象头" class="headerlink" title="Java对象头"></a>Java对象头</h2><p>下面重点说下java对象头。</p>
<blockquote>
<p>众所周知Java中万物皆对象，那对象在内存中是怎么存储的呢？</p>
</blockquote>
<p>每个对象分为三块区域:<em>对象头、实例数据和对齐填充</em>。 </p>
<ul>
<li>对象头包含两部分，第一部分是Mark Word，用于存储对象自身的运行时数据，如哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等等，这一部分占一个字节。第二部分是Klass Pointer（类型指针），是对象指向它的类元数据的指针，<em>虚拟机通过这个指针来确定这个对象是哪个类的实例</em>，这部分也占一个字节。(<em>如果对象是数组类型的，则需要3个字节来存储对象头，因为还需要一个字节存储数组的长度</em>)</li>
<li>实例数据存放的是类属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，<em>这部分内存按4字节对齐</em>。</li>
<li>填充数据是因为虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐。</li>
</ul>
<p>对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到虚拟机的空间效率，Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据对象的状态复用自己的存储空间。例如在32位的HotSpot虚拟机 中对象未被锁定的状态下，Mark Word的32个Bits空间中的25Bits用于存储对象哈希码(HashCode)，4Bits用于存储对象分代年龄，2Bits用于存储锁标志 位，1Bit固定为0，在其他状态(轻量级锁定、重量级锁定、GC标记、可偏向)下对象的存储内容如下表所示。<br><img src="/blogimgs/javaSynchronized/ObjectHead.png" alt="对象头存储结构" title="对象头存储结构"></p>
<p>Synchronized通常被称为重量级锁，但是1.6之后对其进行优化，<em>新增了轻量级锁和偏向锁</em>，这里重点说下重量级锁，随后对Synchronized的优化简单介绍下。</p>
<p>从对象头的存储内容可以看出<strong>锁的状态都保存在对象头</strong>中，Synchronized也不例外，当其从轻量级锁膨胀为重量级锁时，锁标识位为10，其中<em>指针指向的是monitor对象</em>(也称为管程或监视器锁)的起始地址。</p>
<p>关于Synchronized的实现在java对象头里较为简单，只是改变一下标识位，并将指针指向monitor对象的起始地址，其实现的重点是monitor对象。<br>下面介绍下monitor对象。</p>
<h2 id="Monitor对象"><a href="#Monitor对象" class="headerlink" title="Monitor对象"></a>Monitor对象</h2><p>什么是Monitor？我们可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。<br>在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下(位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的)<br>ObjectMonitor中有几个关键属性，</p>
<ul>
<li>_count用来记录该线程获取锁的次数</li>
<li>_WaitSet存放处于wait状态的线程队列</li>
<li>_EntryList存放处于等待获取锁block状态的线程队列，即被阻塞的线程</li>
<li>_owner指向持有ObjectMonitor对象的线程</li>
</ul>
<p>当多个线程同时访问一段同步代码时，首先会进入<code>_EntryList</code>队列中，当某个线程获取到对象的monitor后进入_Owner区域并把monitor中的<code>_owner</code>变量设置为当前线程，同时monitor中的计数器<code>_count</code>加1，若线程调用<code>wait()</code>方法，将释放当前持有的monitor，<code>_owner</code>变量恢复为null，<code>_count</code>自减1，同时该线程进入<code>_WaitSet</code>集合中等待被唤醒。若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。如下图所示<br><img src="/blogimgs/javaSynchronized/monitor.png" alt="Monitor锁对象状态转换" title="Monitor锁对象状态转换"></p>
<h2 id="Synchronized优化"><a href="#Synchronized优化" class="headerlink" title="Synchronized优化"></a>Synchronized优化</h2><p>早期，Synchronized属于重量级锁，效率低下，因为监视器锁(monitor)是依赖于底层的操作系统的Mutex Lock来实现的，而<em>操作系统实现线程之间的切换时需要从用户态转换到核心态</em>，<strong>这个状态之间的转换需要相对比较长的时间，时间成本相对较高，这也是为什么早期的synchronized效率低的原因</strong>。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了偏向锁、轻量级锁和自旋锁等概念，接下来我们将简单了解一下Java官方在JVM层面对Synchronized锁的优化。</p>
<h3 id="偏向锁"><a href="#偏向锁" class="headerlink" title="偏向锁"></a>偏向锁</h3><p>引入偏向锁的主要原因是，<em>经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁</em>。<br>引入的主要目的是，<em>为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径</em>。因为轻量级锁的获取及释放依赖多次CAS原子指令，<em>而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令</em>（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损耗必须小于节省下来的CAS原子指令的性能消耗）。<br>偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提升程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。<br>但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。</p>
<p>其执行流程为：<br>获取锁 </p>
<ol>
<li>检测Mark Word是否为可偏向状态，即是否为偏向锁1，锁标识位为01； </li>
<li>若为可偏向状态，则测试线程ID是否为当前线程ID，如果是，则执行步骤(5)，否则执行步骤(3)； </li>
<li>如果线程ID不为当前线程ID，则<strong>通过CAS操作竞争锁</strong>，竞争成功，则将Mark Word的线程ID替换为当前线程ID，否则执行线程(4)； </li>
<li>通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块； </li>
<li>执行同步代码块</li>
</ol>
<p>释放锁<br>偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。其步骤如下： </p>
<ol>
<li>暂停拥有偏向锁的线程，判断锁对象石是否还处于被锁定状态； </li>
<li>撤销偏向苏，恢复到无锁状态(01)或者轻量级锁的状态；</li>
</ol>
<blockquote>
<p>那么轻量级锁和偏向锁的使用场景为<br>轻量级锁是为了在<strong>线程交替</strong>执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时进一步提高性能。</p>
</blockquote>
<h3 id="轻量级锁"><a href="#轻量级锁" class="headerlink" title="轻量级锁"></a>轻量级锁</h3><p>引入轻量级锁的主要原因是，<em>对绝大部分的锁，在整个同步周期内都不存在竞争</em>，可能是交替获取锁然后执行。(<strong>与偏向锁的区别是，引入偏向锁是假设同一个锁都是由同一线程多次获得，而轻量级锁是假设同一个锁是由n个线程交替获得；相同点是都是假设不存在多线程竞争</strong>)<br>引入轻量级锁的主要目的是，在没有多线程竞争的前提下，<em>减少传统的重量级锁使用操作系统互斥量产生的性能消耗(多指时间消耗)</em>。<br>触发轻量级锁的条件是<em>当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻量级锁</em>，此时Mark Word的结构也变为轻量级锁的结构。<strong>如果存在多个线程同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁</strong>。</p>
<p>其步骤如下：<br>获取锁 </p>
<ol>
<li>判断当前对象是否处于无锁状态（hashcode、0、01），若是，则JVM首先将在当前线程的<em>栈帧</em>中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝（官方把这份拷贝加了一个Displaced前缀，即Displaced Mark Word）；否则执行步骤（3）； </li>
<li>JVM利用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，如果成功表示竞争到锁，则将锁标志位变成00（表示此对象处于轻量级锁状态），执行同步操作；如果失败则执行步骤（3）； </li>
<li>判断当前对象的Mark Word是否指向当前线程的栈帧，如果是则表示当前线程已经持有当前对象的锁，则直接执行同步代码块；否则只能说明该锁对象已经被其他线程抢占了，这时轻量级锁需要膨胀为重量级锁，锁标志位变成10，后面等待的线程将会进入阻塞状态；</li>
</ol>
<p>释放锁<br>轻量级锁的释放也是通过CAS操作来进行的，主要步骤如下： </p>
<ol>
<li>取出在获取轻量级锁保存在Displaced Mark Word中的数据； </li>
<li>用CAS操作将取出的数据替换当前对象的Mark Word中，如果成功，则说明释放锁成功，否则执行（3）； </li>
<li>如果CAS操作替换失败，说明有其他线程尝试获取该锁，则需要在释放锁的同时需要唤醒被挂起的线程。</li>
</ol>
<h3 id="自旋锁"><a href="#自旋锁" class="headerlink" title="自旋锁"></a>自旋锁</h3><p>线程的阻塞和唤醒需要CPU从用户态转为核心态，频繁的阻塞和唤醒对CPU来说是一件负担很重的工作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，<em>对象锁的锁状态只会持续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的</em>。所以引入自旋锁。<br>何谓自旋锁？<br><em>所谓自旋锁，就是让该线程等待一段时间，不会被立即挂起，看持有锁的线程是否会很快释放锁。怎么等待呢？执行一段无意义的循环即可（自旋）</em>。<br>自旋等待不能替代阻塞，虽然它可以避免线程切换带来的开销，但是它占用了处理器的时间。如果持有锁的线程很快就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，它不会做任何有意义的工作，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自旋的次数）必须要有一个限度，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起。<br>自旋锁在JDK 1.4.2中引入，默认关闭，但是可以使用-XX:+UseSpinning开开启，在JDK1.6中默认开启。同时自旋的默认次数为10次，可以通过参数-XX:PreBlockSpin来调整；<br>如果通过参数-XX:preBlockSpin来调整自旋锁的自旋次数，会带来诸多不便。假如我将参数调整为10，但是很多线程都是等你刚刚退出自旋的时候就释放了锁（假如你再多自旋一两次就可以获取锁），你是不是很尴尬。于是JDK1.6引入<em>自适应的自旋锁</em>，让虚拟机会变得越来越聪明。</p>
<p>JDK 1.6引入了更加聪明的自旋锁，即自适应自旋锁。所谓自适应就意味着自旋的次数不再是固定的，它是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。它怎么做呢？<em>线程如果自旋成功了，那么下次自旋的次数会更加多</em>，因为虚拟机认为既然上次成功了，那么此次自旋也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，<em>如果对于某个锁，很少有自旋能够成功的，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器资源</em>。 </p>
<p><em>轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段</em>。如果自旋之后依然没有获取到锁，也就只能升级为重量级锁了。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://blog.csdn.net/javazejian/article/details/72828483" target="_blank" rel="noopener">http://blog.csdn.net/javazejian/article/details/72828483</a><br><a href="http://blog.csdn.net/chenssy/article/details/54883355" target="_blank" rel="noopener">http://blog.csdn.net/chenssy/article/details/54883355</a></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> synchronized </tag>
            
            <tag> 原理 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[git常用命令]]></title>
      <url>http://bigdatadecode.club/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4.html</url>
      <content type="html"><![CDATA[<p>*查看用户名和邮箱<br><code>git config user.name</code><br><code>git config user.email</code></p>
<ul>
<li>首先是配置帐号信息<br><code>git config --global user.name xxx</code><br><code>git config --global user.email xxx@bigdatadecode.club</code></li>
<li>查看配置的信息 <code>git config --list</code></li>
<li>禁止自动换行转换 <code>git config --global core.autocrlf input</code></li>
<li>查看远程分支  <code>git branch -a</code></li>
<li>查看本地分支  <code>git branch</code></li>
<li>创建本地分支并切换 <code>git checkout -b dev</code>，也可使用<code>git branch dev</code>和<code>git checkout dev</code>这两条命令</li>
<li>将本地分支推送到远程 <code>git push origin dev:dev</code> ，第一个dev是本地的分支名字，第二个dev是远程分支的名字，远程分支名字可以不存在，会自动创建</li>
<li>拉取远程分支 <code>git pull origin dev</code></li>
<li>合并远程分支， 先创建一个与远程分支同名的本地分支<code>git checkout -b test</code>，执行合并命令<code>git merge dev</code>(此时的当前分支是test，将dev合并到test分支)，然后push到远程<code>git push origin test</code></li>
<li>查看tag <code>git tag</code></li>
<li>切换tag <code>git checkout tagName # 类似branch</code> </li>
</ul>
<a id="more"></a>
<h2 id="开发本地分支同步到远程dev"><a href="#开发本地分支同步到远程dev" class="headerlink" title="开发本地分支同步到远程dev"></a>开发本地分支同步到远程dev</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先将远程dev同步到本地开发分支 test</span></span><br><span class="line">git pull origin dev</span><br><span class="line"><span class="comment"># 开发结束之后将本地分支提交到远程test分支</span></span><br><span class="line">git add --all</span><br><span class="line">git commit</span><br><span class="line">git push origin <span class="built_in">test</span></span><br><span class="line"><span class="comment"># 将远程test分支合并到dev分支</span></span><br><span class="line">git checkout dev</span><br><span class="line">git merge <span class="built_in">test</span></span><br><span class="line">git push origin dev</span><br></pre></td></tr></table></figure>
<h2 id="本地与远程代码冲突"><a href="#本地与远程代码冲突" class="headerlink" title="本地与远程代码冲突"></a>本地与远程代码冲突</h2><p>当你pull远程代码时，可能发生冲突，报错内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">error: Your <span class="built_in">local</span> changes to the following files would be overwritten by merge:  </span><br><span class="line">...</span><br><span class="line">Please, commit your changes or stash them before you can merge.  </span><br><span class="line">Aborting</span><br></pre></td></tr></table></figure>
<p>提示使用stash命令，具体操作如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git stash  <span class="comment"># 备份当前的工作区的内容到git栈中</span></span><br><span class="line">git pull   <span class="comment"># 拉取git仓库中最新的代码</span></span><br><span class="line">git stash pop  <span class="comment"># 将你保存在git栈中的代码与从git仓库中拉取的代码进行merge</span></span><br><span class="line">git diff -w filePath <span class="comment"># 用diff查看哪些文件进行merge，去相应的文件中解决冲突</span></span><br><span class="line"><span class="comment"># 进入冲突的文件，进行代码修改</span></span><br><span class="line"><span class="comment"># 修改结束之后，将当前的代码push到git仓库</span></span><br><span class="line"><span class="comment"># 将stash中的备份清空</span></span><br><span class="line">git stash clear</span><br></pre></td></tr></table></figure>
<h2 id="版本回滚"><a href="#版本回滚" class="headerlink" title="版本回滚"></a>版本回滚</h2><p>在解决冲突的过程中，或者其它原因可能需要将版本进行回滚，回滚到之前的某个版本，操作如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">log</span>  <span class="comment"># 查看提交提交历史记录    </span></span><br><span class="line"><span class="comment"># (此时就可以看出每次push代码时都要写备注，要不不知道回滚到哪个版本)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果嫌输出信息太多，看得眼花缭乱的，可以试试加上--pretty=oneline参数</span></span><br><span class="line">git <span class="built_in">log</span> --pretty=oneline </span><br><span class="line"></span><br><span class="line"><span class="comment"># 回滚版本</span></span><br><span class="line">git reset --hard HEAD^   <span class="comment"># or git reset --hard HEAD~1</span></span><br></pre></td></tr></table></figure>
<p>如果要回滚的版本和当前版本隔的版本较多，可以使用<code>git reset --hard HEAD~num</code>，其中num是回滚的版本与最新版本的<code>差值+1</code></p>
<p>如果此时又想回到未来的某个版本，则可以从之前的记录中找到未来版本的对应的<code>commit id</code>，使用<code>git reset --hard xxx</code>，版本号没必要写全，前几位就可以了，Git会自动去找，但反正都是复制，为什么不复制全呢。</p>
<h2 id="gitignore-文件的配置"><a href="#gitignore-文件的配置" class="headerlink" title=".gitignore 文件的配置"></a>.gitignore 文件的配置</h2><p>我用intellij开发，intellij的项目中会有个.idea文件夹，其内的内容和其他人的内容不一样，还有一些配置文件会不一样，所以就想把这些给忽略掉。</p>
<p>在项目中创建.gitignore，其内的内容如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">/target/</span><br><span class="line"></span><br><span class="line"><span class="comment"># ignore .idea</span></span><br><span class="line">.idea/*</span><br><span class="line"></span><br><span class="line"><span class="comment"># ignore .gitignore</span></span><br><span class="line"><span class="comment"># 如果.gitignore文件没有被忽略的话，在git命令行中执行</span></span><br><span class="line"><span class="comment"># git update-index --assume-unchanged (PATH/FILE)在PATH/FILE处输入要忽略的文件</span></span><br><span class="line">/.gitignore</span><br><span class="line"></span><br><span class="line"><span class="comment"># 本地忽略文件</span></span><br><span class="line">src/main/resources/config/jdbc.properties</span><br></pre></td></tr></table></figure>
<p>.gitignore配置完之后，向git仓库push代码时，.idea中的文件可能会发生冲突，则将本地.idea的内容从git缓存中删除，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git rm --cached &lt;文件名&gt; 删除文件的缓存</span><br><span class="line">git rm --cached -r &lt;目录名&gt; 删除目录下的所有文件的缓存</span><br></pre></td></tr></table></figure>
<p>然后将代码进行提交</p>
<h2 id="fork分支同步源分支"><a href="#fork分支同步源分支" class="headerlink" title="fork分支同步源分支"></a>fork分支同步源分支</h2><ol>
<li>Clone your fork:<br>git clone <a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>:YOUR-USERNAME/YOUR-FORKED-REPO.git</li>
<li>Add remote from original repository in your forked repository:<br>cd into/cloned/fork-repo<br>git remote add upstream git://github.com/ORIGINAL-DEV-USERNAME/REPO-YOU-FORKED-FROM.git<br>git fetch upstream</li>
<li>Updating your fork from original repo to keep up with their changes:<br>git pull upstream master</li>
</ol>
<h2 id="error-解决"><a href="#error-解决" class="headerlink" title="error 解决"></a>error 解决</h2><p>出现Non-fast-forward时，可以强制提交<code>git push -f</code></p>
<ul>
<li>Pull is not possible because you have unmerged files.(或者在进行其它操作时，提示xx have unmerged files.）<br>应该是因为local文件冲突了，解决方法有两种：</li>
</ul>
<ol>
<li>pull会使用git merge导致冲突，需要将冲突的文件resolve掉，然后执行<code>git add -u</code>, 最后<code>git commit</code>之后才能成功pull。</li>
<li>如果想放弃本地的文件修改，可以使用<code>git reset --hard FETCH_HEAD</code>，FETCH_HEAD表示上一次成功git pull之后形成的commit点。然后git pull。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> git </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之ApplicationMaster架构]]></title>
      <url>http://bigdatadecode.club/YARNSrcApplicationMasterArch.html</url>
      <content type="html"><![CDATA[<p>前面几篇关于ApplicationMaster的文章，把ApplicationMaster与RM之前的相关的流程已梳理完毕了(<em>ApplicationMaster与NM之前的流程随后梳理</em>)，其中有几个关键类ApplicationMaster(以MRAppMaster为例)、AMLivelinessMonitor、ApplicationMasterLauncher和ApplicationMasterService，本篇重点介绍下这4个类之间的关系。</p>
<a id="more"></a>
<p>先看下这4个类之间的整体架构图：<br><img src="/blogimgs/appmaster/amArch.png" alt="ApplicationMaster架构图" title="ApplicationMaster架构图"></p>
<p>简单描述下整个流程：</p>
<ul>
<li><p>首先client向RM提交一个application请求，RM创建一个application，然后再创建一个appattempt，后期的调度和任务的拆解都是对这个appattempt进行的。随着appattempt的状态变化，会触发<code>AMLauncherEventType.LAUNCH</code>事件类型的事件，由<code>ApplicationMasterLauncher.handle</code>进行处理，通过RPC调用<code>containerMgrProxy.startContainers</code>来启动一个ApplicationMaster。</p>
</li>
<li><p>ApplicationMaster启动成功之后，返回到<code>AMLauncher.run</code>中会触发<code>RMAppAttemptEventType.LAUNCHED</code>事件类型的事件，向<code>AMLivelinessMonitor</code>中注册am。</p>
</li>
<li><p>以MRAppMaster为例，当ApplicationMaster启动时会启动<code>MRAppMaster</code>这个服务，MRAppMaster启动的时候会向<code>ApplicationMasterService</code>注册。</p>
</li>
<li><p>然后开启一个心跳线程，由此线程周期性的发送心跳，心跳中包含所需container的请求列表和所要释放的container的列表，通过RPC调用<code>ApplicationMasterService.allocate</code>来获取资源，在此过程中会向<code>AMLivelinessMonitor</code>发送ping，更新在<code>AMLivelinessMonitor</code>中记录的生命时钟。 </p>
</li>
<li><p>当job结束之后，调用<code>ApplicationMaster.finish</code>，通过RPC最终调用<code>ApplicationMasterService.finishApplicationMaster</code>，在此过程中依然会向<code>AMLivelinessMonitor</code>发送ping，更新在<code>AMLivelinessMonitor</code>中记录的生命时钟。</p>
</li>
</ul>
<p>下面概括下各个类的主要作用：</p>
<blockquote>
<p>ApplicationMasterLauncher</p>
</blockquote>
<p>ApplicationMasterLauncher继承了AbstractService实现了EventHandler接口，使其即是一个服务也是一个事件处理器。<br>ApplicationMasterLauncher只处理两类事件，一个是启动AM的<code>LAUNCH</code>和清理AM的<code>CLEANUP</code>请求，这两类事件被放入一个事件队列中，由<em>ApplicationMasterLauncher作为服务时，启动一个launcherHandlingThread线程将事件取出放入线程池中处理</em>。<br>如果ApplicationMasterLauncher收到了<code>LAUNCH</code>类型的事件，它会与对应的NodeManager通信，要求它启动ApplicationMaster。整个过程在<a href="http://bigdatadecode.club/YARNSrcApplicationMasterStart.html">这篇文章</a>中详细介绍了下，这里简单回顾下，首先创建一个ContainerManager协议的Client，然后向对应的NodeManager发起连接请求，接着将启动AM所需的各种信息，包括命令，Jar包、环境变量等信息，封装成一个StartContainerRequest对象，然后通过RPC函数ContainerManager.startContainer()发送给对应的NM。<br>如果ApplicationMasterLauncher收到了<code>CLEANUP</code>类型的事件，它会与对应的NodeManager通信，要求它杀死ApplicationMaster。整个过程与启动AM的过程类似。</p>
<blockquote>
<p>AMLivelinessMonitor</p>
</blockquote>
<p><em>AMLivelinessMonitor主要用来监控am的生命状态</em>，如果AM长时间没有心跳信息更新，RM就会通知NodeManager把AM移除。appattempt在启动的时候会向其注册am信息，然后AMLivelinessMonitor会周期性遍历所有ApplicationMaster，如果一个ApplicationMaster在一定时间（可通过参数yarn.am.liveness-monitor.expiry-interval-ms配置，默认为10min）内未汇报心跳信息，则认为它死掉了，它上面所有正在运行的Container将被置为运行失败（RM不会重新执行这些Container，它只会通过心跳机制告诉对应的AM，由AM决定是否重新执行，如果需要，则AM重新向RM申请资源），AM本身会被重新分配到另外一个节点上（管理员可通过参数yarn.resourcemanager.am.max-retries指定每个ApplicationMaster的尝试次数，默认是1次）执行。</p>
<blockquote>
<p>ApplicationMasterService</p>
</blockquote>
<p>ApplicationMasterService负责处理来自ApplicationMaster的请求，主要包括三种请求：注册、心跳和清理，这部分内容在<a href="http://bigdatadecode.club/YARNSrcRMContainerAllocator.html">这篇文章</a>中详细介绍了下，这里简单回顾下，其中，注册是ApplicationMaster启动时发生的行为，请求包中包含AM所在节点，RPC端口号和tracking URL等信息；心跳是周期性行为，包含请求资源的类型描述、待释放的Container列表等，而AMS则为之返回新分配的Container、已完成的Container等信息；清理是应用程序运行结束时发生的行为，ApplicationMaster向RM发送清理应用程序的请求，以回收资源和清理各种数据结构。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> ApplicationMaster </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之RMContainerAllocator]]></title>
      <url>http://bigdatadecode.club/YARNSrcRMContainerAllocator.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/YarnSrcMRCreateContainerRequest.html">上一篇</a>提到RMContainerAllocator既是一个service也是一个eventHandle，并且简单介绍了下作为eventHandle的功能，现在来介绍下作为service服务的功能。</p>
<a id="more"></a>
<p>RMContainerAllocator继承RMContainerRequestor类，RMContainerRequestor又继承自RMCommunicator，RMCommunicator类在代码中的注释是<code>Registers/unregisters to RM and sends heartbeats to RM.</code></p>
<p>RMContainerAllocator是一个服务，在MRAppMaster.serviceInit中添加到MRAppMaster中，并且在serviceStart中启动该服务，启动时首先调用init，然后调用start。<br>RMContainerAllocator.serviceInit主要是一些属性值的设置，重点看下serviceStart方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceStart</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="comment">// new 一个线程从eventQueue中take事件进行处理</span></span><br><span class="line">  <span class="keyword">this</span>.eventHandlingThread = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      ContainerAllocatorEvent event;</span><br><span class="line">      <span class="keyword">while</span> (!stopped.get() &amp;&amp; !Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          event = RMContainerAllocator.<span class="keyword">this</span>.eventQueue.take();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">          ...</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          handleEvent(event);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">          ...</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">this</span>.eventHandlingThread.start();</span><br><span class="line">  <span class="comment">// 调用父类的serviceStart，重点关注</span></span><br><span class="line">  <span class="keyword">super</span>.serviceStart();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>serviceStart中启动了一个eventHandlingThread线程，用于处理eventQueue中的事件，此时看RMContainerAllocator类的主要功能是eventHandle，接着继续看它调用的父类<code>super.serviceStart()</code>，该父类是<code>RMCommunicator</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceStart</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="comment">// scheduler是ApplicationMasterProtocol类型</span></span><br><span class="line">  scheduler= createSchedulerProxy();</span><br><span class="line">  JobID id = TypeConverter.fromYarn(<span class="keyword">this</span>.applicationId);</span><br><span class="line">  JobId jobId = TypeConverter.toYarn(id);</span><br><span class="line">  job = context.getJob(jobId);</span><br><span class="line">  <span class="comment">// am注册</span></span><br><span class="line">  register();</span><br><span class="line">  <span class="comment">// 启动一个心跳线程</span></span><br><span class="line">  startAllocatorThread();</span><br><span class="line">  <span class="keyword">super</span>.serviceStart();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有两个重要方法，分别是<code>register</code>和<code>startAllocatorThread</code>，其实RMContainerAllocator作为service的主要功能就是<em>注册</em>和<em>心跳</em>。</p>
<h2 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h2><p>register是向rm注册此mr的am，startAllocatorThread是启动am于rm之间心跳的线程。register代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//Register</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    RegisterApplicationMasterRequest request =</span><br><span class="line">      recordFactory.newRecordInstance(RegisterApplicationMasterRequest.class);</span><br><span class="line">    ...</span><br><span class="line">    RegisterApplicationMasterResponse response =</span><br><span class="line">      scheduler.registerApplicationMaster(request);</span><br><span class="line">    isApplicationMasterRegistered = <span class="keyword">true</span>;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception are) &#123;</span><br><span class="line">    LOG.error(<span class="string">"Exception while registering"</span>, are);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(are);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>register是向<code>ApplicationMasterService</code>注册am服务，通过rpc协议<code>ApplicationMasterProtocol</code>调用<code>ApplicationMasterService.registerApplicationMaster</code>向ApplicationMasterService进行注册，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RegisterApplicationMasterResponse <span class="title">registerApplicationMaster</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    RegisterApplicationMasterRequest request)</span> <span class="keyword">throws</span> YarnException,</span></span><br><span class="line"><span class="function">    IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Allow only one thread in AM to do registerApp at a time.</span></span><br><span class="line">  <span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">    AllocateResponse lastResponse = lock.getAllocateResponse();</span><br><span class="line">    <span class="comment">// hasApplicationMasterRegistered中有个双重校验锁</span></span><br><span class="line">    <span class="comment">// responseId&gt;=0是判断是否注册的一个条件</span></span><br><span class="line">    <span class="keyword">if</span> (hasApplicationMasterRegistered(applicationAttemptId)) &#123;</span><br><span class="line">	     ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 向AMLivelinessMonitor更新am存活时间</span></span><br><span class="line">    <span class="keyword">this</span>.amLivelinessMonitor.receivedPing(applicationAttemptId);</span><br><span class="line">    <span class="comment">// Setting the response id to 0 to identify if the</span></span><br><span class="line">    <span class="comment">// application master is register for the respective attemptid</span></span><br><span class="line">    <span class="comment">// 未注册时为-1，判断是否注册的一个标准时&gt;=0</span></span><br><span class="line">    <span class="comment">// responseId从0开始，注册时为0</span></span><br><span class="line">    lastResponse.setResponseId(<span class="number">0</span>);</span><br><span class="line">    lock.setAllocateResponse(lastResponse);</span><br><span class="line">    LOG.info(<span class="string">"AM registration "</span> + applicationAttemptId);</span><br><span class="line">    <span class="comment">// 由异步调度器发出RMAppAttemptEventType.REGISTERED事件</span></span><br><span class="line">    <span class="keyword">this</span>.rmContext</span><br><span class="line">      .getDispatcher()</span><br><span class="line">      .getEventHandler()</span><br><span class="line">      .handle(</span><br><span class="line">        <span class="keyword">new</span> RMAppAttemptRegistrationEvent(applicationAttemptId, request</span><br><span class="line">          .getHost(), request.getRpcPort(), request.getTrackingUrl()));</span><br><span class="line">    RMAuditLogger.logSuccess(app.getUser(), AuditConstants.REGISTER_AM,</span><br><span class="line">      <span class="string">"ApplicationMasterService"</span>, appID, applicationAttemptId);</span><br><span class="line">    <span class="comment">// 构造response</span></span><br><span class="line">    <span class="comment">// Pick up min/max resource from scheduler...</span></span><br><span class="line">    RegisterApplicationMasterResponse response = recordFactory</span><br><span class="line">        .newRecordInstance(RegisterApplicationMasterResponse.class);</span><br><span class="line">    ...</span><br><span class="line">    response.setSchedulerResourceTypes(rScheduler</span><br><span class="line">      .getSchedulingResourceTypes());</span><br><span class="line">    <span class="keyword">return</span> response;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>am向ApplicationMasterService注册时registerApplicationMaster方法是非现场安全的，则注册时需要获取AllocateResponseLock对象锁，其注册的流程是<em>更新am在AMLivelinessMonitor中的生命时钟</em>，设置responseId为0，然后构造一个RMAppAttemptEventType.REGISTERED事件类型的事件，由异步调度器分发给相应的Eventhandle处理。<br>此时注册过程结束，构建一个response返回给客户端。</p>
<h2 id="心跳"><a href="#心跳" class="headerlink" title="心跳"></a>心跳</h2><p>am注册结束之后，回到<code>RMCommunicator.serviceStart</code>中，执行<code>startAllocatorThread</code>启动一个心跳线程，周期性的向<code>ApplicationMasterService</code>进行心跳。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">startAllocatorThread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  allocatorThread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">while</span> (!stopped.get() &amp;&amp; !Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">// 心跳间隔</span></span><br><span class="line">          Thread.sleep(rmPollInterval);</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">          	<span class="comment">// 调用RMContainerAllocator.heartbeat</span></span><br><span class="line">            heartbeat();</span><br><span class="line">          &#125; <span class="keyword">catch</span> (YarnRuntimeException e) &#123;</span><br><span class="line">            ...</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          lastHeartbeatTime = context.getClock().getTime();</span><br><span class="line">          <span class="comment">// 每次心跳都调用这个，干什么？？？？？？</span></span><br><span class="line">          executeHeartbeatCallbacks();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">          ...</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">  allocatorThread.setName(<span class="string">"RMCommunicator Allocator"</span>);</span><br><span class="line">  allocatorThread.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里启动一个线程，将线程命名为<em>RMCommunicator Allocator</em>，每隔rmPollInterval时间，执行一次<code>heartbeat</code>。此文中RMCommunicator抽象类的子类是RMContainerAllocator，则heartbeat的实现方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">heartbeat</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  scheduleStats.updateAndLogIfChanged(<span class="string">"Before Scheduling: "</span>);</span><br><span class="line">  <span class="comment">// 关键方法，会远程调用Scheduler.allocated方法对资源进行allocate</span></span><br><span class="line">  <span class="comment">// 这里只是申请到资源，但资源并没有于task绑定，也就是说资源并没有分配给task</span></span><br><span class="line">  List&lt;Container&gt; allocatedContainers = getResources();</span><br><span class="line">  <span class="keyword">if</span> (allocatedContainers != <span class="keyword">null</span> &amp;&amp; allocatedContainers.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">  	<span class="comment">// 将资源分配给task</span></span><br><span class="line">    scheduledRequests.assign(allocatedContainers);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 如果task的进度发生变化并且剩余的map个大于0，则触发是否调度reduce判断</span></span><br><span class="line">  <span class="keyword">if</span> ((lastCompletedTasks != completedTasks) ||</span><br><span class="line">        (scheduledRequests.maps.size() &gt; <span class="number">0</span>)) &#123;</span><br><span class="line">    lastCompletedTasks = completedTasks;</span><br><span class="line">    recalculateReduceSchedule = <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (recalculateReduceSchedule) &#123;</span><br><span class="line">    preemptReducesIfNeeded();</span><br><span class="line">    <span class="comment">// 是否要调度reduce</span></span><br><span class="line">    <span class="comment">// 这里要关注mapreduce.job.reduce.slowstart.completedmaps</span></span><br><span class="line">    <span class="comment">// 和yarn.app.mapreduce.am.job.reduce.rampup.limit</span></span><br><span class="line">    scheduleReduces(</span><br><span class="line">        getJob().getTotalMaps(), completedMaps,</span><br><span class="line">        scheduledRequests.maps.size(), scheduledRequests.reduces.size(), </span><br><span class="line">        assignedRequests.maps.size(), assignedRequests.reduces.size(),</span><br><span class="line">        mapResourceRequest, reduceResourceRequest,</span><br><span class="line">        pendingReduces.size(), </span><br><span class="line">        maxReduceRampupLimit, reduceSlowStart);</span><br><span class="line">    recalculateReduceSchedule = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  scheduleStats.updateAndLogIfChanged(<span class="string">"After Scheduling: "</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>heartbeat主要用于am和rm之间周期性的通信，以告知rm此am是否存活，但heartbeat中不止只是生命心跳，在发送的request中包含<em>请求资源的列表ask</em>和<em>需要释放的资源列表release</em>，返回的response包含了<em>allocated的资源</em>和<em>已经完成的container(是由上次请求中release列表中得到的)</em>。<br>返回的container资源此时并没有分配给task，而是通过<code>scheduledRequests.assign</code>将container资源分配给具体的task。<br>heartbeat中通过<code>getResources()</code>通过Scheduler获取集群资源，查看下getResources的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> List&lt;Container&gt; <span class="title">getResources</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 发送request，远程调用Scheduler.allocated分配资源</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    response = makeRemoteRequest();</span><br><span class="line">    <span class="comment">// Reset retry count if no exception occurred.</span></span><br><span class="line">    retrystartTime = System.currentTimeMillis();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (ApplicationAttemptNotFoundException e ) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  List&lt;Container&gt; newContainers = response.getAllocatedContainers();</span><br><span class="line">  <span class="comment">// Setting NMTokens</span></span><br><span class="line">  <span class="comment">// Setting AMRMToken</span></span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  List&lt;ContainerStatus&gt; finishedContainers = response.getCompletedContainersStatuses();</span><br><span class="line">  ...</span><br><span class="line"></span><br><span class="line">  <span class="comment">//Called on each allocation. Will know about newly blacklisted/added hosts.</span></span><br><span class="line">  computeIgnoreBlacklisting();</span><br><span class="line">  <span class="comment">// 让response.getUpdatedNodes()进行report，查看是否为不稳定状态，</span></span><br><span class="line">  <span class="comment">// 更新unusableNodes，将这些节点上的task kill掉</span></span><br><span class="line">  handleUpdatedNodes(response);</span><br><span class="line">  <span class="comment">// 对心跳响应中得到的finishContainer进行处理</span></span><br><span class="line">  <span class="keyword">for</span> (ContainerStatus cont : finishedContainers) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Received completed container "</span> + cont.getContainerId());</span><br><span class="line">    TaskAttemptId attemptID = assignedRequests.get(cont.getContainerId());</span><br><span class="line">    <span class="keyword">if</span> (attemptID == <span class="keyword">null</span>) &#123;</span><br><span class="line">      LOG.error(<span class="string">"Container complete event for unknown container id "</span></span><br><span class="line">          + cont.getContainerId());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      pendingRelease.remove(cont.getContainerId());</span><br><span class="line">      assignedRequests.remove(attemptID);</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// send the container completed event to Task attempt</span></span><br><span class="line">      eventHandler.handle(createContainerFinishedEvent(cont, attemptID));</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Send the diagnostics</span></span><br><span class="line">      String diagnostics = StringInterner.weakIntern(cont.getDiagnostics());</span><br><span class="line">      eventHandler.handle(<span class="keyword">new</span> TaskAttemptDiagnosticsUpdateEvent(attemptID,</span><br><span class="line">          diagnostics));</span><br><span class="line">    &#125;      </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> newContainers;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一看getResources这个名字就知道这里会有个远程rpc调用从rm处获取资源，方法为<code>makeRemoteRequest</code>，具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> AllocateResponse <span class="title">makeRemoteRequest</span><span class="params">()</span> <span class="keyword">throws</span> YarnException,</span></span><br><span class="line"><span class="function">    IOException </span>&#123;</span><br><span class="line">  ResourceBlacklistRequest blacklistRequest =</span><br><span class="line">      ResourceBlacklistRequest.newInstance(<span class="keyword">new</span> ArrayList&lt;String&gt;(blacklistAdditions),</span><br><span class="line">          <span class="keyword">new</span> ArrayList&lt;String&gt;(blacklistRemovals));</span><br><span class="line">  <span class="comment">// ask 通过 scheduledRequests.addMap  addResourceRequest 更新</span></span><br><span class="line">  <span class="comment">// 请求中包括 ask &amp; release 集合</span></span><br><span class="line">  AllocateRequest allocateRequest =</span><br><span class="line">      AllocateRequest.newInstance(lastResponseID,</span><br><span class="line">        <span class="keyword">super</span>.getApplicationProgress(), <span class="keyword">new</span> ArrayList&lt;ResourceRequest&gt;(ask),</span><br><span class="line">        <span class="keyword">new</span> ArrayList&lt;ContainerId&gt;(release), blacklistRequest);</span><br><span class="line">  <span class="comment">// 调度器分配资源   scheduler.allocate (ApplicationMasterProtocol)</span></span><br><span class="line">  <span class="comment">// 在allocate中会更新AMLivelinessMonitor中的时间</span></span><br><span class="line">  AllocateResponse allocateResponse = scheduler.allocate(allocateRequest);</span><br><span class="line">  lastResponseID = allocateResponse.getResponseId();</span><br><span class="line">  availableResources = allocateResponse.getAvailableResources();</span><br><span class="line">  lastClusterNmCount = clusterNmCount;</span><br><span class="line">  clusterNmCount = allocateResponse.getNumClusterNodes(); </span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> allocateResponse;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>makeRemoteRequest利用ask和release列表以及blackList构建一个<code>AllocateRequest</code>对象，用于向ApplicationMasterService请求分配资源。<br>这里需要注意的是ask中的所有请求和release列表中container会在每次心跳时发送给ApplicationMasterService，然后此时从ApplicationMasterService返回的response中包含的已分配的container信息并没有此次ask中的请求信息，而是在此次心跳之前发送给ApplicationMasterService的container请求对应的资源。</p>
<p>makeRemoteRequest返回ApplicationMasterService的response，response中包括响应id、当前集群可用的资源和集群的节点个数，还有<em>最关键的分配的container列表以及finishContainer列表</em>。<br>在<code>getResources</code>中拿到<code>newContainers</code>和<code>finishedContainers</code>，对newContainers设置一些Tokens，遍历finishedContainers，从<code>assignedRequests</code>将finishedContainer移除，并触发一个<code>TaskAttemptEvent</code>事件。<br>在getResources中只对finishedContainers进行了处理，对新得到的container资源并没有分配给具体的task。从getResource方法返回到<code>heartbeat</code>中，调用<code>scheduledRequests.assign(allocatedContainers)</code>给task分配资源。具体代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">assign</span><span class="params">(List&lt;Container&gt; allocatedContainers)</span> </span>&#123;</span><br><span class="line">  Iterator&lt;Container&gt; it = allocatedContainers.iterator();</span><br><span class="line">  LOG.info(<span class="string">"Got allocated containers "</span> + allocatedContainers.size());</span><br><span class="line">  containersAllocated += allocatedContainers.size();</span><br><span class="line">  <span class="comment">// 对allocatedContainers进行过滤，将不能分配的资源移除</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 分配资源给task</span></span><br><span class="line">  assignContainers(allocatedContainers);</span><br><span class="line">  <span class="comment">// 将剩余未分配的资源释放掉</span></span><br><span class="line">  <span class="comment">// release container if we could not assign it </span></span><br><span class="line">  it = allocatedContainers.iterator();</span><br><span class="line">  <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">    Container allocated = it.next();</span><br><span class="line">    LOG.info(<span class="string">"Releasing unassigned and invalid container "</span> </span><br><span class="line">        + allocated + <span class="string">". RM may have assignment issues"</span>);</span><br><span class="line">    containerNotAssigned(allocated);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>assign在分配资源之前会先过滤下allocatedContainers列表中的资源，对于无法满足request的container和在黑名单中的container从列表中移除，对过滤过的<code>allocatedContainers</code>调用<code>assignContainers</code>进行分配，最后对没有分配的剩余container进行释放。assignContainers代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">assignContainers</span><span class="params">(List&lt;Container&gt; allocatedContainers)</span> </span>&#123;</span><br><span class="line">  Iterator&lt;Container&gt; it = allocatedContainers.iterator();</span><br><span class="line">  <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">    Container allocated = it.next();</span><br><span class="line">    <span class="comment">// 无本地性要求的task 如 reduce和fail map task</span></span><br><span class="line">    ContainerRequest assigned = assignWithoutLocality(allocated);</span><br><span class="line">    <span class="keyword">if</span> (assigned != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// 将container分配给task attempt，</span></span><br><span class="line">      <span class="comment">// 触发TaskAttemptEventType.TA_ASSIGNED事件类型</span></span><br><span class="line">      containerAssigned(allocated, assigned);</span><br><span class="line">      it.remove();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 分配map</span></span><br><span class="line">  assignMapsWithLocality(allocatedContainers);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分配container时，先对allocatedContainers进行遍历，遍历中对<em>不需要本地性</em>的container进行分配，(不需要本地性的container为<em>失败之后重跑的map和reduce</em>)，遍历结束之后调用<code>assignMapsWithLocality</code>将剩余的container分配给map。<br>这里可以看出失败之后重跑的map和reduce的运行优先级比map的运行优先级高，防止集群中的job都在等待reduce资源，而无法使job结束释放资源。</p>
<p>看下assignMapsWithLocality方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">assignMapsWithLocality</span><span class="params">(List&lt;Container&gt; allocatedContainers)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// try to assign to all nodes first to match node local</span></span><br><span class="line">  Iterator&lt;Container&gt; it = allocatedContainers.iterator();</span><br><span class="line">  <span class="comment">// 数据本地性</span></span><br><span class="line">  <span class="keyword">while</span>(it.hasNext() &amp;&amp; maps.size() &gt; <span class="number">0</span>)&#123;</span><br><span class="line">    Container allocated = it.next();        </span><br><span class="line">    Priority priority = allocated.getPriority();</span><br><span class="line">    <span class="keyword">assert</span> PRIORITY_MAP.equals(priority);</span><br><span class="line">    <span class="comment">// "if (maps.containsKey(tId))" below should be almost always true.</span></span><br><span class="line">    <span class="comment">// hence this while loop would almost always have O(1) complexity</span></span><br><span class="line">    String host = allocated.getNodeId().getHost();</span><br><span class="line">    <span class="comment">// 取出改host对应的attempt列表</span></span><br><span class="line">    LinkedList&lt;TaskAttemptId&gt; list = mapsHostMapping.get(host);</span><br><span class="line">    <span class="keyword">while</span> (list != <span class="keyword">null</span> &amp;&amp; list.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">      TaskAttemptId tId = list.removeFirst();</span><br><span class="line">      <span class="comment">// 如果tId在待执行的map集合中，则去处对应的request进行分配资源</span></span><br><span class="line">      <span class="keyword">if</span> (maps.containsKey(tId)) &#123;</span><br><span class="line">        ContainerRequest assigned = maps.remove(tId);</span><br><span class="line">        <span class="comment">// 无论map还是reduce都是调用次方法</span></span><br><span class="line">        containerAssigned(allocated, assigned);</span><br><span class="line">        it.remove();</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// try to match all rack local</span></span><br><span class="line">  it = allocatedContainers.iterator();</span><br><span class="line">  <span class="keyword">while</span>(it.hasNext() &amp;&amp; maps.size() &gt; <span class="number">0</span>)&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// "if (maps.containsKey(tId))" below should be almost always true.</span></span><br><span class="line">    <span class="comment">// hence this while loop would almost always have O(1) complexity</span></span><br><span class="line">    String host = allocated.getNodeId().getHost();</span><br><span class="line">    String rack = RackResolver.resolve(host).getNetworkLocation();</span><br><span class="line">    LinkedList&lt;TaskAttemptId&gt; list = mapsRackMapping.get(rack);</span><br><span class="line">    <span class="keyword">while</span> (list != <span class="keyword">null</span> &amp;&amp; list.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      TaskAttemptId tId = list.removeFirst();</span><br><span class="line">      <span class="keyword">if</span> (maps.containsKey(tId)) &#123;</span><br><span class="line">        ContainerRequest assigned = maps.remove(tId);</span><br><span class="line">        containerAssigned(allocated, assigned);</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// assign remaining</span></span><br><span class="line">  it = allocatedContainers.iterator();</span><br><span class="line">  <span class="keyword">while</span>(it.hasNext() &amp;&amp; maps.size() &gt; <span class="number">0</span>)&#123;</span><br><span class="line">    Container allocated = it.next();</span><br><span class="line">    Priority priority = allocated.getPriority();</span><br><span class="line">    <span class="keyword">assert</span> PRIORITY_MAP.equals(priority);</span><br><span class="line">    TaskAttemptId tId = maps.keySet().iterator().next();</span><br><span class="line">    ContainerRequest assigned = maps.remove(tId);</span><br><span class="line">    containerAssigned(allocated, assigned);</span><br><span class="line">    it.remove();</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>assignMapsWithLocality先对allocatedContainers列表遍历一边，将container资源进行host本地性分配，host本地性是指container所在的节点上是否有container request，如果有则将request从maps中取出，调用<code>containerAssigned</code>进行资源分配。<br>host本地性分配完之后，再次遍历allocatedContainers列表，将剩下的container针对rack本地性进行分配，此次遍历结束之后，还需进行一次遍历，对剩下的container进行不考虑本地性的分配。</p>
<p>container分配给map还是reduce都是调用<code>containerAssigned</code>，看下具体代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">containerAssigned</span><span class="params">(Container allocated, </span></span></span><br><span class="line"><span class="function"><span class="params">                                ContainerRequest assigned)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Update resource requests</span></span><br><span class="line">  decContainerReq(assigned);</span><br><span class="line">  <span class="comment">// 触发TaskAttemptEventType.TA_ASSIGNED事件类型</span></span><br><span class="line">  <span class="comment">// send the container-assigned event to task attempt</span></span><br><span class="line">  eventHandler.handle(<span class="keyword">new</span> TaskAttemptContainerAssignedEvent(</span><br><span class="line">      assigned.attemptID, allocated, applicationACLs));</span><br><span class="line">  <span class="comment">// 将container放入已分配的集合中</span></span><br><span class="line">  assignedRequests.add(allocated, assigned.attemptID);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇主要介绍了RMContainerAllocator作为一个service时的相关逻辑，这部分逻辑大部分是在<code>RMContainerRequestor</code>中实现的，而RMContainerRequestor又继承自<code>RMCommunicator</code>。</p>
<p>RMContainerAllocator作为service时的主要功能为<strong>注册</strong>和<strong>心跳</strong>。<br>注册时由AM向<code>ApplicationMasterService</code>发出请求，在注册的同时会更新下<code>AMLivelinessMonitor</code>中的存活时间，并触发RMAppAttemptEventType.REGISTERED事件类型的事件，由异步调度器分发给相应的Eventhandle处理。<br>注册比较简单，心跳则有一个专门的线程进行周期性的执行。<br>心跳不止只是用来告诉rm此am是否存活，更重要的是在心跳中会向rm发送申请container的请求，并将接收到的container分配给task。<em>am发送的申请container请求可以认为是异步的，因为一次心跳过程中的发送当前所需的container资源，然后接收到的container响应是之前心跳中发送的container请求，而不是此次心跳中发送的container请求对应的响应，此次心跳中所需的container需在下次心跳或者下下次心跳中才能得到响应</em>。</p>
<p>结合前面几篇关于ApplicationMaster的文章，目前已经把ApplicationMaster与RM之前的相关的流程已梳理完毕了(<em>ApplicationMaster与NM之前的流程随后梳理</em>)，其中有几个关键类ApplicationMaster、AMLivelinessMonitor、ApplicationMasterLauncher和ApplicationMasterService，下面将会有一篇文章综合介绍下这4个类之间的关系。</p>
<!--
AMLivelinessMonitor中的生命时钟是不是就是心跳时间， lastHeartbeatTime 是什么


mapsHostMapping maps reduces 之间的关系
host上有多少个container请求，由addMap更新
maps存放attemptID与request映射，待执行的map集合
-->]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> MRAppMaster </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之MR创建container请求]]></title>
      <url>http://bigdatadecode.club/YarnSrcMRCreateContainerRequest.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/YARNSrcMRAppMasterStart.html">上一篇</a>介绍了MRAppMaster启动时的一些流程。当MRAppMaster启动成功之后，job的状态已由INITED变为SETUP，并且在<code>StartTransition.transition</code>中构建了<code>CommitterEventType.JOB_SETUP</code>事件类型，由<code>CommitterEventHandler.handle</code>进行处理。</p>
<blockquote>
<p>CommitterEventType.JOB_SETUP事件类型的处理器在MRAppMaster中作为一个服务添加到MRAppMaster服务中。</p>
</blockquote>
<a id="more"></a>
<p>来看下具体的流程</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StartTransition.transition 构建CommitterEventType.JOB_SETUP事件类型对象</span></span><br><span class="line">job.eventHandler.handle(<span class="keyword">new</span> CommitterJobSetupEvent(job.jobId, job.jobContext));</span><br><span class="line"></span><br><span class="line"><span class="comment">// CommitterEventHandler.handle</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(CommitterEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// 将事件放入队列中</span></span><br><span class="line">    eventQueue.put(event);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面提到<code>CommitterEventHandler</code>是作为一个Service添加到MRAppMaster服务中的，显然它继承了<code>AbstractService</code>，然而它又能处理事件，则它实现了<code>EventHandler</code>接口。在其<code>handle</code>方法中将event放入事件队列<code>eventQueue</code>中，eventQueue是<code>LinkedBlockingQueue</code>类型的阻塞队列，是线程安全的。</p>
<p>CommitterEventHandler通过handle将event放入eventQueue中，在<code>serviceStart</code>中会启动一个线程从eventQueue中take事件然后交给ThreadPoolExecutor去执行。具体的执行代码在<code>EventProcessor.run</code>中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  LOG.info(<span class="string">"Processing the event "</span> + event.toString());</span><br><span class="line">  <span class="keyword">switch</span> (event.getType()) &#123;</span><br><span class="line">  <span class="keyword">case</span> JOB_SETUP:</span><br><span class="line">    handleJobSetup((CommitterJobSetupEvent) event);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> JOB_COMMIT:</span><br><span class="line">    handleJobCommit((CommitterJobCommitEvent) event);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> JOB_ABORT:</span><br><span class="line">    handleJobAbort((CommitterJobAbortEvent) event);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> TASK_ABORT:</span><br><span class="line">    handleTaskAbort((CommitterTaskAbortEvent) event);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(<span class="string">"Unexpected committer event "</span></span><br><span class="line">        + event.toString());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 此时放入的事件类型是CommitterEventType.JOB_SETUP，则在handleJobSetup中处理</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">handleJobSetup</span><span class="params">(CommitterJobSetupEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// Create the temporary directory that is the root of all of the task work directories.</span></span><br><span class="line">  	<span class="comment">// committer是在MRAppMaster.serviceInit中create的OutputCommitter</span></span><br><span class="line">    committer.setupJob(event.getJobContext());</span><br><span class="line">    <span class="comment">// JobEventType.JOB_SETUP_COMPLETED</span></span><br><span class="line">    context.getEventHandler().handle(</span><br><span class="line">        <span class="keyword">new</span> JobSetupCompletedEvent(event.getJobID()));</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Job setup failed"</span>, e);</span><br><span class="line">    context.getEventHandler().handle(<span class="keyword">new</span> JobSetupFailedEvent(</span><br><span class="line">        event.getJobID(), StringUtils.stringifyException(e)));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>CommitterEventHandler处理CommitterEventType.JOB_SETUP事件类型时，会给job创建<em>临时目录</em>存放mr所需的文件，创建成果之后触发<code>JobEventType.JOB_SETUP_COMPLETED</code>事件类型，失败则触发<code>JobEventType.JOB_SETUP_FAILED</code>。</p>
<p><code>JobEventType.JOB_SETUP_COMPLETED</code>和<code>JobEventType.JOB_SETUP_FAILED</code>都是JobImpl状态机中的状态，此时job的状态是SETUP，当OutputCommitter把job所需的临时目录创建成功之后，触发<code>JobEventType.JOB_SETUP_COMPLETED</code>，由<code>SetupCompletedTransition</code>进行处理，看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(JobImpl job, JobEvent event)</span> </span>&#123;</span><br><span class="line">  job.setupProgress = <span class="number">1.0f</span>;</span><br><span class="line">  <span class="comment">// SETUP 到 RUNNING时，开始调度task</span></span><br><span class="line">  job.scheduleTasks(job.mapTasks, job.numReduceTasks == <span class="number">0</span>);</span><br><span class="line">  job.scheduleTasks(job.reduceTasks, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If we have no tasks, just transition to job completed</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>SetupCompletedTransition处理之后job的状态变为<em>RUNNING</em>，其处理逻辑是调度task，task对象是在<code>InitTransition.transition</code>中调用<code>createMapTasks</code>和<code>createReduceTasks</code>中创建的。<br><code>scheduleTasks</code>对每个task构造一个<code>TaskEventType.T_SCHEDULE</code>类型的TaskEvent事件，并通过异步调度器分发出去，由每个具体的task进行执行，map task之间没有执行顺序上的依赖，这样map task就达到了并行的目的。<br>看下相关代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">scheduleTasks</span><span class="params">(Set&lt;TaskId&gt; taskIDs,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> recoverTaskOutput)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (TaskId taskID : taskIDs) &#123;</span><br><span class="line">    TaskInfo taskInfo = completedTasksFromPreviousRun.remove(taskID);</span><br><span class="line">    <span class="keyword">if</span> (taskInfo != <span class="keyword">null</span>) &#123;</span><br><span class="line">      eventHandler.handle(<span class="keyword">new</span> TaskRecoverEvent(taskID, taskInfo,</span><br><span class="line">          committer, recoverTaskOutput));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 开始调度task</span></span><br><span class="line">      <span class="comment">// 通过异步调度器将task事件分发出去</span></span><br><span class="line">      eventHandler.handle(<span class="keyword">new</span> TaskEvent(taskID, TaskEventType.T_SCHEDULE));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>处理<code>TaskEvent</code>事件的handle是在MRAppMaster中注册到异步调度器dispatcher中的<code>TaskEventDispatcher</code>，其handle中调用了<code>((EventHandler&lt;TaskEvent&gt;)task).handle(event)</code>，进入了task状态机的转换流程中。<br>task在createMapTasks中初始化状态是NEW，<code>TaskEventType.T_SCHEDULE</code>事件类型被触发之后，由<code>InitialScheduleTransition</code>使其状态转为<code>SCHEDULED</code>。看下InitialScheduleTransition的代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(TaskImpl task, TaskEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 调度task attempt，attempt是针对task的</span></span><br><span class="line">  <span class="comment">// 申请container</span></span><br><span class="line">  task.addAndScheduleAttempt(Avataar.VIRGIN);</span><br><span class="line">  task.scheduledTime = task.clock.getTime();</span><br><span class="line">  task.sendTaskStartedEvent();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>yarn中实质性执行操作的都是attempt，如job是jobAttempt，task是taskAttempt，使用attempt是考虑到了失败重试和推测执行(Speculative Execution)。<br>所以task调度时先创建一个attempt并调度，然后向jobhistory发送<code>EventType.TASK_STARTED</code>事件类型。重点看下<code>addAndScheduleAttempt</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addAndScheduleAttempt</span><span class="params">(Avataar avataar)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 将attempt添加到singletonMap的map中</span></span><br><span class="line">  TaskAttempt attempt = addAttempt(avataar);</span><br><span class="line">  inProgressAttempts.add(attempt.getID());</span><br><span class="line">  <span class="comment">//schedule the nextAttemptNumber</span></span><br><span class="line">  <span class="keyword">if</span> (failedAttempts.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    eventHandler.handle(<span class="keyword">new</span> TaskAttemptEvent(attempt.getID(),</span><br><span class="line">        TaskAttemptEventType.TA_RESCHEDULE));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 为task申请container，开启task attempt状态机循环</span></span><br><span class="line">    eventHandler.handle(<span class="keyword">new</span> TaskAttemptEvent(attempt.getID(),</span><br><span class="line">        TaskAttemptEventType.TA_SCHEDULE));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>触发<code>TaskAttemptEventType.TA_SCHEDULE</code>事件类型的<code>TaskAttemptEvent</code>，并通过异步调度器将其分发给<code>TaskAttemptEventDispatcher</code>，调用<code>TaskAttemptImpl.handle</code>进行处理。<br>在<code>scheduleTasks</code>中如此循环，将map task调度结束之后，开始调度reduce task。由于reduce依赖map的执行进度，这里先不对reduce task进行展开，我们继续跟踪下map task的attempt状态转换。</p>
<p>触发<code>TaskAttemptEventType.TA_SCHEDULE</code>事件类型时task attempt的状态时NEW，对应的handle为<code>RequestContainerTransition</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(TaskAttemptImpl taskAttempt, </span></span></span><br><span class="line"><span class="function"><span class="params">    TaskAttemptEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Tell any speculator that we're requesting a container</span></span><br><span class="line">  taskAttempt.eventHandler.handle</span><br><span class="line">      (<span class="keyword">new</span> SpeculatorEvent(taskAttempt.getID().getTaskId(), +<span class="number">1</span>));</span><br><span class="line">  <span class="comment">//request for container</span></span><br><span class="line">  <span class="keyword">if</span> (rescheduled) &#123;</span><br><span class="line">    taskAttempt.eventHandler.handle(</span><br><span class="line">        ContainerRequestEvent.createContainerRequestEventForFailedContainer(</span><br><span class="line">            taskAttempt.attemptId, </span><br><span class="line">            taskAttempt.resourceCapability));</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 请求资源</span></span><br><span class="line">    <span class="comment">// 请求container中包括dataLocalHosts，来自splitInfo.getLocations()</span></span><br><span class="line">    taskAttempt.eventHandler.handle(<span class="keyword">new</span> ContainerRequestEvent(</span><br><span class="line">        taskAttempt.attemptId, taskAttempt.resourceCapability,</span><br><span class="line">        taskAttempt.dataLocalHosts.toArray(</span><br><span class="line">            <span class="keyword">new</span> String[taskAttempt.dataLocalHosts.size()]),</span><br><span class="line">        taskAttempt.dataLocalRacks.toArray(</span><br><span class="line">            <span class="keyword">new</span> String[taskAttempt.dataLocalRacks.size()])));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>container的请求中包含resource大小、数据所在hosts数组和机架数组，以保证计算的本地性。</p>
<p>这里的eventHandler依然是在MRAppMaster中的异步调度器，此时触发的ContainerRequestEvent事件的类型是<code>ContainerAllocator.EventType.CONTAINER_REQ</code>，由<code>containerAllocator</code>处理，在<a href="http://bigdatadecode.club/YARNSrcMRAppMasterStart.html">上一篇</a>中containerAllocator根据mr是否为uber状态创建不同的<code>containerAllocator</code>，这里跟下非uber状态的<code>RMContainerAllocator</code>，查看RMContainerAllocator.handle代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(ContainerAllocatorEvent event)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    eventQueue.put(event);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果你从开头看到这里你会发现这也是一个事件队列eventQueue，(在Hadoop源码中这种方式被广泛使用)，同时<code>RMContainerAllocator</code>既是一个service也是一个eventHandle。<br>看下serviceStart方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceStart</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.eventHandlingThread = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">while</span> (!stopped.get() &amp;&amp; !Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          event = RMContainerAllocator.<span class="keyword">this</span>.eventQueue.take();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">          ...</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          handleEvent(event);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">          ...</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="keyword">this</span>.eventHandlingThread.start();</span><br><span class="line">  <span class="comment">// 调用父类的serviceStart，开启heartbeat线程</span></span><br><span class="line">  <span class="keyword">super</span>.serviceStart();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>serviceStart中创建了一个handle处理线程<code>eventHandlingThread</code>，此线程负责从eventQueue中取出event传给<code>handleEvent</code>方法处理。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">handleEvent</span><span class="params">(ContainerAllocatorEvent event)</span> </span>&#123;</span><br><span class="line">  recalculateReduceSchedule = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">if</span> (event.getType() == ContainerAllocator.EventType.CONTAINER_REQ) &#123;</span><br><span class="line">    ContainerRequestEvent reqEvent = (ContainerRequestEvent) event;</span><br><span class="line">    JobId jobId = getJob().getID();</span><br><span class="line">    Resource supportedMaxContainerCapability = getMaxContainerCapability();</span><br><span class="line">    <span class="keyword">if</span> (reqEvent.getAttemptID().getTaskId().getTaskType().equals(TaskType.MAP)) &#123;</span><br><span class="line">      <span class="keyword">if</span> (mapResourceRequest.equals(Resources.none())) &#123;</span><br><span class="line">        mapResourceRequest = reqEvent.getCapability();</span><br><span class="line">        eventHandler.handle(<span class="keyword">new</span> JobHistoryEvent(jobId,</span><br><span class="line">          <span class="keyword">new</span> NormalizedResourceEvent(</span><br><span class="line">            org.apache.hadoop.mapreduce.TaskType.MAP, mapResourceRequest</span><br><span class="line">              .getMemory())));</span><br><span class="line">        LOG.info(<span class="string">"mapResourceRequest:"</span> + mapResourceRequest);</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// set the resources</span></span><br><span class="line">      <span class="comment">// 对reqEvent中资源进行校验之后对其进行设置</span></span><br><span class="line">      reqEvent.getCapability().setMemory(mapResourceRequest.getMemory());</span><br><span class="line">      reqEvent.getCapability().setVirtualCores(</span><br><span class="line">        mapResourceRequest.getVirtualCores());</span><br><span class="line">      scheduledRequests.addMap(reqEvent);<span class="comment">//maps are immediately scheduled</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// reduce task</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (</span><br><span class="line">      event.getType() == ContainerAllocator.EventType.CONTAINER_DEALLOCATE) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (</span><br><span class="line">      event.getType() == ContainerAllocator.EventType.CONTAINER_FAILED) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时event的事件类型是<code>ContainerAllocator.EventType.CONTAINER_REQ</code>，在handleEvent中将map task通过<em>scheduledRequests</em>进行调度。看下<code>scheduledRequests.addMap</code>方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addMap</span><span class="params">(ContainerRequestEvent event)</span> </span>&#123;</span><br><span class="line">  ContainerRequest request = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (event.getEarlierAttemptFailed()) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 根据本地性将task attempt放入对应的mapping中</span></span><br><span class="line">    <span class="comment">// mapsHostmapping or mapsRackMapping</span></span><br><span class="line">    <span class="keyword">for</span> (String host : event.getHosts()) &#123;</span><br><span class="line">      LinkedList&lt;TaskAttemptId&gt; list = mapsHostMapping.get(host);</span><br><span class="line">      <span class="keyword">if</span> (list == <span class="keyword">null</span>) &#123;</span><br><span class="line">        list = <span class="keyword">new</span> LinkedList&lt;TaskAttemptId&gt;();</span><br><span class="line">        mapsHostMapping.put(host, list);</span><br><span class="line">      &#125;</span><br><span class="line">      list.add(event.getAttemptID());</span><br><span class="line">      ...</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">for</span> (String rack: event.getRacks()) &#123;</span><br><span class="line">     LinkedList&lt;TaskAttemptId&gt; list = mapsRackMapping.get(rack);</span><br><span class="line">     <span class="keyword">if</span> (list == <span class="keyword">null</span>) &#123;</span><br><span class="line">       list = <span class="keyword">new</span> LinkedList&lt;TaskAttemptId&gt;();</span><br><span class="line">       mapsRackMapping.put(rack, list);</span><br><span class="line">     &#125;</span><br><span class="line">     list.add(event.getAttemptID());</span><br><span class="line">     ...</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// 构建一个container request</span></span><br><span class="line">   request = <span class="keyword">new</span> ContainerRequest(event, PRIORITY_MAP);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将container request 和对应的attemptID放入maps中</span></span><br><span class="line">  maps.put(event.getAttemptID(), request);</span><br><span class="line">  <span class="comment">// 将request放入ask集合中</span></span><br><span class="line">  addContainerReq(request);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ScheduledRequests是RMContainerAllocator的一个内部类，这里调用的是<code>addMap</code>，从字面上看是将map的container request放入集合中，那么什么时候从集合<code>maps</code>中remove呢？这里先打个标记，随后再介绍。<br>接下来调用<code>addContainerReq</code>将request放入<code>ask</code>集合中，随后的心跳中会发送给RM。先看下addContainerReq代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">addContainerReq</span><span class="params">(ContainerRequest req)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Create resource requests</span></span><br><span class="line">  <span class="keyword">for</span> (String host : req.hosts) &#123;</span><br><span class="line">    <span class="comment">// Data-local</span></span><br><span class="line">    <span class="keyword">if</span> (!isNodeBlacklisted(host)) &#123;</span><br><span class="line">      addResourceRequest(req.priority, host, req.capability);</span><br><span class="line">    &#125;      </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Nothing Rack-local for now</span></span><br><span class="line">  <span class="keyword">for</span> (String rack : req.racks) &#123;</span><br><span class="line">    addResourceRequest(req.priority, rack, req.capability);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 这条是不是无论如何都会执行？？？？</span></span><br><span class="line">  <span class="comment">// Off-switch</span></span><br><span class="line">  addResourceRequest(req.priority, ResourceRequest.ANY, req.capability);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>这里有点疑惑</strong>，无论这个请求是对数据的要求是本地性还是本rack更或者是ANY，都会执行<code>addResourceRequest(req.priority, ResourceRequest.ANY, req.capability);</code>这段代码？？？？<br>addResourceRequest代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addResourceRequest</span><span class="params">(Priority priority, String resourceName,</span></span></span><br><span class="line"><span class="function"><span class="params">    Resource capability)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 通过优先级priority得到一个map，map的key/value是resourceName/map</span></span><br><span class="line">  <span class="comment">// 也就是该host上对应的request map</span></span><br><span class="line">  Map&lt;String, Map&lt;Resource, ResourceRequest&gt;&gt; remoteRequests =</span><br><span class="line">    <span class="keyword">this</span>.remoteRequestsTable.get(priority);</span><br><span class="line">  <span class="keyword">if</span> (remoteRequests == <span class="keyword">null</span>) &#123;</span><br><span class="line">    remoteRequests = <span class="keyword">new</span> HashMap&lt;String, Map&lt;Resource, ResourceRequest&gt;&gt;();</span><br><span class="line">    <span class="keyword">this</span>.remoteRequestsTable.put(priority, remoteRequests);</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 然后再通过resourceName得到该host/rack上的request map</span></span><br><span class="line">  Map&lt;Resource, ResourceRequest&gt; reqMap = remoteRequests.get(resourceName);</span><br><span class="line">  <span class="keyword">if</span> (reqMap == <span class="keyword">null</span>) &#123;</span><br><span class="line">    reqMap = <span class="keyword">new</span> HashMap&lt;Resource, ResourceRequest&gt;();</span><br><span class="line">    remoteRequests.put(resourceName, reqMap);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 最后通过资源的大小得到一个请求</span></span><br><span class="line">  ResourceRequest remoteRequest = reqMap.get(capability);</span><br><span class="line">  <span class="comment">// 如果该资源大小没有对应的request，则新建一个，注意此时container的num为0</span></span><br><span class="line">  <span class="keyword">if</span> (remoteRequest == <span class="keyword">null</span>) &#123;</span><br><span class="line">    remoteRequest = recordFactory.newRecordInstance(ResourceRequest.class);</span><br><span class="line">    remoteRequest.setPriority(priority);</span><br><span class="line">    remoteRequest.setResourceName(resourceName);</span><br><span class="line">    remoteRequest.setCapability(capability);</span><br><span class="line">    remoteRequest.setNumContainers(<span class="number">0</span>);</span><br><span class="line">    reqMap.put(capability, remoteRequest);</span><br><span class="line">  &#125;</span><br><span class="line">  remoteRequest.setNumContainers(remoteRequest.getNumContainers() + <span class="number">1</span>);</span><br><span class="line">  <span class="comment">// Note this down for next interaction with ResourceManager</span></span><br><span class="line">  addResourceRequestToAsk(remoteRequest);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>addResourceRequest的作用是将container request在remoteRequestsTable中记录，只是记录对应request的个数，然后将更新后的ResourceRequest放入ask set中。<br>调用addResourceRequestToAsk将ResourceRequest放入ask set中，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addResourceRequestToAsk</span><span class="params">(ResourceRequest remoteRequest)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// because objects inside the resource map can be deleted ask can end up </span></span><br><span class="line">  <span class="comment">// containing an object that matches new resource object but with different</span></span><br><span class="line">  <span class="comment">// numContainers. So exisintg values must be replaced explicitly</span></span><br><span class="line">  <span class="keyword">if</span>(ask.contains(remoteRequest)) &#123;</span><br><span class="line">    ask.remove(remoteRequest);</span><br><span class="line">  &#125;</span><br><span class="line">  ask.add(remoteRequest);    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到这里看似代码到此断了，实则不然，上文中提到<code>RMContainerAllocator</code>既是一个service也是一个eventHandle，那么它作为服务时，会有哪些功能呢？</p>
<h2 id="承上启下"><a href="#承上启下" class="headerlink" title="承上启下"></a>承上启下</h2><p>本篇从job的状态由INITED变为SETUP之后，又经过一些事件触发使job变为RUNNING状态，开始创建task，并创建container request，将request放入ask中。<br>接下来就是AM中的RMContainerAllocator服务与RM保持心跳，在下次心跳时向RM申请资源，这部分在下一篇介绍。</p>
<!--
这里将remoteRequest放入ask中，remoteRequest中记录了priority resourceName capability container'num，则在host上一次分配多个container？
这个container没有与attemptID关联？？
-->]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> MRAppMaster </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之MRAppMaster启动]]></title>
      <url>http://bigdatadecode.club/YARNSrcMRAppMasterStart.html</url>
      <content type="html"><![CDATA[<p>由<a href="http://bigdatadecode.club/YARNSrcApplicationMasterStart.html">YARN源码分析之ApplicationMaster启动流程</a>中得知MR的AppMaster是由MRAppMaster启动的，在脚本中调用了AppMaster的main方法。</p>
<p>本文就顺着代码来对MRAppMaster进行解析下。</p>
<a id="more"></a>
<p>先来看下该类的main方法，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// Environment中的环境变量是在launch_container.sh中export的</span></span><br><span class="line">    String containerIdStr =</span><br><span class="line">        System.getenv(Environment.CONTAINER_ID.name());</span><br><span class="line">    String nodeHostString = System.getenv(Environment.NM_HOST.name());</span><br><span class="line">    String nodePortString = System.getenv(Environment.NM_PORT.name());</span><br><span class="line">    String nodeHttpPortString =</span><br><span class="line">        System.getenv(Environment.NM_HTTP_PORT.name());</span><br><span class="line">    String appSubmitTimeStr =</span><br><span class="line">        System.getenv(ApplicationConstants.APP_SUBMIT_TIME_ENV);</span><br><span class="line">    ...    </span><br><span class="line">    <span class="comment">// 一个MR对应一个MRAppMater对象</span></span><br><span class="line">    MRAppMaster appMaster =</span><br><span class="line">        <span class="keyword">new</span> MRAppMaster(applicationAttemptId, containerId, nodeHostString,</span><br><span class="line">            Integer.parseInt(nodePortString),</span><br><span class="line">            Integer.parseInt(nodeHttpPortString), appSubmitTime);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 初始化并启动appMaster</span></span><br><span class="line">    initAndStartAppMaster(appMaster, conf, jobUserName);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    LOG.fatal(<span class="string">"Error starting MRAppMaster"</span>, t);</span><br><span class="line">    ExitUtil.terminate(<span class="number">1</span>, t);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MRAppMaster首先从环境变量中获取相关的信息，然后调用<code>initAndStartAppMaster</code>开启AppMaster服务。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">initAndStartAppMaster</span><span class="params">(<span class="keyword">final</span> MRAppMaster appMaster,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> JobConf conf, String jobUserName)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">    InterruptedException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  appMasterUgi.doAs(<span class="keyword">new</span> PrivilegedExceptionAction&lt;Object&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">      appMaster.init(conf);</span><br><span class="line">      appMaster.start();</span><br><span class="line">      <span class="keyword">if</span>(appMaster.errorHappenedShutDown) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Was asked to shut down."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MRAppMaster继承了CompositeService，则调用init进行服务初始化，start启动服务。而init又调用<code>MRAppMaster.serviceInit</code>对appMaster进行初始化，调用<code>MRAppMaster.serviceStart</code>启动AppMaster服务。</p>
<h2 id="MRAppMaster初始化"><a href="#MRAppMaster初始化" class="headerlink" title="MRAppMaster初始化"></a>MRAppMaster初始化</h2><p>先看下AppMaster的初始化。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceInit</span><span class="params">(<span class="keyword">final</span> Configuration conf)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ...  </span><br><span class="line">  <span class="comment">// 判断一些目录是否存在</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    String user = UserGroupInformation.getCurrentUser().getShortUserName();</span><br><span class="line">    <span class="comment">// 目录为 /tmp/hadoop-yarn/staging/user/.staging</span></span><br><span class="line">    Path stagingDir = MRApps.getStagingAreaDir(conf, user);</span><br><span class="line">    FileSystem fs = getFileSystem(conf);</span><br><span class="line">    <span class="keyword">boolean</span> stagingExists = fs.exists(stagingDir);</span><br><span class="line">    <span class="comment">// 目录为 /tmp/hadoop-yarn/staging/user/.staging/jobId/COMMIT_STARTED</span></span><br><span class="line">    Path startCommitFile = MRApps.getStartJobCommitFile(conf, user, jobId);</span><br><span class="line">    <span class="keyword">boolean</span> commitStarted = fs.exists(startCommitFile);</span><br><span class="line">    <span class="comment">// 目录为 /tmp/hadoop-yarn/staging/user/.staging/jobId/COMMIT_SUCCESS</span></span><br><span class="line">    Path endCommitSuccessFile = MRApps.getEndJobCommitSuccessFile(conf, user, jobId);</span><br><span class="line">    <span class="keyword">boolean</span> commitSuccess = fs.exists(endCommitSuccessFile);</span><br><span class="line">    <span class="comment">// 目录为 /tmp/hadoop-yarn/staging/user/.staging/jobId/COMMIT_FAIL</span></span><br><span class="line">    Path endCommitFailureFile = MRApps.getEndJobCommitFailureFile(conf, user, jobId);</span><br><span class="line">    <span class="keyword">boolean</span> commitFailure = fs.exists(endCommitFailureFile);</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(<span class="string">"Error while initializing"</span>, e);</span><br><span class="line">  &#125;  </span><br><span class="line">  <span class="keyword">if</span> (errorHappenedShutDown) &#123;</span><br><span class="line">    <span class="comment">// 发生error的处理逻辑</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  	<span class="comment">// 创建MR依赖的OutputCommitter</span></span><br><span class="line">    committer = createOutputCommitter(conf);</span><br><span class="line">    <span class="comment">// 为MRAppMaster服务创建异步调度器服务</span></span><br><span class="line">    dispatcher = createDispatcher();</span><br><span class="line">    addIfService(dispatcher);</span><br><span class="line">    <span class="comment">//service to handle requests from JobClient</span></span><br><span class="line">    <span class="comment">// 创建MRClientService</span></span><br><span class="line">    clientService = createClientService(context);</span><br><span class="line">    <span class="comment">// Init ClientService separately so that we stop it separately, since this</span></span><br><span class="line">    <span class="comment">// service needs to wait some time before it stops so clients can know the</span></span><br><span class="line">    <span class="comment">// final states</span></span><br><span class="line">    clientService.init(conf);</span><br><span class="line">    <span class="comment">// 根据mr的运行方式创建不同的container分配router</span></span><br><span class="line">    <span class="comment">// 调度各个状态 流程 ？？？？？？？？？##########################？？？？？？？？？？</span></span><br><span class="line">    <span class="comment">// 请求的流程，分配的container是rm已经分配到am上的资源？？？主动分配的？在哪申请</span></span><br><span class="line">    containerAllocator = createContainerAllocator(clientService, context);</span><br><span class="line">    <span class="comment">//service to handle the output committer</span></span><br><span class="line">    committerEventHandler = createCommitterEventHandler(context, committer);</span><br><span class="line">    addIfService(committerEventHandler);</span><br><span class="line">    <span class="comment">//service to handle requests to TaskUmbilicalProtocol</span></span><br><span class="line">    <span class="comment">// 主要负责启动task 使用TaskUmbilicalProtocol协议</span></span><br><span class="line">    taskAttemptListener = createTaskAttemptListener(context);</span><br><span class="line">    addIfService(taskAttemptListener);</span><br><span class="line">    <span class="comment">//service to log job history events</span></span><br><span class="line">    EventHandler&lt;JobHistoryEvent&gt; historyService = </span><br><span class="line">      createJobHistoryHandler(context);</span><br><span class="line">    dispatcher.register(org.apache.hadoop.mapreduce.jobhistory.EventType.class,</span><br><span class="line">        historyService);</span><br><span class="line">    <span class="keyword">this</span>.jobEventDispatcher = <span class="keyword">new</span> JobEventDispatcher();</span><br><span class="line">    <span class="comment">//register the event dispatchers</span></span><br><span class="line">    dispatcher.register(JobEventType.class, jobEventDispatcher);</span><br><span class="line">    dispatcher.register(TaskEventType.class, <span class="keyword">new</span> TaskEventDispatcher());</span><br><span class="line">    dispatcher.register(TaskAttemptEventType.class, </span><br><span class="line">        <span class="keyword">new</span> TaskAttemptEventDispatcher());</span><br><span class="line">    dispatcher.register(CommitterEventType.class, committerEventHandler);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// Now that there's a FINISHING state for application on RM to give AMs</span></span><br><span class="line">    <span class="comment">// plenty of time to clean up after unregister it's safe to clean staging</span></span><br><span class="line">    <span class="comment">// directory after unregistering with RM. So, we start the staging-dir</span></span><br><span class="line">    <span class="comment">// cleaner BEFORE the ContainerAllocator so that on shut-down,</span></span><br><span class="line">    <span class="comment">// ContainerAllocator unregisters first and then the staging-dir cleaner</span></span><br><span class="line">    <span class="comment">// deletes staging directory.</span></span><br><span class="line">    <span class="comment">// 开启清理服务</span></span><br><span class="line">    <span class="comment">// 与OutputCommitter的区别</span></span><br><span class="line">    addService(createStagingDirCleaningService());</span><br><span class="line">    <span class="comment">// service to allocate containers from RM (if non-uber) or to fake it (uber)</span></span><br><span class="line">    addIfService(containerAllocator);</span><br><span class="line">    dispatcher.register(ContainerAllocator.EventType.class, containerAllocator);</span><br><span class="line">    <span class="comment">// corresponding service to launch allocated containers via NodeManager</span></span><br><span class="line">    containerLauncher = createContainerLauncher(context);</span><br><span class="line">    addIfService(containerLauncher);</span><br><span class="line">    dispatcher.register(ContainerLauncher.EventType.class, containerLauncher);</span><br><span class="line">    <span class="comment">// Add the JobHistoryEventHandler last so that it is properly stopped first.</span></span><br><span class="line">    <span class="comment">// This will guarantee that all history-events are flushed before AM goes</span></span><br><span class="line">    <span class="comment">// ahead with shutdown.</span></span><br><span class="line">    <span class="comment">// Note: Even though JobHistoryEventHandler is started last, if any</span></span><br><span class="line">    <span class="comment">// component creates a JobHistoryEvent in the meanwhile, it will be just be</span></span><br><span class="line">    <span class="comment">// queued inside the JobHistoryEventHandler</span></span><br><span class="line">    <span class="comment">// 可见服务的启动顺序是先进后出</span></span><br><span class="line">    addIfService(historyService);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">super</span>.serviceInit(conf);</span><br><span class="line">&#125; <span class="comment">// end of init()</span></span><br></pre></td></tr></table></figure>
<p>如果一切正常会进入最后一个<code>if</code> <code>else</code>语句块的else中进行AM的初始化。来看下初始化中都包括哪些服务。</p>
<blockquote>
<p>先创建<code>OutputCommitter</code>对象，这是一个抽象类，实现类有FileOutputCommitter。随后用与构建<code>CommitterEventHandler</code>服务，并将此服务加入AppMaster服务中。<br>OutputCommitter的作用有</p>
</blockquote>
<ol>
<li>job初始化时进行一些准备工作，比如为job创建临时输出目录</li>
<li>job完成时进行一些扫尾工作，比如当job完成之后删除临时输出目录</li>
<li>为task准备临时输出目录</li>
<li>检查task是否需要commit</li>
<li>commit task输出目录</li>
<li>放弃task commit</li>
</ol>
<blockquote>
<p>创建异步调度器dispatcher。主要用于事件的调度，是yarn框架中一个重要的概念。</p>
</blockquote>
<blockquote>
<p>创建MRClientService对象clientService，MRClientService主要用于client与am进行通信，需要对其进行单独的初始化和停止。</p>
</blockquote>
<blockquote>
<p>创建TaskAttemptListenerImpl服务，主要用与和task的通行。</p>
</blockquote>
<blockquote>
<p>创建StagingDirCleaningService服务，用于删除临时目录。此服务要在containerAllocator服务之前添加，因为container注销之后才能清楚该container的临时目录。======那和outputCommitter有什么区别呢？？？？</p>
</blockquote>
<blockquote>
<p>创建ContainerAllocatorRouter服务，用与分配container。根据MR是否为Uber类型创建不同的分配策略，如果是Uber则创建<code>LocalContainerAllocator</code>，否则创建<code>RMContainerAllocator</code></p>
</blockquote>
<blockquote>
<p>创建JobHistoryEventHandler服务，这个服务是最后添加的，要保证此服务先停止。</p>
</blockquote>
<p>初始化不只是添加一些服务还会向异步调度器中注册一些事件处理器，包括jobhistory.EventType、JobEventType、TaskEventType、TaskAttemptEventType、CommitterEventType、ContainerAllocator.EventType和ContainerLauncher.EventType。</p>
<h2 id="MRAppMaster启动"><a href="#MRAppMaster启动" class="headerlink" title="MRAppMaster启动"></a>MRAppMaster启动</h2><p>初始化之后，调用<code>serviceStart</code>启动服务，看下都启动了什么服务</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceStart</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// /////////////////// Create the job itself.</span></span><br><span class="line">  <span class="comment">// 开启job的状态机 JobImpl NEW</span></span><br><span class="line">  job = createJob(getConfig(), forcedState, shutDownMessage);</span><br><span class="line">  <span class="comment">// job创建成功之后，向jobHistory发送EventType.AM_STARTED事件类型，</span></span><br><span class="line">  <span class="comment">// 但是为什么会有amInfos，amInfos用来干啥？</span></span><br><span class="line">  <span class="keyword">for</span> (AMInfo info : amInfos) &#123;</span><br><span class="line">    dispatcher.getEventHandler().handle(</span><br><span class="line">        <span class="keyword">new</span> JobHistoryEvent(job.getID(), <span class="keyword">new</span> AMStartedEvent(info</span><br><span class="line">            .getAppAttemptId(), info.getStartTime(), info.getContainerId(),</span><br><span class="line">            info.getNodeManagerHost(), info.getNodeManagerPort(), info</span><br><span class="line">                .getNodeManagerHttpPort())));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Send out an MR AM inited event for this AM.</span></span><br><span class="line">  dispatcher.getEventHandler().handle(</span><br><span class="line">      <span class="keyword">new</span> JobHistoryEvent(job.getID(), <span class="keyword">new</span> AMStartedEvent(amInfo</span><br><span class="line">          .getAppAttemptId(), amInfo.getStartTime(), amInfo.getContainerId(),</span><br><span class="line">          amInfo.getNodeManagerHost(), amInfo.getNodeManagerPort(), amInfo</span><br><span class="line">              .getNodeManagerHttpPort(), <span class="keyword">this</span>.forcedState == <span class="keyword">null</span> ? <span class="keyword">null</span></span><br><span class="line">                  : <span class="keyword">this</span>.forcedState.toString())));</span><br><span class="line">  amInfos.add(amInfo);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// metrics system init is really init &amp; start.</span></span><br><span class="line">  <span class="comment">// It's more test friendly to put it here.</span></span><br><span class="line">  DefaultMetricsSystem.initialize(<span class="string">"MRAppMaster"</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">boolean</span> initFailed = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">if</span> (!errorHappenedShutDown) &#123;</span><br><span class="line">    <span class="comment">// create a job event for job intialization</span></span><br><span class="line">    <span class="comment">// job init  job从NEW变为INITED</span></span><br><span class="line">    JobEvent initJobEvent = <span class="keyword">new</span> JobEvent(job.getID(), JobEventType.JOB_INIT);</span><br><span class="line">    <span class="comment">// Send init to the job (this does NOT trigger job execution)</span></span><br><span class="line">    <span class="comment">// This is a synchronous call, not an event through dispatcher. We want</span></span><br><span class="line">    <span class="comment">// job-init to be done completely here.</span></span><br><span class="line">    <span class="comment">// 注意注释的内容，与dispatcher的区别</span></span><br><span class="line">    jobEventDispatcher.handle(initJobEvent);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If job is still not initialized, an error happened during</span></span><br><span class="line">    <span class="comment">// initialization. Must complete starting all of the services so failure</span></span><br><span class="line">    <span class="comment">// events can be processed.</span></span><br><span class="line">    initFailed = (((JobImpl)job).getInternalState() != JobStateInternal.INITED);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// Start ClientService here, since it's not initialized if</span></span><br><span class="line">    <span class="comment">// errorHappenedShutDown is true</span></span><br><span class="line">    clientService.start();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//start all the components</span></span><br><span class="line">  <span class="keyword">super</span>.serviceStart();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// finally set the job classloader</span></span><br><span class="line">  MRApps.setClassLoader(jobClassLoader, getConfig());</span><br><span class="line">  <span class="comment">// 如果job INITED失败，则job的状态为JOB_INIT_FAILED</span></span><br><span class="line">  <span class="keyword">if</span> (initFailed) &#123;</span><br><span class="line">    JobEvent initFailedEvent = <span class="keyword">new</span> JobEvent(job.getID(), JobEventType.JOB_INIT_FAILED);</span><br><span class="line">    jobEventDispatcher.handle(initFailedEvent);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// All components have started, start the job.</span></span><br><span class="line">    startJobs();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在启动MRAppMaster所有服务之前</p>
<ol>
<li>先调用<code>createJob</code>创建job，job是JobImpl对象。job的创建开启了job的状态机旅程，初始的状态是<em>NEW</em>。在createJob中还会向异步调度器注册JobFinishEvent事件类型。</li>
<li>触发job的JOB_INIT并交给事件处理器JobEventDispatcher进行处理，<strong>此时是同步的，等待job init的结果</strong>。</li>
<li>在启动MRAppMaster中服务之前要先启动clientService，然后启动所有的服务</li>
<li>如果job从NEW转化为INITED时发生了故障，则置<code>initFailed</code>为true，向JobEventDispatcher发送JobEventType.JOB_INIT_FAILED事件类型</li>
<li>一切正常之后调用<code>startJobs()</code></li>
</ol>
<p>针对上述流程我们看下具体代码，</p>
<p>serviceStart时先调用createJob创建一个job，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Job <span class="title">createJob</span><span class="params">(Configuration conf, JobStateInternal forcedState, </span></span></span><br><span class="line"><span class="function"><span class="params">    String diagnostic)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// new 出job对象，开启job状态机(初始化job的状态时NEW)</span></span><br><span class="line">  <span class="comment">// create single job</span></span><br><span class="line">  Job newJob =</span><br><span class="line">      <span class="keyword">new</span> JobImpl(jobId, appAttemptID, conf, dispatcher.getEventHandler(),</span><br><span class="line">          taskAttemptListener, jobTokenSecretManager, jobCredentials, clock,</span><br><span class="line">          completedTasksFromPreviousRun, metrics,</span><br><span class="line">          committer, newApiCommitter,</span><br><span class="line">          currentUser.getUserName(), appSubmitTime, amInfos, context, </span><br><span class="line">          forcedState, diagnostic);</span><br><span class="line">  ((RunningAppContext) context).jobs.put(newJob.getID(), newJob);</span><br><span class="line">  <span class="comment">// 开始job的状态之后，向异步调度器注册JobFinishEvent事件类型的handler</span></span><br><span class="line">  dispatcher.register(JobFinishEvent.Type.class,</span><br><span class="line">      createJobFinishEventHandler());     </span><br><span class="line">  <span class="keyword">return</span> newJob;</span><br><span class="line">&#125; <span class="comment">// end createJob()</span></span><br></pre></td></tr></table></figure>
<p>createJob的时候用到一个属性<code>amInfos</code>，amInfos是一个list，在serviceStart时实例化。</p>
<blockquote>
<p>在createJob之后，会将amInfos中的amInfo构建一个EventType.AM_STARTED事件类型的JobHistoryEvent事件，这里有些疑问，一个mr会有多个amInfo？而且不是因为重试？？？</p>
</blockquote>
<p>如果期间没有发生error，则触发JobEventType.JOB_INIT事件类型，由<code>jobEventDispatcher.handle(initJobEvent)</code>处理，最终调用的是JobImpl.handle交由状态机进行处理，job原先状态是NEW，则JobEventType.JOB_INIT的处理类是<code>InitTransition</code>，逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> JobStateInternal <span class="title">transition</span><span class="params">(JobImpl job, JobEvent event)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 创建job context</span></span><br><span class="line">  <span class="keyword">if</span> (job.newApiCommitter) &#123;</span><br><span class="line">    job.jobContext = <span class="keyword">new</span> JobContextImpl(job.conf,</span><br><span class="line">        job.oldJobId);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    job.jobContext = <span class="keyword">new</span> org.apache.hadoop.mapred.JobContextImpl(</span><br><span class="line">        job.conf, job.oldJobId);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    setup(job);</span><br><span class="line">    job.fs = job.getFileSystem(job.conf);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//log to job history</span></span><br><span class="line">    <span class="comment">// EventType.JOB_SUBMITTED</span></span><br><span class="line">    JobSubmittedEvent jse = <span class="keyword">new</span> JobSubmittedEvent(job.oldJobId,</span><br><span class="line">          job.conf.get(MRJobConfig.JOB_NAME, <span class="string">"test"</span>), </span><br><span class="line">        job.conf.get(MRJobConfig.USER_NAME, <span class="string">"mapred"</span>),</span><br><span class="line">        job.appSubmitTime,</span><br><span class="line">        job.remoteJobConfFile.toString(),</span><br><span class="line">        job.jobACLs, job.queueName,</span><br><span class="line">        job.conf.get(MRJobConfig.WORKFLOW_ID, <span class="string">""</span>),</span><br><span class="line">        job.conf.get(MRJobConfig.WORKFLOW_NAME, <span class="string">""</span>),</span><br><span class="line">        job.conf.get(MRJobConfig.WORKFLOW_NODE_NAME, <span class="string">""</span>),</span><br><span class="line">        getWorkflowAdjacencies(job.conf),</span><br><span class="line">        job.conf.get(MRJobConfig.WORKFLOW_TAGS, <span class="string">""</span>));</span><br><span class="line">    job.eventHandler.handle(<span class="keyword">new</span> JobHistoryEvent(job.jobId, jse));</span><br><span class="line">    <span class="comment">//TODO JH Verify jobACLs, UserName via UGI?</span></span><br><span class="line">    <span class="comment">// 根据在JobSubmitter.submitJobInternal中划分的文件来切分task</span></span><br><span class="line">    <span class="comment">// 读取文件切分元信息</span></span><br><span class="line">    TaskSplitMetaInfo[] taskSplitMetaInfo = createSplits(job, job.jobId);</span><br><span class="line">    job.numMapTasks = taskSplitMetaInfo.length;</span><br><span class="line">    job.numReduceTasks = job.conf.getInt(MRJobConfig.NUM_REDUCES, <span class="number">0</span>);</span><br><span class="line">    <span class="comment">// mapWeight 和 reduceWeight 用来计算mr的进度</span></span><br><span class="line">    <span class="keyword">if</span> (job.numMapTasks == <span class="number">0</span> &amp;&amp; job.numReduceTasks == <span class="number">0</span>) &#123;</span><br><span class="line">      job.addDiagnostic(<span class="string">"No of maps and reduces are 0 "</span> + job.jobId);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (job.numMapTasks == <span class="number">0</span>) &#123;</span><br><span class="line">      job.reduceWeight = <span class="number">0.9f</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (job.numReduceTasks == <span class="number">0</span>) &#123;</span><br><span class="line">      job.mapWeight = <span class="number">0.9f</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      job.mapWeight = job.reduceWeight = <span class="number">0.45f</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">long</span> inputLength = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; job.numMapTasks; ++i) &#123;</span><br><span class="line">      inputLength += taskSplitMetaInfo[i].getInputDataLength();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 判断该job是否可以在uber模式下运行</span></span><br><span class="line">    job.makeUberDecision(inputLength);</span><br><span class="line">    </span><br><span class="line">    job.taskAttemptCompletionEvents =</span><br><span class="line">        <span class="keyword">new</span> ArrayList&lt;TaskAttemptCompletionEvent&gt;(</span><br><span class="line">            job.numMapTasks + job.numReduceTasks + <span class="number">10</span>);</span><br><span class="line">    job.mapAttemptCompletionEvents =</span><br><span class="line">        <span class="keyword">new</span> ArrayList&lt;TaskCompletionEvent&gt;(job.numMapTasks + <span class="number">10</span>);</span><br><span class="line">    job.taskCompletionIdxToMapCompletionIdx = <span class="keyword">new</span> ArrayList&lt;Integer&gt;(</span><br><span class="line">        job.numMapTasks + job.numReduceTasks + <span class="number">10</span>);</span><br><span class="line">    <span class="comment">// 这里错误率，是指可以容忍一些map失败，而mr忽略这些失败的task，继续正常执行？？？？</span></span><br><span class="line">    job.allowedMapFailuresPercent =</span><br><span class="line">        job.conf.getInt(MRJobConfig.MAP_FAILURES_MAX_PERCENT, <span class="number">0</span>);</span><br><span class="line">    job.allowedReduceFailuresPercent =</span><br><span class="line">        job.conf.getInt(MRJobConfig.REDUCE_FAILURES_MAXPERCENT, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// create the Tasks but don't start them yet</span></span><br><span class="line">    <span class="comment">// 创建map reduce task对象</span></span><br><span class="line">    createMapTasks(job, inputLength, taskSplitMetaInfo);</span><br><span class="line">    createReduceTasks(job);</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> JobStateInternal.INITED;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// Leave job in the NEW state. The MR AM will detect that the state is</span></span><br><span class="line">    <span class="comment">// not INITED and send a JOB_INIT_FAILED event.</span></span><br><span class="line">    <span class="keyword">return</span> JobStateInternal.NEW;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>job init的时候会根据文件split的元数据信息创建map和reduce task，此时并没有启动这些task</em>。</p>
<p>initJob执行结束之后，返回给serviceStart目前job的状态，成功返回INITED，然后继续执行，启动在serviceInit中添加的service，然后执行startJob</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">startJobs</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">/** create a job-start event to get this ball rolling */</span></span><br><span class="line">  JobEvent startJobEvent = <span class="keyword">new</span> JobStartEvent(job.getID(),</span><br><span class="line">      recoveredJobStartTime);</span><br><span class="line">  <span class="comment">/** send the job-start event. this triggers the job execution. */</span></span><br><span class="line">  <span class="comment">// 触发job execution</span></span><br><span class="line">  dispatcher.getEventHandler().handle(startJobEvent);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>startJobs主要是创建一个<code>JobEventType.JOB_START</code>事件类型，由JobImpl的状态机进行处理。<br>startJobs之前job的状态为INITED，则由<code>StartTransition</code>进行处理，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * This transition executes in the event-dispatcher thread, though it's</span></span><br><span class="line"><span class="comment"> * triggered in MRAppMaster's startJobs() method.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(JobImpl job, JobEvent event)</span> </span>&#123;</span><br><span class="line">  JobStartEvent jse = (JobStartEvent) event;</span><br><span class="line">  <span class="keyword">if</span> (jse.getRecoveredJobStartTime() != <span class="number">0</span>) &#123;</span><br><span class="line">    job.startTime = jse.getRecoveredJobStartTime();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    job.startTime = job.clock.getTime();</span><br><span class="line">  &#125;</span><br><span class="line">  JobInitedEvent jie =</span><br><span class="line">    <span class="keyword">new</span> JobInitedEvent(job.oldJobId,</span><br><span class="line">         job.startTime,</span><br><span class="line">         job.numMapTasks, job.numReduceTasks,</span><br><span class="line">         job.getState().toString(),</span><br><span class="line">         job.isUber());</span><br><span class="line">  job.eventHandler.handle(<span class="keyword">new</span> JobHistoryEvent(job.jobId, jie));</span><br><span class="line">  JobInfoChangeEvent jice = <span class="keyword">new</span> JobInfoChangeEvent(job.oldJobId,</span><br><span class="line">      job.appSubmitTime, job.startTime);</span><br><span class="line">  job.eventHandler.handle(<span class="keyword">new</span> JobHistoryEvent(job.jobId, jice));</span><br><span class="line">  job.metrics.runningJob(job);</span><br><span class="line">  <span class="comment">// CommitterEventHandler.handle CommitterEventType.JOB_SETUP</span></span><br><span class="line">  job.eventHandler.handle(<span class="keyword">new</span> CommitterJobSetupEvent(</span><br><span class="line">          job.jobId, job.jobContext));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>serviceStart</code>跳用<code>startJobs</code>之后，就完成了job的启动，MRAppMaster也启动完毕，触发job execution，使job之后会在另一个线程中进行状态机的转换，随后就是MRAppMaster中的各个服务来配合job来进行工作。</p>
<p>在StartTransition中，创建<code>CommitterEventType.JOB_SETUP</code>事件类型，由<code>CommitterEventHandler.handle</code>处理，进行job的准备工作。</p>
<p>最后这里需要注意下<code>StartTransition</code>上的注释，说StartTransition.transition是在<strong>事件异步调度器</strong>线程中执行的，也就是说现在job以后的流程已经和MRAppMaster分离了。<br>MRAppMaster在startJobs中异步调用<code>dispatcher.getEventHandler().handle(startJobEvent)</code>，然后返回到serviceStart，此时MRAppMaster启动成功，之后就是以服务的形态存活。</p>
<p>下一篇接着介绍job在接收到<code>JobEventType.JOB_START</code>事件类型之后由INITED状态变为SETUP之后的流程。</p>
<blockquote>
<p>本篇只介绍了MRAppMaster的启动过程，并没有把MRAppMaster在MR执行过程的作用介绍完整，随后几篇我会顺着MR的执行流程来介绍MRAppMaster的具体作用。</p>
</blockquote>
<!--
删除临时文件到底在哪？
LOG.info("Deleting staging directory " + FileSystem.getDefaultUri(getConfig()) +
            " " + jobTempDir);
-->]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> MRAppMaster </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS之Cannot obtain block length for LocatedBlock异常]]></title>
      <url>http://bigdatadecode.club/HDFSCannotObtainBlockLengthForLocatedBlock.html</url>
      <content type="html"><![CDATA[<p>昨天公司集群升级，采集平台的flume agent没有停，导致一些文件异常，无法读，也无法使用cp或者get命令，报<code>Cannot obtain block length for LocatedBlock</code>。</p>
<a id="more"></a>
<p>首先使用fsck来检查下该文件，命令<code>hdfs fsck file_path -files -blocks -locations</code>，提示如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Status: HEALTHY</span><br><span class="line"> Total size: 	0 B (Total open files size: 18935B)</span><br></pre></td></tr></table></figure>
<p>现实文件依然是打开的，使用命令<code>hadoop fsck file_path -openforwrite</code>查看目录下打开的文件，显示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">17</span>/<span class="number">08</span>/<span class="number">03</span> <span class="number">15</span>:<span class="number">21</span>:<span class="number">50</span> WARN ssl.FileBasedKeyStoresFactory: The property <span class="string">'ssl.client.truststore.location'</span> has not been set, no TrustStore will be loaded</span><br><span class="line">Connecting to namenode via http:<span class="comment">//namenode:50070</span></span><br><span class="line"><span class="function">FSCK started by <span class="title">portal</span> <span class="params">(auth:KERBEROS_SSL)</span> from /10.160.xx.22 <span class="keyword">for</span> path file_path at Thu Aug 03 15:21:51 CST 2017</span></span><br><span class="line"><span class="function">............/file_path/xx.1501646609139.lzo.tmp 827 bytes, 1 <span class="title">block</span><span class="params">(s)</span>, OPENFORWRITE: ......................./file_path/xx.1501650099752.lzo 333 bytes, 1 <span class="title">block</span><span class="params">(s)</span>, OPENFORWRITE:</span></span><br><span class="line"><span class="function">/file_path/xx.1501650099752.lzo: MISSING 1 blocks of total size 333 B........................Status: CORRUPT</span></span><br></pre></td></tr></table></figure>
<p>显示<code>OPENFORWRITE</code>，也有<code>MISSING</code>信息，推断应该是文件没有close成功。</p>
<p>之所以没有关成功，通过看flume的log发现集群是safemode状态，无法close成功，flume catch住异常之后只是抛出了个WARN，设置<code>failedToClose</code>为true，然后继续执行代码进行rename操作，rename操作没有成功被放到一个线程中不断的去尝试rename，等集群恢复之后，rename成功了。</p>
<p>下面就是怎么恢复文件，文件是打开状态是因为namenode依然记录这该文件的租约，该租约没有被关闭，使用appendToFile命令检验下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这个命令执行之后，允许在窗体中输入字符串，Ctrl + C退出stdin，此后stdin数据将会追加到hdfs文件中。</span></span><br><span class="line">$ hadoop dfs -appendToFile - /file_path/<span class="number">341</span>.lzo</span><br><span class="line">DEPRECATED: Use of <span class="keyword">this</span> script to execute hdfs command is deprecated.</span><br><span class="line">Instead use the hdfs command <span class="keyword">for</span> it.</span><br><span class="line"></span><br><span class="line">appendToFile: Failed to APPEND_FILE /file_path/<span class="number">341</span>.lzo <span class="keyword">for</span> DFSClient_NONMAPREDUCE_-<span class="number">1675067591_1</span> on <span class="number">10.120</span>.233.47 because <span class="keyword">this</span> file lease is currently owned by DFSClient_NONMAPREDUCE_-<span class="number">1514310687_13</span> on <span class="number">10.200</span>.128.130</span><br></pre></td></tr></table></figure>
<p>租约冲突了，确认租约没有关闭。</p>
<p>在hdfs官网上查看hdfs有恢复租约的命令，<code>hdfs debug recoverLease -path</code>，但是在2.7版本以后才有，昨天集群升级到了2.7.3，但是坑的是客户端没有升级依然是老版的，没有这个命令。<br>(让Hadoop运维给执行下debug命令居然让我把损坏的文件删掉。。。)只好自己装个2.7.3的客户端了，然后执行recoverLease命令之后，文件恢复正常。</p>
<p>批量处理命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fsck /file_path -openforwrite | egrep -v <span class="string">'^\.+$'</span> | egrep <span class="string">"MISSING|OPENFORWRITE"</span> | grep -o <span class="string">"/[^ ]*"</span> | sed -e <span class="string">"s/:$//"</span> | xargs -i hdfs debug recoverLease -path &#123;&#125;</span><br></pre></td></tr></table></figure></p>
<p>为什么会出现租约没有关闭这个很奇怪，HDFS是有租约恢复机制的，但为什么没有关成功有点遗憾，之前分析的HDFS租约机制有些细节不太记得了，有时间在review下。<br><!-- flume close失败之后，将此path从map中移除，就不在操作此文件了，也就不会触发此文件的租约，hdfs并没有因为timeout而关闭租约，为什么没有timeout？？？--></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> Lease </tag>
            
            <tag> LocatedBlock异常 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[利用canal同步mysql到HDFS]]></title>
      <url>http://bigdatadecode.club/MysqlToHDFSWithCanal.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/实时抓取MySQL的更新数据到Hadoop.html">之前有一篇</a>介绍性的文章简单介绍了实时同步mysql到hdfs的几种方案，本篇主要记录下利用canal同步mysql到hdfs的具体方案。</p>
<a id="more"></a>
<h2 id="canal-server-部署"><a href="#canal-server-部署" class="headerlink" title="canal server 部署"></a>canal server 部署</h2><p>在canal中一个mysql实例对应一个配置文件，配置文件放在conf目录下的一个文件夹中，该文件夹的名字就代表了mysql实例。结构如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-rwxr-xr-x 1 dc user 2645 Jul 18 14:25 canal.properties</span><br><span class="line">-rwxr-xr-x 1 dc user 2521 Jul 17 18:31 canal.properties.bak</span><br><span class="line">-rwxr-xr-x 1 dc user 3045 Jul 17 18:31 logback.xml</span><br><span class="line">drwxr-xr-x 2 dc user 4096 Jul 17 18:38 spring</span><br><span class="line">drwxr-xr-x 2 dc user 4096 Jul 19 11:55 trans1</span><br></pre></td></tr></table></figure>
<p>trans1代表一个mysql实例，该文件夹中有个instance.properties文件，在里面配置mysql数据库的信息</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## mysql serverId 部署ha的话，slaveId不能重复</span></span><br><span class="line">canal.instance.mysql.slaveId = 1235</span><br><span class="line">canal.instance.master.address = 10.172.152.66:3306</span><br><span class="line"><span class="comment"># username/password</span></span><br><span class="line">canal.instance.dbUsername = root</span><br><span class="line">canal.instance.dbPassword = root</span><br><span class="line"><span class="comment"># 采集表的正则</span></span><br><span class="line">canal.instance.filter.regex = .*\\..*</span><br></pre></td></tr></table></figure>
<h3 id="canal-server-HA部署"><a href="#canal-server-HA部署" class="headerlink" title="canal server HA部署"></a>canal server HA部署</h3><p>采用canal的HA模式，canal的HA是依赖zk来实现的。<br>修改配置文件，配置文件是conf目录下大canal.properties</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># common argument</span></span><br><span class="line">canal.id= 1             <span class="comment"># 另一台 canal.id= 2</span></span><br><span class="line">canal.ip= 10.172.152.66 <span class="comment"># 另一台 canal.ip= 10.172.152.124</span></span><br><span class="line">canal.port= 11111</span><br><span class="line">canal.zkServers= 10.172.152.66:2181,10.172.152.124:2181,10.172.152.125:2181</span><br><span class="line"><span class="comment"># conf目录下mysql实例的文件名</span></span><br><span class="line">canal.destinations= trans1</span><br><span class="line"><span class="comment"># 使用ha必须使用default-instance.xml</span></span><br><span class="line">canal.instance.global.spring.xml = classpath:spring/default-instance.xml</span><br></pre></td></tr></table></figure>
<p>canal的部署比较简单，在instance.properties也设置从哪个binlog某个位置处开始读(未测)。<br>下面看下client的设计，由于canal并没有继承client只是提供了一套client的api由用户自己去实现，则这里重点记录下client的设计。</p>
<h2 id="canal-client-功能设计"><a href="#canal-client-功能设计" class="headerlink" title="canal client 功能设计"></a>canal client 功能设计</h2><p>client的主要功能是与canal server的某个destinations建立连接消费订阅的binlog信息，并将binlog进行解析落地到存储系统中。</p>
<h3 id="client消费原理"><a href="#client消费原理" class="headerlink" title="client消费原理"></a>client消费原理</h3><p>client api中有ack和rollback机制，保证了数据不丢失。<br>ack机制采用异步确认，也就是可以连续调用get多次，后续异步按顺序提交ack/rollback，这种机制在canal中称为<em>流失api</em>设计。</p>
<p>流式api设计的好处：</p>
<ul>
<li>get/ack异步化，减少因ack带来的网络延迟和操作成本 (99%的状态都是处于正常状态，异常的rollback属于个别情况，没必要为个别的case牺牲整个性能)</li>
<li>get获取数据后，业务消费存在瓶颈或者需要多进程/多线程消费时，可以不停的轮询get数据，不停的往后发送任务，提高并行化。</li>
</ul>
<h3 id="数据格式及使用"><a href="#数据格式及使用" class="headerlink" title="数据格式及使用"></a>数据格式及使用</h3><p>client将binlog中的信息解析成json，json格式分为两种，一种是DML，主要包括insert、update和delete，另一种是DDL，主要包括create、alter和drop。<br>json格式如下：</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">// DML-json</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"database"</span>:<span class="string">"test"</span>,</span><br><span class="line">   <span class="attr">"table"</span>:<span class="string">"e"</span>,</span><br><span class="line">   <span class="attr">"type"</span>:<span class="string">"delete/insert/update"</span>,</span><br><span class="line">   <span class="attr">"executeTime"</span>:<span class="string">"1501645930000"</span>,</span><br><span class="line">   <span class="attr">"consumerTime"</span>:<span class="string">"1501645930000"</span>,</span><br><span class="line">   <span class="attr">"data"</span>:[</span><br><span class="line">   		&#123;<span class="attr">"id"</span>:<span class="string">"1"</span>,<span class="attr">"num"</span>:<span class="string">"1"</span>&#125;,</span><br><span class="line">   		&#123;<span class="attr">"id"</span>:<span class="string">"2"</span>,<span class="attr">"num"</span>:<span class="string">"2"</span>&#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;</span><br><span class="line">// DDL-json</span><br><span class="line">&#123;</span><br><span class="line">   <span class="attr">"database"</span>:<span class="string">"test"</span>,</span><br><span class="line">   <span class="attr">"table"</span>:<span class="string">"e"</span>,</span><br><span class="line">   <span class="attr">"type"</span>:<span class="string">"create/alter/drop"</span>,</span><br><span class="line">   <span class="attr">"executeTime"</span>:<span class="string">"1501645930000"</span>,</span><br><span class="line">   <span class="attr">"consumerTime"</span>:<span class="string">"1501645930000"</span>,</span><br><span class="line">   <span class="attr">"isDDL"</span>:<span class="string">"true/false"</span>,</span><br><span class="line">   <span class="attr">"sql"</span>:<span class="string">"create table e(id int)"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>之所以分为两个json格式，是因为想把<em>DML-json里的数据直接格式化作为当天的增量使用</em>，而DDL-json则需要解析成hql，个人建议在执行时需要人工check，DDL-json每天应该不会太多，初期人工check的压力不大，等程序成熟之后可以不用人工check。</p>
<blockquote>
<p>解析DML-json的时候需要给数据新增一列来标识数据的状态，数据的状态是指数据是否被删除。</p>
</blockquote>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>方便程序的移植性将一些参数提出，作为配置文件，由程序动态周期性的加载。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ZK_HOSTS = <span class="comment"># canal server ha的zk地址</span></span><br><span class="line">DESTINATION =  <span class="comment"># 要消费的mysql实例</span></span><br><span class="line">FILTER_REGEX =  <span class="comment"># 订阅的表信息的正则</span></span><br><span class="line">BATCH_SIZE =  <span class="comment"># 批量获取的条数</span></span><br><span class="line">DML_PATH = </span><br><span class="line">DDL_PATH = </span><br><span class="line">DELAY_TIME =  <span class="comment"># 延迟报警的阈值，单位ms</span></span><br></pre></td></tr></table></figure>
<h3 id="多线程异步处理数据"><a href="#多线程异步处理数据" class="headerlink" title="多线程异步处理数据"></a>多线程异步处理数据</h3><p>client api提供get／ack／rollback接口，为了提高消费效率，采用异步ack的机制。</p>
<p>设计一个一定大小的<code>ackQueue</code>，get不断的获取数据，将message交给新线程处理并将<code>batchId</code>放入ackQueue中，待新线程处理完message之后进行ack确认，从ackQueue中取出batchId按顺序确认，如遇到异常进行回滚。</p>
<p>伪代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">	<span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">		Message message = connector.getWithoutAck(BATCH_SIZE); <span class="comment">// 获取指定数量的数据</span></span><br><span class="line">        batchId = message.getId();</span><br><span class="line">        ackQueue.put(batchId);</span><br><span class="line">        executorService.submit(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            	<span class="comment">// 需要一个线程和文件的映射，防止多个线程写同一个文件</span></span><br><span class="line">                parseMessage(message);</span><br><span class="line">                <span class="comment">// 判断batchId是否和ackQueue中取得的batchId一致，大于则等待小于报异常</span></span><br><span class="line">                ackMessage(batchId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">	connector.rollback(batchId);</span><br><span class="line">&#125;<span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="数据归档"><a href="#数据归档" class="headerlink" title="数据归档"></a>数据归档</h3><p>由于目前的使用场景对实时要求不高，而是离线使用，则建议将数据直接写入本地文件系统，然后批量上传至HDFS。<br>这样既可以提高写的效率又可以减少对hdfs的操作，并且在上传hdfs时可以对数据进行合并，从源头上减少小文件的生成。</p>
<p>数据归档方案：</p>
<ol>
<li>数据文件切分可以按照持有一个文件句柄的时间来进行切分并且到零点统一关闭所有句柄。</li>
<li>使用binlog中的executeTime进行文件切分，保证数据归档的时间准备性。<h3 id="跨网络传输"><a href="#跨网络传输" class="headerlink" title="跨网络传输"></a>跨网络传输</h3>北京的数据向杭州传输采用两种方案：</li>
<li>client将数据写入本地，然后通过rsync传输到杭州服务器</li>
<li>client调用Avro rpc将数据写入杭州的flume agent的Avro source中，通过fileChannel将数据写入杭州服务器。</li>
</ol>
<p>对比：<br>方案1使用rsync进行数据传输，简单方便只开一次接口权限。而且client和杭州的client一致，不需要额外的开发。</p>
<p>方案2由于使用rpc传输则每个client对应一个port，需要多次申请port权限，同样在杭州的机器上也需要开通port权限，这样暴露的port较多，而且需要运维开通权限。<br>由于一个mysql实例对应一个client，则会需要多个port进行数据传输。</p>
<blockquote>
<p>建议rsync同步 </p>
</blockquote>
<h3 id="监控报警"><a href="#监控报警" class="headerlink" title="监控报警"></a>监控报警</h3><p>监控主要是监控消费延迟，判断消费延迟的依据是处理当前message的时间和该message在binlog中的executeTime的差值，大于设置的阈值则认为消费滞后，进行报警。<br>也可以判断一个时间窗口中两个时间点差值进行是否消费滞后的判断。</p>
]]></content>
      
        <categories>
            
            <category> BigData </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> HDFS </tag>
            
            <tag> MySQL </tag>
            
            <tag> canal </tag>
            
            <tag> 同步 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java虚拟机及GC基础介绍]]></title>
      <url>http://bigdatadecode.club/Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%8AGC%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D.html</url>
      <content type="html"><![CDATA[<p>作为一个hadoop开发，工作中难免会遇到gc的问题，以前总是一头雾水，这次抽时间系统的整理下，只是入门，更加深入的知识在工作中用到了再整理。</p>
<p>要理解gc先要搞清楚JVM，JVM是一个抽象的计算机结构。Java程序根据JVM的特性编写。JVM针对特定于操作系统并且可以将Java指令翻译成底层系统的指令并执行。JVM确保了Java的平台无关性。</p>
<a id="more"></a>
<h2 id="JVM架构"><a href="#JVM架构" class="headerlink" title="JVM架构"></a>JVM架构</h2><p>下图是JVM的架构(此架构图是HotSpot JVM)<br><img src="/blogimgs/Java虚拟机基础介绍/JVM架构.jpg" alt="JVM架构图" title="JVM架构图"><br>下面简单介绍下各个组件：</p>
<blockquote>
<p>class files文件是通过.java文件编译而来的。</p>
</blockquote>
<blockquote>
<p><em>ClassLoader的作用是装载能被JVM识别的指令，也就是加载.class文件到堆中，形成一个该类的对象(也就是说ClassLoader将class文件翻译为对象存放在堆内存中。)</em>。其加载流程为<em>加载 –&gt; 验证 –&gt; 准备 –&gt; 解析 –&gt; 初始化</em>。<br>ClassLoader，这个东西还是非常重要的，<em>在JVM中是通过ClassLoader和类本身共同去判断两个Class是否相同</em>。换句话说就是：不同的ClassLoader加载同一个Class文件，那么JVM认为他们生成的类是不同的。有些时候不会从Class文件中加载流（比如Java Applet是从网络中加载），那么这个ClassLoader和普通的实现逻辑当然是不一样的，通过不同的ClassLoader就可以解决这个问题。</p>
</blockquote>
<blockquote>
<p>Runtime Data Area(运行数据区域)也是Java内存区域，在此区域内又分为5部分，GC就是对这些区域内存的操作。其中这5部分根据是否被线程共享可以分为两大类，<em>PC Register、Java Stacks 和 Native Method Statck为线程私有的，Heap Memory 和 Method Area是线程共享的</em>。</p>
</blockquote>
<p>1、PC Register(程序计数器)</p>
<p>PC Register是一个比较小的内存区域，用于指示当前线程所执行的字节码执行到了第几行，可以理解为是当前线程的行号指示器。字节码解释器在工作时，会通过改变这个计数器的值来取下一条语句指令。<br>每个程序计数器只用来记录一个线程的行号，所以它是<strong>线程私有</strong>（一个线程就有一个程序计数器）的。<br>如果程序执行的是一个Java方法，则计数器记录的是正在执行的虚拟机字节码指令地址；如果正在执行的是一个本地（native，由C语言编写完成）方法，则计数器的值为Undefined，由于程序计数器只是记录当前指令地址，所以不存在内存溢出的情况，因此，<strong>程序计数器是JVM内存区域中唯一一个不会发生OutOfMemoryError的区域</strong>。</p>
<p>2、Java Stacks(Java 栈)</p>
<p>Java栈也称为方法栈，存放这与方法相关的信息，如<em>方法中的局部变量、方法入口、方法出口</em>等。<br>一个线程的每个方法在执行的同时，都会创建一个<em>栈帧</em>(Statck Frame)，栈帧中存储的有局部变量表、操作站、动态链接、方法出口等，<em>当方法被调用时，栈帧在Java栈中入栈，当方法执行完成时，栈帧出栈</em>。</p>
<p>局部变量表中存储着方法的相关<em>局部变量</em>，包括各种基本数据类型，对象的引用，返回地址等。在局部变量表中，只有long和double类型会占用2个局部变量空间(Slot，对于32位机器，一个Slot就是32个bit)，其它都是1个Slot。需要注意的是，<em>局部变量表是在<strong>编译</strong>时就已经确定好的，方法运行所需要分配的空间在栈帧中是完全确定的</em>，在方法的生命周期内都不会改变。</p>
<p>Java栈中定义了两种异常，如果线程调用的栈深度大于虚拟机允许的最大深度(例如递归的深度较大)，则抛出<em>StatckOverFlowError</em>(栈溢出)；不过多数Java虚拟机都允许动态扩展虚拟机栈的大小(有少部分是固定长度的)，所以线程可以一直申请栈，直到内存不足，此时，会抛出<em>OutOfMemoryError</em>(内存溢出)。</p>
<p>Java栈也是一个线程对应着一个Java栈，因此Java栈也是<strong>线程私有</strong>的。</p>
<p>3、Native Method Statck(本地方法栈)</p>
<p><em>本地方法栈在作用，运行机制，异常类型等方面都与Java栈相同</em>，唯一的区别是：Java栈是执行Java方法的，而<em>本地方法栈是用来执行native方法</em>(也就是由c语言编写的方法)的，在很多虚拟机中（如Sun的JDK默认的HotSpot虚拟机），会将本地方法栈与虚拟机栈放在一起使用。<br>本地方法栈也是<em>线程私有</em>的。</p>
<p>4、Heap Memory(堆内存)</p>
<p>堆内存主要是用来<em>动态的存储对象实例</em>，原则上讲，所有的对象都在堆区上分配内存(不过现代技术里，也不是这么绝对的，也有栈上直接分配的)。也是<em>Java GC机制所管理的主要内存区域</em>，堆区由所有<em>线程共享</em>，在虚拟机启动时创建。堆区的存在是为了存储对象实例，</p>
<p>一般的，根据Java虚拟机规范规定，堆内存需要在逻辑上是连续的（在物理上不需要），在实现时，可以是固定大小的，也可以是可扩展的，目前主流的虚拟机都是可扩展的。<em>如果在执行垃圾回收之后，仍没有足够的内存分配，也不能再扩展，将会抛出OutOfMemoryError:<strong>Java heap space</strong>异常</em>。</p>
<p>堆内存的详细内存在下面的章节进行扩展。</p>
<p>5、Method Area(方法区)</p>
<p>方法区也就是平时所说的<em>非堆内存</em>(Non-heap)，但按照Java GC的分代收集机制来说，方法区也叫永久代(Permanent Generation)。</p>
<p>方法区是各个<em>线程共享</em>的区域，用于存储已经被虚拟机加载的<em>类信息</em>(即加载类时需要加载的信息，包括版本、field、方法、接口等信息)、<em>final常量</em>、<em>静态变量</em>、编译器即时编译的代码等。</p>
<p>方法区在物理上也不需要是连续的，可以选择固定大小或可扩展大小，并且方法区比堆还多了一个限制：可以选择是否执行垃圾收集。一般的，方法区上执行的垃圾收集是很少的，这也是方法区被称为永久代的原因之一（HotSpot），但这也不代表着在方法区上完全没有垃圾收集，其上的垃圾收集主要是针对<em>常量池的内存回收和对已加载类的卸载</em>。</p>
<p>在方法区上进行垃圾收集，条件苛刻而且相当困难，效果也不令人满意，所以一般不做太多考虑，可以留作以后进一步深入研究时使用。</p>
<p>方法区在内存不足时抛出OutOfMemoryError:<strong>PermGen space</strong>异常，。</p>
<blockquote>
<p>Execution Engine(执行引擎)的功能是执行classes中的指令。任何JVM specification实现(JDK)的核心都是Execution engine，而Execution engine最核心的两块是JIT(just in time)即时编译器和GC(Garbage Collection)垃圾回收器。Execution Engine包含Interpreter(解释器)、JIT、Hotspot profiler和GC。</p>
</blockquote>
<p>Interpreter：主要功能是读bytecode，然后执行相对应的指令。<br>JIT(Just-in-time) Compiler：这个部分主要是用以优化execution engine的性能，一般execution engine会先用interpreter去解释bytecode, 然后执行对应的命令。在很多时候，JIT compliler可以将相类似的bytecode都翻译成native code，然后直接运行。直接执行native code会比bytecode快。<br>Hotspot profiler: 这个部分也是用来优化性能的，当某些method被多次使用时，Hotspot这个部分就会用profiler去记录那些method所对应的native code， 这样就可以直接用native code而不是byte code了。<br>Garbage collector: 这个部分主要负责内存的管理，当程序中的object不再被用的时候，garbage collector会将其删除。</p>
<p>通过类装载器装载的，被分配到JVM的运行时数据区的字节码会被<em>执行引擎</em>执行。执行引擎以指令为单位读取Java字节码。它就像一个CPU一样，一条一条地执行机器指令。每个字节码指令都由一个1字节的操作码和附加的操作数组成。执行引擎取得一个操作码，然后根据操作数来执行任务，完成后就继 续执行下一条操作码。<br>不过Java字节码是用一种人类可以读懂的语言编写的，而不是用机器可以直接执行的语言。因此，执行引擎必须把字节码转换成可以直接被JVM执行的语言。字节码可以通过以下两种方式转换成合适的语言。</p>
<ul>
<li><p>解释器(解释执行)：一条一条地读取，解释并且执行字节码指令。因为它一条一条地解释和执行指令，所以它可以很快地解释字节码，但是执行起来会比较慢。这是解释执行的语言的一个缺点。字节码这种“语言”基本来说是解释执行的。</p>
</li>
<li><p>即时(Just-In-Time)编译器(编译执行)： 即时编译器被引入用来弥补解释器的缺点。执行引擎首先按照解释执行的方式来执行，然后在合适的时候，即时编译器把整段字节码编译成本地代码。然后，执行引 擎就没有必要再去解释执行方法了，它可以直接通过本地代码去执行它。执行本地代码比一条一条进行解释执行的速度快很多。编译后的代码可以执行的很快，因为 本地代码是保存在缓存里的。</p>
</li>
</ul>
<p>不过，用JIT编译器来编译代码所花的时间要比用解释器去一条条解释执行花的时间要多。因此，如果代码只被执行一次的话，那么最好还是解释执行而不是编译后再执行。因此，内置了JIT编译器的JVM都会检查方法的执行频率，<em>如果一个方法的执行频率超过一个特定的值的话，那么这个方法就会被编译成本地代码</em>。</p>
<h2 id="垃圾回收-GC"><a href="#垃圾回收-GC" class="headerlink" title="垃圾回收(GC)"></a>垃圾回收(GC)</h2><p><em>垃圾回收主要组件是堆内存和垃圾回收器</em>。堆内存是内存数据区，用来保存运行时的对象实例。垃圾回收器也会在这里操作。垃圾回收器是个守护进程。</p>
<p>GC主要是对堆内存的回收，堆内存按照隔代划分将堆内存划分为新生代(Young Generation)、老年代(Old Generation)，方法区(non-heap)划分为永久代(Permanent Generation)。java的内存分配如下图：<br><img src="/blogimgs/Java虚拟机基础介绍/java内存分配.png" alt="java内存分配" title="java内存分配"></p>
<ul>
<li>新生代</li>
</ul>
<p>新生代分为3个区域：Eden、Survivor0和Survivor1。</p>
<p>新创建的对象被分配在Eden区(大对象可以直接被创建在年老代)，由于大部分对象在创建后会很快不再使用，所以很多对象被创建在新生代，然后消失。对象从这个区域消失的过程我们称之为<em>minor GC(or young gc)</em>。</p>
<p>新生代minor gc的流程为：<br>1、新生成的对象放入Eden区，等Eden区满之后，执行一次minor gc，将Eden中存活下来的对象放入S0(Survivor0)中<br>2、此时Eden区为空，新生的对象再次放入Eden区，Eden区再次被放满，执行一次minor gc，此时将Eden中存活的对象再次放入S0中，<em>循环几次待S0也满之后</em>，将Eden和S0中存活的对象放入S1中，此时Eden和S0为空<br>3、反复上述流程15次(默认15次，由-XX:MaxTenuringThreshold控制，大于该值进入老年代，<em>但这只是个最大值，并不代表一定是这个值</em>)之后，将S0或者S1中依然存活的对象放入老年代中，将Eden中存活的对象放入S0或者S1中。</p>
<blockquote>
<p>S0和S1两个幸存区同时只有一个区域里有数据</p>
</blockquote>
<blockquote>
<p>Eden、S0和S1所占的比例由参数-XX:SurvivorRatio控制，默认SurvivorRatio=8，即Eden:S0:S1=8:1:1。如果SurvivorRatio=10，Eden:S0:S1=10:1:1，Eden占新生代的10/12，S0和S1各占1/12。</p>
</blockquote>
<p>在执行minor gc时可能<em>需要查询整个老年代以确定新生代中的对象是否可以清理回收</em>，这显然是低效的。解决的方法是，老年代中维护一个<em>card table</em>，他是一个512 byte大小的块。所有老年代对象引用新生代对象的记录都记录在这里。当针对新生代执行GC的时候，只需要查询card table来决定是否可以被回收，而不用查询整个老年代。这个card table由一个write barrier来管理。write barrier给GC带来了很大的性能提升，虽然由此可能带来一些开销，但GC的整体时间被显著的减少。</p>
<ul>
<li>老年代</li>
</ul>
<p>对象如果在年轻代存活了足够长的时间而没有被清理掉(即在几次Young GC后存活了下来)，则会被复制到老年代，老年代的空间一般比新生代大，能存放更多的对象，在老年代上发生的GC次数也比新生代少。当老年代内存不足时，将执行<em>Major GC，也叫Full GC</em>。</p>
<p>他们是一个概念，就是针对老年代/永久代进行GC。因为取名叫Full就会让人疑惑，到底会不会先Minor GC。<em>事实上Full GC本身不会先进行Minor GC</em>，<strong>我们可以配置</strong>，让Full GC之前先进行一次Minor GC，因为老年代很多对象都会引用到新生代的对象，先进行一次Minor GC可以提高老年代GC的速度。<em>比如老年代使用CMS时，设置CMSScavengeBeforeRemark优化，让CMS remark之前先进行一次Minor GC</em>。</p>
<blockquote>
<p>个人理解Major GC针对Old区，此区域的gc算法包括CMS、G1等。而Full GC的次数是由STW(stop the world)决定的，则当使用CMS(initial mark、concurrent mark、remark和concurrent sweep)时，对Old区进行gc时，full gc的个数会加2，因为CMS中STW的次数是2(分别为initial mark和remark阶段)</p>
</blockquote>
<blockquote>
<p><strong>CMS 不等于Full GC，我们可以看到CMS分为多个阶段，只有stop the world的阶段被计算到了Full GC的次数和时间，而和业务线程并发的GC的次数和时间则不被认为是Full GC</strong></p>
</blockquote>
<blockquote>
<p>新生代和老年代所占内存的比例参数由-XX:NewRatio控制，默认NewRatio=3，即Old:Young=3:1，则Old占内存的3/4，Young占内存的1/4。</p>
</blockquote>
<ul>
<li>永久代</li>
</ul>
<p>永久代用来保存<em>类常量以及字符串常量</em>。因此，<em>这个区域不是用来永久的存储那些从老年代存活下来的对象</em>。这个区域也可能发生GC。并且发生在这个区域上的GC事件也会被算为<em>major GC</em>。</p>
<p><em>运行时常量池</em>(Runtime Constant Pool)是存在该区域，用于存储编译期就生成的字面常量、符号引用、翻译出来的直接引用(符号引用就是编码是用字符串表示某个变量、接口的位置，直接引用就是根据符号引用翻译出来的地址，将在类链接阶段完成翻译)；运行时常量池除了存储编译期常量外，也可以存储在运行时间产生的常量(比如String类的intern()方法，作用是String维护了一个常量池，如果调用的字符“abc”已经在常量池中，则返回池中的字符串地址，否则，新建一个常量加入池中，并返回地址)。</p>
<h2 id="GC监控"><a href="#GC监控" class="headerlink" title="GC监控"></a>GC监控</h2><p>GC监控主要是为了搞清楚JVM是如何执行GC的，鉴别JVM是否在高效地执行GC，以及是否有必要进行额外的性能调优。</p>
<p>监控GC有很多种方法，这里主要介绍两种，一种是图形化的GC监控，一种是命令行式的监控命令。</p>
<h3 id="图形化GC监控"><a href="#图形化GC监控" class="headerlink" title="图形化GC监控"></a>图形化GC监控</h3><p>图形化GC监控主要介绍下JDK自带的Java VisualVM。</p>
<p>Java VisualVM存在JDK的安装目录下的bin文件夹中。主要用于：</p>
<ul>
<li>生成并分析堆的内存转储；</li>
<li>在MBeans上观察并操作；</li>
<li>监视垃圾回收；</li>
<li>内存和CPU性能分析；</li>
</ul>
<p>更多详细内容请看<a href="http://www.importnew.com/13838.html" target="_blank" rel="noopener">这里</a></p>
<h3 id="GC监控命令"><a href="#GC监控命令" class="headerlink" title="GC监控命令"></a>GC监控命令</h3><p>GC监控命令常用的有<em>jstat和jmap</em>。</p>
<ul>
<li>jstat</li>
</ul>
<p>jstat用于监视虚拟机各种运行状态信息的命令行工具。可以显示本地或者远程虚拟机进程中的<em>类装载、内存、垃圾收集、JIT编译</em>等运行数据。<br>其命令格式为<code>jstat [ option vmid|lvmid [interval[s|ms] [count]]]</code>，其中vmid是连接本地虚拟机用的，lvmid是连接远程虚拟机用的，参数interval和count代表查询间隔和次数，省略说明查询1次。假设需要每250毫秒查询一次进程1234垃圾收集的状态，一共查询3次，则命令为<code>jstat -gc 1234 250 3</code>，输出如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">S0C       S1C       S0U    S1U      EC         EU          OC         OU         PC         PU         YGC     YGCT    FGC      FGCT     GCT</span><br><span class="line">3008.0   3072.0    0.0     1511.1   343360.0   46383.0     699072.0   283690.2   75392.0    41064.3    2540    18.454    4      1.133    19.588</span><br><span class="line">3008.0   3072.0    0.0     1511.1   343360.0   47530.9     699072.0   283690.2   75392.0    41064.3    2540    18.454    4      1.133    19.588</span><br><span class="line">3008.0   3072.0    0.0     1511.1   343360.0   47793.0     699072.0   283690.2   75392.0    41064.3    2540    18.454    4      1.133    19.588</span><br></pre></td></tr></table></figure>
<p>其中各列代表的意思如下：<br>S0C  输出Survivor0空间的大小。单位KB。<br>S1C     输出Survivor1空间的大小。单位KB。<br>S0U     输出Survivor0已用空间的大小。单位KB。<br>S1U     输出Survivor1已用空间的大小。单位KB。<br>EC  输出Eden空间的大小。单位KB。<br>EU  输出Eden已用空间的大小。单位KB。<br>OC  输出老年代空间的大小。单位KB。<br>OU  输出老年代已用空间的大小。单位KB。<br>PC  输出持久代空间的大小。单位KB。<br>PU  输出持久代已用空间的大小。单位KB。<br>YGC     新生代空间GC时间发生的次数。<br>YGCT  新生代GC处理花费的时间。<br>FGC     full GC发生的次数。<br>FGCT  full GC操作花费的时间<br>GCT     GC操作花费的总时间。</p>
<ul>
<li>jmap</li>
</ul>
<p>jamp是内存映射工具，用于生成堆转储快照(一般称为heapdump或者dump文件)。<em>jmap的作用不仅仅是为了生成dump文件，还可以查询finalize执行队列、java堆和永久代的详细信息</em>，如空间使用率、当前用的是哪种垃圾收集器等。<br>其命令格式为<code>jmap [ option ] vmid</code>，常用option有-dump和-heap，-dump用于生成java堆转储快照。-heap用于显示java堆的详细信息，如使用哪种回收器、参数配置、分代情况等。</p>
<p>查看进程pid的内存使用情况<br>命令<code>jmap -histo:live pid &gt; mem</code><br>或者<br>命令<code>jmap -histo pid &gt; mem</code></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇主要科普了下JVM的架构和Java的内存分配。在JVM架构中主要关注运行时数据区域，这里分为两大类，线程共享的方法区和Java堆，线程私有的程序计数器、Java栈和本地方法栈，线程私有是指每个线程都会有这3个模块。在整个运行时数据区域只有程序计数器不会发生OOM，其它部分都会发生OOM，OOM的主要类型有<em>Java heap space、PermGen space、OutOfMemoryError和StatckOverFlowError</em>。</p>
<!-- 
// JVM sizing options
-server -Xms40g -Xmx40g -XX:MaxDirectMemorySize=4096m -XX:PermSize=256m -XX:MaxPermSize=256m   
// Young generation options
-XX:NewSize=6g -XX:MaxNewSize=6g -XX:+UseParNewGC -XX:MaxTenuringThreshold=2 -XX:SurvivorRatio=8 -XX:+UnlockDiagnosticVMOptions -XX:ParGCCardsPerStrideChunk=32768
// Old generation  options
-XX:+UseConcMarkSweepGC -XX:CMSParallelRemarkEnabled -XX:+ParallelRefProcEnabled -XX:+CMSClassUnloadingEnabled  -XX:CMSInitiatingOccupancyFraction=80 -XX:+UseCMSInitiatingOccupancyOnly   
// Other options
-XX:+AlwaysPreTouch -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution -XX:+PrintGCApplicationStoppedTime -XX:-OmitStackTraceInFastThrow
-->
<h2 id="附加：直接内存"><a href="#附加：直接内存" class="headerlink" title="附加：直接内存"></a>附加：直接内存</h2><p>直接内存并不是JVM管理的内存，则直接内存在分配时不会受到Java堆大小的限制，但是会受到本机内存大小的限制，所有也可能会抛<em>OutOfMemoryError异常</em>。可以这样理解，直接内存，就是JVM以外的机器内存，比如，你有4G的内存，JVM占用了1G，则其余的3G就是直接内存。</p>
<p>JDK中有一种基于通道(Channel)和缓冲区(Buffer)的内存分配方式，将由C语言实现的native函数库分配在直接内存中，用存储在JVM堆中的DirectByteBuffer来引用。<br>在NIO类中引入一种基于通道与缓冲区的IO方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> jvm </tag>
            
            <tag> gc </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[unclean.leader.election.enable引起的outOfRanger]]></title>
      <url>http://bigdatadecode.club/unclean.leader.election.enable%E5%BC%95%E8%B5%B7%E7%9A%84outOfRanger.html</url>
      <content type="html"><![CDATA[<p>前段时间采集平台的数据量发生异常，对数据进行排查发现hdfs上存在历史数据重复消费的问题。</p>
<blockquote>
<p>采集平台是由TailDirSource+KafkaChannel将数据写入kafka，然后通过kafkaChannel+HDFSSink将数据写入hdfs </p>
</blockquote>
<p>整个采集平台可能出现的故障的地方如下：</p>
<ol>
<li>taildir重复采集了log </li>
<li>taildir调用kafkachannel向kafka写数据时进行了回滚</li>
<li>hdfsSink调用kafkachannel消费数据时，进行了重复消费</li>
<li>hdfsSink写入hdfs时发生了回滚</li>
</ol>
<a id="more"></a>
<h2 id="故障分析"><a href="#故障分析" class="headerlink" title="故障分析"></a>故障分析</h2><ol>
<li>首先检查了下hdfs上的数据量异常的现象，是多余的数据是最新的数据还是历史数据，经数据校验确认数据量暴增是由于历史数据造成的。</li>
<li>查看业务方服务器上历史log是否发生变化，查证后log的历史文件没有发生变化。</li>
<li>采集端的flume log无异常，在kafka到hdfs的环节中的flume log中发现<em>info级别的offset重置信息</em>。初步怀疑是offset发生了out of ranger，然后被重置了offset，而这个offset又是比较早的一个offset，导致重新读取了大量的历史数据。<br>log 内容如下：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">15 五月 2017 17:56:59,396 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.kafka.clients.consumer.internals.Fetcher.handleFetchResponse:595)  - Fetch offset 2261734 is out of range, resetting offset</span><br></pre></td></tr></table></figure>
<h2 id="实践验证"><a href="#实践验证" class="headerlink" title="实践验证"></a>实践验证</h2><p>在KafkaOffsetMonitor的log中发现offset重置的记录，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2017-05-18 13:25:17 INFO  KafkaOffsetGetter$:68 - Processed commit message: [consumer-group,topic-xx,8] =&gt; OffsetAndMetadata[119088,0e78ce6b-4dca-4cd6-b914-22b78ebbaaff,1495085117090]</span><br><span class="line"><span class="comment"># 下一次记录的offset就发生了重置，内容如下：</span></span><br><span class="line">2017-05-18 13:25:20 INFO  KafkaOffsetGetter$:68 - Processed commit message: [bconsumer-group,topic-xx,8] =&gt; OffsetAndMetadata[418,b0abba89-4f7a-4168-9e90-39a4db2a62f0,1495085120134]</span><br></pre></td></tr></table></figure>
<p>从log中可以看出topic topic-xx的8分区的offset从119088置成了418。</p>
<p>然后从代码中查找out of ranger相关的代码并结合当前集群的状态进行分析，发现当某个topic的leader和followers的状态不一致时，发生leader切换时，会发送out of range，此时consumer进行消费时发现offset非法，就会被重置为earliest，进行重复消费。</p>
<h2 id="故障重现"><a href="#故障重现" class="headerlink" title="故障重现"></a>故障重现</h2><p>在测试环境中创建一个topic test，3个分区，2个副本，broker 1为leader，broker 2为follower。<br>写入一些数据flume进行正常消费，消费至最新状态A处之后，将test的follower的broker2停掉，继续向test写入数据，并让consumer再次消费至最新状态B处。</p>
<blockquote>
<p>此时停掉的follower broker 2的状态已和leader broker 1的状态不一样，已滞后leader的状态。</p>
</blockquote>
<p>现在将follower broker 2启动，此时follower和leader的状态不一样，follower需要和leader进行同步，但当follower与leader未同步成功之前将leader broker 1停掉，然后follower broker 2经过leader的选举机制被迫选为leader(<em>unclean.leader.election.enable为true时，选择第一个启动的副本为leader</em>)，在被选举为leader之前broker 2的状态并没有和broker 1的状态一致，<strong>也就是说broker 2上的LEO并没有同步到B处，而broker 2被选举为了leader，此时producer继续向topic中写数据，写入之后consumer会进行消费，consumer需要消费的offset的B，而broker 2的LEO并没有同步到B处，此时就发生了out of ranger，offset被重置为了earliest</strong>。</p>
<h2 id="优化方案"><a href="#优化方案" class="headerlink" title="优化方案"></a>优化方案</h2><p>针对以上情况我们进行了一下修改：</p>
<ol>
<li>将topic的副本数设置为3(原先为2)，减少ISR列表只有一个leader的几率</li>
<li>调整<code>min.insync.replicas</code>为2(默认是1)，此参数的意思是当ISR中的个数小于此值时，producer无法写入数据，会抛出异常。此参数还需要结合acks来使用，需要将acks设置为all或者-1(flume中kafkaChannel默认是all)。</li>
<li>调整<code>unclean.leader.election.enable</code>参数为false(默认为true)，此参数标识当ISR中没有副本时，选举最早启动的broker为leader。</li>
<li>调整操作磁盘的线程数num.io.threads为24(原来为12)</li>
<li>对flume taildirSource进行二次开发，在body中添加log所在主机名、log 路径和采集时间。添加这些元数据信息为日后故障排除提供方便。</li>
<li>kafkachannel中增加producer端重试的metrics统计(第2点中写入失败的次数会在此处记录)该功能提交，<a href="https://issues.apache.org/jira/browse/FLUME-3104" target="_blank" rel="noopener">patch</a> </li>
<li>集群因为维护需要重启时，先停掉一台broker，然后重启该broker，等到该broker已加入到ISR中之后，再对其它broker进行如上操作，切勿单个broker依次重启。</li>
</ol>
]]></content>
      
        <categories>
            
            <category> Kafka </category>
            
        </categories>
        
        
        <tags>
            
            <tag> big data </tag>
            
            <tag> kafka </tag>
            
            <tag> 运维 </tag>
            
            <tag> offset resetting </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之ApplicationMaster启动流程]]></title>
      <url>http://bigdatadecode.club/YARNSrcApplicationMasterStart.html</url>
      <content type="html"><![CDATA[<p>任何一个计算框架或者说一个服务要运行在yarn上，都需要一个master来对job进行管理，这个master就是ApplicationMaster。</p>
<p>ApplicationMaster是一个job的大脑，下面就以MapReduce为例，介绍下ApplicationMaster的启动流程。</p>
<a id="more"></a>
<p>首先client向RM提交一个application请求，RM创建一个application，然后再创建一个appattempt，后期的调度和任务的拆解都是对这个appattempt进行的，当appattempt的状态从<code>ALLOCATED_SAVING</code>变成<code>ALLOCATED</code>时，由<code>AttemptStoredTransition.transition</code>调用<code>appAttempt.launchAttempt()</code>进行启动，下面来看下具体代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RMAppAttemptImpl.java</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">launchAttempt</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="comment">// Send event to launch the AM Container</span></span><br><span class="line">  <span class="comment">// 通过异步调度器得到该事件注册的handle (在ResourceManager中注册)</span></span><br><span class="line">  <span class="comment">// AMLauncherEvent 对应的handle是ApplicationMasterLauncher</span></span><br><span class="line">  eventHandler.handle(<span class="keyword">new</span> AMLauncherEvent(AMLauncherEventType.LAUNCH, <span class="keyword">this</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AMLauncherEvent对应的handle是ApplicationMasterLauncher，事件类型是LAUNCH，在<code>ApplicationMasterLauncher.handle</code>中会调用<code>launch(application)</code>，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">launch</span><span class="params">(RMAppAttempt application)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 创建一个线程</span></span><br><span class="line">  Runnable launcher = createRunnableLauncher(application, </span><br><span class="line">      AMLauncherEventType.LAUNCH);</span><br><span class="line">  <span class="comment">// 将线程放入阻塞队列中</span></span><br><span class="line">  masterEvents.add(launcher);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只从这个方法来分析，首先创建了一个launcher线程，然后将其放入一个队列中，等待另一个线程从队列中取出进行操作，这是典型的生产者消费者模型。那么我们就来看下<code>ApplicationMasterLauncher</code>(ApplicationMasterLauncher是一个事件也是一个服务)关于这块代码的具体实现。</p>
<p>先看下<code>createRunnableLauncher</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Runnable <span class="title">createRunnableLauncher</span><span class="params">(RMAppAttempt application, </span></span></span><br><span class="line"><span class="function"><span class="params">    AMLauncherEventType event)</span> </span>&#123;</span><br><span class="line">  Runnable launcher =</span><br><span class="line">      <span class="keyword">new</span> AMLauncher(context, application, event, getConfig());</span><br><span class="line">  <span class="keyword">return</span> launcher;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里只是new了一个AMLauncher，AMLauncher实现了Runnable接口，是执行AM操作的线程，只执行<code>launch</code>和<code>cleanup</code>。</p>
<p>launcher线程创建之后add到阻塞队列masterEvents中，那么必然会有另一个线程来队列中take launcher，这个线程是<code>LauncherThread</code>类型的<code>launcherHandlingThread</code>，launcherHandlingThread将launcher取出丢给线程池去执行，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">LauncherThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">LauncherThread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(<span class="string">"ApplicationMaster Launcher"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (!<span class="keyword">this</span>.isInterrupted()) &#123;</span><br><span class="line">      Runnable toLaunch;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">      	<span class="comment">// 从阻塞队列中取出 </span></span><br><span class="line">        toLaunch = masterEvents.take();</span><br><span class="line">        <span class="comment">// 交给线程池执行</span></span><br><span class="line">        <span class="comment">// this.launcherPool = new ThreadPoolExecutor(10, 10, 1, TimeUnit.HOURS, new LinkedBlockingQueue&lt;Runnable&gt;());</span></span><br><span class="line">        launcherPool.execute(toLaunch);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        LOG.warn(<span class="keyword">this</span>.getClass().getName() + <span class="string">" interrupted. Returning."</span>);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>放入线程池之后，launcher线程就开始执行，调用的是<code>AMLauncher.run</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">switch</span> (eventType) &#123;</span><br><span class="line">  <span class="keyword">case</span> LAUNCH:</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      LOG.info(<span class="string">"Launching master"</span> + application.getAppAttemptId());</span><br><span class="line">      launch();</span><br><span class="line">      <span class="comment">// 向AMLivelinessMonitor中注册am</span></span><br><span class="line">      handler.handle(<span class="keyword">new</span> RMAppAttemptEvent(application.getAppAttemptId(),</span><br><span class="line">          RMAppAttemptEventType.LAUNCHED));</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Exception ie) &#123;</span><br><span class="line">      String message = <span class="string">"Error launching "</span> + application.getAppAttemptId()</span><br><span class="line">          + <span class="string">". Got exception: "</span> + StringUtils.stringifyException(ie);</span><br><span class="line">      LOG.info(message);</span><br><span class="line">      handler.handle(<span class="keyword">new</span> RMAppAttemptLaunchFailedEvent(application</span><br><span class="line">          .getAppAttemptId(), message));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> CLEANUP:</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    LOG.warn(<span class="string">"Received unknown event-type "</span> + eventType + <span class="string">". Ignoring."</span>);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>之前放入阻塞队列masterEvents的事件类型是LAUNCH，则此处调用<code>launch()</code>方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">launch</span><span class="params">()</span> <span class="keyword">throws</span> IOException, YarnException </span>&#123;</span><br><span class="line">  <span class="comment">// 得到对应node的rpc客户端</span></span><br><span class="line">  connect();</span><br><span class="line">  ContainerId masterContainerID = masterContainer.getId();</span><br><span class="line">  ApplicationSubmissionContext applicationContext =</span><br><span class="line">    application.getSubmissionContext();</span><br><span class="line">  LOG.info(<span class="string">"Setting up container "</span> + masterContainer</span><br><span class="line">      + <span class="string">" for AM "</span> + application.getAppAttemptId());  </span><br><span class="line">  ContainerLaunchContext launchContext =</span><br><span class="line">      createAMContainerLaunchContext(applicationContext, masterContainerID);</span><br><span class="line">  <span class="comment">// 构建request</span></span><br><span class="line">  StartContainerRequest scRequest =</span><br><span class="line">      StartContainerRequest.newInstance(launchContext,</span><br><span class="line">        masterContainer.getContainerToken());</span><br><span class="line">  List&lt;StartContainerRequest&gt; list = <span class="keyword">new</span> ArrayList&lt;StartContainerRequest&gt;();</span><br><span class="line">  list.add(scRequest);</span><br><span class="line">  StartContainersRequest allRequests =</span><br><span class="line">      StartContainersRequest.newInstance(list);</span><br><span class="line">  <span class="comment">// 远程调用startContainers</span></span><br><span class="line">  StartContainersResponse response =</span><br><span class="line">      containerMgrProxy.startContainers(allRequests);</span><br><span class="line">  <span class="keyword">if</span> (response.getFailedRequests() != <span class="keyword">null</span></span><br><span class="line">      &amp;&amp; response.getFailedRequests().containsKey(masterContainerID)) &#123;</span><br><span class="line">    Throwable t =</span><br><span class="line">        response.getFailedRequests().get(masterContainerID).deSerialize();</span><br><span class="line">    parseAndThrowException(t);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    LOG.info(<span class="string">"Done launching container "</span> + masterContainer + <span class="string">" for AM "</span></span><br><span class="line">        + application.getAppAttemptId());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AMLaunch.launch先在<code>connect()</code>中拿到对应node的rpc客户端<code>containerMgrProxy</code>，然后构造request，最后调用rpc函数<code>startContainers()</code>并返回response。看下<em>node端</em>的<code>startContainers</code>代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> StartContainersResponse</span><br><span class="line">    startContainers(StartContainersRequest requests) <span class="keyword">throws</span> YarnException,</span><br><span class="line">        IOException &#123;</span><br><span class="line">  ...</span><br><span class="line">  UserGroupInformation remoteUgi = getRemoteUgi();</span><br><span class="line">  NMTokenIdentifier nmTokenIdentifier = selectNMTokenIdentifier(remoteUgi);</span><br><span class="line">  authorizeUser(remoteUgi,nmTokenIdentifier);</span><br><span class="line">  List&lt;ContainerId&gt; succeededContainers = <span class="keyword">new</span> ArrayList&lt;ContainerId&gt;();</span><br><span class="line">  Map&lt;ContainerId, SerializedException&gt; failedContainers =</span><br><span class="line">      <span class="keyword">new</span> HashMap&lt;ContainerId, SerializedException&gt;();</span><br><span class="line">  <span class="keyword">for</span> (StartContainerRequest request : requests.getStartContainerRequests()) &#123;</span><br><span class="line">    ContainerId containerId = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      ContainerTokenIdentifier containerTokenIdentifier =</span><br><span class="line">          BuilderUtils.newContainerTokenIdentifier(request.getContainerToken());</span><br><span class="line">      verifyAndGetContainerTokenIdentifier(request.getContainerToken(),</span><br><span class="line">        containerTokenIdentifier);</span><br><span class="line">      containerId = containerTokenIdentifier.getContainerID();</span><br><span class="line">      startContainerInternal(nmTokenIdentifier, containerTokenIdentifier,</span><br><span class="line">        request);</span><br><span class="line">      succeededContainers.add(containerId);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (YarnException e) &#123;</span><br><span class="line">      failedContainers.put(containerId, SerializedException.newInstance(e));</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InvalidToken ie) &#123;</span><br><span class="line">      failedContainers.put(containerId, SerializedException.newInstance(ie));</span><br><span class="line">      <span class="keyword">throw</span> ie;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="keyword">throw</span> RPCUtil.getRemoteException(e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> StartContainersResponse.newInstance(getAuxServiceMetaData(),</span><br><span class="line">    succeededContainers, failedContainers);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>startContainers对request中的container请求进行遍历，调用<code>startContainerInternal</code>启动一个container，这个container是在nodemanager上准备运行task的。启动成功的放入succeededContainers列表中，失败的则放入failedContainers中，遍历结束构造一个response返回给rm。</p>
<p>看下启动container的startContainerInternal方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startContainerInternal</span><span class="params">(NMTokenIdentifier nmTokenIdentifier,</span></span></span><br><span class="line"><span class="function"><span class="params">    ContainerTokenIdentifier containerTokenIdentifier,</span></span></span><br><span class="line"><span class="function"><span class="params">    StartContainerRequest request)</span> <span class="keyword">throws</span> YarnException, IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  ContainerId containerId = containerTokenIdentifier.getContainerID();</span><br><span class="line">  String containerIdStr = containerId.toString();</span><br><span class="line">  String user = containerTokenIdentifier.getApplicationSubmitter();</span><br><span class="line"></span><br><span class="line">  LOG.info(<span class="string">"Start request for "</span> + containerIdStr + <span class="string">" by user "</span> + user);</span><br><span class="line">  <span class="comment">// 得到当前container的上下文信息</span></span><br><span class="line">  ContainerLaunchContext launchContext = request.getContainerLaunchContext();</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 创建container对象，开始NodeManager上container的状态机转换</span></span><br><span class="line">  <span class="comment">// container的初始状态为NEW</span></span><br><span class="line">  Container container =</span><br><span class="line">      <span class="keyword">new</span> ContainerImpl(getConfig(), <span class="keyword">this</span>.dispatcher,</span><br><span class="line">          context.getNMStateStore(), launchContext,</span><br><span class="line">        credentials, metrics, containerTokenIdentifier);</span><br><span class="line"></span><br><span class="line">  ApplicationId applicationID =</span><br><span class="line">      containerId.getApplicationAttemptId().getApplicationId();</span><br><span class="line">  <span class="comment">// 将container放入context的containers中</span></span><br><span class="line">  <span class="keyword">if</span> (context.getContainers().putIfAbsent(containerId, container) != <span class="keyword">null</span>) &#123;</span><br><span class="line">    NMAuditLogger.logFailure(user, AuditConstants.START_CONTAINER,</span><br><span class="line">      <span class="string">"ContainerManagerImpl"</span>, <span class="string">"Container already running on this node!"</span>,</span><br><span class="line">      applicationID, containerId);</span><br><span class="line">    <span class="keyword">throw</span> RPCUtil.getRemoteException(<span class="string">"Container "</span> + containerIdStr</span><br><span class="line">        + <span class="string">" already is running on this node!!"</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">this</span>.readLock.lock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!serviceStopped) &#123;</span><br><span class="line">      <span class="comment">// Create the application</span></span><br><span class="line">      <span class="comment">// 创建application对象</span></span><br><span class="line">      Application application =</span><br><span class="line">          <span class="keyword">new</span> ApplicationImpl(dispatcher, user, applicationID, credentials, context);</span><br><span class="line">      <span class="comment">// 如果是该application的第一个container，则进行一些辅助操作，如启动log aggregation服务</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">null</span> == context.getApplications().putIfAbsent(applicationID,</span><br><span class="line">        application)) &#123;</span><br><span class="line">        LOG.info(<span class="string">"Creating a new application reference for app "</span> + applicationID);</span><br><span class="line">        LogAggregationContext logAggregationContext =</span><br><span class="line">            containerTokenIdentifier.getLogAggregationContext();</span><br><span class="line">        Map&lt;ApplicationAccessType, String&gt; appAcls =</span><br><span class="line">            container.getLaunchContext().getApplicationACLs();</span><br><span class="line">        <span class="comment">// logAggregationContext放入context中共用</span></span><br><span class="line">        context.getNMStateStore().storeApplication(applicationID,</span><br><span class="line">            buildAppProto(applicationID, user, credentials, appAcls,</span><br><span class="line">              logAggregationContext));</span><br><span class="line">        <span class="comment">// 触发ApplicationEventType.INIT_APPLICATION事件类型</span></span><br><span class="line">        dispatcher.getEventHandler().handle(</span><br><span class="line">          <span class="keyword">new</span> ApplicationInitEvent(applicationID, appAcls,</span><br><span class="line">            logAggregationContext));</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">this</span>.context.getNMStateStore().storeContainer(containerId, request);</span><br><span class="line">      <span class="comment">// 触发ApplicationEventType.INIT_CONTAINER事件类型</span></span><br><span class="line">      dispatcher.getEventHandler().handle(</span><br><span class="line">        <span class="keyword">new</span> ApplicationContainerInitEvent(container));</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> YarnException(</span><br><span class="line">          <span class="string">"Container start failed as the NodeManager is "</span> +</span><br><span class="line">          <span class="string">"in the process of shutting down"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">this</span>.readLock.unlock();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>startContainerInternal首先创建一个container对象，这也就开启了container的状态机之旅，新建的container状态是NEW。<br>随后判断该container是否是该application的第一个container，如果是则启动日志聚合功能，并触发ApplicationEventType.INIT_APPLICATION事件类型，使application的状态由<em>ApplicationState.NEW</em>变为<em>ApplicationState.INITING</em>，最后触发ApplicationEventType.INIT_CONTAINER事件类型，更新container的状态。如果不是则直接触发ApplicationEventType.INIT_CONTAINER事件类型。</p>
<p>if语句执行完之后，application的状态由NEW变为了INITING，此时将container信息存储在context中，并触发ApplicationEventType.INIT_CONTAINER事件类型，<em>由于此时application的状态是INITING，事件类型为INIT_CONTAINER，则处理次事件的handler是<code>InitContainerTransition</code>，随后application的状态依然是INITING</em>，看下InitContainerTransition.transition方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(ApplicationImpl app, ApplicationEvent event)</span> </span>&#123;</span><br><span class="line">  ApplicationContainerInitEvent initEvent =</span><br><span class="line">    (ApplicationContainerInitEvent) event;</span><br><span class="line">  Container container = initEvent.getContainer();</span><br><span class="line">  app.containers.put(container.getContainerId(), container);</span><br><span class="line">  LOG.info(<span class="string">"Adding "</span> + container.getContainerId()</span><br><span class="line">      + <span class="string">" to application "</span> + app.toString());</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">switch</span> (app.getApplicationState()) &#123;</span><br><span class="line">  <span class="keyword">case</span> RUNNING:</span><br><span class="line">    app.dispatcher.getEventHandler().handle(<span class="keyword">new</span> ContainerInitEvent(</span><br><span class="line">        container.getContainerId()));</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> INITING:</span><br><span class="line">  <span class="keyword">case</span> NEW:</span><br><span class="line">    <span class="comment">// these get queued up and sent out in AppInitDoneTransition</span></span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    <span class="keyword">assert</span> <span class="keyword">false</span> : <span class="string">"Invalid state for InitContainerTransition: "</span> +</span><br><span class="line">        app.getApplicationState();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看代码可见当application的状态是INITING和NEW时，触发INIT_CNONTAINER方法时不进行任何操作，则application的状态也不会发生变化。<em>只有当application的状态时RUNNING时</em>，才会触发由<code>ContainerEventType.INIT_CONTAINER</code>事件类型触发container的状态转移。</p>
<p>那么何时application的状态才会变为RUNNING呢？我们回到在新建application对象时触发的<code>ApplicationEventType.INIT_APPLICATION</code>事件类型上，此时application刚被new出来，则初始状态上NEW，则处理该事件类型的handler是<code>AppInitTransition</code>，下面看下<code>AppInitTransition.transition</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(ApplicationImpl app, ApplicationEvent event)</span> </span>&#123;</span><br><span class="line">  ApplicationInitEvent initEvent = (ApplicationInitEvent)event;</span><br><span class="line">  ...</span><br><span class="line">  app.dispatcher.getEventHandler().handle(</span><br><span class="line">      <span class="keyword">new</span> LogHandlerAppStartedEvent(app.appId, app.user,</span><br><span class="line">          app.credentials, ContainerLogsRetentionPolicy.ALL_CONTAINERS,</span><br><span class="line">          app.applicationACLs, app.logAggregationContext)); </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该transtion中是一个异步调度器，处理的事件是<code>LogHandlerAppStartedEvent</code>，事件类型是<code>LogHandlerEventType.APPLICATION_STARTED</code>，此事件类型是在<code>LogAggregationService</code>中处理的，看下对应的handle方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(LogHandlerEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">switch</span> (event.getType()) &#123;</span><br><span class="line">    <span class="keyword">case</span> APPLICATION_STARTED:</span><br><span class="line">      LogHandlerAppStartedEvent appStartEvent =</span><br><span class="line">          (LogHandlerAppStartedEvent) event;</span><br><span class="line">      initApp(appStartEvent.getApplicationId(), appStartEvent.getUser(),</span><br><span class="line">          appStartEvent.getCredentials(),</span><br><span class="line">          appStartEvent.getLogRetentionPolicy(),</span><br><span class="line">          appStartEvent.getApplicationAcls(),</span><br><span class="line">          appStartEvent.getLogAggregationContext());</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> CONTAINER_FINISHED:</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> APPLICATION_FINISHED:</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      ; <span class="comment">// Ignore</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>LogAggregationService从名字来看，只要是用来进行日志聚合的，处理的事件类型有<code>APPLICATION_STARTED</code>、<code>CONTAINER_FINISHED</code>和<code>APPLICATION_FINISHED</code>。<br>APPLICATION_STARTED事件类型会调用<code>initApp</code>方法，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initApp</span><span class="params">(<span class="keyword">final</span> ApplicationId appId, String user,</span></span></span><br><span class="line"><span class="function"><span class="params">    Credentials credentials, ContainerLogsRetentionPolicy logRetentionPolicy,</span></span></span><br><span class="line"><span class="function"><span class="params">    Map&lt;ApplicationAccessType, String&gt; appAcls,</span></span></span><br><span class="line"><span class="function"><span class="params">    LogAggregationContext logAggregationContext)</span> </span>&#123;</span><br><span class="line">  ApplicationEvent eventResponse;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    verifyAndCreateRemoteLogDir(getConfig());</span><br><span class="line">    initAppAggregator(appId, user, credentials, logRetentionPolicy, appAcls,</span><br><span class="line">        logAggregationContext);</span><br><span class="line">    eventResponse = <span class="keyword">new</span> ApplicationEvent(appId,</span><br><span class="line">        ApplicationEventType.APPLICATION_LOG_HANDLING_INITED);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (YarnRuntimeException e) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Application failed to init aggregation"</span>, e);</span><br><span class="line">    eventResponse = <span class="keyword">new</span> ApplicationEvent(appId,</span><br><span class="line">        ApplicationEventType.APPLICATION_LOG_HANDLING_FAILED);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">this</span>.dispatcher.getEventHandler().handle(eventResponse);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>logDir创建成功之后，会触发<code>ApplicationEventType.APPLICATION_LOG_HANDLING_INITED</code>事件类型，此时application的状态是INITING，则对应的handler是<code>AppLogInitDoneTransition</code>，看下transition方法:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(ApplicationImpl app, ApplicationEvent event)</span> </span>&#123;</span><br><span class="line">  app.dispatcher.getEventHandler().handle(</span><br><span class="line">      <span class="keyword">new</span> ApplicationLocalizationEvent(</span><br><span class="line">          LocalizationEventType.INIT_APPLICATION_RESOURCES, app));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当LogAggregationService为application创建了logDir并且启动日志聚合线程之后，才会通过AppLogInitDoneTransition处理APPLICATION_LOG_HANDLING_INITED事件。<br>在AppLogInitDoneTransition中触发<code>LocalizationEventType.INIT_APPLICATION_RESOURCES</code>在ResourceLocalizationService中被捕获，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(LocalizationEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> create log dir as $logdir/$user/$appId</span></span><br><span class="line">  <span class="keyword">switch</span> (event.getType()) &#123;</span><br><span class="line">  <span class="keyword">case</span> INIT_APPLICATION_RESOURCES:</span><br><span class="line">    handleInitApplicationResources(</span><br><span class="line">        ((ApplicationLocalizationEvent)event).getApplication());</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> INIT_CONTAINER_RESOURCES:</span><br><span class="line">    LOG.info(<span class="string">"&#123;intellij&#125; ResourceLocalizationsService handle INIT_CONTAINER_RESOURCES"</span>);</span><br><span class="line">    handleInitContainerResources((ContainerLocalizationRequestEvent) event);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> CACHE_CLEANUP:</span><br><span class="line">    handleCacheCleanup(event);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> CLEANUP_CONTAINER_RESOURCES:</span><br><span class="line">    handleCleanupContainerResources((ContainerLocalizationCleanupEvent)event);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> DESTROY_APPLICATION_RESOURCES:</span><br><span class="line">    handleDestroyApplicationResources(</span><br><span class="line">        ((ApplicationLocalizationEvent)event).getApplication());</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(<span class="string">"Unknown localization event: "</span> + event);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>handle中处理不同的事件类型，INIT_APPLICATION_RESOURCES由<code>handleInitApplicationResources</code>处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleInitApplicationResources</span><span class="params">(Application app)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 0) Create application tracking structs</span></span><br><span class="line">  String userName = app.getUser();</span><br><span class="line">  privateRsrc.putIfAbsent(userName, <span class="keyword">new</span> LocalResourcesTrackerImpl(userName,</span><br><span class="line">      <span class="keyword">null</span>, dispatcher, <span class="keyword">true</span>, <span class="keyword">super</span>.getConfig(), stateStore));</span><br><span class="line">  String appIdStr = ConverterUtils.toString(app.getAppId());</span><br><span class="line">  appRsrc.putIfAbsent(appIdStr, <span class="keyword">new</span> LocalResourcesTrackerImpl(app.getUser(),</span><br><span class="line">      app.getAppId(), dispatcher, <span class="keyword">false</span>, <span class="keyword">super</span>.getConfig(), stateStore));</span><br><span class="line">  <span class="comment">// 1) Signal container init</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// This is handled by the ApplicationImpl state machine and allows</span></span><br><span class="line">  <span class="comment">// containers to proceed with launching.</span></span><br><span class="line">  dispatcher.getEventHandler().handle(<span class="keyword">new</span> ApplicationInitedEvent(</span><br><span class="line">        app.getAppId()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里会触发<code>ApplicationEventType.APPLICATION_INITED</code>，在application的状态机中处理，对应的handler是<code>AppInitDoneTransition</code>，处理之后application的状态由INITING转化为RUNNING。AppInitDoneTransition.transition方法如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">transition</span><span class="params">(ApplicationImpl app, ApplicationEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Start all the containers waiting for ApplicationInit</span></span><br><span class="line">  <span class="keyword">for</span> (Container container : app.containers.values()) &#123;</span><br><span class="line">    app.dispatcher.getEventHandler().handle(<span class="keyword">new</span> ContainerInitEvent(</span><br><span class="line">          container.getContainerId()));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里会触发ContainerEventType.INIT_CONTAINER事件类型，由此事件类型开启container的状态转移。<br>在<code>startContainerInternal</code>中新建了一个container，初始化状态为NEW。此时当<code>ApplicationEventType.APPLICATION_INITED</code>触发之后，对应的handler会触发<code>ContainerEventType.INIT_CONTAINER</code>，container开始状态的转化，对应的handler是<code>RequestResourcesTransition</code>，看下transtion的代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ContainerState <span class="title">transition</span><span class="params">(ContainerImpl container,</span></span></span><br><span class="line"><span class="function"><span class="params">    ContainerEvent event)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">final</span> ContainerLaunchContext ctxt = container.launchContext;</span><br><span class="line">  container.metrics.initingContainer();</span><br><span class="line"></span><br><span class="line">  container.dispatcher.getEventHandler().handle(<span class="keyword">new</span> AuxServicesEvent</span><br><span class="line">      (AuxServicesEventType.CONTAINER_INIT, container));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Inform the AuxServices about the opaque serviceData</span></span><br><span class="line">  Map&lt;String,ByteBuffer&gt; csd = ctxt.getServiceData();</span><br><span class="line">  <span class="keyword">if</span> (csd != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// This can happen more than once per Application as each container may</span></span><br><span class="line">    <span class="comment">// have distinct service data</span></span><br><span class="line">    <span class="keyword">for</span> (Map.Entry&lt;String,ByteBuffer&gt; service : csd.entrySet()) &#123;</span><br><span class="line">      container.dispatcher.getEventHandler().handle(</span><br><span class="line">          <span class="keyword">new</span> AuxServicesEvent(AuxServicesEventType.APPLICATION_INIT,</span><br><span class="line">              container.user, container.containerId</span><br><span class="line">                  .getApplicationAttemptId().getApplicationId(),</span><br><span class="line">              service.getKey().toString(), service.getValue()));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Send requests for public, private resources</span></span><br><span class="line">  <span class="comment">// 为public和private资源发送远程请求，这里的请求协议是yarn_protos.ContainerLaunchContextProto</span></span><br><span class="line">  Map&lt;String,LocalResource&gt; cntrRsrc = ctxt.getLocalResources();</span><br><span class="line">  <span class="keyword">if</span> (!cntrRsrc.isEmpty()) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> (Map.Entry&lt;String,LocalResource&gt; rsrc : cntrRsrc.entrySet()) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          LocalResourceRequest req =</span><br><span class="line">              <span class="keyword">new</span> LocalResourceRequest(rsrc.getValue());</span><br><span class="line">          List&lt;String&gt; links = container.pendingResources.get(req);</span><br><span class="line">          <span class="keyword">if</span> (links == <span class="keyword">null</span>) &#123;</span><br><span class="line">            links = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">            container.pendingResources.put(req, links);</span><br><span class="line">          &#125;</span><br><span class="line">          links.add(rsrc.getKey());</span><br><span class="line">          <span class="keyword">switch</span> (rsrc.getValue().getVisibility()) &#123;</span><br><span class="line">          <span class="keyword">case</span> PUBLIC:</span><br><span class="line">            container.publicRsrcs.add(req);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          <span class="keyword">case</span> PRIVATE:</span><br><span class="line">            container.privateRsrcs.add(req);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          <span class="keyword">case</span> APPLICATION:</span><br><span class="line">            container.appRsrcs.add(req);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (URISyntaxException e) &#123;</span><br><span class="line">          LOG.info(<span class="string">"Got exception parsing "</span> + rsrc.getKey()</span><br><span class="line">              + <span class="string">" and value "</span> + rsrc.getValue());</span><br><span class="line">          <span class="keyword">throw</span> e;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (URISyntaxException e) &#123;</span><br><span class="line">      <span class="comment">// malformed resource; abort container launch</span></span><br><span class="line">      LOG.warn(<span class="string">"Failed to parse resource-request"</span>, e);</span><br><span class="line">      container.cleanup();</span><br><span class="line">      container.metrics.endInitingContainer();</span><br><span class="line">      <span class="keyword">return</span> ContainerState.LOCALIZATION_FAILED;</span><br><span class="line">    &#125;</span><br><span class="line">    Map&lt;LocalResourceVisibility, Collection&lt;LocalResourceRequest&gt;&gt; req =</span><br><span class="line">        <span class="keyword">new</span> HashMap&lt;LocalResourceVisibility, </span><br><span class="line">                    Collection&lt;LocalResourceRequest&gt;&gt;();</span><br><span class="line">    <span class="keyword">if</span> (!container.publicRsrcs.isEmpty()) &#123;</span><br><span class="line">      req.put(LocalResourceVisibility.PUBLIC, container.publicRsrcs);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!container.privateRsrcs.isEmpty()) &#123;</span><br><span class="line">      req.put(LocalResourceVisibility.PRIVATE, container.privateRsrcs);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!container.appRsrcs.isEmpty()) &#123;</span><br><span class="line">      req.put(LocalResourceVisibility.APPLICATION, container.appRsrcs);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    LOG.info(<span class="string">"&#123;intellij&#125; ContainerImpl new to localizing handle"</span>);</span><br><span class="line">    container.dispatcher.getEventHandler().handle(</span><br><span class="line">          <span class="keyword">new</span> ContainerLocalizationRequestEvent(container, req));</span><br><span class="line">    <span class="keyword">return</span> ContainerState.LOCALIZING;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    container.sendLaunchEvent();</span><br><span class="line">    container.metrics.endInitingContainer();</span><br><span class="line">    <span class="keyword">return</span> ContainerState.LOCALIZED;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从该handler的名字上可以看出其主要作用是请求container的resources，方法中会判断该container是否需要请求resources，</p>
<ul>
<li>如果需要则将资源进行本地化，触发<code>LocalizationEventType.INIT_CONTAINER_RESOURCES</code>，返回<code>ContainerState.LOCALIZING</code>，使<em>container由NEW转换为LOCALIZING状态</em>。而LocalizationEventType.INIT_CONTAINER_RESOURCES被<code>ResourceLocalizationService</code>进行捕获，开始Resource的本地化。</li>
<li>如果不需要则发送<code>LAUNCH_CONTAINER</code>事件，返回<code>ContainerState.LOCALIZED</code>，使<em>container从NEW直接转化为LOCALIZED</em>。</li>
</ul>
<p>这里我们跟下不需要请求resources的情况，调用<code>sendLaunchEvent</code>发送<code>ContainersLauncherEventType.LAUNCH_CONTAINER</code>事件类型，由<code>ContainersLauncher</code>捕获。其handle方法如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(ContainersLauncherEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> ContainersLauncher launches containers one by one!!</span></span><br><span class="line">  Container container = event.getContainer();</span><br><span class="line">  ContainerId containerId = container.getContainerId();</span><br><span class="line">  <span class="keyword">switch</span> (event.getType()) &#123;</span><br><span class="line">    <span class="keyword">case</span> LAUNCH_CONTAINER:</span><br><span class="line">      Application app =</span><br><span class="line">        context.getApplications().get(</span><br><span class="line">            containerId.getApplicationAttemptId().getApplicationId());</span><br><span class="line">      <span class="comment">// 新建一个ContainerLaunch线程，然后放入线程池containerLauncher中执行</span></span><br><span class="line">      ContainerLaunch launch =</span><br><span class="line">          <span class="keyword">new</span> ContainerLaunch(context, getConfig(), dispatcher, exec, app,</span><br><span class="line">            event.getContainer(), dirsHandler, containerManager);</span><br><span class="line">      containerLauncher.submit(launch);</span><br><span class="line">      running.put(containerId, launch);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> RECOVER_CONTAINER:</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> CLEANUP_CONTAINER:</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ContainerLaunch线程提交到containerLauncher线程池之后开始执行此线程。ContainerLaunch实现了Callable接口，则线程的执行逻辑在call方法中，如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Integer <span class="title">call</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// LaunchContainer is a blocking call. We are here almost means the</span></span><br><span class="line">    <span class="comment">// container is launched, so send out the event.</span></span><br><span class="line">    <span class="comment">// 处理ContainerEventType.CONTAINER_LAUNCHED，使container由LOCALIZED变为RUNNING</span></span><br><span class="line">    <span class="comment">// 并开始监控这个container使用的内存(物理内存和虚拟内存)</span></span><br><span class="line">    dispatcher.getEventHandler().handle(<span class="keyword">new</span> ContainerEvent(</span><br><span class="line">          containerID,</span><br><span class="line">          ContainerEventType.CONTAINER_LAUNCHED));</span><br><span class="line">    context.getNMStateStore().storeContainerLaunched(containerID);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if the container is signalled to be killed.</span></span><br><span class="line">    <span class="keyword">if</span> (!shouldLaunchContainer.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">      LOG.info(<span class="string">"Container "</span> + containerIdStr + <span class="string">" not launched as "</span></span><br><span class="line">          + <span class="string">"cleanup already called"</span>);</span><br><span class="line">      ret = ExitCode.TERMINATED.getExitCode();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">      exec.activateContainer(containerID, pidFilePath);</span><br><span class="line">      <span class="comment">// 执行启动container的脚本</span></span><br><span class="line">      ret = exec.launchContainer(container, nmPrivateContainerScriptPath,</span><br><span class="line">              nmPrivateTokensPath, user, appIdStr, containerWorkDir,</span><br><span class="line">              localDirs, logDirs);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Failed to launch container."</span>, e);</span><br><span class="line">    dispatcher.getEventHandler().handle(<span class="keyword">new</span> ContainerExitEvent(</span><br><span class="line">        containerID, ContainerEventType.CONTAINER_EXITED_WITH_FAILURE, ret,</span><br><span class="line">        e.getMessage()));</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    completed.set(<span class="keyword">true</span>);</span><br><span class="line">    exec.deactivateContainer(containerID);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      context.getNMStateStore().storeContainerCompleted(containerID, ret);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      LOG.error(<span class="string">"Unable to set exit code for container "</span> + containerID);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  dispatcher.getEventHandler().handle(</span><br><span class="line">      <span class="keyword">new</span> ContainerEvent(containerID,</span><br><span class="line">          ContainerEventType.CONTAINER_EXITED_WITH_SUCCESS));</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ContainerLaunch将container运行环境准备好之后，触发<code>ContainerEventType.CONTAINER_LAUNCHED</code>事件类型，LaunchTransition捕获之后，<strong>触发监控container的事件(监控container所需的物理内存和虚拟内存)</strong>，使container由LOCALIZED变为RUNNING。<br>触发ContainerEventType.CONTAINER_LAUNCHED事件类型之后，继续执行，调用<code>exec.launchContainer</code>启动container，<em>该方法在container执行完毕之后才会返回</em>。如果正常结束ret为0，触发<code>ContainerEventType.CONTAINER_EXITED_WITH_SUCCESS</code>事件类型，<em>使container由RUNNING变为EXITED_WITH_SUCCESS</em>。</p>
<p>这里exec.launchContainer的实现是<code>DefaultContainerExecutor.launchContainer</code>，在launchContainer方法中会执行<code>bash default_container_executor.sh</code>命令，default_container_executor.sh脚本的内容是:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">/bin/bash <span class="string">"/xx/usercache/user/appcache/application_1499422474367_0001/container_1499422474367_0001_01_000001/default_container_executor_session.sh"</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>调用了default_container_executor_session.sh脚本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">...</span><br><span class="line"><span class="built_in">exec</span> /bin/bash <span class="string">"/xx/usercache/user/appcache/application_1499422474367_0001/container_1499422474367_0001_01_000001/launch_container.sh"</span></span><br></pre></td></tr></table></figure>
<p>最后调用了launch_container.sh脚本，内容如下:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="built_in">exec</span> /bin/bash -c <span class="string">"<span class="variable">$JAVA_HOME</span>/bin/java -Dlog4j.configuration=container-log4j.properties -Dyarn.app.container.log.dir=/xx/application_1499422474367_0001/container_1499422474367_0001_01_000001 -Dyarn.app.container.log.filesize=0 -Dhadoop.root.logger=INFO,CLA  -Xmx1024m org.apache.hadoop.mapreduce.v2.app.MRAppMaster 1&gt;/xx/application_1499422474367_0001/container_1499422474367_0001_01_000001/stdout 2&gt;/xx/application_1499422474367_0001/container_1499422474367_0001_01_000001/stderr "</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>这个container是appmaster，所以这里调用的是<code>MRAppMaster</code>，并将标准输出写到stdout中，将标准错误输出写到stderr中。这也就是container的log目录里有三个文件的原因。</p>
<p>至此，AppMaster启动完毕，过程比较繁琐，下面附上一张图。随后介绍下MRAppMaster的运行过程。<br><img src="/blogimgs/appmaster/appMaster.png" alt="AppMaster启动流程" title="AppMaster启动流程"></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> ApplicationMaster </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之ApplicationMaster分配策略]]></title>
      <url>http://bigdatadecode.club/YARNSrcAMAssignPolicy.html</url>
      <content type="html"><![CDATA[<p>一次和朋友的谈话中涉及到ApplicationMaster的container分配策略是什么，我映像中是随机分配的，但他说是根据各节点空闲资源来分配的。<br>之前看代码的时候也没注意这块的逻辑，既然现在有了疑惑那就去代码里瞅瞅。</p>
<a id="more"></a>
<p>从MR的运行log中可以找到AM的container是在什么时候分配的，见log</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">2017-04-09 03:26:17,113 INFO org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptImpl: appattempt_1491729774382_0001_000001 State change from SUBMITTED to SCHEDULED</span><br><span class="line">2017-04-09 03:26:17,415 INFO org.apache.hadoop.yarn.server.resourcemanager.rmcontainer.RMContainerImpl: container_1491729774382_0001_01_000001 Container Transitioned from NEW to ALLOCATED</span><br></pre></td></tr></table></figure>
<p>AM container是在appattempt的状态由<code>SUBMITTED</code>变为<code>SCHEDULED</code>时初始化的。<br>appattempt由<code>SUBMITTED</code>变为<code>SCHEDULED</code>状态的处理逻辑为:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">ScheduleTransition</span></span></span><br><span class="line"><span class="class">    <span class="keyword">implements</span></span></span><br><span class="line"><span class="class">    <span class="title">MultipleArcTransition</span>&lt;<span class="title">RMAppAttemptImpl</span>, <span class="title">RMAppAttemptEvent</span>, <span class="title">RMAppAttemptState</span>&gt; </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> RMAppAttemptState <span class="title">transition</span><span class="params">(RMAppAttemptImpl appAttempt,</span></span></span><br><span class="line"><span class="function"><span class="params">      RMAppAttemptEvent event)</span> </span>&#123;</span><br><span class="line">    ApplicationSubmissionContext subCtx = appAttempt.submissionContext;</span><br><span class="line">    <span class="keyword">if</span> (!subCtx.getUnmanagedAM()) &#123;</span><br><span class="line">      <span class="comment">// Need reset #containers before create new attempt, because this request</span></span><br><span class="line">      <span class="comment">// will be passed to scheduler, and scheduler will deduct the number after</span></span><br><span class="line">      <span class="comment">// AM container allocated</span></span><br><span class="line">      <span class="comment">// 设置am container的请求</span></span><br><span class="line">      appAttempt.amReq.setNumContainers(<span class="number">1</span>);</span><br><span class="line">      appAttempt.amReq.setPriority(AM_CONTAINER_PRIORITY);</span><br><span class="line">      <span class="comment">// ResourceName为ANY表示任何机架上的任一机器</span></span><br><span class="line">      appAttempt.amReq.setResourceName(ResourceRequest.ANY);</span><br><span class="line">      appAttempt.amReq.setRelaxLocality(<span class="keyword">true</span>);</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// 由调度器来分配资源</span></span><br><span class="line">      Allocation amContainerAllocation =</span><br><span class="line">          appAttempt.scheduler.allocate(appAttempt.applicationAttemptId,</span><br><span class="line">              Collections.singletonList(appAttempt.amReq),</span><br><span class="line">              EMPTY_CONTAINER_RELEASE_LIST, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">return</span> RMAppAttemptState.SCHEDULED;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先为AM container构造container请求，其实从<code>appAttempt.amReq.setResourceName(ResourceRequest.ANY)</code>就可以看出am container的分配原则是随机的，因为在创建请求时对ResourceName并没有要求。但我们还是继续看下代码以验证下。<br>请求创建成功之后，由调度器来分配资源，这里默认使用的是Capacity调度，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CapacityScheduler.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Allocation <span class="title">allocate</span><span class="params">(ApplicationAttemptId applicationAttemptId,</span></span></span><br><span class="line"><span class="function"><span class="params">    List&lt;ResourceRequest&gt; ask, List&lt;ContainerId&gt; release, </span></span></span><br><span class="line"><span class="function"><span class="params">    List&lt;String&gt; blacklistAdditions, List&lt;String&gt; blacklistRemovals)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  FiCaSchedulerApp application = getApplicationAttempt(applicationAttemptId);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Release containers</span></span><br><span class="line">  releaseContainers(release, application);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">synchronized</span> (application) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span> (!ask.isEmpty()) &#123;</span><br><span class="line">      ...</span><br><span class="line">      application.showRequests();</span><br><span class="line">      <span class="comment">// 将请求该application attempt的map中</span></span><br><span class="line">      <span class="comment">// Update application requests</span></span><br><span class="line">      application.updateResourceRequests(ask);</span><br><span class="line">      application.showRequests();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    application.updateBlacklist(blacklistAdditions, blacklistRemovals);</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">return</span> application.getAllocation(getResourceCalculator(),</span><br><span class="line">                 clusterResource, getMinimumResourceCapability());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>CapacityScheduler分配请求时，调用<code>application.updateResourceRequests(ask)</code>将请求放入map中，等待nm心跳时来取。<br>这个application是<code>FiCaSchedulerApp</code>的对象，FiCaSchedulerApp其实对应的是application attempt。updateResurceRequests代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">updateResourceRequests</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    List&lt;ResourceRequest&gt; requests)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!isStopped) &#123;</span><br><span class="line">  	<span class="comment">// AppSchedulingInfo.updateResourceRequests</span></span><br><span class="line">    appSchedulingInfo.updateResourceRequests(requests, <span class="keyword">false</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>AppSchedulingInfo记录了application的所有消费情况，当然也包括<strong>这个application</strong>正在运行或者已经完成的container。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateResourceRequests</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    List&lt;ResourceRequest&gt; requests, <span class="keyword">boolean</span> recoverPreemptedRequest)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Update resource requests</span></span><br><span class="line">  <span class="keyword">for</span> (ResourceRequest request : requests) &#123;</span><br><span class="line">    Priority priority = request.getPriority();</span><br><span class="line">    String resourceName = request.getResourceName();</span><br><span class="line">    <span class="keyword">boolean</span> updatePendingResources = <span class="keyword">false</span>;</span><br><span class="line">    ResourceRequest lastRequest = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 如果request的ResourceName是ResourceRequest.ANY</span></span><br><span class="line">    <span class="comment">// 只有am container是ANY？？？不应该吧</span></span><br><span class="line">    <span class="keyword">if</span> (resourceName.equals(ResourceRequest.ANY)) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// ResourceRequest.ANY才置为true？？</span></span><br><span class="line">      updatePendingResources = <span class="keyword">true</span>;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Premature optimization?</span></span><br><span class="line">      <span class="comment">// Assumes that we won't see more than one priority request updated</span></span><br><span class="line">      <span class="comment">// in one call, reasonable assumption... however, it's totally safe</span></span><br><span class="line">      <span class="comment">// to activate same application more than once.</span></span><br><span class="line">      <span class="comment">// Thus we don't need another loop ala the one in decrementOutstanding()  </span></span><br><span class="line">      <span class="comment">// which is needed during deactivate.</span></span><br><span class="line">      <span class="keyword">if</span> (request.getNumContainers() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        activeUsersManager.activateApplication(user, applicationId);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// requests是一个请求列表 map</span></span><br><span class="line">    <span class="comment">// 查看requests中是否已有该优先级的请求</span></span><br><span class="line">    <span class="comment">// this.requests中存放的是这个application的request</span></span><br><span class="line">    Map&lt;String, ResourceRequest&gt; asks = <span class="keyword">this</span>.requests.get(priority);</span><br><span class="line">    <span class="comment">// 没有此优先级的请求，则new一个map</span></span><br><span class="line">    <span class="keyword">if</span> (asks == <span class="keyword">null</span>) &#123;</span><br><span class="line">      asks = <span class="keyword">new</span> HashMap&lt;String, ResourceRequest&gt;();</span><br><span class="line">      <span class="keyword">this</span>.requests.put(priority, asks);</span><br><span class="line">      <span class="keyword">this</span>.priorities.add(priority);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// asks不为null，查看asks中是否有与此请求ResourceName一样的请求</span></span><br><span class="line">    lastRequest = asks.get(resourceName);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (recoverPreemptedRequest &amp;&amp; lastRequest != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// Increment the number of containers to 1, as it is recovering a</span></span><br><span class="line">      <span class="comment">// single container.</span></span><br><span class="line">      request.setNumContainers(lastRequest.getNumContainers() + <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 把原来的请求拿出赋值给lastRequest，</span></span><br><span class="line">    <span class="comment">// 然后将新的request将入asks中，lastRequest怎么办？在哪处理的？</span></span><br><span class="line">    asks.put(resourceName, request);</span><br><span class="line">    <span class="keyword">if</span> (updatePendingResources) &#123;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Similarly, deactivate application?</span></span><br><span class="line">      <span class="keyword">if</span> (request.getNumContainers() &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        LOG.info(<span class="string">"checking for deactivate... "</span>);</span><br><span class="line">        checkForDeactivation();</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">int</span> lastRequestContainers = lastRequest != <span class="keyword">null</span> ? lastRequest</span><br><span class="line">          .getNumContainers() : <span class="number">0</span>;</span><br><span class="line">      Resource lastRequestCapability = lastRequest != <span class="keyword">null</span> ? lastRequest</span><br><span class="line">          .getCapability() : Resources.none();</span><br><span class="line">      metrics.incrPendingResources(user, request.getNumContainers(),</span><br><span class="line">          request.getCapability());</span><br><span class="line">      metrics.decrPendingResources(user, lastRequestContainers,</span><br><span class="line">          lastRequestCapability);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>updateResourceRequests主要是将请求放入<code>requests</code>中，等待nm心跳来取。不过这里有点模糊，在更新requests之前，如果存在该ResourceName的请求则取出，赋值给<code>lastRequest</code>，然后这个lastRequest是怎么处理的呢？不知道怎么回事，标注下。</p>
<!-- priority对应的value也是一个map，是ResourceName和ResourceRequest的key value对 -->
<p>更新完requests之后，回到<code>CapacityScheduler.allocate</code>中继续执行，return时执行<code>application.getAllocation</code>返回一个Allocation对象，这里会给container创建TOKEN，这里创建TOKEN的container是已经分配给nm的，也就是已经实例化的RMContainer，<em>是不是说调度器在调度container时，先创建一个请求，然后从<code>newlyAllocatedContainers</code>列表中取出上次请求container的响应结果</em>？</p>
<hr>
<p>am container的请求创建好之后，等待nm心跳来取</p>
<p>某个nm发送来了心跳，<br>代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// CapacityScheduler.handle  NODE_UPDATE事件</span></span><br><span class="line"><span class="keyword">case</span> NODE_UPDATE:</span><br><span class="line">&#123;</span><br><span class="line">  NodeUpdateSchedulerEvent nodeUpdatedEvent = (NodeUpdateSchedulerEvent)event;</span><br><span class="line">  RMNode node = nodeUpdatedEvent.getRMNode();</span><br><span class="line">  <span class="comment">// 更新该节点上的container的信息</span></span><br><span class="line">  <span class="comment">// 对刚分配到该节点的container进行launch，已经完成的container进行状态转移</span></span><br><span class="line">  nodeUpdate(node);</span><br><span class="line">  <span class="keyword">if</span> (!scheduleAsynchronously) &#123;</span><br><span class="line">  	<span class="comment">// 该节点取container请求</span></span><br><span class="line">    allocateContainersToNode(getNode(node.getNodeID()));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>nm与CapacityScheduler心跳之后，通过<code>nodeUpdate(node)</code>对改节点上已有的container进行状态更新，然后调用<code>allocateContainersToNode</code>去拉取新的container请求。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">allocateContainersToNode</span><span class="params">(FiCaSchedulerNode node)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Assign new containers...</span></span><br><span class="line">  <span class="comment">// 1. Check for reserved applications</span></span><br><span class="line">  <span class="comment">// 2. Schedule if there are no reservations</span></span><br><span class="line">  <span class="comment">// 如果有预留container的话先分配预留的container</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Try to schedule more if there are no reservations to fulfill</span></span><br><span class="line">  <span class="keyword">if</span> (node.getReservedContainer() == <span class="keyword">null</span>) &#123;</span><br><span class="line">  	<span class="comment">// 计算nm上是否还有空闲的资源进行分配container</span></span><br><span class="line">    <span class="keyword">if</span> (calculator.computeAvailableContainers(node.getAvailableResource(),</span><br><span class="line">      minimumAllocation) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(<span class="string">"Trying to schedule on node: "</span> + node.getNodeName() +</span><br><span class="line">            <span class="string">", available: "</span> + node.getAvailableResource());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 分配container</span></span><br><span class="line">      root.assignContainers(clusterResource, node, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    LOG.info(<span class="string">"Skipping scheduling since node "</span> + node.getNodeID() + </span><br><span class="line">        <span class="string">" is reserved by application "</span> + </span><br><span class="line">        node.getReservedContainer().getContainerId().getApplicationAttemptId()</span><br><span class="line">        );</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调度器给这台nm调度container时，先判断这台nm上是否有预留的container，如果有先对预留的container进行分配，如果没有预留的container才调用<code>root.assignContainers</code>进行调度。<br>root是<code>CSQueue</code>对象，CSQueue是一个接口，抽象类AbstractCSQueue实现了该接口，而AbstractCSQueue又被ParentQueue和ChildQueue继承，这里调用的是ParentQueue的assignContainers，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> CSAssignment <span class="title">assignContainers</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Resource clusterResource, FiCaSchedulerNode node, <span class="keyword">boolean</span> needToUnreserve)</span> </span>&#123;</span><br><span class="line">  CSAssignment assignment = </span><br><span class="line">      <span class="keyword">new</span> CSAssignment(Resources.createResource(<span class="number">0</span>, <span class="number">0</span>), NodeType.NODE_LOCAL);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// if our queue cannot access this node, just return</span></span><br><span class="line">  <span class="keyword">if</span> (!SchedulerUtils.checkQueueAccessToNode(accessibleLabels,</span><br><span class="line">      labelManager.getLabelsOnNode(node.getNodeID()))) &#123;</span><br><span class="line">    <span class="keyword">return</span> assignment;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">while</span> (canAssign(clusterResource, node)) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">boolean</span> localNeedToUnreserve = <span class="keyword">false</span>;</span><br><span class="line">    Set&lt;String&gt; nodeLabels = labelManager.getLabelsOnNode(node.getNodeID()); </span><br><span class="line">    <span class="comment">// Are we over maximum-capacity for this queue?</span></span><br><span class="line">    <span class="keyword">if</span> (!canAssignToThisQueue(clusterResource, nodeLabels)) &#123;</span><br><span class="line">      <span class="comment">// check to see if we could if we unreserve first</span></span><br><span class="line">      localNeedToUnreserve = assignToQueueIfUnreserve(clusterResource);</span><br><span class="line">      <span class="keyword">if</span> (!localNeedToUnreserve) &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Schedule</span></span><br><span class="line">    CSAssignment assignedToChild = </span><br><span class="line">        assignContainersToChildQueues(clusterResource, node, localNeedToUnreserve | needToUnreserve);</span><br><span class="line">    assignment.setType(assignedToChild.getType());</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// Do not assign more than one container if this isn't the root queue</span></span><br><span class="line">    <span class="comment">// or if we've already assigned an off-switch container</span></span><br><span class="line">    <span class="keyword">if</span> (!rootQueue || assignment.getType() == NodeType.OFF_SWITCH) &#123;</span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (rootQueue &amp;&amp; assignment.getType() == NodeType.OFF_SWITCH) &#123;</span><br><span class="line">          LOG.debug(<span class="string">"Not assigning more than one off-switch container,"</span> +</span><br><span class="line">              <span class="string">" assignments so far: "</span> + assignment);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; </span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> assignment;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>分配时，先判断此队列是否可以访问该nm，然后判断是否可以访问该nm上的label，都判断通过之后调用<code>assignContainersToChildQueues</code>进行分配，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> CSAssignment <span class="title">assignContainersToChildQueues</span><span class="params">(Resource cluster, </span></span></span><br><span class="line"><span class="function"><span class="params">    FiCaSchedulerNode node, <span class="keyword">boolean</span> needToUnreserve)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Try to assign to most 'under-served' sub-queue</span></span><br><span class="line">  <span class="keyword">for</span> (Iterator&lt;CSQueue&gt; iter=childQueues.iterator(); iter.hasNext();) &#123;</span><br><span class="line">    CSQueue childQueue = iter.next();</span><br><span class="line">    ...</span><br><span class="line">    assignment = childQueue.assignContainers(cluster, node, needToUnreserve);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// If we do assign, remove the queue and re-insert in-order to re-sort</span></span><br><span class="line">    <span class="keyword">if</span> (Resources.greaterThan(</span><br><span class="line">            resourceCalculator, cluster, </span><br><span class="line">            assignment.getResource(), Resources.none())) &#123;</span><br><span class="line">      <span class="comment">// Remove and re-insert to sort</span></span><br><span class="line">      iter.remove();</span><br><span class="line">      LOG.info(<span class="string">"Re-sorting assigned queue: "</span> + childQueue.getQueuePath() + </span><br><span class="line">          <span class="string">" stats: "</span> + childQueue);</span><br><span class="line">      childQueues.add(childQueue);</span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        printChildQueues();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> assignment;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>assignContainersToChildQueues调用ChildQueue的assignContainer进行分配，分配之后要讲改childQueue从队列中remove掉，然后重新插入到队列中，进行排序。<br>childQueue.assignContainers如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> CSAssignment <span class="title">assignContainers</span><span class="params">(Resource clusterResource,</span></span></span><br><span class="line"><span class="function"><span class="params">    FiCaSchedulerNode node, <span class="keyword">boolean</span> needToUnreserve)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// if our queue cannot access this node, just return</span></span><br><span class="line">  <span class="keyword">if</span> (!SchedulerUtils.checkQueueAccessToNode(accessibleLabels,</span><br><span class="line">      labelManager.getLabelsOnNode(node.getNodeID()))) &#123;</span><br><span class="line">    <span class="keyword">return</span> NULL_ASSIGNMENT;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Check for reserved resources</span></span><br><span class="line">  RMContainer reservedContainer = node.getReservedContainer();</span><br><span class="line">  <span class="keyword">if</span> (reservedContainer != <span class="keyword">null</span>) &#123;</span><br><span class="line">    FiCaSchedulerApp application = </span><br><span class="line">        getApplication(reservedContainer.getApplicationAttemptId());</span><br><span class="line">    <span class="keyword">synchronized</span> (application) &#123;</span><br><span class="line">      <span class="keyword">return</span> assignReservedContainer(application, node, reservedContainer,</span><br><span class="line">          clusterResource);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Try to assign containers to applications in order</span></span><br><span class="line">  <span class="keyword">for</span> (FiCaSchedulerApp application : activeApplications) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 加锁</span></span><br><span class="line">    <span class="keyword">synchronized</span> (application) &#123;</span><br><span class="line">      <span class="comment">// Check if this resource is on the blacklist</span></span><br><span class="line">      <span class="keyword">if</span> (SchedulerAppUtils.isBlacklisted(application, node, LOG)) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Schedule in priority order</span></span><br><span class="line">      <span class="keyword">for</span> (Priority priority : application.getPriorities()) &#123;</span><br><span class="line">      	<span class="comment">// 为什么是ANY？</span></span><br><span class="line">      	<span class="comment">// 如果当前application中的request中没有ANY就不分配？</span></span><br><span class="line">      	<span class="comment">// 想办法debug试一下</span></span><br><span class="line">        ResourceRequest anyRequest =</span><br><span class="line">            application.getResourceRequest(priority, ResourceRequest.ANY);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> == anyRequest) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Required resource</span></span><br><span class="line">        Resource required = anyRequest.getCapability();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Do we need containers at this 'priority'?</span></span><br><span class="line">        <span class="keyword">if</span> (application.getTotalRequiredResources(priority) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!<span class="keyword">this</span>.reservationsContinueLooking) &#123;</span><br><span class="line">          <span class="keyword">if</span> (!needContainers(application, priority, required)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"doesn't need containers based on reservation algo!"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        Set&lt;String&gt; requestedNodeLabels =</span><br><span class="line">            getRequestLabelSetByExpression(anyRequest</span><br><span class="line">                .getNodeLabelExpression());</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Compute user-limit &amp; set headroom</span></span><br><span class="line">        <span class="comment">// Note: We compute both user-limit &amp; headroom with the highest </span></span><br><span class="line">        <span class="comment">//       priority request as the target. </span></span><br><span class="line">        <span class="comment">//       This works since we never assign lower priority requests</span></span><br><span class="line">        <span class="comment">//       before all higher priority ones are serviced.</span></span><br><span class="line">        Resource userLimit = </span><br><span class="line">            computeUserLimitAndSetHeadroom(application, clusterResource, </span><br><span class="line">                required, requestedNodeLabels);          </span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Check queue max-capacity limit</span></span><br><span class="line">        <span class="keyword">if</span> (!canAssignToThisQueue(clusterResource, required,</span><br><span class="line">            labelManager.getLabelsOnNode(node.getNodeID()), application, <span class="keyword">true</span>)) &#123;</span><br><span class="line">          <span class="keyword">return</span> NULL_ASSIGNMENT;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Check user limit</span></span><br><span class="line">        <span class="keyword">if</span> (!assignToUser(clusterResource, application.getUser(), userLimit,</span><br><span class="line">            application, <span class="keyword">true</span>, requestedNodeLabels)) &#123;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Inform the application it is about to get a scheduling opportunity</span></span><br><span class="line">        <span class="comment">// 这又是什么鬼？增加调度的机会？</span></span><br><span class="line">        application.addSchedulingOpportunity(priority);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Try to schedule</span></span><br><span class="line">        <span class="comment">// 开始调度</span></span><br><span class="line">        CSAssignment assignment =  </span><br><span class="line">          assignContainersOnNode(clusterResource, node, application, priority, </span><br><span class="line">              <span class="keyword">null</span>, needToUnreserve);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Did the application skip this node?</span></span><br><span class="line">        <span class="keyword">if</span> (assignment.getSkipped()) &#123;</span><br><span class="line">          <span class="comment">// Don't count 'skipped nodes' as a scheduling opportunity!</span></span><br><span class="line">          application.subtractSchedulingOpportunity(priority);</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Did we schedule or reserve a container?</span></span><br><span class="line">        Resource assigned = assignment.getResource();</span><br><span class="line">        <span class="keyword">if</span> (Resources.greaterThan(</span><br><span class="line">            resourceCalculator, clusterResource, assigned, Resources.none())) &#123;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// Book-keeping </span></span><br><span class="line">          <span class="comment">// Note: Update headroom to account for current allocation too...</span></span><br><span class="line">          allocateResource(clusterResource, application, assigned,</span><br><span class="line">              labelManager.getLabelsOnNode(node.getNodeID()));</span><br><span class="line">          </span><br><span class="line">          <span class="comment">// Don't reset scheduling opportunities for non-local assignments</span></span><br><span class="line">          <span class="comment">// otherwise the app will be delayed for each non-local assignment.</span></span><br><span class="line">          <span class="comment">// This helps apps with many off-cluster requests schedule faster.</span></span><br><span class="line">          <span class="keyword">if</span> (assignment.getType() != NodeType.OFF_SWITCH) &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"Resetting scheduling opportunities"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            application.resetSchedulingOpportunities(priority);</span><br><span class="line">          &#125;</span><br><span class="line">          </span><br><span class="line">          <span class="comment">// Done</span></span><br><span class="line">          <span class="keyword">return</span> assignment;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// Do not assign out of order w.r.t priorities</span></span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"post-assignContainers for application "</span></span><br><span class="line">        + application.getApplicationId());</span><br><span class="line">    &#125;</span><br><span class="line">    application.showRequests();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> NULL_ASSIGNMENT;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>LeafQueue.assignContainers会从遍历当前队列中正在运行的application的container请求，通过一系列的逻辑之后调用<code>assignContainersOnNode</code>进行调度</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> CSAssignment <span class="title">assignContainersOnNode</span><span class="params">(Resource clusterResource,</span></span></span><br><span class="line"><span class="function"><span class="params">    FiCaSchedulerNode node, FiCaSchedulerApp application, Priority priority,</span></span></span><br><span class="line"><span class="function"><span class="params">    RMContainer reservedContainer, <span class="keyword">boolean</span> needToUnreserve)</span> </span>&#123;</span><br><span class="line">  Resource assigned = Resources.none();</span><br><span class="line">  <span class="comment">// 如果ResourceName是NODE_LOCAL</span></span><br><span class="line">  ResourceRequest nodeLocalResourceRequest =</span><br><span class="line">      application.getResourceRequest(priority, node.getNodeName());</span><br><span class="line">  <span class="keyword">if</span> (nodeLocalResourceRequest != <span class="keyword">null</span>) &#123;</span><br><span class="line">    assigned = </span><br><span class="line">        assignNodeLocalContainers(clusterResource, nodeLocalResourceRequest, </span><br><span class="line">            node, application, priority, reservedContainer, needToUnreserve); </span><br><span class="line">    <span class="keyword">if</span> (Resources.greaterThan(resourceCalculator, clusterResource, </span><br><span class="line">        assigned, Resources.none())) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> CSAssignment(assigned, NodeType.NODE_LOCAL);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 如果ResourceName是Rack-local</span></span><br><span class="line">  ResourceRequest rackLocalResourceRequest =</span><br><span class="line">      application.getResourceRequest(priority, node.getRackName());</span><br><span class="line">  <span class="keyword">if</span> (rackLocalResourceRequest != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!rackLocalResourceRequest.getRelaxLocality()) &#123;</span><br><span class="line">      <span class="keyword">return</span> SKIP_ASSIGNMENT;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    assigned = </span><br><span class="line">        assignRackLocalContainers(clusterResource, rackLocalResourceRequest, </span><br><span class="line">            node, application, priority, reservedContainer, needToUnreserve);</span><br><span class="line">    <span class="keyword">if</span> (Resources.greaterThan(resourceCalculator, clusterResource, </span><br><span class="line">        assigned, Resources.none())) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">new</span> CSAssignment(assigned, NodeType.RACK_LOCAL);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 如果ResourceName是Off-switch，也就是ANY</span></span><br><span class="line">  ResourceRequest offSwitchResourceRequest =</span><br><span class="line">      application.getResourceRequest(priority, ResourceRequest.ANY);</span><br><span class="line">  <span class="keyword">if</span> (offSwitchResourceRequest != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!offSwitchResourceRequest.getRelaxLocality()) &#123;</span><br><span class="line">      <span class="keyword">return</span> SKIP_ASSIGNMENT;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> CSAssignment(</span><br><span class="line">        assignOffSwitchContainers(clusterResource, offSwitchResourceRequest,</span><br><span class="line">            node, application, priority, reservedContainer, needToUnreserve), </span><br><span class="line">            NodeType.OFF_SWITCH);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> SKIP_ASSIGNMENT;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>assignContainersOnNode会根据请求中资源的类型进行不同的逻辑处理，由于am container中ResourceRequest为ANY，所以这里只关注下Off-switch的处理逻辑，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Resource <span class="title">assignOffSwitchContainers</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Resource clusterResource, ResourceRequest offSwitchResourceRequest,</span></span></span><br><span class="line"><span class="function"><span class="params">    FiCaSchedulerNode node, FiCaSchedulerApp application, Priority priority, </span></span></span><br><span class="line"><span class="function"><span class="params">    RMContainer reservedContainer, <span class="keyword">boolean</span> needToUnreserve)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (canAssign(application, priority, node, NodeType.OFF_SWITCH, </span><br><span class="line">      reservedContainer)) &#123;</span><br><span class="line">    <span class="keyword">return</span> assignContainer(clusterResource, node, application, priority,</span><br><span class="line">        offSwitchResourceRequest, NodeType.OFF_SWITCH, reservedContainer,</span><br><span class="line">        needToUnreserve);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> Resources.none();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>assignOffSwitchContainers又调用了assignContainer，继续跟踪</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Resource <span class="title">assignContainer</span><span class="params">(Resource clusterResource, FiCaSchedulerNode node, </span></span></span><br><span class="line"><span class="function"><span class="params">    FiCaSchedulerApp application, Priority priority, </span></span></span><br><span class="line"><span class="function"><span class="params">    ResourceRequest request, NodeType type, RMContainer rmContainer,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> needToUnreserve)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// container的资源大小  </span></span><br><span class="line">  Resource capability = request.getCapability();</span><br><span class="line">  <span class="comment">// 节点可用的资源大小</span></span><br><span class="line">  Resource available = node.getAvailableResource();</span><br><span class="line">  <span class="comment">// 节点总共资源大小</span></span><br><span class="line">  Resource totalResource = node.getTotalResource();</span><br><span class="line">  <span class="comment">// 判断请求的资源是否超过了节点的总量</span></span><br><span class="line">  <span class="keyword">if</span> (!Resources.fitsIn(capability, totalResource)) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Node : "</span> + node.getNodeID()</span><br><span class="line">        + <span class="string">" does not have sufficient resource for request : "</span> + request</span><br><span class="line">        + <span class="string">" node total capability : "</span> + node.getTotalResource());</span><br><span class="line">    <span class="keyword">return</span> Resources.none();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">assert</span> Resources.greaterThan(</span><br><span class="line">      resourceCalculator, clusterResource, available, Resources.none());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Create the container if necessary</span></span><br><span class="line">  <span class="comment">// 生成containerId</span></span><br><span class="line">  Container container = </span><br><span class="line">      getContainer(rmContainer, application, node, capability, priority);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 先判断是否可以分配预留的container，</span></span><br><span class="line">  <span class="comment">// 可以分配正常的container时，才去判断空闲的资源是否可以分配</span></span><br><span class="line">  <span class="comment">// Can we allocate a container on this node?</span></span><br><span class="line">  <span class="keyword">int</span> availableContainers = </span><br><span class="line">      resourceCalculator.computeAvailableContainers(available, capability);</span><br><span class="line">  <span class="keyword">if</span> (availableContainers &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Allocate...</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// Inform the application</span></span><br><span class="line">    RMContainer allocatedContainer = </span><br><span class="line">        application.allocate(type, node, priority, request, container);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Does the application need this resource?</span></span><br><span class="line">    <span class="keyword">if</span> (allocatedContainer == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> Resources.none();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 通知node进行分配，将container放入launchedContainers map中</span></span><br><span class="line">    <span class="comment">// Inform the node</span></span><br><span class="line">    node.allocateContainer(allocatedContainer);</span><br><span class="line"></span><br><span class="line">    LOG.info(<span class="string">"assignedContainer"</span> +</span><br><span class="line">        <span class="string">" application attempt="</span> + application.getApplicationAttemptId() +</span><br><span class="line">        <span class="string">" container="</span> + container + </span><br><span class="line">        <span class="string">" queue="</span> + <span class="keyword">this</span> + </span><br><span class="line">        <span class="string">" clusterResource="</span> + clusterResource);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> container.getResource();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// if we are allowed to allocate but this node doesn't have space, reserve it or</span></span><br><span class="line">    <span class="comment">// if this was an already a reserved container, reserve it again</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> Resources.none();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>assignContainer首先判断container请求的资源是否超过了节点的总资源量，如果没有超过调用<code>getContainer</code>查看当前节点上是否有预留的container，没有则<code>createContainer</code>，<strong>生成containerId</strong>。containerId生成之后，去判断当前节点上的空闲资源能否够分配，如果可以的话就调用<code>application.allocate</code>进行分配，application是FiCaSchedulerApp的对象。最后将container放入<code>launchedContainers</code>中，随后会心跳返回给node。allocate代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">public</span> RMContainer <span class="title">allocate</span><span class="params">(NodeType type, FiCaSchedulerNode node,</span></span></span><br><span class="line"><span class="function"><span class="params">    Priority priority, ResourceRequest request, </span></span></span><br><span class="line"><span class="function"><span class="params">    Container container)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// container在RM端称为RMcontainer</span></span><br><span class="line">  <span class="comment">// Create RMContainer</span></span><br><span class="line">  RMContainer rmContainer = <span class="keyword">new</span> RMContainerImpl(container, <span class="keyword">this</span></span><br><span class="line">      .getApplicationAttemptId(), node.getNodeID(),</span><br><span class="line">      appSchedulingInfo.getUser(), <span class="keyword">this</span>.rmContext);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Add it to allContainers list.</span></span><br><span class="line">  <span class="comment">// 将生成的container放入allContainers list</span></span><br><span class="line">  <span class="comment">// 调度器在调度的时候从中取出container</span></span><br><span class="line">  newlyAllocatedContainers.add(rmContainer);</span><br><span class="line">  liveContainers.put(container.getId(), rmContainer);    </span><br><span class="line"></span><br><span class="line">  <span class="comment">// Update consumption and track allocations</span></span><br><span class="line">  List&lt;ResourceRequest&gt; resourceRequestList = appSchedulingInfo.allocate(</span><br><span class="line">      type, node, priority, request, container);</span><br><span class="line">  Resources.addTo(currentConsumption, container.getResource());</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Update resource requests related to "request" and store in RMContainer </span></span><br><span class="line">  ((RMContainerImpl)rmContainer).setResourceRequests(resourceRequestList);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Inform the container</span></span><br><span class="line">  <span class="comment">// 时间调度器来通知container已经准备好，触发container状态机</span></span><br><span class="line">  rmContainer.handle(</span><br><span class="line">      <span class="keyword">new</span> RMContainerEvent(container.getId(), RMContainerEventType.START));</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> rmContainer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>allocate创建一个RMContainer，并将其放入allContainers列表<code>newlyAllocatedContainers</code>中，并触发了RMContainer的状态机变化。<br>调度器从newlyAllocatedContainers取出container分配给node。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>大致的流程顺着代码理解的差不多了，但一些细节还是没有搞太清楚，随后详细debug下，在更新吧。<br><strong>说下我目前的理解，调度器首先创建一个container请求，并查看<code>newlyAllocatedContainers</code>中是否有可调度的container，如果有则创建该container的TOKEN。然后nm来进行心跳的时候，从requests中取出对应的请求进行实例化，随后再放入<code>newlyAllocatedContainers</code>列表中，等待调度。</strong></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> ApplicationMaster </tag>
            
            <tag> 分配策略 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Intellij idea中依赖模块间的test代码]]></title>
      <url>http://bigdatadecode.club/Intellij%20idea%E4%B8%AD%E4%BE%9D%E8%B5%96%E6%A8%A1%E5%9D%97%E9%97%B4%E7%9A%84test%E4%BB%A3%E7%A0%81.html</url>
      <content type="html"><![CDATA[<p>为了方便平时看代码和debug代码，我在hadoop的源码中新建了个模块<em>hadoop-hunhun</em>，此模块依赖其余hadoop模块，这样就可以直接在src中debug代码了。</p>
<p>在使用<code>MiniMRClientCluster</code>进行mr测试时，发现需要依赖一些模块的test代码，下面就来记录下载intellij idea中模块怎么依赖其余模块的test代码。</p>
<a id="more"></a>
<p>首先找到所依赖的test代码在哪个模块，这里会依赖jobclient、yarn-server-test和common模块中的test代码，操作步骤为：</p>
<p>File -&gt; Project Structure<br>点击新建的hadoop-hunhun模块，选择Dependencies选项卡，这里我已经添加了对其它模块的依赖，如图：<br><img src="/blogimgs/modulesDependence/dependence.png" alt="dependencies" title="dependencies"></p>
<p>在添加test依赖之前，要在test所在模块中找到test代码的输出路径，以jobclient中test为例，在<em>Project Structure</em>中点击<code>hadoop-mapreduce-client-jobclient</code>模块，然后选择<code>Paths</code>，将其<strong>Test Output path</strong>的内容进行复制，如下：<br><img src="/blogimgs/modulesDependence/testoutput.png" alt="TestOutputPath" title="TestOutputPath"></p>
<p>然后再次回到<em>hadoop-hunhun</em>模块中的dependencies选项卡中，点击右下角的”+”,选择<strong>Library</strong>，如下：<br><img src="/blogimgs/modulesDependence/library.png" alt="Library" title="Library"><br>在弹出的对话框中点击<em>New Library</em>，选择<em>java</em>，输入在上一步中复制的Test Output Path，点击ok，之后点击Add Selected。</p>
<p>完成上述步骤则添加成功。</p>
<p>之后就可以利用<code>MiniMRClientCluster</code>在src中debug代码了。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> Intellij idea </tag>
            
            <tag> model dependence </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[flume事务解析]]></title>
      <url>http://bigdatadecode.club/flume%E4%BA%8B%E5%8A%A1%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p>在flume中<em>事务</em>是一个重要的概念，事务保证了数据的可用性。这里的事务有别于数据库中的事务，比事务在回滚时，可能会造成数据重复，<em>所以flume保证的是每条数据最少发送一次，以此来保证数据不丢失</em>。</p>
<p>此篇从具体的数据流中分析事务，配置的数据流是<em>taildir+kafkachannel</em>，然后<em>kafkachannel+hdfsSink</em>。</p>
<p>kafkachannel中维护了两个事务，分别是put事务和take事务。</p>
<a id="more"></a>
<h2 id="put事务"><a href="#put事务" class="headerlink" title="put事务"></a>put事务</h2><p>kafkachannel的put事务是由taildir触发的，我们从代码中跟下put事务的流程。</p>
<p>taildir的入口是TaildirSource.process，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Status <span class="title">process</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Status status = Status.READY;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    existingInodes.clear();</span><br><span class="line">    existingInodes.addAll(reader.updateTailFiles());</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">long</span> inode : existingInodes) &#123;</span><br><span class="line">      TailFile tf = reader.getTailFiles().get(inode);</span><br><span class="line">      <span class="comment">// 判断是否需要tail</span></span><br><span class="line">      <span class="comment">// 判断规则，修改时间是否大于上次记录的tial时间，记录的postition是否大于该文件的length</span></span><br><span class="line">      <span class="keyword">if</span> (tf.needTail()) &#123;</span><br><span class="line">        tailFileProcess(tf, <span class="keyword">true</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    closeTailFiles();</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当file的修改时间大于记录的上次tail时间或者记录的postition大于file的length时(从0处tail)，需要tail该file。<br>文件的tail逻辑在<code>tailFileProcess</code>代码中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">tailFileProcess</span><span class="params">(TailFile tf, <span class="keyword">boolean</span> backoffWithoutNL)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    reader.setCurrentFile(tf);</span><br><span class="line">    <span class="comment">// 从文件中读取batchSize条数据</span></span><br><span class="line">    List&lt;Event&gt; events = reader.readEvents(batchSize, backoffWithoutNL);</span><br><span class="line">    <span class="keyword">if</span> (events.isEmpty()) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    sourceCounter.addToEventReceivedCount(events.size());</span><br><span class="line">    sourceCounter.incrementAppendBatchReceivedCount();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 事务的实现</span></span><br><span class="line">      getChannelProcessor().processEventBatch(events);</span><br><span class="line">      reader.commit();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ChannelException ex) &#123;</span><br><span class="line">      logger.warn(<span class="string">"The channel is full or unexpected failure. "</span> +</span><br><span class="line">          <span class="string">"The source will try again after "</span> + retryInterval + <span class="string">" ms"</span>);</span><br><span class="line">      TimeUnit.MILLISECONDS.sleep(retryInterval);</span><br><span class="line">      retryInterval = retryInterval &lt;&lt; <span class="number">1</span>;</span><br><span class="line">      retryInterval = Math.min(retryInterval, maxRetryInterval);</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    retryInterval = <span class="number">1000</span>;</span><br><span class="line">    sourceCounter.addToEventAcceptedCount(events.size());</span><br><span class="line">    sourceCounter.incrementAppendBatchAcceptedCount();</span><br><span class="line">    <span class="comment">// 追上写入的速度之后才会退出当前file？是否存在其它文件无法得到tail的机会？？</span></span><br><span class="line">    <span class="comment">// 这应该是个bug</span></span><br><span class="line">    <span class="keyword">if</span> (events.size() &lt; batchSize) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>上面的bug是当一个fileGroup中有多个正在写入的文件时，如果某个文件的写入量大，致使每次都能从中读取batchSize条数据，则其它文件将没有机会被读取。<br>这个bug我已提交到社区<a href="https://issues.apache.org/jira/browse/FLUME-3101" target="_blank" rel="noopener">FLUME-3101</a></p>
</blockquote>
<p>下面看下事务具体是怎么实现的，<br><code>getChannelProcessor().processEventBatch(events)</code> -&gt; <code>ChannelProcesser.processEventBatch</code>，看下processEventBatch的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processEventBatch</span><span class="params">(List&lt;Event&gt; events)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 将event与channel组成map</span></span><br><span class="line">  <span class="keyword">for</span> (Event event : events) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Process required channels</span></span><br><span class="line">  <span class="keyword">for</span> (Channel reqChannel : reqChannelQueue.keySet()) &#123;</span><br><span class="line">  	<span class="comment">// 得到channel对应的事务</span></span><br><span class="line">    Transaction tx = reqChannel.getTransaction();</span><br><span class="line">    Preconditions.checkNotNull(tx, <span class="string">"Transaction object must not be null"</span>);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 开始事务</span></span><br><span class="line">      tx.begin();</span><br><span class="line">      <span class="comment">// 处理事务，这里是先将event写入内存，然后由commit批量将events写入kafka</span></span><br><span class="line">      List&lt;Event&gt; batch = reqChannelQueue.get(reqChannel);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (Event event : batch) &#123;</span><br><span class="line">        reqChannel.put(event);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 提交事务，也是一个事务的结束</span></span><br><span class="line">      tx.commit();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      <span class="comment">// 发生议程，进行事务回滚</span></span><br><span class="line">      tx.rollback();</span><br><span class="line">      <span class="keyword">if</span> (t <span class="keyword">instanceof</span> Error) &#123;</span><br><span class="line">        LOG.error(<span class="string">"Error while writing to required channel: "</span> + reqChannel, t);</span><br><span class="line">        <span class="keyword">throw</span> (Error) t;</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (t <span class="keyword">instanceof</span> ChannelException) &#123;</span><br><span class="line">        <span class="keyword">throw</span> (ChannelException) t;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> ChannelException(<span class="string">"Unable to put batch on required "</span> +</span><br><span class="line">            <span class="string">"channel: "</span> + reqChannel, t);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (tx != <span class="keyword">null</span>) &#123;</span><br><span class="line">        tx.close();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Process optional channels</span></span><br><span class="line">  <span class="keyword">for</span> (Channel optChannel : optChannelQueue.keySet()) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先从该source中绑定的channel中拿到对应的<code>Transaction</code>，然后调用<code>begin</code>方法开始事务，等数据处理结束之后，调用<code>commit</code>提交事务，如果处理数据的过程中发生错误，则在catch中捕获，调用<code>rollback</code>进行事务回滚。</p>
<p>先看下数据处理的逻辑，通过<code>reqChannel.put(event)</code>将数据将入channel的内存中。看似调用的是channel的方法，其实channel的put只是对Transaction的put进行了下封装，而<code>Transaction.put</code>的具体实现是在channel中的Transaction.doPut里实现的。<br><code>reqChannel.put(event)</code> -&gt; <code>BasicChannelSemantics.put</code> -&gt; <code>BasicTransactionSemantics.put</code> -&gt; <code>BasicTransactionSemantics.duPut</code><br>其中<code>doPut</code>是一个抽象方法，其具体实现放在各个channel的Transaction中。这里使用的kafkaChannel，其实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doPut</span><span class="params">(Event event)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">// 事务类型 PUT or TAKE</span></span><br><span class="line">  type = TransactionType.PUT;</span><br><span class="line">  ...</span><br><span class="line">  Integer partitionId = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (staticPartitionId != <span class="keyword">null</span>) &#123;</span><br><span class="line">      partitionId = staticPartitionId;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//Allow a specified header to override a static ID</span></span><br><span class="line">    <span class="keyword">if</span> (partitionHeader != <span class="keyword">null</span>) &#123;</span><br><span class="line">      String headerVal = event.getHeaders().get(partitionHeader);</span><br><span class="line">      <span class="keyword">if</span> (headerVal != <span class="keyword">null</span>) &#123;</span><br><span class="line">        partitionId = Integer.parseInt(headerVal);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将event构建一个ProducerRecord对象放入producerRecords中，</span></span><br><span class="line">    <span class="comment">// 等待commit时写入kafka</span></span><br><span class="line">    <span class="keyword">if</span> (partitionId != <span class="keyword">null</span>) &#123;</span><br><span class="line">      producerRecords.get().add(</span><br><span class="line">          <span class="keyword">new</span> ProducerRecord&lt;String, <span class="keyword">byte</span>[]&gt;(topic.get(), partitionId, key,</span><br><span class="line">                                             serializeValue(event, parseAsFlumeEvent)));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      producerRecords.get().add(</span><br><span class="line">          <span class="keyword">new</span> ProducerRecord&lt;String, <span class="keyword">byte</span>[]&gt;(topic.get(), key,</span><br><span class="line">                                             serializeValue(event, parseAsFlumeEvent)));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (NumberFormatException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ChannelException(<span class="string">"Non integer partition id specified"</span>, e);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ChannelException(<span class="string">"Error while serializing event"</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>doPut首先给事务的类型赋值，然后将event放入内存中，如果此过程中没有发生错误，则会调用<code>commit</code>对内存中的event提交到kafka中。</p>
<p>下面看下<code>commit</code>的代码，commit的调用逻辑和put类似，具体实现是在KafkaChannel.KafkaTransaction的duCommit中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doCommit</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.NONE)) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 判断需要commit的事务类型</span></span><br><span class="line">  <span class="comment">// 此处先分析PUT的commit</span></span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.PUT)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!kafkaFutures.isPresent()) &#123;</span><br><span class="line">      kafkaFutures = Optional.of(<span class="keyword">new</span> LinkedList&lt;Future&lt;RecordMetadata&gt;&gt;());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">long</span> batchSize = producerRecords.get().size();</span><br><span class="line">      <span class="keyword">long</span> startTime = System.nanoTime();</span><br><span class="line">      <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">for</span> (ProducerRecord&lt;String, <span class="keyword">byte</span>[]&gt; record : producerRecords.get()) &#123;</span><br><span class="line">        index++;</span><br><span class="line">        <span class="comment">// 多线程之间共享一个producer实例(官方推荐，但也可以根据自己的情况而定)</span></span><br><span class="line">        <span class="comment">// The producer is thread safe and sharing a single producer instance </span></span><br><span class="line">        <span class="comment">// across threads will generally be faster than having multiple instances.</span></span><br><span class="line">        kafkaFutures.get().add(producer.send(record, <span class="keyword">new</span> ChannelCallback(index, startTime)));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//prevents linger.ms from being a problem</span></span><br><span class="line">      <span class="comment">// 强制发送累加队列RecordAccumulator中的数据</span></span><br><span class="line">      producer.flush();</span><br><span class="line">      <span class="comment">// 等待各线程将数据发送至kafka</span></span><br><span class="line">      <span class="keyword">for</span> (Future&lt;RecordMetadata&gt; future : kafkaFutures.get()) &#123;</span><br><span class="line">        future.get();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">long</span> endTime = System.nanoTime();</span><br><span class="line">      counter.addToKafkaEventSendTimer((endTime - startTime) / (<span class="number">1000</span> * <span class="number">1000</span>));</span><br><span class="line">      counter.addToEventPutSuccessCount(batchSize);</span><br><span class="line">      producerRecords.get().clear();</span><br><span class="line">      kafkaFutures.get().clear();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">      logger.warn(<span class="string">"Sending events to Kafka failed"</span>, ex);</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ChannelException(<span class="string">"Commit failed as send to Kafka failed"</span>,</span><br><span class="line">              ex);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PUT类型的事务和TAKE类型的事务都是在doCommit中提交，这里调用的都是kafka的Java Api，需要注意的是各个线程之间共享一个producer实例，event发送到kafka可以认为是同步发送，因为调用了<code>future.get</code>等待各个线程的结束。<br>这里还调用了<code>producer.flush()</code>，这是为了防止配置了<code>linger.ms</code>对record进行合并发送，flush强制将队列中的数据发送到kafka。</p>
<p>无论是在doPut还是在doCommit中发生错误，都会对事务进行回滚。回滚是在doRollback中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doRollback</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.NONE)) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.PUT)) &#123;</span><br><span class="line">  	<span class="comment">// PUT时发生错误，则把内存中的数据清空</span></span><br><span class="line">  	<span class="comment">// 但没有对回滚的次数进行统计</span></span><br><span class="line">    producerRecords.get().clear();</span><br><span class="line">    kafkaFutures.get().clear();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>由上面的分析可知，kafkachannel是将event通过doPut写入内存，然后通过doCommit将内存中的数据发送到kafka，这个事务是将event写入到kafka时才结束。<br>而memorychannel则是将event通过doPut写入内存(putList)中，然后通过doCommit将putList中的数据写入queue中，写入queue成功则事务结束。可见如果使用kafkachannel向kafka中写数据时会比memorychannel要高效，更重要的是能保证数据的事务性</em>。</p>
<p>下面看下take事务</p>
<h2 id="take事务"><a href="#take事务" class="headerlink" title="take事务"></a>take事务</h2><p>kafkachannel中的take事务是由sink触发的，这里是指hdfsSink，下面看下take的事务代码。</p>
<p>此处的sink用的是HDFSEventSink，其process代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 非线程安全</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Status <span class="title">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException </span>&#123;</span><br><span class="line">  <span class="comment">// 拿到sink关联的channel</span></span><br><span class="line">  Channel channel = getChannel();</span><br><span class="line">  <span class="comment">// 从channel中得到Transaction</span></span><br><span class="line">  Transaction transaction = channel.getTransaction();</span><br><span class="line">  List&lt;BucketWriter&gt; writers = Lists.newArrayList();</span><br><span class="line">  <span class="comment">// 开始事务</span></span><br><span class="line">  transaction.begin();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> txnEventCount = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (txnEventCount = <span class="number">0</span>; txnEventCount &lt; batchSize; txnEventCount++) &#123;</span><br><span class="line">      <span class="comment">// 从channel中取出一条数据</span></span><br><span class="line">      Event event = channel.take();</span><br><span class="line">      <span class="keyword">if</span> (event == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">synchronized</span> (sfWritersLock) &#123;</span><br><span class="line">        bucketWriter = sfWriters.get(lookupPath);</span><br><span class="line">        <span class="comment">// we haven't seen this file yet, so open it and cache the handle</span></span><br><span class="line">        <span class="comment">// 没有文件的句柄，则新建一个</span></span><br><span class="line">        <span class="keyword">if</span> (bucketWriter == <span class="keyword">null</span>) &#123;</span><br><span class="line">          hdfsWriter = writerFactory.getWriter(fileType);</span><br><span class="line">          bucketWriter = initializeBucketWriter(realPath, realName,</span><br><span class="line">            lookupPath, hdfsWriter, closeCallback);</span><br><span class="line">          sfWriters.put(lookupPath, bucketWriter);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// track the buckets getting written in this transaction</span></span><br><span class="line">      <span class="comment">// 一次事务中，take的event可能来自不同topic的parition，则需要同时打开多个文件句柄</span></span><br><span class="line">      <span class="keyword">if</span> (!writers.contains(bucketWriter)) &#123;</span><br><span class="line">        writers.add(bucketWriter);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Write the data to HDFS</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        bucketWriter.append(event);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (BucketClosedException ex) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// flush all pending buckets before committing the transaction</span></span><br><span class="line">    <span class="keyword">for</span> (BucketWriter bucketWriter : writers) &#123;</span><br><span class="line">      bucketWriter.flush();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 事务提交</span></span><br><span class="line">    transaction.commit();</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException eIO) &#123;</span><br><span class="line">  	<span class="comment">// 发生异常进行事务回滚</span></span><br><span class="line">    transaction.rollback();</span><br><span class="line">    LOG.warn(<span class="string">"HDFS IO error"</span>, eIO);</span><br><span class="line">    <span class="keyword">return</span> Status.BACKOFF;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable th) &#123;</span><br><span class="line">    transaction.rollback();</span><br><span class="line">    LOG.error(<span class="string">"process failed"</span>, th);</span><br><span class="line">    <span class="keyword">if</span> (th <span class="keyword">instanceof</span> Error) &#123;</span><br><span class="line">      <span class="keyword">throw</span> (Error) th;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> EventDeliveryException(th);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    transaction.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>sink的process中先从对应的channel中得到Transaction，然后调用<code>begin</code>开始执行事务，然后开始处理数据。<br>处理数据时，调用<code>channel.take</code>从channel中take一条event，<code>take</code>最终调用的是<code>KafkaTransaction.doTake</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Event <span class="title">doTake</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">// 事务类型</span></span><br><span class="line">  type = TransactionType.TAKE;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// channelUUID是final类型的，那一个kafkachannel实例只有一个consumer？</span></span><br><span class="line">    <span class="keyword">if</span> (!(consumerAndRecords.get().uuid.equals(channelUUID))) &#123;</span><br><span class="line">      logger.info(<span class="string">"UUID mismatch, creating new consumer"</span>);</span><br><span class="line">      decommissionConsumerAndRecords(consumerAndRecords.get());</span><br><span class="line">      consumerAndRecords.remove();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">    logger.warn(<span class="string">"Error while shutting down consumer"</span>, ex);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!events.isPresent()) &#123;</span><br><span class="line">    events = Optional.of(<span class="keyword">new</span> LinkedList&lt;Event&gt;());</span><br><span class="line">  &#125;</span><br><span class="line">  Event e;</span><br><span class="line">  <span class="comment">// Give the channel a chance to commit if there has been a rebalance</span></span><br><span class="line">  <span class="keyword">if</span> (rebalanceFlag.get()) &#123;</span><br><span class="line">    logger.debug(<span class="string">"Returning null event after Consumer rebalance."</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!consumerAndRecords.get().failedEvents.isEmpty()) &#123;</span><br><span class="line">    e = consumerAndRecords.get().failedEvents.removeFirst();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> ( logger.isTraceEnabled() ) &#123;</span><br><span class="line">      logger.trace(<span class="string">"Assignment during take: &#123;&#125;"</span>,</span><br><span class="line">          consumerAndRecords.get().consumer.assignment().toString());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">long</span> startTime = System.nanoTime();</span><br><span class="line">      <span class="keyword">if</span> (!consumerAndRecords.get().recordIterator.hasNext()) &#123;</span><br><span class="line">        consumerAndRecords.get().poll();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (consumerAndRecords.get().recordIterator.hasNext()) &#123;</span><br><span class="line">        ConsumerRecord&lt;String, <span class="keyword">byte</span>[]&gt; record = consumerAndRecords.get().recordIterator.next();</span><br><span class="line">        e = deserializeValue(record.value(), parseAsFlumeEvent);</span><br><span class="line">        TopicPartition tp = <span class="keyword">new</span> TopicPartition(record.topic(), record.partition());</span><br><span class="line">        OffsetAndMetadata oam = <span class="keyword">new</span> OffsetAndMetadata(record.offset() + <span class="number">1</span>, batchUUID);</span><br><span class="line">        consumerAndRecords.get().saveOffsets(tp,oam);</span><br><span class="line"></span><br><span class="line">        <span class="comment">//Add the key to the header</span></span><br><span class="line">        <span class="keyword">if</span> (record.key() != <span class="keyword">null</span>) &#123;</span><br><span class="line">          e.getHeaders().put(KEY_HEADER, record.key());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> endTime = System.nanoTime();</span><br><span class="line">        counter.addToKafkaEventGetTimer((endTime - startTime) / (<span class="number">1000</span> * <span class="number">1000</span>));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">          logger.debug(<span class="string">"&#123;&#125; processed output from partition &#123;&#125; offset &#123;&#125;"</span>,</span><br><span class="line">              <span class="keyword">new</span> Object[] &#123;getName(), record.partition(), record.offset()&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">      logger.warn(<span class="string">"Error while getting events from Kafka. This is usually caused by "</span> +</span><br><span class="line">                  <span class="string">"trying to read a non-flume event. Ensure the setting for "</span> +</span><br><span class="line">                  <span class="string">"parseAsFlumeEvent is correct"</span>, ex);</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> ChannelException(<span class="string">"Error while getting events from Kafka"</span>, ex);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  eventTaken = <span class="keyword">true</span>;</span><br><span class="line">  events.get().add(e);</span><br><span class="line">  <span class="keyword">return</span> e;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>doTake其实就是使用consumer消费kafka。<em>理想情况下应该让一个consumer消费多个topic的一个partition</em>，<strong>但这里consumer是和channelUUID对应的，而channelUUID又是final类型的，那是不是说kafkachannel实例中只有一个consumer</strong>？<br>这里的消费逻辑是consumer通过poll将数据拉到本地内存中，然后在sink中一条一条的取，每取一条offset就加1，内存取完之后再调用一次poll。<br>sink拿到event之后，根据event的信息放入相应的<code>bucketWriter</code>中，取出batchSize大小之后将所有的bucketWriter进行一次<code>flush</code>。flush成功之后进行<em>事务的commit</em>。</p>
<p>commit调用的是doCommit，下面看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doCommit</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  logger.trace(<span class="string">"Starting commit"</span>);</span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.NONE)) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.PUT)) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// event taken ensures that we have collected events in this transaction</span></span><br><span class="line">    <span class="comment">// before committing</span></span><br><span class="line">    <span class="comment">// commit之前要保证当前事务中的event都被采集了</span></span><br><span class="line">    <span class="keyword">if</span> (consumerAndRecords.get().failedEvents.isEmpty() &amp;&amp; eventTaken) &#123;</span><br><span class="line">      logger.trace(<span class="string">"About to commit batch"</span>);</span><br><span class="line">      <span class="keyword">long</span> startTime = System.nanoTime();</span><br><span class="line">      <span class="comment">// 提交offset</span></span><br><span class="line">      consumerAndRecords.get().commitOffsets();</span><br><span class="line">      <span class="keyword">long</span> endTime = System.nanoTime();</span><br><span class="line">      counter.addToKafkaCommitTimer((endTime - startTime) / (<span class="number">1000</span> * <span class="number">1000</span>));</span><br><span class="line">      <span class="keyword">if</span> (logger.isDebugEnabled()) &#123;</span><br><span class="line">        logger.debug(consumerAndRecords.get().getCommittedOffsetsString());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> takes = events.get().size();</span><br><span class="line">    <span class="keyword">if</span> (takes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      counter.addToEventTakeSuccessCount(takes);</span><br><span class="line">      events.get().clear();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里offset是手动触发的，调用的是kafka consumer的api<code>consumer.commitSync(offsets)</code>。<br>如果在commit或者flush的过程中发生异常，则进行事务回滚，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">doRollback</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.NONE)) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (type.equals(TransactionType.PUT)) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  	<span class="comment">// 回滚次数统计</span></span><br><span class="line">    counter.addToRollbackCounter(events.get().size());</span><br><span class="line">    <span class="comment">// 将内存中的event放入failedEvents中</span></span><br><span class="line">    consumerAndRecords.get().failedEvents.addAll(events.get());</span><br><span class="line">    events.get().clear();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>flume的事务保证了数据不会丢失，是flume中一个重要的概念。</p>
<h2 id="疑虑"><a href="#疑虑" class="headerlink" title="疑虑"></a>疑虑</h2><p>HdfsSink 和 kafkachannel consumer都是单线程吗？<br>一个kafkachannel实例一个consumer，sink从consumer中取数，然后分给不同的bucketWriter，可以认为consumer是单线程，处理数据是多线程？</p>
]]></content>
      
        <categories>
            
            <category> Flume </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Flume </tag>
            
            <tag> 事务 </tag>
            
            <tag> kafkachannel </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[kafka channel写入kafka报RecordTooLargeException异常]]></title>
      <url>http://bigdatadecode.club/kafka%20channel%E5%86%99%E5%85%A5kafka%E6%8A%A5RecordTooLargeException%E5%BC%82%E5%B8%B8.html</url>
      <content type="html"><![CDATA[<p>flume通过kafka channel直接将数据写入kafka时，如果producer一次写入kafka的数据比较大时，会报异常，异常如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">15 五月 2017 17:17:09,814 WARN  [PollableSourceRunner-TaildirSource-r-op_hiveserver] (org.apache.flume.channel.kafka.KafkaChannel<span class="variable">$KafkaTransaction</span>.doCommit:560)  - Sending events to Kafka failed</span><br><span class="line">java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.RecordTooLargeException: The message is 1730741 bytes when serialized <span class="built_in">which</span> is larger than the maximum request size you have configured with the max.request.size configuration.</span><br><span class="line">	at org.apache.kafka.clients.producer.KafkaProducer<span class="variable">$FutureFailure</span>.&lt;init&gt;(KafkaProducer.java:686)</span><br><span class="line">	at org.apache.kafka.clients.producer.KafkaProducer.send(KafkaProducer.java:449)</span><br><span class="line">	at org.apache.flume.channel.kafka.KafkaChannel<span class="variable">$KafkaTransaction</span>.doCommit(KafkaChannel.java:546)</span><br><span class="line">	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)</span><br><span class="line">	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:194)</span><br><span class="line">	at org.apache.flume.source.taildir.TaildirSource.tailFileProcess(TaildirSource.java:263)</span><br><span class="line">	at org.apache.flume.source.taildir.TaildirSource.process(TaildirSource.java:226)</span><br><span class="line">	at org.apache.flume.source.PollableSourceRunner<span class="variable">$PollingRunner</span>.run(PollableSourceRunner.java:133)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: org.apache.kafka.common.errors.RecordTooLargeException: The message is 1730741 bytes when serialized <span class="built_in">which</span> is larger than the maximum request size you have configured with the max.request.size configuration.</span><br></pre></td></tr></table></figure>
<p>发送的数据量超过了<code>max.request.size</code>的阈值(默认是1048576)，那就在kafka channel中将此参数调大，<code>a1.channels.c1.kafka.producer.max.request.size = 10485760</code></p>
<a id="more"></a>
<p>接着又出现了如下异常：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">15 五月 2017 17:20:00,799 WARN  [PollableSourceRunner-TaildirSource-r-op_hiveserver] (org.apache.flume.channel.kafka.KafkaChannel<span class="variable">$KafkaTransaction</span>.doCommit:560)  - Sending events to Kafka failed</span><br><span class="line">java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.RecordTooLargeException: The request included a message larger than the max message size the server will accept.</span><br><span class="line">	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.valueOrError(FutureRecordMetadata.java:56)</span><br><span class="line">	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:43)</span><br><span class="line">	at org.apache.kafka.clients.producer.internals.FutureRecordMetadata.get(FutureRecordMetadata.java:25)</span><br><span class="line">	at org.apache.flume.channel.kafka.KafkaChannel<span class="variable">$KafkaTransaction</span>.doCommit(KafkaChannel.java:552)</span><br><span class="line">	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)</span><br><span class="line">	at org.apache.flume.channel.ChannelProcessor.processEventBatch(ChannelProcessor.java:194)</span><br><span class="line">	at org.apache.flume.source.taildir.TaildirSource.tailFileProcess(TaildirSource.java:263)</span><br><span class="line">	at org.apache.flume.source.taildir.TaildirSource.process(TaildirSource.java:226)</span><br><span class="line">	at org.apache.flume.source.PollableSourceRunner<span class="variable">$PollingRunner</span>.run(PollableSourceRunner.java:133)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:745)</span><br><span class="line">Caused by: org.apache.kafka.common.errors.RecordTooLargeException: The request included a message larger than the max message size the server will accept.</span><br></pre></td></tr></table></figure>
<p>异常变了，变成<strong>server 不接收</strong>，那就是说还得改kafka集群的配置，在<code>server.properties</code>中添加如下配置:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">message.max.bytes=10000120</span><br><span class="line">replica.fetch.max.bytes=10485760</span><br></pre></td></tr></table></figure>
<ul>
<li>message.max.bytes是指kafka一次能接收数据的上限，message.max.bytes是针对整个集群进行配置，还可以对某个topic进行配置，参数是<code>max.message.bytes</code>，命令为<code>bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic my-topic --config max.message.bytes=10485760</code></li>
<li>replica.fetch.max.bytes是从partition中读取数据时的上限，但并不是决对的上限，假如某个非空partition的第一条message的大小超出了此值，依然能够读出。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Flume </category>
            
        </categories>
        
        
        <tags>
            
            <tag> big data </tag>
            
            <tag> flume </tag>
            
            <tag> kafka </tag>
            
            <tag> 运维 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[重启Kafka时，加载.index时，报错：Corrupt index found]]></title>
      <url>http://bigdatadecode.club/kafka-corrupt%20index%20found.html</url>
      <content type="html"><![CDATA[<h2 id="错误出现场景"><a href="#错误出现场景" class="headerlink" title="错误出现场景"></a>错误出现场景</h2><p>使用<code>kill -9 pid</code>强制退出kafka进程之后，重启出现此错误，提示信息如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ERROR There was an error <span class="keyword">in</span> one of the threads during logs loading: java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (<span class="variable">$&#123;log.dirs&#125;</span>/<span class="variable">$&#123;topicName&#125;</span>-0/00000000000001964914.index) has non-zero size but the last offset is 1964914 and the base offset is 1964914 (kafka.log.LogManager)</span><br><span class="line">[2016-02-22 18:01:01,213] FATAL [Kafka Server 0], Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)</span><br><span class="line">java.lang.IllegalArgumentException: requirement failed: Corrupt index found, index file (<span class="variable">$&#123;log.dirs&#125;</span>/<span class="variable">$&#123;topicName&#125;</span>-0/00000000000001964914.index) has non-zero size but the last offset is 1964914 and the base offset is 1964914</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>查看提示信息是加载.index文件时出错，将<strong>00000000000001964914.index</strong>删除，再次重启，启动正常。</p>
<h2 id="错误原因及解决方法分析"><a href="#错误原因及解决方法分析" class="headerlink" title="错误原因及解决方法分析"></a>错误原因及解决方法分析</h2><ul>
<li>Kafka的文件存储机制</li>
</ul>
<blockquote>
<p>kafka中的message以topic的形式存在，topic在物理上又分为很多的partition，partition物理上由很多segment组成，segment是存放message的真正载体。</p>
</blockquote>
<p>下面具体介绍下segment文件：<br>(1) 每个partition(目录)相当于一个巨型文件被平均分配到多个大小相等segment(段)数据文件中。但每个段segment file消息数量不一定相等，这种特性方便old segment file快速被删除。<br>(2) 每个partiton只需要支持顺序读写就行了，segment文件生命周期由服务端配置参数决定。<br>(3) <strong>segment file组成：由2大部分组成，分别为index file和data file，此2个文件一一对应，成对出现，后缀”.index”和“.log”分别表示为segment索引文件、数据文件.</strong><br>(4) segment文件命名规则：partion全局的第一个segment从0开始，后续每个segment文件名为上一个segment文件最后一条消息的offset值。数值最大为64位long大小，19位数字字符长度，没有数字用0填充。<br>segment中index&lt;—-&gt;data file对应关系物理结构如下：<br><img src="/blogimgs/kafka corrupt index found/kafka-fs-index-correspond-data.png" alt="index与log映射关系" title="index与log映射关系"><br><code>.index</code>文件存放的是message逻辑相对偏移量（相对offset=绝对offset-base offset）与在相应的<code>.log</code>文件中的物理位置（position）。但<code>.index</code>并不是为每条message都指定到物理位置的映射，而是以entry为单位，每条entry可以指定连续n条消息的物理位置映射（例如：假设有20000~20009共10条消息，<code>.index</code>文件可配置为每条entry<br>指定连续10条消息的物理位置映射，该例中，index entry会记录偏移量为20000的消息到其物理文件位置，一旦该条消息被定位，20001~20009可以很快查到。）。每个entry大小8字节，前4个字节是这个message相对于该log segment第一个消息offset（base offset）的相对偏移量，后4个字节是这个消息在log文件中的物理位置。</p>
<ul>
<li>Kafka启动加载log流程</li>
</ul>
<p>kafka数据log的管理类是LogManager.scala，关键源码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LogManager</span>(<span class="params">val logDirs: <span class="type">Array</span>[<span class="type">File</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">                 val topicConfigs: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">LogConfig</span>],</span></span></span><br><span class="line"><span class="class"><span class="params">                 val defaultConfig: <span class="type">LogConfig</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 val cleanerConfig: <span class="type">CleanerConfig</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 ioThreads: <span class="type">Int</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 val flushCheckMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 val flushCheckpointMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 val retentionCheckMs: <span class="type">Long</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 scheduler: <span class="type">Scheduler</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 val brokerState: <span class="type">BrokerState</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">                 private val time: <span class="type">Time</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="keyword">val</span> <span class="type">RecoveryPointCheckpointFile</span> = <span class="string">"recovery-point-offset-checkpoint"</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">LockFile</span> = <span class="string">".lock"</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">InitialTaskDelayMs</span> = <span class="number">30</span>*<span class="number">1000</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> logCreationOrDeletionLock = <span class="keyword">new</span> <span class="type">Object</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> logs = <span class="keyword">new</span> <span class="type">Pool</span>[<span class="type">TopicAndPartition</span>, <span class="type">Log</span>]()</span><br><span class="line"></span><br><span class="line">  createAndValidateLogDirs(logDirs)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> dirLocks = lockLogDirs(logDirs)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> recoveryPointCheckpoints = logDirs.map(dir =&gt; (dir, <span class="keyword">new</span> <span class="type">OffsetCheckpoint</span>(<span class="keyword">new</span> <span class="type">File</span>(dir, <span class="type">RecoveryPointCheckpointFile</span>)))).toMap</span><br><span class="line">  loadLogs()      <span class="comment">//  关键方法</span></span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>loadLogs()</code>中先判断上次关闭是否为cleanshutdown，判断依据为<code>${log.dirs}</code>目录中是否存在<code>.kafka_cleanshutDown</code>的文件</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (cleanShutdownFile.exists) &#123;</span><br><span class="line">  debug(</span><br><span class="line">    <span class="string">"Found clean shutdown file. "</span> +</span><br><span class="line">    <span class="string">"Skipping recovery for all logs in data directory: "</span> +</span><br><span class="line">    dir.getAbsolutePath)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="comment">// log recovery itself is being performed by `Log` class during initialization</span></span><br><span class="line">  brokerState.newState(<span class="type">RecoveringFromUncleanShutdown</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后开始加载log，其中new Log方法为初始化log file 和index file</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> jobsForDir = <span class="keyword">for</span> &#123;</span><br><span class="line">  dirContent &lt;- <span class="type">Option</span>(dir.listFiles).toList</span><br><span class="line">  logDir &lt;- dirContent <span class="keyword">if</span> logDir.isDirectory</span><br><span class="line">&#125; <span class="keyword">yield</span> &#123;</span><br><span class="line">  <span class="type">Utils</span>.runnable &#123;</span><br><span class="line">    debug(<span class="string">"Loading log '"</span> + logDir.getName + <span class="string">"'"</span>)</span><br><span class="line">    <span class="comment">//从文件目录上获得topic和partition</span></span><br><span class="line">    <span class="keyword">val</span> topicPartition = <span class="type">Log</span>.parseTopicPartitionName(logDir.getName)</span><br><span class="line">    <span class="keyword">val</span> config = topicConfigs.getOrElse(topicPartition.topic, defaultConfig)</span><br><span class="line">    <span class="keyword">val</span> logRecoveryPoint = recoveryPoints.getOrElse(topicPartition, <span class="number">0</span>L)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> current = <span class="keyword">new</span> <span class="type">Log</span>(logDir, config, logRecoveryPoint, scheduler, time)</span><br><span class="line">    <span class="keyword">val</span> previous = <span class="keyword">this</span>.logs.put(topicPartition, current)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (previous != <span class="literal">null</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(</span><br><span class="line">        <span class="string">"Duplicate log directories found: %s, %s!"</span>.format(</span><br><span class="line">        current.dir.getAbsolutePath, previous.dir.getAbsolutePath))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Log中的关键方法是<code>loadSegments()</code>方法</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">loadSegments</span></span>() &#123;</span><br><span class="line">  <span class="comment">// create the log directory if it doesn't exist</span></span><br><span class="line">  dir.mkdirs()</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// first do a pass through the files in the log directory and remove any temporary files </span></span><br><span class="line">  <span class="comment">// and complete any interrupted swap operations</span></span><br><span class="line">  <span class="keyword">for</span>(file &lt;- dir.listFiles <span class="keyword">if</span> file.isFile) &#123;</span><br><span class="line">    <span class="keyword">if</span>(!file.canRead)</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IOException</span>(<span class="string">"Could not read file "</span> + file)</span><br><span class="line">    <span class="keyword">val</span> filename = file.getName</span><br><span class="line">    <span class="comment">// DeletedFileSuffix = ".deleted"  CleanedFileSuffix = ".cleaned"</span></span><br><span class="line">    <span class="comment">// 删除所有后缀名为.cleaned和.delete的文件</span></span><br><span class="line">    <span class="keyword">if</span>(filename.endsWith(<span class="type">DeletedFileSuffix</span>) || filename.endsWith(<span class="type">CleanedFileSuffix</span>)) &#123;</span><br><span class="line">      <span class="comment">// if the file ends in .deleted or .cleaned, delete it</span></span><br><span class="line">      file.delete()</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span>(filename.endsWith(<span class="type">SwapFileSuffix</span>)) &#123;   <span class="comment">// SwapFileSuffix = ".swap"</span></span><br><span class="line">      <span class="comment">// we crashed in the middle of a swap operation, to recover:</span></span><br><span class="line">      <span class="comment">// if a log, swap it in and delete the .index file</span></span><br><span class="line">      <span class="comment">// if an index just delete it, it will be rebuilt</span></span><br><span class="line">      <span class="keyword">val</span> baseName = <span class="keyword">new</span> <span class="type">File</span>(<span class="type">Utils</span>.replaceSuffix(file.getPath, <span class="type">SwapFileSuffix</span>, <span class="string">""</span>))</span><br><span class="line">      <span class="keyword">if</span>(baseName.getPath.endsWith(<span class="type">IndexFileSuffix</span>)) &#123;</span><br><span class="line">      	<span class="comment">// 如果.swap文件是index文件，则删除该index</span></span><br><span class="line">        file.delete()</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span>(baseName.getPath.endsWith(<span class="type">LogFileSuffix</span>))&#123;</span><br><span class="line">      	<span class="comment">// 如果.swap是log文件，则删除该log文件对应的index文件，然后多log文件进行重命名</span></span><br><span class="line">        <span class="comment">// delete the index</span></span><br><span class="line">        <span class="keyword">val</span> index = <span class="keyword">new</span> <span class="type">File</span>(<span class="type">Utils</span>.replaceSuffix(baseName.getPath, <span class="type">LogFileSuffix</span>, <span class="type">IndexFileSuffix</span>))</span><br><span class="line">        index.delete()</span><br><span class="line">        <span class="comment">// complete the swap operation</span></span><br><span class="line">        <span class="keyword">val</span> renamed = file.renameTo(baseName)</span><br><span class="line">        <span class="keyword">if</span>(renamed)</span><br><span class="line">          info(<span class="string">"Found log file %s from interrupted swap operation, repairing."</span>.format(file.getPath))</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">KafkaException</span>(<span class="string">"Failed to rename file %s."</span>.format(file.getPath))</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// now do a second pass and load all the .log and .index files</span></span><br><span class="line">  <span class="keyword">for</span>(file &lt;- dir.listFiles <span class="keyword">if</span> file.isFile) &#123;</span><br><span class="line">    <span class="keyword">val</span> filename = file.getName</span><br><span class="line">    <span class="comment">// IndexFileSuffix = ".index" </span></span><br><span class="line">    <span class="keyword">if</span>(filename.endsWith(<span class="type">IndexFileSuffix</span>)) &#123;</span><br><span class="line">      <span class="comment">// if it is an index file, make sure it has a corresponding .log file</span></span><br><span class="line">      <span class="keyword">val</span> logFile = <span class="keyword">new</span> <span class="type">File</span>(file.getAbsolutePath.replace(<span class="type">IndexFileSuffix</span>, <span class="type">LogFileSuffix</span>))</span><br><span class="line">      <span class="keyword">if</span>(!logFile.exists) &#123;</span><br><span class="line">        warn(<span class="string">"Found an orphaned index file, %s, with no corresponding log file."</span>.format(file.getAbsolutePath))</span><br><span class="line">        <span class="comment">//  如果仅存在index文件，没有相应的log文件，则直接删除index文件</span></span><br><span class="line">        file.delete()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span>(filename.endsWith(<span class="type">LogFileSuffix</span>)) &#123;    <span class="comment">// LogFileSuffix = ".log"</span></span><br><span class="line">      <span class="comment">// if its a log file, load the corresponding log segment</span></span><br><span class="line">      <span class="keyword">val</span> start = filename.substring(<span class="number">0</span>, filename.length - <span class="type">LogFileSuffix</span>.length).toLong</span><br><span class="line">      <span class="keyword">val</span> hasIndex = <span class="type">Log</span>.indexFilename(dir, start).exists</span><br><span class="line">      <span class="keyword">val</span> segment = <span class="keyword">new</span> <span class="type">LogSegment</span>(dir = dir, </span><br><span class="line">                                   startOffset = start,</span><br><span class="line">                                   indexIntervalBytes = config.indexInterval, </span><br><span class="line">                                   maxIndexSize = config.maxIndexSize,</span><br><span class="line">                                   rollJitterMs = config.randomSegmentJitter,</span><br><span class="line">                                   time = time)</span><br><span class="line">      <span class="comment">// 如果log文件对应的index文件不存在，则对index文件进行rebuild                             </span></span><br><span class="line">      <span class="keyword">if</span>(!hasIndex) &#123;</span><br><span class="line">        error(<span class="string">"Could not find index file corresponding to log file %s, rebuilding index..."</span>.format(segment.log.file.getAbsolutePath))</span><br><span class="line">        segment.recover(config.maxMessageSize)</span><br><span class="line">      &#125;</span><br><span class="line">      segments.put(start, segment)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(logSegments.size == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// no existing segments, create a new mutable segment beginning at offset 0</span></span><br><span class="line">    segments.put(<span class="number">0</span>L, <span class="keyword">new</span> <span class="type">LogSegment</span>(dir = dir,</span><br><span class="line">                                   startOffset = <span class="number">0</span>,</span><br><span class="line">                                   indexIntervalBytes = config.indexInterval, </span><br><span class="line">                                   maxIndexSize = config.maxIndexSize,</span><br><span class="line">                                   rollJitterMs = config.randomSegmentJitter,</span><br><span class="line">                                   time = time))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    recoverLog()</span><br><span class="line">    <span class="comment">// reset the index size of the currently active log segment to allow more entries</span></span><br><span class="line">    activeSegment.index.resize(config.maxIndexSize)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// sanity check the index file of every segment to ensure we don't proceed with a corrupt segment</span></span><br><span class="line">  <span class="comment">// 这里是报错的关键代码</span></span><br><span class="line">  <span class="keyword">for</span> (s &lt;- logSegments)</span><br><span class="line">    s.index.sanityCheck()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// OffsetIndex.scala</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Do a basic sanity check on this index to detect obvious problems</span></span><br><span class="line"><span class="comment"> * @throws IllegalArgumentException if any problems are found</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sanityCheck</span></span>() &#123;</span><br><span class="line">	<span class="comment">// 错误提示信息</span></span><br><span class="line">	<span class="comment">// 正常情况下 最后一个index的文件大小为0， lastoffset大于baseoffset</span></span><br><span class="line">  require(entries == <span class="number">0</span> || lastOffset &gt; baseOffset,</span><br><span class="line">          <span class="string">"Corrupt index found, index file (%s) has non-zero size but the last offset is %d and the base offset is %d"</span></span><br><span class="line">          .format(file.getAbsolutePath, lastOffset, baseOffset))</span><br><span class="line">    <span class="keyword">val</span> len = file.length()</span><br><span class="line">    require(len % <span class="number">8</span> == <span class="number">0</span>,</span><br><span class="line">            <span class="string">"Index file "</span> + file.getName + <span class="string">" is corrupt, found "</span> + len +</span><br><span class="line">            <span class="string">" bytes which is not positive or not a multiple of 8."</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>由上述代码可见，kafka加载log的大致流程为：<br>1、 检查上次关闭kafka是否为clean shutdown<br>2、 删除所有后缀名为.cleaned和.delete的文件<br>3、 对于.swp结尾的文件，如果是log文件则直接恢复(去掉.swp, 变为.log)；                      如果是index文件直接删掉（然后rebuild index文件）；<br>4、 对于.index文件，如果没有对应的.log文件(同一个logSement其index和log的主文件名相同), 则删除该index文件；<br>5、 对于.log文件，加载入内存；如果其没有对应的.index文件（可能在第<2>步中被删除), 重新恢复其index文件；<br>6、 如果Kafka已经加载到log, 则开始recover log segments<br>7、 最后做sanityCheck, 主要是检查每个log sement的index文件，确保不会加载一个出错的Log Segment</2></p>
</blockquote>
<ul>
<li>推理验证</li>
</ul>
<p>查看先前出现异常时备份kafka <code>.log</code> 和<code>.index</code>文件，使用<code>ll</code>命令查看文件的大小（这里说下<code>ll</code>和<code>du</code>的区别，<code>du</code>查看的是文件占用的磁盘块的大小，而<code>ll</code>查看的是文件大小）如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-rw-rw-r-- 1 username username    1678200 Feb 22 17:43 00000000000000163891.index</span><br><span class="line">-rw-rw-r-- 1 username username 1073741823 Feb 22 16:16 00000000000000163891.log</span><br><span class="line">-rw-rw-r-- 1 username username    1666008 Feb 22 17:43 00000000000001131903.index</span><br><span class="line">-rw-rw-r-- 1 username username 1073741375 Feb 22 16:42 00000000000001131903.log</span><br><span class="line">-rw-rw-r-- 1 username username   10485760 Feb 22 18:01 00000000000001964914.index</span><br><span class="line">-rw-rw-r-- 1 username username  834044222 Feb 22 17:31 00000000000001964914.log</span><br></pre></td></tr></table></figure>
<p>发现<code>00000000000001964914.index</code> 的大小为<code>10485760b</code>，即10M，将其删除可以正常启动。</p>
<h2 id="index为什么会发生损坏"><a href="#index为什么会发生损坏" class="headerlink" title="index为什么会发生损坏"></a>index为什么会发生损坏</h2><p><code>.index</code>文件是一个索引文件映射，它不会对每条消息都索引,所以是稀疏文件。<br>kafka运行时会创建一个<code>log.index.size.max.bytes</code>大小的<code>.index</code>文件，向其中写入稀疏索引，内容达到阈值会进行roll。<br><code>.index</code>的中索引并不是往<code>.log</code>中写一条message就写入一条索引，而是间隔<code>indexIntervalBytes</code>大小之后才写入一条索引条目</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//Append the given messages starting with the given offset. Add an entry to the index if needed.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">append</span></span>(offset: <span class="type">Long</span>, messages: <span class="type">ByteBufferMessageSet</span>) &#123;</span><br><span class="line">  <span class="keyword">if</span> (messages.sizeInBytes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span>(bytesSinceLastIndexEntry &gt; indexIntervalBytes) &#123;</span><br><span class="line">      index.append(offset, log.sizeInBytes())             <span class="comment">// append an entry to the index (if needed)</span></span><br><span class="line">      <span class="keyword">this</span>.bytesSinceLastIndexEntry = <span class="number">0</span>                   <span class="comment">// 成功写一次索引后,重置为0</span></span><br><span class="line">    &#125;</span><br><span class="line">    log.append(messages)                                  <span class="comment">// append the messages</span></span><br><span class="line">    <span class="keyword">this</span>.bytesSinceLastIndexEntry += messages.sizeInBytes <span class="comment">// 统计值增加,用于判断是否需要写索引</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于<code>.index</code>文件是稀疏文件，所以需要对其进行compacted，在使用kill -9 时可能会导致kafka 对<code>.index</code>文件compacted失败。</p>
<h2 id="相关patch"><a href="#相关patch" class="headerlink" title="相关patch"></a>相关patch</h2><p><a href="https://issues.apache.org/jira/browse/KAFKA-1791" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/KAFKA-1791</a><br><a href="https://issues.apache.org/jira/browse/KAFKA-1554" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/KAFKA-1554</a><br>patch1554对其进行了修复，但修复的逻辑也就把相关<code>.index</code>删除，代码如下</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sanity check the index file of every segment to ensure we don't proceed with a corrupt segment</span></span><br><span class="line"><span class="comment">// delete any corrupt index file. It will be rebuilt</span></span><br><span class="line"><span class="keyword">for</span> (s &lt;- logSegments) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    s.index.sanityCheck()</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">IllegalArgumentException</span> =&gt;</span><br><span class="line">      warn(<span class="string">"Found a corrupt index file %s. Deleting it, will be rebuilt"</span>.format(s.index.file.getAbsolutePath))</span><br><span class="line">      <span class="comment">// 删除相关index文件</span></span><br><span class="line">      s.index.delete()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>需要注意的是sanity check的位置发生了变化，在加载<code>.log</code>和<code>.index</code>文件之前先进行检查。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://tech.meituan.com/kafka-fs-design-theory.html" target="_blank" rel="noopener">http://tech.meituan.com/kafka-fs-design-theory.html</a><br><a href="http://blog.csdn.net/jsky_studio/article/details/42012561" target="_blank" rel="noopener">http://blog.csdn.net/jsky_studio/article/details/42012561</a><br><a href="http://zqhxuyuan.github.io/2016/01/10/2016-01-10-Kafka_LogAppend/#handleProducerRequest" target="_blank" rel="noopener">http://zqhxuyuan.github.io/2016/01/10/2016-01-10-Kafka_LogAppend/#handleProducerRequest</a></p>
]]></content>
      
        <categories>
            
            <category> Kafka </category>
            
        </categories>
        
        
        <tags>
            
            <tag> big data </tag>
            
            <tag> kafka </tag>
            
            <tag> 运维 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[利用zookeeper监控flume进程报警]]></title>
      <url>http://bigdatadecode.club/%E5%88%A9%E7%94%A8zookeeper%E7%9B%91%E6%8E%A7flume%E8%BF%9B%E7%A8%8B%E6%8A%A5%E8%AD%A6.html</url>
      <content type="html"><![CDATA[<p>利用flume进行日志采集已在业界广泛使用，如果需要采集的log比较多，并且分布在多个服务器上，那么对flume agent的管理就是一个头疼的事情。<br>本篇主要介绍下利用zookeeper对flume进程进行监控，当flume异常退出时进行报警，以至于我们能够及时的发现故障解决故障。</p>
<a id="more"></a>
<p>思路很简单，其实开发起来也很简单，嘿嘿。。<br>主要是利用了zookeeper临时节点的功能，当flume agent启动时与zk建立连接创建一个临时节点，并周期的与zk进行心跳，当flume发生异常退出程序时，与zk的心跳失败，导致临时节点被zk删除，监听到这个事件之后就可以进行报警，达到监控的目的。</p>
<p>是不是很简单，但是如果只就这样去开发上线是有个bug的，当你正常退出flume进程时，zk上的临时节点也会被删除，同样会监听到此事件，也会报警。<strong>其实我们应该给每个flume agent在zk上创建一个临时节点的同时也应该创建一个永久性节点，这个永久性节点用来标识此agent的信息，当agent异常退出时，临时性节点会被删除但永久性节点不会被删除，这样当watcher监听到临时节点被删除，并且检测到永久性节点并没有被删除，那就可以断定agent是异常退出，需要报警，当agent正常退出时，会将永久性节点删除，同样临时节点也会被删除，这样watcher监听到临时节点被删除去检测永久性节点时，发现也被删除了，就可以断定此agent是正常退出，不需要报警。</strong></p>
<p>此思路借鉴了HDFS HA机制，之所以利用zookeeper来进行监控是因为我们是将flume采集的log写入kafka，这样zookeeper已是我们的组件之一，重复利用现有的组件可以减少我们的维护量和开发量，并且zookeeper避免单点故障，也不用我们自己开发心跳模块和监听模块，开发量很小。</p>
<p>扯了那么多来点干货吧。</p>
<p>我没有直接在agent的启动流程中添加与zk的连接，感觉这样对flume的侵入性太大了，而是引入了<a href="https://github.com/cloudera/flume/blob/master/flume-core/src/main/java/com/cloudera/flume/watchdog/Watchdog.java" target="_blank" rel="noopener">watchdog</a>,在watchdog中添加相关代码。</p>
<blockquote>
<p>watchdog 是老版flume中的组件，用来监控agent进程，当agent异常退出之后进行重启。watchdog的具体代码可以参考github，我们在此基础上进行了修改。</p>
</blockquote>
<p>在watchdog的<code>startup</code>中与zk建立连接，zk client用的是<a href="http://curator.apache.org/" target="_blank" rel="noopener">Curator</a> 。<br>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">startup</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">...</span><br><span class="line">    <span class="comment">// 与zk建立连接</span></span><br><span class="line">	CuratorFramework client = CuratorFrameworkFactory.newClient(ZK_ADDRESS, <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">    client.start();</span><br><span class="line">    <span class="comment">// 创建永久节点</span></span><br><span class="line">    client.create().withMode(CreateMode.PERSISTENT).forPath(PATH_P + <span class="string">"/test"</span>, <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>]);</span><br><span class="line">    <span class="comment">// 创建临时节点</span></span><br><span class="line">    client.create().withMode(CreateMode.EPHEMERAL).forPath(PATH + <span class="string">"/test"</span>, <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>agent端的代码就算结束了，我们需要再起一个服务来监听zk上节点的信息。</p>
<p>监听服务我使用的是Curator的<code>PathCache</code>来监听一个目录的所有子节点的delete事件。此服务在与zk建立连接时注册一个watcher，代码是在PathCache的example的基础上进行了修改，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">    CuratorFramework client = <span class="keyword">null</span>;</span><br><span class="line">    PathChildrenCache cache = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span></span><br><span class="line">    &#123;</span><br><span class="line">        client = CuratorFrameworkFactory.newClient(ZK_ADDRESS, <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>, <span class="number">3</span>));</span><br><span class="line">        client.start();</span><br><span class="line">        <span class="comment">// path cache 类似 zk中的watcher</span></span><br><span class="line">        <span class="comment">// in this example we will cache data. Notice that this is optional.</span></span><br><span class="line">        cache = <span class="keyword">new</span> PathChildrenCache(client, PATH, <span class="keyword">true</span>);</span><br><span class="line">        cache.start();</span><br><span class="line">        <span class="comment">// 给cache注册监听器，对相应事件进行处理</span></span><br><span class="line">        addListener(cache);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">finally</span></span><br><span class="line">    &#123;</span><br><span class="line">        CloseableUtils.closeQuietly(cache);</span><br><span class="line">        CloseableUtils.closeQuietly(client);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">addListener</span><span class="params">(PathChildrenCache cache)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// a PathChildrenCacheListener is optional. Here, it's used just to log changes</span></span><br><span class="line">    PathChildrenCacheListener listener = <span class="keyword">new</span> PathChildrenCacheListener()</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">childEvent</span><span class="params">(CuratorFramework client, PathChildrenCacheEvent event)</span> <span class="keyword">throws</span> Exception</span></span><br><span class="line"><span class="function">        </span>&#123;</span><br><span class="line">            <span class="keyword">switch</span> ( event.getType() )</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">case</span> CHILD_ADDED:</span><br><span class="line">                &#123;</span><br><span class="line">                    System.out.println(<span class="string">"Node added: "</span> + ZKPaths.getNodeFromPath(event.getData().getPath()));</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">case</span> CHILD_UPDATED:</span><br><span class="line">                &#123;</span><br><span class="line">                    System.out.println(<span class="string">"Node changed: "</span> + ZKPaths.getNodeFromPath(event.getData().getPath()));</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">case</span> CHILD_REMOVED:</span><br><span class="line">                &#123;</span><br><span class="line">                	System.out.println(<span class="string">"判断永久节点是否存在，决定是否报警"</span>);</span><br><span class="line">                    System.out.println(<span class="string">"Node removed: "</span> + ZKPaths.getNodeFromPath(event.getData().getPath()));</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    cache.getListenable().addListener(listener);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个服务比较简单，就一个类，打算随后将其集成到自动化部署平台中，上面只是伪代码，详细代码以后有时间再不全。</p>
]]></content>
      
        <categories>
            
            <category> Flume </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Flume </tag>
            
            <tag> zookeeper </tag>
            
            <tag> 监控 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[hexo-next主题添加近期文章版块]]></title>
      <url>http://bigdatadecode.club/hexo-next%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E8%BF%91%E6%9C%9F%E6%96%87%E7%AB%A0%E7%89%88%E5%9D%97.html</url>
      <content type="html"><![CDATA[<p>前几天看到别人的博客有个近期文章版块，感觉挺好，于是就想给自己的博客也加这么个功能。由于使用的是next主题，而next默认是没有这个版块的，那就自己搞一个吧。废话不多说，直接上代码，挺简单的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if theme.recent_posts %&#125;</span><br><span class="line">    &lt;div class=&quot;links-of-blogroll motion-element &#123;&#123; &quot;links-of-blogroll-&quot; + theme.recent_posts_layout  &#125;&#125;&quot;&gt;</span><br><span class="line">      &lt;div class=&quot;links-of-blogroll-title&quot;&gt;</span><br><span class="line">        &lt;!-- modify icon to fire by szw --&gt;</span><br><span class="line">        &lt;i class=&quot;fa fa-history fa-&#123;&#123; theme.recent_posts_icon | lower &#125;&#125;&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;</span><br><span class="line">        &#123;&#123; theme.recent_posts_title &#125;&#125;</span><br><span class="line">      &lt;/div&gt;</span><br><span class="line">      &lt;ul class=&quot;links-of-blogroll-list&quot;&gt;</span><br><span class="line">        &#123;% set posts = site.posts.sort(&apos;-date&apos;) %&#125;</span><br><span class="line">        &#123;% for post in posts.slice(&apos;0&apos;, &apos;5&apos;) %&#125;</span><br><span class="line">          &lt;li&gt;</span><br><span class="line">            &lt;a href=&quot;&#123;&#123; url_for(post.path) &#125;&#125;&quot; title=&quot;&#123;&#123; post.title &#125;&#125;&quot; target=&quot;_blank&quot;&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt;</span><br><span class="line">          &lt;/li&gt;</span><br><span class="line">        &#123;% endfor %&#125;</span><br><span class="line">      &lt;/ul&gt;</span><br><span class="line">    &lt;/div&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>
<p>将此代码贴在<code>next/layout/_macro/sidebar.swig</code>中的<code>if theme.links</code>对应的<code>endif</code>后面，就ok了，是不是很简单。。。。<br>为了配置方便，在主题的<code>_config.yml</code>中添加了几个变量，如下：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">recent_posts_title: 近期文章</span><br><span class="line">recent_posts_layout: block</span><br><span class="line">recent_posts: true</span><br></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> hexo </tag>
            
            <tag> next </tag>
            
            <tag> 近期文章 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce应用实例--二次排序之reduce内有序]]></title>
      <url>http://bigdatadecode.club/MapReduce%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B--%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E4%B9%8Breduce%E5%86%85%E6%9C%89%E5%BA%8F.html</url>
      <content type="html"><![CDATA[<p>MapReduce天生就具有排序的特性，但是面对稍微复杂的排序时我们还是希望能够充分利用其自身的设计原理来达到我们的目的。其中二次排序就是一个很好的例子，下面主要介绍下二次排序。</p>
<p>二次排序的场景是不仅需要对key排序依然需要对value中的某个值进行排序，也就是先对key排序然后对相同key的record再对value进行排序。</p>
<p>对key排序我们可以使用MR自身的排序，但是怎么对value中的某个值进行排序呢？</p>
<p>MapReduce留出了很多可以自定义的接口，比如partition、comparator和group等等接口，这里只需用到这三个，其它以后用的接口再介绍。</p>
<a id="more"></a>
<blockquote>
<p>之前有几篇介绍MapReduce流程的blog，可以自行搜索，关键字为<em>MapReduce源码解析</em>。</p>
</blockquote>
<p>熟悉MapReduce流程的同学会知道key的<em>第一次排序</em>发生在map端的sortAndSpill阶段，此阶段是将<em>内存中的数据先根据partition进行排序然后再对key排序(排序算法是改进的快排)</em>，<em>第二次排序</em>发生在reduce端的merge阶段，此阶段是将从map端copy来的segment(<em>局部有序的数据，局部有序的原因是map端已将数据按key排序，reduce copy时从n个map中将此reduce需要的数据复制过来，则每个map内的数据是有序的，而各个map之间的数据是无序的</em>)进行堆排序，使数据按照key有序。(<em>这里的第二次排序其实也可以说是第三次排序</em>，因为在map端也会有个merge阶段，将spill到磁盘的临时文件merge成一个大文件，这个过程将spills文件中按照partition和key进行排序)</p>
<p>由此可知MapReduce整个流程是以key排序为核心的，那么针对上面的需求是否可以在key上做点文章呢？</p>
<p>针对上面需求的解决方案是<em>将需要排序的key和value1(value中的某个属性)组成一个复合键compositeKey，在map端按照key分区和排序，则相同的key被分到同一个reduce中，在reduce中对相同key的value1进行排序，然后根据key进行分组，以便形成相同key的Iterator，这时输出的数据就是按照key和value1排序的。</em></p>
<blockquote>
<p>这里需要注意下由于partition选择的方法不一样，可能会导致最终的结果<em>可能是reduce内有序和全局有序</em>。</p>
</blockquote>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>问题如下：<br>有两个文件a.txt和b.txt<br>a.txt中的内容是<br>1990 31<br>1991 20<br>1991 18<br>1991 33<br>1990 22<br>1990 17<br>b.txt中的内容是<br>1992 31<br>1991 27<br>1993 18<br>1993 33<br>1992 22<br>1990 10<br>想要的排序结果是<br>1990    10<br>1990    17<br>1990    22<br>1990    31<br>1991    18<br>1991    20<br>1991    27<br>1991    33<br>1992    22<br>1992    31<br>1993    18<br>1993    33</p>
<p>先来看下根据复合键compositeKey中的key进行hash分区的代码</p>
<h2 id="hash分区代码示例"><a href="#hash分区代码示例" class="headerlink" title="hash分区代码示例"></a>hash分区代码示例</h2><p>复合键compositeKey的形成有两种形式：一种是将key和value拼接成一个字符串，key和value之前用特殊字符分隔，另一种是<em>实现WritableComparable接口</em>自己写一个新的数据类型。</p>
<p>先来个简单的，将key和value拼接为一个字符串</p>
<h3 id="key和value拼接字符串为复合键"><a href="#key和value拼接字符串为复合键" class="headerlink" title="key和value拼接字符串为复合键"></a>key和value拼接字符串为复合键</h3><p>key和value拼接为字符串是在map中执行的，先看下map的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span></span></span><br><span class="line"><span class="class">        <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">        String[] arr = value.toString().split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 将内容key value作为复合key输出</span></span><br><span class="line">        context.write(<span class="keyword">new</span> Text(arr[<span class="number">0</span>] + <span class="string">" "</span> + arr[<span class="number">1</span>]), <span class="keyword">new</span> IntWritable(Integer.parseInt(arr[<span class="number">1</span>])));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>源文件里的key和value是用空格分隔的，在map中将key和value分隔开然后将key和value组合为一个新的newKey，将value依然作为value输出。</p>
<p>这里既然看了map的代码，那么不防再看下reduce代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span></span></span><br><span class="line"><span class="class">        <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                       Context context</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">            <span class="comment">// 将内容key value作为复合key输出</span></span><br><span class="line">              context.write(key, NullWritable.get());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>reduce只是将key(<em>这里的key是指在map中组合之后的复合键</em>)输出，value是<em>hadoop中提供的null对象NullWritable</em>。</p>
<p>这里之所以只是直接将key输出是因为我们在<strong>整个MR流程中通过key的第一个字段进行分区和分组，比较两个key的大小时是先比较key的第一个字段，相同时再比较第二个字段(这里需要注意的是源文件中第二个字段是int，如果第二个字段也是string类型的，则就可以利用Text自身的比较器进行两个key的比较)</strong>。这样的好处是你可以自定义key和value之前的分隔符(而不用重写outputFormater去定义key和value之间的分隔符)，但也有一些局限性，具体看自己需求吧。</p>
<p>下面来看下我们是怎么对这个复合键进行处理的。首先看下分区策略：</p>
<p>自定义分区策略时要继承<code>Partitioner</code>类，重写<code>getPartition</code>方法，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FirstPartition</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(Text text, IntWritable intWritable, <span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    	<span class="comment">// 拿到复合键中的第一个值，也就是源文件中的key，</span></span><br><span class="line">    	<span class="comment">// 然后根据其值进行hash分区</span></span><br><span class="line">        <span class="keyword">return</span> Math.abs(text.toString().split(<span class="string">" "</span>)[<span class="number">0</span>].hashCode() * <span class="number">127</span>) % i;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对数据分区之后，就该对复合键进行排序了，这里的比较原则是先将复合键进行切分，然后先对第一个字段进行比较，相同之后在对第二个字段进行比较。<em>由于源文件中key是string，value是int，将key和value组成Text类型的复合键时，不能使用Text自身的比较器(因为value是int)，则这里需要自定义比较器</em>。</p>
<p>Hadoop中自定义比较器要继承<code>WritableComparator</code>并且重载<code>compare(WritableComparable a, WritableComparable b)</code>方法(<em>需要特别注意的是，必须有一个构造函数</em>)，自定义比较器也可以实现<code>RawComparator</code>接口。这里是继承<code>WritableComparator</code>类，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">KeyComparator</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构造函数必须有</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">KeyComparator</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(Text.class, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line">    	<span class="comment">// 对复合键进行切分</span></span><br><span class="line">        String[] arr_a = a.toString().split(<span class="string">" "</span>);</span><br><span class="line">        String[] arr_b = b.toString().split(<span class="string">" "</span>);</span><br><span class="line">        System.out.println(<span class="string">"=========KeyComparator========="</span>);</span><br><span class="line">        <span class="comment">// 先比较第一个字段然后再比较第二个</span></span><br><span class="line">        <span class="keyword">if</span> (arr_a[<span class="number">0</span>].compareTo(arr_b[<span class="number">0</span>]) != <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> arr_a[<span class="number">0</span>].compareTo(arr_b[<span class="number">0</span>]);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> Integer.parseInt(arr_a[<span class="number">1</span>]) - Integer.parseInt(arr_b[<span class="number">1</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//    构造函数是必须的，但当构造函数和下面的方法同时存在的时候，排序会出问题</span></span><br><span class="line"><span class="comment">//	  如果没有构造函数时，执行的比较方法是下面的方法，但排序貌似有问题</span></span><br><span class="line"><span class="comment">//    @Override</span></span><br><span class="line"><span class="comment">//    public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) &#123;</span></span><br><span class="line"><span class="comment">//        System.out.println("Key++++++++++++Comparator");</span></span><br><span class="line"><span class="comment">//        String str1 = new String(b1,s1,l1);</span></span><br><span class="line"><span class="comment">//        String str2 = new String(b1,s1,l1);</span></span><br><span class="line"><span class="comment">//        System.out.println(str1.split(" ")[0]);</span></span><br><span class="line"><span class="comment">////        byte[] bytes1 = str1.split(" ")[0].getBytes();</span></span><br><span class="line"><span class="comment">////        byte[] bytes2 = str2.split(" ")[0].getBytes();</span></span><br><span class="line"><span class="comment">//        if (!str1.split(" ")[0].equals(str2.split(" ")[0]))&#123;</span></span><br><span class="line"><span class="comment">//            return str1.split(" ")[0].compareTo(str2.split(" ")[0]);</span></span><br><span class="line"><span class="comment">//        &#125;else &#123;</span></span><br><span class="line"><span class="comment">//            return str1.split(" ")[1].compareTo(str2.split(" ")[1]);</span></span><br><span class="line"><span class="comment">//        &#125;</span></span><br><span class="line"><span class="comment">////        return str1.split(" ")[0].compareTo(str2.split(" ")[0]);</span></span><br><span class="line"><span class="comment">////        return this.compareBytes(b1, s1, l1, b2, s2, l2);</span></span><br><span class="line"><span class="comment">//    &#125;</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>到此代码其实就已经实现了reduce输出的局部有序，但有些场景也需要重写reduce端的分组策略，所以这里也加上自定义的分组策略。自定义分组策略时要<strong>其实也是重写一个比较器</strong>，这里依然采用继承<code>WritableComparator</code>类，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GroupComparator</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 继承WritableComparator时必须有构造方法</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">GroupComparator</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(Text.class, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line">        String[] arr_a = a.toString().split(<span class="string">" "</span>);</span><br><span class="line">        String[] arr_b = b.toString().split(<span class="string">" "</span>);</span><br><span class="line">        System.out.println(<span class="string">"=========GroupComparator========="</span>);</span><br><span class="line">        <span class="comment">// 根据复合键中的第一个字段进行分组比较</span></span><br><span class="line">        <span class="keyword">return</span> arr_a[<span class="number">0</span>].compareTo(arr_b[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后就是main主类了，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    <span class="comment">// 本地ide远程连接集群时，需要设置文件存储格式</span></span><br><span class="line">    conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://192.168.244.131:9000"</span>);</span><br><span class="line"></span><br><span class="line">    String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">    <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">        System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;"</span>);</span><br><span class="line">        System.exit(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Job job = Job.getInstance(conf, <span class="string">"word count"</span>);</span><br><span class="line">    job.setJarByClass(SecondSort.class);</span><br><span class="line">    job.setMapperClass(MyMapper.class);</span><br><span class="line">    job.setReducerClass(MyReducer.class);</span><br><span class="line">    <span class="comment">// 设置了下reduce的个数</span></span><br><span class="line">    job.setNumReduceTasks(<span class="number">2</span>);</span><br><span class="line">    <span class="comment">// 由于map和reduce的输出格式不一样，需要分别设置</span></span><br><span class="line">    job.setMapOutputKeyClass(Text.class);</span><br><span class="line">    job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(NullWritable.class);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 重定义partition</span></span><br><span class="line">    job.setPartitionerClass(FirstPartition.class);</span><br><span class="line">    <span class="comment">// 重写排序方法</span></span><br><span class="line">    job.setSortComparatorClass(KeyComparator.class);</span><br><span class="line">    <span class="comment">// 重定义分组方法</span></span><br><span class="line">    job.setGroupingComparatorClass(GroupComparator.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">        FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[i]));</span><br><span class="line">    &#125;</span><br><span class="line">    FileOutputFormat.setOutputPath(job,</span><br><span class="line">            <span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]));</span><br><span class="line">    <span class="comment">// 删除out输出的内容，以免每次执行之前手动删除</span></span><br><span class="line">    FileSystem fs = FileSystem.get(conf);</span><br><span class="line">    <span class="keyword">if</span> (fs.exists(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>])))&#123;</span><br><span class="line">        fs.delete(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]), <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出结果如下：<br>因为有两个reduce则有两个输出，part-r-00000和part-r-00001。<br>part-r-00000的内容如下：<br>1991 18<br>1991 20<br>1991 27<br>1991 33<br>1993 18<br>1993 33<br>part-r-00001的内容如下：<br>1990 10<br>1990 17<br>1990 22<br>1990 31<br>1992 22<br>1992 31</p>
<h3 id="自定义数据类型为reduce的key"><a href="#自定义数据类型为reduce的key" class="headerlink" title="自定义数据类型为reduce的key"></a>自定义数据类型为reduce的key</h3><p>将需要排序的字段组合为一个新的数据类型，由此新数据类型作为key。Hadoop自定义数据类型时需要实现<code>WritableComparable</code>接口。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntityPair</span> <span class="keyword">implements</span> <span class="title">WritableComparable</span>&lt;<span class="title">EntityPair</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Text firstKey;</span><br><span class="line">    <span class="keyword">private</span> IntWritable secondKey;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Text <span class="title">getFirstKey</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> firstKey;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFirstKey</span><span class="params">(Text firstKey)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.firstKey = firstKey;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> IntWritable <span class="title">getSecondKey</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> secondKey;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSecondKey</span><span class="params">(IntWritable secondKey)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.secondKey = secondKey;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">EntityPair</span><span class="params">(Text firstKey, IntWritable secondKey)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.firstKey = firstKey;</span><br><span class="line">        <span class="keyword">this</span>.secondKey = secondKey;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">EntityPair</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(EntityPair o)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.firstKey.compareTo(o.getFirstKey());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        dataOutput.writeUTF(firstKey.toString());</span><br><span class="line">        dataOutput.writeInt(secondKey.get());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        firstKey = <span class="keyword">new</span> Text(dataInput.readUTF());</span><br><span class="line">        secondKey = <span class="keyword">new</span> IntWritable(dataInput.readInt());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.getFirstKey() + <span class="string">" "</span> + <span class="keyword">this</span>.getSecondKey();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>则分区策略、比较规则和分组策略和上一节的思路大体一样，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 自定义分区策略</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntityPartition</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">EntityPair</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(EntityPair text, IntWritable intWritable, <span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    	<span class="comment">// 得到EntityPair中的第一个firstKey</span></span><br><span class="line">        <span class="keyword">return</span> Math.abs(text.getFirstKey().hashCode() * <span class="number">127</span>) % i;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 自定义比较器</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntityComparator</span> <span class="keyword">extends</span> <span class="title">WritableComparator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">EntityComparator</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(EntityPair.class, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line">        EntityPair entityPair1 = (EntityPair) a;</span><br><span class="line">        EntityPair entityPair2 = (EntityPair) b;</span><br><span class="line">        System.out.println(<span class="string">"=========Comparator========="</span>);</span><br><span class="line">        <span class="keyword">if</span> (!entityPair1.getFirstKey().toString().equals(entityPair2.getFirstKey().toString()))&#123;</span><br><span class="line">            <span class="keyword">return</span> entityPair1.getFirstKey().toString().compareTo(entityPair2.getFirstKey().toString());</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> entityPair1.getSecondKey().get() - entityPair2.getSecondKey().get();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 自定义分组策略</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntityGroup</span>  <span class="keyword">extends</span> <span class="title">WritableComparator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">EntityGroup</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(EntityPair.class, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(WritableComparable a, WritableComparable b)</span> </span>&#123;</span><br><span class="line">        EntityPair entityPair1 = (EntityPair) a;</span><br><span class="line">        EntityPair entityPair2 = (EntityPair) b;</span><br><span class="line">        System.out.println(<span class="string">"=========GroupComparator========="</span>);</span><br><span class="line">        <span class="keyword">return</span> entityPair1.getFirstKey().toString().compareTo(entityPair2.getFirstKey().toString());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面是MR类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntitySecondSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = Logger.getLogger(EntitySecondSort.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span></span></span><br><span class="line"><span class="class">            <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">EntityPair</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">        )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] arr = value.toString().split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将内容key value作为复合key输出</span></span><br><span class="line">            context.write(<span class="keyword">new</span> EntityPair(<span class="keyword">new</span> Text(arr[<span class="number">0</span>]), <span class="keyword">new</span> IntWritable(Integer.parseInt(arr[<span class="number">1</span>]))),</span><br><span class="line">                    <span class="keyword">new</span> IntWritable(Integer.parseInt(arr[<span class="number">1</span>])));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span></span></span><br><span class="line"><span class="class">            <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">EntityPair</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(EntityPair key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Context context</span></span></span><br><span class="line"><span class="function"><span class="params">        )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">                <span class="comment">// 分组之后</span></span><br><span class="line">                context.write(<span class="keyword">new</span> Text(key.getFirstKey()), val);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://192.168.244.131:9000"</span>);</span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;"</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Job job = Job.getInstance(conf, <span class="string">"word count"</span>);</span><br><span class="line">        job.setJarByClass(EntitySecondSort.class);</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setNumReduceTasks(<span class="number">2</span>);</span><br><span class="line">        job.setMapOutputKeyClass(EntityPair.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line">        <span class="comment">// 重定义partition</span></span><br><span class="line">        job.setPartitionerClass(EntityPartition.class);</span><br><span class="line">        <span class="comment">// 重写排序方法</span></span><br><span class="line">        job.setSortComparatorClass(EntityComparator.class);</span><br><span class="line">        <span class="comment">// 自定义分组策略</span></span><br><span class="line">        job.setGroupingComparatorClass(EntityGroup.class);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[i]));</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputFormat.setOutputPath(job,</span><br><span class="line">                <span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">if</span> (fs.exists(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>])))&#123;</span><br><span class="line">            fs.delete(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]), <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里的分组策略也不是必须的，(只有在reduce中需要对相同key的values进行合并操作时，才需要对其records根据复合键的第一个值进行分组。)</p>
<p>上面的reduce代码输出的是键值对，之所以这样是考虑到value中可能包含很多属性，而只需要对其中的某一个属性value1进行排序，则将剩余的属性列出。</p>
<blockquote>
<p>关于二次排序的例子Hadoop自带的MapReduce例子中也有样例，类名<code>SecondarySort</code></p>
</blockquote>
<p>上面的代码只实现了reduce内有序，各个reduce之间是无序的，<strong>那么如何得到一个全局有序的结果呢</strong>？看<a href="http://bigdatadecode.club/MapReduce应用实例--二次排序之全局有序.html">下篇</a></p>
<h2 id="附加-equals和hashCode的关系"><a href="#附加-equals和hashCode的关系" class="headerlink" title="附加: equals和hashCode的关系"></a>附加: equals和hashCode的关系</h2><p>这里补充下equals和hashCode的关系</p>
<p>equals和hashCode都是Object类的方法，可以在任务一个类中重写，Object<strong>默认</strong>的equals实现是<em>判断两个对象的地址是否相等</em>(即，是否是同一个对象)来区分它们是否相等，<strong>此时等价于”==”</strong>。但是equals方法往往被类重写，用来判断两个对象的内容是否相等，如String类的equals方法。</p>
<p>hashCode主要是用来判断对象在散列表中的位置，则如果两个对象相同则在散列表中的位置也应该是相同的，但是判断两个对象是否相同是由equals判断的，则<em><strong>如果某个类的对象要在散列表中使用</strong>，重写equals方法时往往也要重写hashCode方法，以保证equals为true时，hashCode是相同的</em>。如果某个类不会出现在散列表中，则equals和hashCode并没有什么直接的关系。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce应用实例 </tag>
            
            <tag> 二次排序 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce源码解析--环形缓冲区]]></title>
      <url>http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--%E7%8E%AF%E5%BD%A2%E7%BC%93%E5%86%B2%E5%8C%BA.html</url>
      <content type="html"><![CDATA[<p>之前有两篇文件分别分析了<a href="http://bigdatadecode.club/MapReduce源码解析--Map解析.html">Map</a>和<a href="http://bigdatadecode.club/MapReduce源码解析--Reduce解析.html">Reduce</a>阶段的流程，这篇文章把Map阶段的<em>环形缓冲区</em>单独拿出来进行分析，对环形缓冲区的数据结构和数据进入环形缓冲区然后溢写到磁盘的流程进行分析。</p>
<a id="more"></a>
<h2 id="环形缓冲区数据结构"><a href="#环形缓冲区数据结构" class="headerlink" title="环形缓冲区数据结构"></a>环形缓冲区数据结构</h2><p>Map过程中环形缓冲区是指数据被map处理之后会先放入内存，内存中的这片区域就是环形缓冲区。</p>
<p>环形缓冲区是在<code>MapTask.MapOutputBuffer</code>中定义的，相关的属性如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// k/v accounting</span></span><br><span class="line"><span class="comment">// 存放meta数据的IntBuffer，都是int entry，占4byte</span></span><br><span class="line"><span class="keyword">private</span> IntBuffer kvmeta; <span class="comment">// metadata overlay on backing store</span></span><br><span class="line"><span class="keyword">int</span> kvstart;            <span class="comment">// marks origin of spill metadata</span></span><br><span class="line"><span class="keyword">int</span> kvend;              <span class="comment">// marks end of spill metadata</span></span><br><span class="line"><span class="keyword">int</span> kvindex;            <span class="comment">// marks end of fully serialized records</span></span><br><span class="line"><span class="comment">// 分割meta和key value内容的标识   </span></span><br><span class="line"><span class="comment">// meta数据和key value内容都存放在同一个环形缓冲区，所以需要分隔开</span></span><br><span class="line"><span class="keyword">int</span> equator;            <span class="comment">// marks origin of meta/serialization</span></span><br><span class="line"><span class="keyword">int</span> bufstart;           <span class="comment">// marks beginning of spill</span></span><br><span class="line"><span class="keyword">int</span> bufend;             <span class="comment">// marks beginning of collectable</span></span><br><span class="line"><span class="keyword">int</span> bufmark;            <span class="comment">// marks end of record</span></span><br><span class="line"><span class="keyword">int</span> bufindex;           <span class="comment">// marks end of collected</span></span><br><span class="line"><span class="keyword">int</span> bufvoid;            <span class="comment">// marks the point where we should stop</span></span><br><span class="line">                        <span class="comment">// reading at the end of the buffer</span></span><br><span class="line"><span class="comment">// 存放key value的byte数组，单位是byte，注意与kvmeta区分</span></span><br><span class="line"><span class="keyword">byte</span>[] kvbuffer;        <span class="comment">// main output buffer</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] b0 = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// key value在kvbuffer中的地址存放在偏移kvindex的距离</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> VALSTART = <span class="number">0</span>;         <span class="comment">// val offset in acct</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> KEYSTART = <span class="number">1</span>;         <span class="comment">// key offset in acct</span></span><br><span class="line"><span class="comment">// partition信息存在kvmeta中偏移kvindex的距离</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PARTITION = <span class="number">2</span>;        <span class="comment">// partition offset in acct</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> VALLEN = <span class="number">3</span>;           <span class="comment">// length of value</span></span><br><span class="line"><span class="comment">// 一对key value的meta数据在kvmeta中占用的个数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> NMETA = <span class="number">4</span>;            <span class="comment">// num meta ints</span></span><br><span class="line"><span class="comment">// 一对key value的meta数据在kvmeta中占用的byte数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> METASIZE = NMETA * <span class="number">4</span>; <span class="comment">// size in bytes</span></span><br></pre></td></tr></table></figure>
<p>环形缓冲区其实是一个数组，数组中存放着key、value的序列化数据和key、value的元数据信息，key/value的元数据存储的格式是int类型，每个key/value对应一个元数据，元数据由4个int组成，第一个int存放value的起始位置，第二个存放key的起始位置，第三个存放partition，最后一个存放value的长度。</p>
<p>key/value序列化的数据和元数据在环形缓冲区中的存储是由<em>equator</em>分隔的，key/value按照<em>索引递增</em>的方向存储，meta则按照<em>索引递减</em>的方向存储，将其数组抽象为一个环形结构之后，<em>以equator为界，key/value顺时针存储，meta逆时针存储</em>。</p>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>环形缓冲区的结构在<code>MapOutputBuffer.init</code>中创建。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(MapOutputCollector.Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                )</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="comment">//MAP_SORT_SPILL_PERCENT = mapreduce.map.sort.spill.percent</span></span><br><span class="line">  <span class="comment">// map 端buffer所占的百分比</span></span><br><span class="line">  <span class="comment">//sanity checks</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">float</span> spillper =</span><br><span class="line">    job.getFloat(JobContext.MAP_SORT_SPILL_PERCENT, (<span class="keyword">float</span>)<span class="number">0.8</span>);</span><br><span class="line">  <span class="comment">//IO_SORT_MB = "mapreduce.task.io.sort.mb"</span></span><br><span class="line">  <span class="comment">// map 端buffer大小</span></span><br><span class="line">  <span class="comment">// mapreduce.task.io.sort.mb * mapreduce.map.sort.spill.percent 最好是16的整数倍</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> sortmb = job.getInt(JobContext.IO_SORT_MB, <span class="number">100</span>);</span><br><span class="line">  <span class="comment">// 所有的spill index 在内存所占的大小的阈值</span></span><br><span class="line">  indexCacheMemoryLimit = job.getInt(JobContext.INDEX_CACHE_MEMORY_LIMIT,</span><br><span class="line">                                     INDEX_CACHE_MEMORY_LIMIT_DEFAULT);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 排序的实现类，可以自己实现。 这里用的是改写的快排</span></span><br><span class="line">  sorter = ReflectionUtils.newInstance(job.getClass(<span class="string">"map.sort.class"</span>,</span><br><span class="line">        QuickSort.class, IndexedSorter.class), job);</span><br><span class="line">  <span class="comment">// buffers and accounting</span></span><br><span class="line">  <span class="comment">// 上面IO_SORT_MB的单位是MB，左移20位将单位转化为byte</span></span><br><span class="line">  <span class="keyword">int</span> maxMemUsage = sortmb &lt;&lt; <span class="number">20</span>;</span><br><span class="line">  <span class="comment">// METASIZE是元数据的长度，元数据有4个int单元，分别为</span></span><br><span class="line">  <span class="comment">// VALSTART、KEYSTART、PARTITION、VALLEN，而int为4个byte，</span></span><br><span class="line">  <span class="comment">// 所以METASIZE长度为16。下面是计算buffer中最多有多少byte来存元数据</span></span><br><span class="line">  maxMemUsage -= maxMemUsage % METASIZE;</span><br><span class="line">  <span class="comment">// 元数据数组  以byte为单位</span></span><br><span class="line">  kvbuffer = <span class="keyword">new</span> <span class="keyword">byte</span>[maxMemUsage];</span><br><span class="line">  bufvoid = kvbuffer.length;</span><br><span class="line">  <span class="comment">// 将kvbuffer转化为int型的kvmeta  以int为单位，也就是4byte</span></span><br><span class="line">  kvmeta = ByteBuffer.wrap(kvbuffer)</span><br><span class="line">     .order(ByteOrder.nativeOrder())</span><br><span class="line">     .asIntBuffer();</span><br><span class="line">  <span class="comment">// 设置buf和kvmeta的分界线</span></span><br><span class="line">  setEquator(<span class="number">0</span>);</span><br><span class="line">  bufstart = bufend = bufindex = equator;</span><br><span class="line">  kvstart = kvend = kvindex;</span><br><span class="line">  <span class="comment">// kvmeta中存放元数据实体的最大个数</span></span><br><span class="line">  maxRec = kvmeta.capacity() / NMETA;</span><br><span class="line">  <span class="comment">// buffer spill时的阈值（不单单是sortmb*spillper）</span></span><br><span class="line">  <span class="comment">// 更加精确的是kvbuffer.length*spiller</span></span><br><span class="line">  softLimit = (<span class="keyword">int</span>)(kvbuffer.length * spillper);</span><br><span class="line">  <span class="comment">// 此变量较为重要，作为spill的动态衡量标准</span></span><br><span class="line">  bufferRemaining = softLimit;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// k/v serialization</span></span><br><span class="line">  comparator = job.getOutputKeyComparator();</span><br><span class="line">  keyClass = (Class&lt;K&gt;)job.getMapOutputKeyClass();</span><br><span class="line">  valClass = (Class&lt;V&gt;)job.getMapOutputValueClass();</span><br><span class="line">  serializationFactory = <span class="keyword">new</span> SerializationFactory(job);</span><br><span class="line">  keySerializer = serializationFactory.getSerializer(keyClass);</span><br><span class="line">  <span class="comment">// 将bb作为key序列化写入的output</span></span><br><span class="line">  keySerializer.open(bb);</span><br><span class="line">  valSerializer = serializationFactory.getSerializer(valClass);</span><br><span class="line">  <span class="comment">// 将bb作为value序列化写入的output</span></span><br><span class="line">  valSerializer.open(bb);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// combiner</span></span><br><span class="line">  ...</span><br><span class="line">  spillInProgress = <span class="keyword">false</span>;</span><br><span class="line">  <span class="comment">// 最后一次merge时，在有combiner的情况下，超过此阈值才执行combiner</span></span><br><span class="line">  minSpillsForCombine = job.getInt(JobContext.MAP_COMBINE_MIN_SPILLS, <span class="number">3</span>);</span><br><span class="line">  spillThread.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">  spillThread.setName(<span class="string">"SpillThread"</span>);</span><br><span class="line">  spillLock.lock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    spillThread.start();</span><br><span class="line">    <span class="keyword">while</span> (!spillThreadRunning) &#123;</span><br><span class="line">      spillDone.await();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Spill thread failed to initialize"</span>, e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    spillLock.unlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (sortSpillException != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Spill thread failed to initialize"</span>,</span><br><span class="line">        sortSpillException);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>init是对环形缓冲区进行初始化构造，由<em>mapreduce.task.io.sort.mb</em>决定map中环形缓冲区的大小sortmb，默认是100M。</p>
<p>此缓冲区也用于存放meta，一个meta占用METASIZE(16byte)，则其中用于存放数据的大小是<em>maxMemUsage -= sortmb &lt;&lt; 20 % METASIZE</em>(由此可知最好设置sortmb转换为byte之后是16的整数倍)，然后用maxMemUsage初始化<em>kvbuffer字节数组</em>和<em>kvmeta整形数组</em>，最后设置数组的一些标识信息。利用<code>setEquator(0)</code>设置kvbuffer和kvmeta的分界线，初始化的时候以<strong>0</strong>为分界线，kvindex为<em>aligned - METASIZE + kvbuffer.length</em>，其位置在环形数组中相当于按照逆时针方向减去METASIZE，由kvindex设置<em>kvstart = kvend = kvindex</em>，由equator设置<em>bufstart = bufend = bufindex = equator</em>，还得设置<em>bufvoid = kvbuffer.length</em>，bufvoid用于标识用于存放数据的最大位置。</p>
<p>为了提高效率，当buffer占用达到阈值之后，会进行spill，这个阈值是由<em>bufferRemaining</em>进行检查的，bufferRemaining由<code>softLimit = (int)(kvbuffer.length * spillper); bufferRemaining = softLimit;</code>进行初始化赋值，这里需要注意的是softLimit并不是<em>sortmb*spillper</em>，而是<em>kvbuffer.length * spillper</em>，当sortmb &lt;&lt; 20是16的整数倍时，才可以认为softLimit是sortmb*spillper。</p>
<p>下面是setEquator的代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// setEquator(0)的代码如下</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setEquator</span><span class="params">(<span class="keyword">int</span> pos)</span> </span>&#123;</span><br><span class="line">  equator = pos;</span><br><span class="line">  <span class="comment">// set index prior to first entry, aligned at meta boundary</span></span><br><span class="line">  <span class="comment">// 第一个 entry的末尾位置，即元数据和kv数据的分界线   单位是byte</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> aligned = pos - (pos % METASIZE);</span><br><span class="line">  <span class="comment">// Cast one of the operands to long to avoid integer overflow</span></span><br><span class="line">  <span class="comment">// 元数据中存放数据的起始位置</span></span><br><span class="line">  kvindex = (<span class="keyword">int</span>)</span><br><span class="line">    (((<span class="keyword">long</span>)aligned - METASIZE + kvbuffer.length) % kvbuffer.length) / <span class="number">4</span>;</span><br><span class="line">  LOG.info(<span class="string">"(EQUATOR) "</span> + pos + <span class="string">" kvi "</span> + kvindex +</span><br><span class="line">      <span class="string">"("</span> + (kvindex * <span class="number">4</span>) + <span class="string">")"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>buffer初始化之后的抽象数据结构如下图所示：<br><img src="/blogimgs/MapOutputBuffer/buffer_init.png" alt="环形缓冲区数据结构图" title="环形缓冲区数据结构图"></p>
<h2 id="写入buffer"><a href="#写入buffer" class="headerlink" title="写入buffer"></a>写入buffer</h2><p>Map通过<code>NewOutputCollector.write</code>方法调用<code>collector.collect</code>向buffer中写入数据，数据写入之前已在<code>NewOutputCollector.write</code>中对要写入的数据进行逐条分区，下面看下<em>collect</em></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MapOutputBuffer.collect</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">collect</span><span class="params">(K key, V value, <span class="keyword">final</span> <span class="keyword">int</span> partition</span></span></span><br><span class="line"><span class="function"><span class="params">                                 )</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 新数据collect时，先将剩余的空间减去元数据的长度，之后进行判断</span></span><br><span class="line">  bufferRemaining -= METASIZE;</span><br><span class="line">  <span class="keyword">if</span> (bufferRemaining &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// start spill if the thread is not running and the soft limit has been</span></span><br><span class="line">    <span class="comment">// reached</span></span><br><span class="line">    spillLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">// 首次spill时，spillInProgress是false</span></span><br><span class="line">        <span class="keyword">if</span> (!spillInProgress) &#123;</span><br><span class="line">          <span class="comment">// 得到kvindex的byte位置</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> kvbidx = <span class="number">4</span> * kvindex;</span><br><span class="line">          <span class="comment">// 得到kvend的byte位置</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> kvbend = <span class="number">4</span> * kvend;</span><br><span class="line">          <span class="comment">// serialized, unspilled bytes always lie between kvindex and</span></span><br><span class="line">          <span class="comment">// bufindex, crossing the equator. Note that any void space</span></span><br><span class="line">          <span class="comment">// created by a reset must be included in "used" bytes</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> bUsed = distanceTo(kvbidx, bufindex);</span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">boolean</span> bufsoftlimit = bUsed &gt;= softLimit;</span><br><span class="line">          <span class="keyword">if</span> ((kvbend + METASIZE) % kvbuffer.length !=</span><br><span class="line">              equator - (equator % METASIZE)) &#123;</span><br><span class="line">            <span class="comment">// spill finished, reclaim space</span></span><br><span class="line">            resetSpill();</span><br><span class="line">            bufferRemaining = Math.min(</span><br><span class="line">                distanceTo(bufindex, kvbidx) - <span class="number">2</span> * METASIZE,</span><br><span class="line">                softLimit - bUsed) - METASIZE;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (bufsoftlimit &amp;&amp; kvindex != kvend) &#123;</span><br><span class="line">            <span class="comment">// spill records, if any collected; check latter, as it may</span></span><br><span class="line">            <span class="comment">// be possible for metadata alignment to hit spill pcnt</span></span><br><span class="line">            startSpill();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> avgRec = (<span class="keyword">int</span>)</span><br><span class="line">              (mapOutputByteCounter.getCounter() /</span><br><span class="line">              mapOutputRecordCounter.getCounter());</span><br><span class="line">            <span class="comment">// leave at least half the split buffer for serialization data</span></span><br><span class="line">            <span class="comment">// ensure that kvindex &gt;= bufindex</span></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> distkvi = distanceTo(bufindex, kvbidx);</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> newPos = (bufindex +</span><br><span class="line">              Math.max(<span class="number">2</span> * METASIZE - <span class="number">1</span>,</span><br><span class="line">                      Math.min(distkvi / <span class="number">2</span>,</span><br><span class="line">                               distkvi / (METASIZE + avgRec) * METASIZE)))</span><br><span class="line">              % kvbuffer.length;</span><br><span class="line">            setEquator(newPos);</span><br><span class="line">            bufmark = bufindex = newPos;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> serBound = <span class="number">4</span> * kvend;</span><br><span class="line">            <span class="comment">// bytes remaining before the lock must be held and limits</span></span><br><span class="line">            <span class="comment">// checked is the minimum of three arcs: the metadata space, the</span></span><br><span class="line">            <span class="comment">// serialization space, and the soft limit</span></span><br><span class="line">            bufferRemaining = Math.min(</span><br><span class="line">                <span class="comment">// metadata max</span></span><br><span class="line">                distanceTo(bufend, newPos),</span><br><span class="line">                Math.min(</span><br><span class="line">                  <span class="comment">// serialization max</span></span><br><span class="line">                  distanceTo(newPos, serBound),</span><br><span class="line">                  <span class="comment">// soft limit</span></span><br><span class="line">                  softLimit)) - <span class="number">2</span> * METASIZE;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">while</span> (<span class="keyword">false</span>);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      spillLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将key value 及元数据信息写入缓冲区</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// serialize key bytes into buffer</span></span><br><span class="line">    <span class="keyword">int</span> keystart = bufindex;</span><br><span class="line">    <span class="comment">// 将key序列化写入kvbuffer中，并移动bufindex</span></span><br><span class="line">    keySerializer.serialize(key);</span><br><span class="line">    <span class="comment">// key所占空间被bufvoid分隔，则移动key，</span></span><br><span class="line">    <span class="comment">// 将其值放在连续的空间中便于sort时key的对比</span></span><br><span class="line">    <span class="keyword">if</span> (bufindex &lt; keystart) &#123;</span><br><span class="line">      <span class="comment">// wrapped the key; must make contiguous</span></span><br><span class="line">      bb.shiftBufferedKey();</span><br><span class="line">      keystart = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// serialize value bytes into buffer</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> valstart = bufindex;</span><br><span class="line">    valSerializer.serialize(value);</span><br><span class="line">    <span class="comment">// It's possible for records to have zero length, i.e. the serializer</span></span><br><span class="line">    <span class="comment">// will perform no writes. To ensure that the boundary conditions are</span></span><br><span class="line">    <span class="comment">// checked and that the kvindex invariant is maintained, perform a</span></span><br><span class="line">    <span class="comment">// zero-length write into the buffer. The logic monitoring this could be</span></span><br><span class="line">    <span class="comment">// moved into collect, but this is cleaner and inexpensive. For now, it</span></span><br><span class="line">    <span class="comment">// is acceptable.</span></span><br><span class="line">    bb.write(b0, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the record must be marked after the preceding write, as the metadata</span></span><br><span class="line">    <span class="comment">// for this record are not yet written</span></span><br><span class="line">    <span class="keyword">int</span> valend = bb.markRecord();</span><br><span class="line"></span><br><span class="line">    mapOutputRecordCounter.increment(<span class="number">1</span>);</span><br><span class="line">    mapOutputByteCounter.increment(</span><br><span class="line">        distanceTo(keystart, valend, bufvoid));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// write accounting info</span></span><br><span class="line">    kvmeta.put(kvindex + PARTITION, partition);</span><br><span class="line">    kvmeta.put(kvindex + KEYSTART, keystart);</span><br><span class="line">    kvmeta.put(kvindex + VALSTART, valstart);</span><br><span class="line">    kvmeta.put(kvindex + VALLEN, distanceTo(valstart, valend));</span><br><span class="line">    <span class="comment">// advance kvindex</span></span><br><span class="line">    kvindex = (kvindex - NMETA + kvmeta.capacity()) % kvmeta.capacity();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (MapBufferTooSmallException e) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Record too large for in-memory buffer: "</span> + e.getMessage());</span><br><span class="line">    spillSingleRecord(key, value, partition);</span><br><span class="line">    mapOutputRecordCounter.increment(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每次写入数据时，执行<code>bufferRemaining -= METASIZE</code>之后，检查<em>bufferRemaining</em>，</p>
<p>如果大于0，直接将key/value序列化对和对应的meta写入buffer中，key/value是序列化之后写入的，key/value经过一些列的方法调用<code>Serializer.serialize(key/value) -&gt; WritableSerializer.serialize(key/value) -&gt; BytesWritable.write(dataOut) -&gt; DataOutputStream.write(bytes, 0, size) -&gt; MapOutputBuffer.Buffer.write(b, off, len)</code>，最后由<code>MapOutputBuffer.Buffer.write(b, off, len)</code>将数据写入<em>kvbuffer</em>中，write方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// must always verify the invariant that at least METASIZE bytes are</span></span><br><span class="line">  <span class="comment">// available beyond kvindex, even when len == 0</span></span><br><span class="line">  bufferRemaining -= len;</span><br><span class="line">  <span class="keyword">if</span> (bufferRemaining &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// writing these bytes could exhaust available buffer space or fill</span></span><br><span class="line">    <span class="comment">// the buffer to soft limit. check if spill or blocking are necessary</span></span><br><span class="line">    <span class="keyword">boolean</span> blockwrite = <span class="keyword">false</span>;</span><br><span class="line">    spillLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">do</span> &#123;</span><br><span class="line">        checkSpillException();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> kvbidx = <span class="number">4</span> * kvindex;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> kvbend = <span class="number">4</span> * kvend;</span><br><span class="line">        <span class="comment">// ser distance to key index</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> distkvi = distanceTo(bufindex, kvbidx);</span><br><span class="line">        <span class="comment">// ser distance to spill end index</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> distkve = distanceTo(bufindex, kvbend);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// if kvindex is closer than kvend, then a spill is neither in</span></span><br><span class="line">        <span class="comment">// progress nor complete and reset since the lock was held. The</span></span><br><span class="line">        <span class="comment">// write should block only if there is insufficient space to</span></span><br><span class="line">        <span class="comment">// complete the current write, write the metadata for this record,</span></span><br><span class="line">        <span class="comment">// and write the metadata for the next record. If kvend is closer,</span></span><br><span class="line">        <span class="comment">// then the write should block if there is too little space for</span></span><br><span class="line">        <span class="comment">// either the metadata or the current write. Note that collect</span></span><br><span class="line">        <span class="comment">// ensures its metadata requirement with a zero-length write</span></span><br><span class="line">        blockwrite = distkvi &lt;= distkve</span><br><span class="line">          ? distkvi &lt;= len + <span class="number">2</span> * METASIZE</span><br><span class="line">          : distkve &lt;= len || distanceTo(bufend, kvbidx) &lt; <span class="number">2</span> * METASIZE;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!spillInProgress) &#123;</span><br><span class="line">          <span class="keyword">if</span> (blockwrite) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((kvbend + METASIZE) % kvbuffer.length !=</span><br><span class="line">                equator - (equator % METASIZE)) &#123;</span><br><span class="line">              <span class="comment">// spill finished, reclaim space</span></span><br><span class="line">              <span class="comment">// need to use meta exclusively; zero-len rec &amp; 100% spill</span></span><br><span class="line">              <span class="comment">// pcnt would fail</span></span><br><span class="line">              resetSpill(); <span class="comment">// resetSpill doesn't move bufindex, kvindex</span></span><br><span class="line">              bufferRemaining = Math.min(</span><br><span class="line">                  distkvi - <span class="number">2</span> * METASIZE,</span><br><span class="line">                  softLimit - distanceTo(kvbidx, bufindex)) - len;</span><br><span class="line">              <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// we have records we can spill; only spill if blocked</span></span><br><span class="line">            <span class="keyword">if</span> (kvindex != kvend) &#123;</span><br><span class="line">              startSpill();</span><br><span class="line">              <span class="comment">// Blocked on this write, waiting for the spill just</span></span><br><span class="line">              <span class="comment">// initiated to finish. Instead of repositioning the marker</span></span><br><span class="line">              <span class="comment">// and copying the partial record, we set the record start</span></span><br><span class="line">              <span class="comment">// to be the new equator</span></span><br><span class="line">              setEquator(bufmark);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              <span class="comment">// We have no buffered records, and this record is too large</span></span><br><span class="line">              <span class="comment">// to write into kvbuffer. We must spill it directly from</span></span><br><span class="line">              <span class="comment">// collect</span></span><br><span class="line">              <span class="keyword">final</span> <span class="keyword">int</span> size = distanceTo(bufstart, bufindex) + len;</span><br><span class="line">              setEquator(<span class="number">0</span>);</span><br><span class="line">              bufstart = bufend = bufindex = equator;</span><br><span class="line">              kvstart = kvend = kvindex;</span><br><span class="line">              bufvoid = kvbuffer.length;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> MapBufferTooSmallException(size + <span class="string">" bytes"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (blockwrite) &#123;</span><br><span class="line">          <span class="comment">// wait for spill</span></span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (spillInProgress) &#123;</span><br><span class="line">              reporter.progress();</span><br><span class="line">              spillDone.await();</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">                  <span class="string">"Buffer interrupted while waiting for the writer"</span>, e);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">while</span> (blockwrite);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      spillLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// here, we know that we have sufficient space to write</span></span><br><span class="line">  <span class="keyword">if</span> (bufindex + len &gt; bufvoid) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> gaplen = bufvoid - bufindex;</span><br><span class="line">    System.arraycopy(b, off, kvbuffer, bufindex, gaplen);</span><br><span class="line">    len -= gaplen;</span><br><span class="line">    off += gaplen;</span><br><span class="line">    bufindex = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  System.arraycopy(b, off, kvbuffer, bufindex, len);</span><br><span class="line">  bufindex += len;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>write方法将key/value写入kvbuffer中，如果bufindex+len超过了bufvoid，则将写入的内容分开存储，将一部分写入bufindex和bufvoid之间，然后重置bufindex，将剩余的部分写入，这里不区分key和value，写入key之后会在collect中判断<code>bufindex &lt; keystart</code>，当bufindex小时，则key被分开存储，执行<code>bb.shiftBufferedKey()</code>，value则直接写入，不用判断是否被分开存储，key不能分开存储是因为要对key进行排序。</p>
<p><em>这里需要注意的是要写入的数据太长</em>，并且<em>kvinde==kvend</em>，则抛出<em>MapBufferTooSmallException</em>异常，在collect中捕获，将此数据直接spill到磁盘<code>spillSingleRecord</code>，<em>也就是当单条记录过长时，不写buffer，直接写入磁盘</em>。</p>
<p>下面看下bb.shiftBufferedKey()代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// BlockingBuffer.shiftBufferedKey</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">shiftBufferedKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// spillLock unnecessary; both kvend and kvindex are current</span></span><br><span class="line">  <span class="keyword">int</span> headbytelen = bufvoid - bufmark;</span><br><span class="line">  bufvoid = bufmark;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> kvbidx = <span class="number">4</span> * kvindex;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> kvbend = <span class="number">4</span> * kvend;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> avail =</span><br><span class="line">    Math.min(distanceTo(<span class="number">0</span>, kvbidx), distanceTo(<span class="number">0</span>, kvbend));</span><br><span class="line">  <span class="keyword">if</span> (bufindex + headbytelen &lt; avail) &#123;</span><br><span class="line">    System.arraycopy(kvbuffer, <span class="number">0</span>, kvbuffer, headbytelen, bufindex);</span><br><span class="line">    System.arraycopy(kvbuffer, bufvoid, kvbuffer, <span class="number">0</span>, headbytelen);</span><br><span class="line">    bufindex += headbytelen;</span><br><span class="line">    bufferRemaining -= kvbuffer.length - bufvoid;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">byte</span>[] keytmp = <span class="keyword">new</span> <span class="keyword">byte</span>[bufindex];</span><br><span class="line">    System.arraycopy(kvbuffer, <span class="number">0</span>, keytmp, <span class="number">0</span>, bufindex);</span><br><span class="line">    bufindex = <span class="number">0</span>;</span><br><span class="line">    out.write(kvbuffer, bufmark, headbytelen);</span><br><span class="line">    out.write(keytmp);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>shiftBufferedKey时，判断首部是否有足够的空间存放key，有没有足够的空间，则先将首部的部分key写入keytmp中，然后分两次写入，再次调用Buffer.write，如果有足够的空间，分两次copy，先将首部的部分key复制到headbytelen的位置，然后将末尾的部分key复制到首部，移动bufindex，重置bufferRemaining的值。</p>
<p>key/value写入之后，继续写入元数据信息并重置kvindex的值。</p>
<h2 id="spill"><a href="#spill" class="headerlink" title="spill"></a>spill</h2><p>一次写入buffer结束，当写入数据比较多，<em>bufferRemaining小于等于0</em>时，准备进行spill，首次spill，spillInProgress为false，此时查看<em>bUsed = distanceTo(kvbidx, bufindex)</em>，此时<em>bUsed &gt;= softLimit</em> 并且 <code>(kvbend + METASIZE) % kvbuffer.length == equator - (equator % METASIZE)</code>，则进行spill，调用<code>startSpill</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startSpill</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 元数据的边界赋值</span></span><br><span class="line">  kvend = (kvindex + NMETA) % kvmeta.capacity();</span><br><span class="line">  <span class="comment">// key/value的边界赋值</span></span><br><span class="line">  bufend = bufmark;</span><br><span class="line">  <span class="comment">// 设置spill运行标识</span></span><br><span class="line">  spillInProgress = <span class="keyword">true</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 利用重入锁，对spill线程进行唤醒</span></span><br><span class="line">  spillReady.signal();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>startSpill唤醒spill线程之后，进程spill操作，但此时map向buffer的写入操作并没有阻塞，需要重新边界equator和bufferRemaining的值，先来看下equator和bufferRemaining值的设定：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 根据已经写入的kv得出每个record的平均长度</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> avgRec = (<span class="keyword">int</span>) (mapOutputByteCounter.getCounter() /</span><br><span class="line">  mapOutputRecordCounter.getCounter());</span><br><span class="line"><span class="comment">// leave at least half the split buffer for serialization data</span></span><br><span class="line"><span class="comment">// ensure that kvindex &gt;= bufindex</span></span><br><span class="line"><span class="comment">// 得到空余空间的大小</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> distkvi = distanceTo(bufindex, kvbidx);</span><br><span class="line"><span class="comment">// 得出新equator的位置</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> newPos = (bufindex +</span><br><span class="line">  Math.max(<span class="number">2</span> * METASIZE - <span class="number">1</span>,</span><br><span class="line">          Math.min(distkvi / <span class="number">2</span>,</span><br><span class="line">                   distkvi / (METASIZE + avgRec) * METASIZE)))</span><br><span class="line">  % kvbuffer.length;</span><br><span class="line">setEquator(newPos);</span><br><span class="line">bufmark = bufindex = newPos;</span><br><span class="line"><span class="keyword">final</span> <span class="keyword">int</span> serBound = <span class="number">4</span> * kvend;</span><br><span class="line"><span class="comment">// bytes remaining before the lock must be held and limits</span></span><br><span class="line"><span class="comment">// checked is the minimum of three arcs: the metadata space, the</span></span><br><span class="line"><span class="comment">// serialization space, and the soft limit</span></span><br><span class="line">bufferRemaining = Math.min(</span><br><span class="line">    <span class="comment">// metadata max</span></span><br><span class="line">    distanceTo(bufend, newPos),</span><br><span class="line">    Math.min(</span><br><span class="line">      <span class="comment">// serialization max</span></span><br><span class="line">      distanceTo(newPos, serBound),</span><br><span class="line">      <span class="comment">// soft limit</span></span><br><span class="line">      softLimit)) - <span class="number">2</span> * METASIZE;</span><br></pre></td></tr></table></figure>
<p><strong>因为equator是kvbuffer和kvmeta的分界线，为了更多的空间存储kv，则最多拿出distkvi的一半来存储meta，并且利用avgRec估算distkvi能存放多少个record和meta对，根据record和meta对的个数估算meta所占空间的大小，从distkvi/2和meta所占空间的大小中取最小值，又因为distkvi中最少得存放一个meta，所占空间为METASIZE，在选取kvindex时需要求aligned，aligned最多为METASIZE-1，总和上述因素，最终选取equator为<code>(bufindex + Math.max(2 * METASIZE - 1, Math.min(distkvi / 2, distkvi / (METASIZE + avgRec) * METASIZE)))</code></strong>。equator选取之后，设置bufmark = bufindex = newPos和kvindex，但此时并不设置bufstart、bufend和kvstart、kvend，因为这几个值要用来表示spill数据的边界。</p>
<p>spill之后，可用的空间减少了，则控制spill的bufferRemaining也应该重新设置，bufferRemaining取三个值的最小值<em>减去2*METASIZE</em>，三个值分别是meta可用占用的空间<code>distanceTo(bufend, newPos)</code>,kv可用空间<code>distanceTo(newPos, serBound)</code>和softLimit。<strong>这里为什么要减去2*METASIZE，一个是spill之前kvend到kvindex的距离，另一个是当时的kvindex空间？？？？</strong>此时，已有一个record要写入buffer，需要从bufferRemaining中减去当前record的元数据占用的空间，即减去METASIZE，另一个METASIZE是在计算equator时，没有包括kvindex到kvend(spill之前)的这段METASIZE，所以要减去这个METASIZE。</p>
<p>接下来解析下SpillThread线程，查看其run方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  spillLock.lock();</span><br><span class="line">  spillThreadRunning = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">      spillDone.signal();</span><br><span class="line">      <span class="comment">// 判断是否在spill，false则挂起SpillThread线程，等待唤醒</span></span><br><span class="line">      <span class="keyword">while</span> (!spillInProgress) &#123;</span><br><span class="line">        spillReady.await();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        spillLock.unlock();</span><br><span class="line">        <span class="comment">// 唤醒之后，进行排序和溢写到磁盘</span></span><br><span class="line">        sortAndSpill();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        sortSpillException = t;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        spillLock.lock();</span><br><span class="line">        <span class="keyword">if</span> (bufend &lt; bufstart) &#123;</span><br><span class="line">          bufvoid = kvbuffer.length;</span><br><span class="line">        &#125;</span><br><span class="line">        kvstart = kvend;</span><br><span class="line">        bufstart = bufend;</span><br><span class="line">        spillInProgress = <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    Thread.currentThread().interrupt();</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    spillLock.unlock();</span><br><span class="line">    spillThreadRunning = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>run中主要是<code>sortAndSpill</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sortAndSpill</span><span class="params">()</span> <span class="keyword">throws</span> IOException, ClassNotFoundException,</span></span><br><span class="line"><span class="function">                                   InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">//approximate the length of the output file to be the length of the</span></span><br><span class="line">  <span class="comment">//buffer + header lengths for the partitions</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> size = distanceTo(bufstart, bufend, bufvoid) +</span><br><span class="line">              partitions * APPROX_HEADER_LENGTH;</span><br><span class="line">  FSDataOutputStream out = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// create spill file</span></span><br><span class="line">    <span class="comment">// 用来存储index文件</span></span><br><span class="line">    <span class="keyword">final</span> SpillRecord spillRec = <span class="keyword">new</span> SpillRecord(partitions);</span><br><span class="line">    <span class="comment">// 创建写入磁盘的spill文件</span></span><br><span class="line">    <span class="keyword">final</span> Path filename =</span><br><span class="line">        mapOutputFile.getSpillFileForWrite(numSpills, size);</span><br><span class="line">    <span class="comment">// 打开文件流</span></span><br><span class="line">    out = rfs.create(filename);</span><br><span class="line">    <span class="comment">// kvend/4 是截止到当前位置能存放多少个元数据实体</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> mstart = kvend / NMETA;</span><br><span class="line">    <span class="comment">// kvstart 处能存放多少个元数据实体</span></span><br><span class="line">    <span class="comment">// 元数据则在mstart和mend之间，(mstart - mend)则是元数据的个数</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> mend = <span class="number">1</span> + <span class="comment">// kvend is a valid record</span></span><br><span class="line">      (kvstart &gt;= kvend</span><br><span class="line">      ? kvstart</span><br><span class="line">      : kvmeta.capacity() + kvstart) / NMETA;</span><br><span class="line">    <span class="comment">// 排序  只对元数据进行排序,只调整元数据在kvmeta中的顺序</span></span><br><span class="line">    <span class="comment">// 排序规则是MapOutputBuffer.compare， </span></span><br><span class="line">    <span class="comment">// 先对partition进行排序其次对key值排序</span></span><br><span class="line">    sorter.sort(MapOutputBuffer.<span class="keyword">this</span>, mstart, mend, reporter);</span><br><span class="line">    <span class="keyword">int</span> spindex = mstart;</span><br><span class="line">    <span class="comment">// 创建rec，用于存放该分区在数据文件中的信息</span></span><br><span class="line">    <span class="keyword">final</span> IndexRecord rec = <span class="keyword">new</span> IndexRecord();</span><br><span class="line">    <span class="keyword">final</span> InMemValBytes value = <span class="keyword">new</span> InMemValBytes();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; partitions; ++i) &#123;</span><br><span class="line">      <span class="comment">// 临时文件是IFile格式的</span></span><br><span class="line">      IFile.Writer&lt;K, V&gt; writer = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">long</span> segmentStart = out.getPos();</span><br><span class="line">        FSDataOutputStream partitionOut = CryptoUtils.wrapIfNecessary(job, out);</span><br><span class="line">        writer = <span class="keyword">new</span> Writer&lt;K, V&gt;(job, partitionOut, keyClass, valClass, codec,</span><br><span class="line">                                  spilledRecordsCounter);</span><br><span class="line">        <span class="comment">// 往磁盘写数据时先判断是否有combiner</span></span><br><span class="line">        <span class="keyword">if</span> (combinerRunner == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// spill directly</span></span><br><span class="line">          DataInputBuffer key = <span class="keyword">new</span> DataInputBuffer();</span><br><span class="line">          <span class="comment">// 写入相同partition的数据</span></span><br><span class="line">          <span class="keyword">while</span> (spindex &lt; mend &amp;&amp;</span><br><span class="line">              kvmeta.get(offsetFor(spindex % maxRec) + PARTITION) == i) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> kvoff = offsetFor(spindex % maxRec);</span><br><span class="line">            <span class="keyword">int</span> keystart = kvmeta.get(kvoff + KEYSTART);</span><br><span class="line">            <span class="keyword">int</span> valstart = kvmeta.get(kvoff + VALSTART);</span><br><span class="line">            key.reset(kvbuffer, keystart, valstart - keystart);</span><br><span class="line">            getVBytesForOffset(kvoff, value);</span><br><span class="line">            writer.append(key, value);</span><br><span class="line">            ++spindex;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">int</span> spstart = spindex;</span><br><span class="line">          <span class="keyword">while</span> (spindex &lt; mend &amp;&amp;</span><br><span class="line">              kvmeta.get(offsetFor(spindex % maxRec)</span><br><span class="line">                        + PARTITION) == i) &#123;</span><br><span class="line">            ++spindex;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// Note: we would like to avoid the combiner if we've fewer</span></span><br><span class="line">          <span class="comment">// than some threshold of records for a partition</span></span><br><span class="line">          <span class="keyword">if</span> (spstart != spindex) &#123;</span><br><span class="line">            combineCollector.setWriter(writer);</span><br><span class="line">            RawKeyValueIterator kvIter =</span><br><span class="line">              <span class="keyword">new</span> MRResultIterator(spstart, spindex);</span><br><span class="line">            combinerRunner.combine(kvIter, combineCollector);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// close the writer</span></span><br><span class="line">        writer.close();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// record offsets</span></span><br><span class="line">        <span class="comment">// 记录当前partition i的信息写入索文件rec中</span></span><br><span class="line">        rec.startOffset = segmentStart;</span><br><span class="line">        rec.rawLength = writer.getRawLength() + CryptoUtils.cryptoPadding(job);</span><br><span class="line">        rec.partLength = writer.getCompressedLength() + CryptoUtils.cryptoPadding(job);</span><br><span class="line">        <span class="comment">// spillRec中存放了spill中partition的信息，便于后续堆排序时，取出partition相关的数据进行排序</span></span><br><span class="line">        spillRec.putIndex(rec, i);</span><br><span class="line"></span><br><span class="line">        writer = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != writer) writer.close();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 判断内存中的index文件是否超出阈值，超出则将index文件写入磁盘</span></span><br><span class="line">    <span class="comment">// 当超出阈值时只是把当前index和之后的index写入磁盘</span></span><br><span class="line">    <span class="keyword">if</span> (totalIndexCacheMemory &gt;= indexCacheMemoryLimit) &#123;</span><br><span class="line">      <span class="comment">// create spill index file</span></span><br><span class="line">      <span class="comment">// 创建index文件</span></span><br><span class="line">      Path indexFilename =</span><br><span class="line">          mapOutputFile.getSpillIndexFileForWrite(numSpills, partitions</span><br><span class="line">              * MAP_OUTPUT_INDEX_RECORD_LENGTH);</span><br><span class="line">      spillRec.writeToFile(indexFilename, job);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      indexCacheList.add(spillRec);</span><br><span class="line">      totalIndexCacheMemory +=</span><br><span class="line">        spillRec.size() * MAP_OUTPUT_INDEX_RECORD_LENGTH;</span><br><span class="line">    &#125;</span><br><span class="line">    LOG.info(<span class="string">"Finished spill "</span> + numSpills);</span><br><span class="line">    ++numSpills;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (out != <span class="keyword">null</span>) out.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>sortAndSpill中，有mstart和mend得到一共有多少条record需要spill到磁盘，调用sorter.sort对meta进行排序，先对partition进行排序，然后按key排序，排序的结果只调整meta的顺序。</p>
<p>排序之后，判断是否有combiner，没有则直接将record写入磁盘，写入时是一个partition一个IndexRecord，如果有combiner，则将该partition的record写入kvIter，然后调用combinerRunner.combine执行combiner。</p>
<p>写入磁盘之后，将spillx.out对应的spillRec放入内存<em>indexCacheList.add(spillRec)</em>，如果所占内存totalIndexCacheMemory超过了indexCacheMemoryLimit，则创建index文件，将此次及以后的spillRec写入index文件存入磁盘。</p>
<p>最后spill次数递增。sortAndSpill结束之后，回到run方法中，执行finally中的代码，对kvstart和bufstart赋值，<code>kvstart = kvend</code>，<code>bufstart = bufend</code>，设置spillInProgress的状态为false。</p>
<p>在spill的同时，map往buffer的写操作并没有停止，依然在调用collect，再次回到collect方法中，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MapOutputBuffer.collect</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">collect</span><span class="params">(K key, V value, <span class="keyword">final</span> <span class="keyword">int</span> partition</span></span></span><br><span class="line"><span class="function"><span class="params">                                 )</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 新数据collect时，先将剩余的空间减去元数据的长度，之后进行判断</span></span><br><span class="line">  bufferRemaining -= METASIZE;</span><br><span class="line">  <span class="keyword">if</span> (bufferRemaining &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// start spill if the thread is not running and the soft limit has been</span></span><br><span class="line">    <span class="comment">// reached</span></span><br><span class="line">    spillLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">// 首次spill时，spillInProgress是false</span></span><br><span class="line">        <span class="keyword">if</span> (!spillInProgress) &#123;</span><br><span class="line">          <span class="comment">// 得到kvindex的byte位置</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> kvbidx = <span class="number">4</span> * kvindex;</span><br><span class="line">          <span class="comment">// 得到kvend的byte位置</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> kvbend = <span class="number">4</span> * kvend;</span><br><span class="line">          <span class="comment">// serialized, unspilled bytes always lie between kvindex and</span></span><br><span class="line">          <span class="comment">// bufindex, crossing the equator. Note that any void space</span></span><br><span class="line">          <span class="comment">// created by a reset must be included in "used" bytes</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> bUsed = distanceTo(kvbidx, bufindex);</span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">boolean</span> bufsoftlimit = bUsed &gt;= softLimit;</span><br><span class="line">          <span class="keyword">if</span> ((kvbend + METASIZE) % kvbuffer.length !=</span><br><span class="line">              equator - (equator % METASIZE)) &#123;</span><br><span class="line">            <span class="comment">// spill finished, reclaim space</span></span><br><span class="line">            resetSpill();</span><br><span class="line">            bufferRemaining = Math.min(</span><br><span class="line">                distanceTo(bufindex, kvbidx) - <span class="number">2</span> * METASIZE,</span><br><span class="line">                softLimit - bUsed) - METASIZE;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (bufsoftlimit &amp;&amp; kvindex != kvend) &#123;</span><br><span class="line">            ...</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">while</span> (<span class="keyword">false</span>);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      spillLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有新的record需要写入buffer时，判断<code>bufferRemaining -= METASIZE</code>，此时的bufferRemaining是在开始spill时被重置过的(此时的bufferRemaining应该比初始的softLimit要小)，当bufferRemaining小于等于0时，进入if，此时spillInProgress的状态为false，进入if (!spillInProgress)，startSpill时对kvend和bufend进行了重置，则此时<code>(kvbend + METASIZE) % kvbuffer.length != equator - (equator % METASIZE)</code>，调用<code>resetSpill()</code>，将kvstart、kvend和bufstart、bufend设置为上次startSpill时的位置。此时buffer已将一部分内容写入磁盘，有大量空余的空间，则对bufferRemaining进行重置，此次不spill。</p>
<p>bufferRemaining取值为<code>Math.min(distanceTo(bufindex, kvbidx) - 2 * METASIZE, softLimit - bUsed) - METASIZE</code></p>
<p>最后一个METASIZE是当前record进入collect之后bufferRemaining减去的那个METASIZE，为什么要减去2*METASIZE，不知道。。。。。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">resetSpill</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> e = equator;</span><br><span class="line">  bufstart = bufend = e;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> aligned = e - (e % METASIZE);</span><br><span class="line">  <span class="comment">// set start/end to point to first meta record</span></span><br><span class="line">  <span class="comment">// Cast one of the operands to long to avoid integer overflow</span></span><br><span class="line">  kvstart = kvend = (<span class="keyword">int</span>)</span><br><span class="line">    (((<span class="keyword">long</span>)aligned - METASIZE + kvbuffer.length) % kvbuffer.length) / <span class="number">4</span>;</span><br><span class="line">  LOG.info(<span class="string">"(RESET) equator "</span> + e + <span class="string">" kv "</span> + kvstart + <span class="string">"("</span> +</span><br><span class="line">    (kvstart * <span class="number">4</span>) + <span class="string">")"</span> + <span class="string">" kvi "</span> + kvindex + <span class="string">"("</span> + (kvindex * <span class="number">4</span>) + <span class="string">")"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当bufferRemaining再次小于等于0时，进行spill，这以后就都是套路了。环形缓冲区分析到此结束。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce </tag>
            
            <tag> 环形缓冲区 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce源码解析--Map解析]]></title>
      <url>http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--Map%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<h2 id="MapReduce–Map"><a href="#MapReduce–Map" class="headerlink" title="MapReduce–Map"></a>MapReduce–Map</h2><p>MapReduce由Map和Reduce组成，而Map和Reduce又可以分为很多个小phase，下面就从源码的角度去扒下Map的流程。<br>通过intellij idea进行debug调试，在New API的流程发现Map中具体流程可以大致分为两种情况：有Reduce和没有Reduce</p>
<ul>
<li>没有Reduce</li>
</ul>
<blockquote>
<p>split–&gt;read–map(用户自定义的map函数)–&gt;write(未排序)–&gt;output</p>
</blockquote>
<ul>
<li>有Reduce</li>
</ul>
<blockquote>
<p>split–&gt;read–&gt;map(用户自定义的map函数)–&gt;partition–&gt;collect–&gt;buffer–&gt;quicksort–&gt;(combiner)–&gt;spill–&gt;merge(heapsort、combiner)–&gt;output</p>
</blockquote>
<p>本篇主要介绍有Reduce的情况下Map中各个阶段的流程。</p>
<a id="more"></a>
<p>跟踪代码到MapTask.run中，代码中先根据是否有Reduce对Map阶段进行分割，然后判断Map Task的类型（Map Task分为job setup、job cleanup、map task、task cleanup），主要跟下map task，进入<code>runNewMapper</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">final</span> JobConf job, <span class="keyword">final</span> TaskUmbilicalProtocol umbilical)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.umbilical = umbilical;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (isMapTask()) &#123;</span><br><span class="line">    <span class="comment">// If there are no reducers then there won't be any sort. Hence the map </span></span><br><span class="line">    <span class="comment">// phase will govern the entire attempt's progress.</span></span><br><span class="line">    <span class="keyword">if</span> (conf.getNumReduceTasks() == <span class="number">0</span>) &#123;</span><br><span class="line">      mapPhase = getProgress().addPhase(<span class="string">"map"</span>, <span class="number">1.0f</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// If there are reducers then the entire attempt's progress will be </span></span><br><span class="line">      <span class="comment">// split between the map phase (67%) and the sort phase (33%).</span></span><br><span class="line">      mapPhase = getProgress().addPhase(<span class="string">"map"</span>, <span class="number">0.667f</span>);</span><br><span class="line">      sortPhase  = getProgress().addPhase(<span class="string">"sort"</span>, <span class="number">0.333f</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  TaskReporter reporter = startReporter(umbilical);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">boolean</span> useNewApi = job.getUseNewMapper();</span><br><span class="line">  initialize(job, getJobID(), reporter, useNewApi);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// check if it is a cleanupJobTask</span></span><br><span class="line">  <span class="keyword">if</span> (jobCleanup) &#123;</span><br><span class="line">    runJobCleanupTask(umbilical, reporter);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (jobSetup) &#123;</span><br><span class="line">    runJobSetupTask(umbilical, reporter);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (taskCleanup) &#123;</span><br><span class="line">    runTaskCleanupTask(umbilical, reporter);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (useNewApi) &#123;</span><br><span class="line">    runNewMapper(job, splitMetaInfo, umbilical, reporter);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    runOldMapper(job, splitMetaInfo, umbilical, reporter);</span><br><span class="line">  &#125;</span><br><span class="line">  done(umbilical, reporter);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> &lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runNewMapper</span><span class="params">(<span class="keyword">final</span> JobConf job,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">final</span> TaskSplitIndex splitIndex,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">final</span> TaskUmbilicalProtocol umbilical,</span></span></span><br><span class="line"><span class="function"><span class="params">                  TaskReporter reporter</span></span></span><br><span class="line"><span class="function"><span class="params">                  )</span> <span class="keyword">throws</span> IOException, ClassNotFoundException,</span></span><br><span class="line"><span class="function">                           InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">// make a task context so we can get the classes</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// make a mapper</span></span><br><span class="line">  <span class="comment">// 通过反射得到Mapper的实现类</span></span><br><span class="line">  org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt; mapper =</span><br><span class="line">    (org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;)</span><br><span class="line">      ReflectionUtils.newInstance(taskContext.getMapperClass(), job);</span><br><span class="line">  <span class="comment">// make the input format</span></span><br><span class="line">  org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt; inputFormat =</span><br><span class="line">    (org.apache.hadoop.mapreduce.InputFormat&lt;INKEY,INVALUE&gt;)</span><br><span class="line">      ReflectionUtils.newInstance(taskContext.getInputFormatClass(), job);</span><br><span class="line">  <span class="comment">// rebuild the input split</span></span><br><span class="line">  org.apache.hadoop.mapreduce.InputSplit split = <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// 得到map对应的split</span></span><br><span class="line">  split = getSplitDetails(<span class="keyword">new</span> Path(splitIndex.getSplitLocation()),</span><br><span class="line">      splitIndex.getStartOffset());</span><br><span class="line">  LOG.info(<span class="string">"Processing split: "</span> + split);</span><br><span class="line">  <span class="comment">// 得到RecordReader对象，用于读取split中的文本，使其变为key value的格式</span></span><br><span class="line">  org.apache.hadoop.mapreduce.RecordReader&lt;INKEY,INVALUE&gt; input =</span><br><span class="line">    <span class="keyword">new</span> NewTrackingRecordReader&lt;INKEY,INVALUE&gt;</span><br><span class="line">      (split, inputFormat, reporter, taskContext);</span><br><span class="line">  </span><br><span class="line">  job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());</span><br><span class="line">  org.apache.hadoop.mapreduce.RecordWriter output = <span class="keyword">null</span>;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// get an output object</span></span><br><span class="line">  <span class="keyword">if</span> (job.getNumReduceTasks() == <span class="number">0</span>) &#123;</span><br><span class="line">  	<span class="comment">// 没有reduce时，直接输出</span></span><br><span class="line">    output = </span><br><span class="line">      <span class="keyword">new</span> NewDirectOutputCollector(taskContext, job, umbilical, reporter);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    output = <span class="keyword">new</span> NewOutputCollector(taskContext, job, umbilical, reporter);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  org.apache.hadoop.mapreduce.MapContext&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt; </span><br><span class="line">  mapContext = </span><br><span class="line">    <span class="keyword">new</span> MapContextImpl&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;(job, getTaskID(), </span><br><span class="line">        input, output, </span><br><span class="line">        committer, </span><br><span class="line">        reporter, split);</span><br><span class="line"></span><br><span class="line">  org.apache.hadoop.mapreduce.Mapper&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;.Context </span><br><span class="line">      mapperContext = </span><br><span class="line">        <span class="keyword">new</span> WrappedMapper&lt;INKEY, INVALUE, OUTKEY, OUTVALUE&gt;().getMapContext(</span><br><span class="line">            mapContext);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// read split</span></span><br><span class="line">    input.initialize(split, mapperContext);</span><br><span class="line">    <span class="comment">// 调用用户继承的Mapper类中的方法   也就是用户编写的map阶段</span></span><br><span class="line">    mapper.run(mapperContext);</span><br><span class="line">    mapPhase.complete();</span><br><span class="line">    <span class="comment">// SORT阶段，在此阶段进行merge 临时文件</span></span><br><span class="line">    setPhase(TaskStatus.Phase.SORT);</span><br><span class="line">    statusUpdate(umbilical);</span><br><span class="line">    input.close();</span><br><span class="line">    input = <span class="keyword">null</span>;</span><br><span class="line">    output.close(mapperContext);</span><br><span class="line">    output = <span class="keyword">null</span>;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    closeQuietly(input);</span><br><span class="line">    closeQuietly(output, mapperContext);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Split"><a href="#Split" class="headerlink" title="Split"></a>Split</h2><p><code>runNewMapper</code>中包含了整个Map的所有phase，首先通过<code>split = getSplitDetails()</code>得到当前map对应的split，split是在<code>JobSubmitter.submitJobInternal</code>中调用<code>writeSplits</code>得到的，有多少个split就对应多少个map。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T extends InputSplit&gt;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">writeNewSplits</span><span class="params">(JobContext job, Path jobSubmitDir)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">    InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="comment">// 通过InputFormat从原文件中达到splits</span></span><br><span class="line">  List&lt;InputSplit&gt; splits = input.getSplits(job);</span><br><span class="line">  T[] array = (T[]) splits.toArray(<span class="keyword">new</span> InputSplit[splits.size()]);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// sort the splits into order based on size, so that the biggest</span></span><br><span class="line">  <span class="comment">// go first</span></span><br><span class="line">  Arrays.sort(array, <span class="keyword">new</span> SplitComparator());</span><br><span class="line">  JobSplitWriter.createSplitFiles(jobSubmitDir, conf, </span><br><span class="line">      jobSubmitDir.getFileSystem(conf), array);</span><br><span class="line">  <span class="keyword">return</span> array.length;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//FileInputFormat.getSplits</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> List&lt;InputSplit&gt; <span class="title">getSplits</span><span class="params">(JobContext job)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  Stopwatch sw = <span class="keyword">new</span> Stopwatch().start();</span><br><span class="line">  <span class="keyword">long</span> minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));</span><br><span class="line">  <span class="keyword">long</span> maxSize = getMaxSplitSize(job);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// generate splits</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">for</span> (FileStatus file: files) &#123;</span><br><span class="line">	...</span><br><span class="line">    <span class="keyword">if</span> (length != <span class="number">0</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (isSplitable(job, path)) &#123;</span><br><span class="line">        <span class="keyword">long</span> blockSize = file.getBlockSize();</span><br><span class="line">        <span class="comment">// 得到split的大小，此参数关系着map的个数，比较重要</span></span><br><span class="line">        <span class="keyword">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> bytesRemaining = length;</span><br><span class="line">        <span class="comment">// 如果当前file的大小小于splitSize则不进入while循环，即不对该file进行split</span></span><br><span class="line">        <span class="comment">// 也就是说如果当前mr中包含大量的小文件，则该splitSize不能决定map的个数</span></span><br><span class="line">        <span class="keyword">while</span> (((<span class="keyword">double</span>) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;</span><br><span class="line">          <span class="keyword">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class="line">          splits.add(makeSplit(path, length-bytesRemaining, splitSize,</span><br><span class="line">                      blkLocations[blkIndex].getHosts(),</span><br><span class="line">                      blkLocations[blkIndex].getCachedHosts()));</span><br><span class="line">          bytesRemaining -= splitSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (bytesRemaining != <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class="line">          splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining,</span><br><span class="line">                     blkLocations[blkIndex].getHosts(),</span><br><span class="line">                     blkLocations[blkIndex].getCachedHosts()));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123; <span class="comment">// not splitable</span></span><br><span class="line">        splits.add(makeSplit(path, <span class="number">0</span>, length, blkLocations[<span class="number">0</span>].getHosts(),</span><br><span class="line">                    blkLocations[<span class="number">0</span>].getCachedHosts()));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">      <span class="comment">//Create empty hosts array for zero length files</span></span><br><span class="line">      splits.add(makeSplit(path, <span class="number">0</span>, length, <span class="keyword">new</span> String[<span class="number">0</span>]));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> splits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的代码将mr的输入文件进行切分为splits，其中<code>splitSize</code>参数比较重要，在此对其取值代码进行解析下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">long</span> minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">getFormatMinSplitSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getMinSplitSize</span><span class="params">(JobContext job)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// SPLIT_MINSIZE = "mapreduce.input.fileinputformat.split.minsize"</span></span><br><span class="line">  <span class="comment">// 默认为0</span></span><br><span class="line">  <span class="keyword">return</span> job.getConfiguration().getLong(SPLIT_MINSIZE, <span class="number">1L</span>);</span><br><span class="line">&#125;</span><br><span class="line">minSize = Math.max(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">long</span> maxSize = getMaxSplitSize(job);</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">long</span> <span class="title">getMaxSplitSize</span><span class="params">(JobContext context)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// SPLIT_MAXSIZE = "mapreduce.input.fileinputformat.split.maxsize"</span></span><br><span class="line">  <span class="keyword">return</span> context.getConfiguration().getLong(SPLIT_MAXSIZE, </span><br><span class="line">                                            Long.MAX_VALUE);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// hads中块的大小，默认128M</span></span><br><span class="line"><span class="keyword">long</span> blockSize = file.getBlockSize();</span><br><span class="line"><span class="keyword">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize);</span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">long</span> <span class="title">computeSplitSize</span><span class="params">(<span class="keyword">long</span> blockSize, <span class="keyword">long</span> minSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">long</span> maxSize)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> Math.max(minSize, Math.min(maxSize, blockSize));</span><br><span class="line">&#125;</span><br><span class="line">splitSize = Math.max(max(<span class="number">1</span>, mapreduce.input.fileinputformat.split.minsize),</span><br><span class="line">		min(mapreduce.input.fileinputformat.split.maxsize, blockSize));</span><br></pre></td></tr></table></figure>
<p>splitSize的大小由<code>split.minsize</code>、<code>split.maxsize</code>和<code>blocksize</code>这三个参数控制，其中主要是由<code>split.minsize</code>和<code>blocksize</code>两个参数决定，<em>取这两个的较大值</em>。</p>
<h2 id="read"><a href="#read" class="headerlink" title="read"></a>read</h2><p>将输入文件切分为splits之后，在MapTask.runNewMapper中加载，由RecordReader对象进行读取</p>
<h2 id="map-用户自定义的map函数"><a href="#map-用户自定义的map函数" class="headerlink" title="map(用户自定义的map函数)"></a>map(用户自定义的map函数)</h2><p>读取split文件之后，调用<code>Mapper.run</code>方法，进入用户自己继承的Mapper类中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Mapper.run</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">// 执行用户重写的setup</span></span><br><span class="line">  setup(context);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// 迭代</span></span><br><span class="line">    <span class="keyword">while</span> (context.nextKeyValue()) &#123;</span><br><span class="line">      <span class="comment">// 执行用户重写的map函数</span></span><br><span class="line">      map(context.getCurrentKey(), context.getCurrentValue(), context);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    cleanup(context);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//以WordCount代码为例</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());</span><br><span class="line">    <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;</span><br><span class="line">        word.set(itr.nextToken());</span><br><span class="line">        context.write(word, one);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="collect"><a href="#collect" class="headerlink" title="collect"></a>collect</h2><p>map逻辑完之后，将map的每条结果通过<code>context.write</code>进行collect。此处的<code>context.write</code>最终调用的是在<code>runNewMapper</code>中实例化的output（<code>output = new NewOutputCollector(taskContext, job, umbilical, reporter)</code>）对象的<code>write</code>方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// NewOutputCollector.write</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(K key, V value)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  collector.collect(key, value,</span><br><span class="line">                    partitioner.getPartition(key, value, partitions));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="partition"><a href="#partition" class="headerlink" title="partition"></a>partition</h2><p>由上面的代码可以看出每条被map处理之后的结果在collect中，会对先对其进行分区处理，默认使用HashPartitioner.java</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">int</span> numReduceTasks)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> (key.hashCode() &amp; Integer.MAX_VALUE) % numReduceTasks;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="buffer"><a href="#buffer" class="headerlink" title="buffer"></a>buffer</h2><p>将map处理之后的key value 进行分区之后，写入buffer中的<em>环形缓冲区</em>中。<br>先来看下环形缓冲区的数据结构，然后理解其数据写入就比较容易了。<br>环形缓冲区在<code>MapTask.MapOutputBuffer</code>中定义，相关的属性如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// k/v accounting</span></span><br><span class="line"><span class="comment">// 存放meta数据的IntBuffer，都是int entry，占4byte</span></span><br><span class="line"><span class="keyword">private</span> IntBuffer kvmeta; <span class="comment">// metadata overlay on backing store</span></span><br><span class="line"><span class="keyword">int</span> kvstart;            <span class="comment">// marks origin of spill metadata</span></span><br><span class="line"><span class="keyword">int</span> kvend;              <span class="comment">// marks end of spill metadata</span></span><br><span class="line"><span class="keyword">int</span> kvindex;            <span class="comment">// marks end of fully serialized records</span></span><br><span class="line"><span class="comment">// 分割meta和key value内容的标识   </span></span><br><span class="line"><span class="comment">// meta数据和key value内容都存放在同一个环形缓冲区，所以需要分隔开</span></span><br><span class="line"><span class="keyword">int</span> equator;            <span class="comment">// marks origin of meta/serialization</span></span><br><span class="line"><span class="keyword">int</span> bufstart;           <span class="comment">// marks beginning of spill</span></span><br><span class="line"><span class="keyword">int</span> bufend;             <span class="comment">// marks beginning of collectable</span></span><br><span class="line"><span class="keyword">int</span> bufmark;            <span class="comment">// marks end of record</span></span><br><span class="line"><span class="keyword">int</span> bufindex;           <span class="comment">// marks end of collected</span></span><br><span class="line"><span class="keyword">int</span> bufvoid;            <span class="comment">// marks the point where we should stop</span></span><br><span class="line">                        <span class="comment">// reading at the end of the buffer</span></span><br><span class="line"><span class="comment">// 存放key value的byte数组，单位是byte，注意与kvmeta区分</span></span><br><span class="line"><span class="keyword">byte</span>[] kvbuffer;        <span class="comment">// main output buffer</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] b0 = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// key value在kvbuffer中的地址存放在偏移kvindex的距离</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> VALSTART = <span class="number">0</span>;         <span class="comment">// val offset in acct</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> KEYSTART = <span class="number">1</span>;         <span class="comment">// key offset in acct</span></span><br><span class="line"><span class="comment">// partition信息存在kvmeta中偏移kvindex的距离</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PARTITION = <span class="number">2</span>;        <span class="comment">// partition offset in acct</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> VALLEN = <span class="number">3</span>;           <span class="comment">// length of value</span></span><br><span class="line"><span class="comment">// 一对key value的meta数据在kvmeta中占用的个数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> NMETA = <span class="number">4</span>;            <span class="comment">// num meta ints</span></span><br><span class="line"><span class="comment">// 一对key value的meta数据在kvmeta中占用的byte数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> METASIZE = NMETA * <span class="number">4</span>; <span class="comment">// size in bytes</span></span><br></pre></td></tr></table></figure>
<p>环形缓冲区的结构在<code>MapOutputBuffer.init</code>中创建。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(MapOutputCollector.Context context</span></span></span><br><span class="line"><span class="function"><span class="params">                )</span> <span class="keyword">throws</span> IOException, ClassNotFoundException </span>&#123;</span><br><span class="line">...</span><br><span class="line">  <span class="comment">//MAP_SORT_SPILL_PERCENT = mapreduce.map.sort.spill.percent</span></span><br><span class="line">  <span class="comment">// map 端buffer所占的百分比</span></span><br><span class="line">  <span class="comment">//sanity checks</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">float</span> spillper =</span><br><span class="line">    job.getFloat(JobContext.MAP_SORT_SPILL_PERCENT, (<span class="keyword">float</span>)<span class="number">0.8</span>);</span><br><span class="line">  <span class="comment">//IO_SORT_MB = "mapreduce.task.io.sort.mb"</span></span><br><span class="line">  <span class="comment">// map 端buffer大小</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> sortmb = job.getInt(JobContext.IO_SORT_MB, <span class="number">100</span>);</span><br><span class="line">  <span class="comment">// 所有的spill index 在内存所占的大小的阈值</span></span><br><span class="line">  indexCacheMemoryLimit = job.getInt(JobContext.INDEX_CACHE_MEMORY_LIMIT,</span><br><span class="line">                                     INDEX_CACHE_MEMORY_LIMIT_DEFAULT);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 排序的实现类，可以自己实现。 这里用的是改写的快排</span></span><br><span class="line">  sorter = ReflectionUtils.newInstance(job.getClass(<span class="string">"map.sort.class"</span>,</span><br><span class="line">        QuickSort.class, IndexedSorter.class), job);</span><br><span class="line">  <span class="comment">// buffers and accounting</span></span><br><span class="line">  <span class="comment">// 上面IO_SORT_MB的单位是MB，左移20位将单位转化为byte</span></span><br><span class="line">  <span class="keyword">int</span> maxMemUsage = sortmb &lt;&lt; <span class="number">20</span>;</span><br><span class="line">  <span class="comment">// METASIZE是元数据的长度，元数据有4个int单元，分别为</span></span><br><span class="line">  <span class="comment">// VALSTART、KEYSTART、PARTITION、VALLEN，而int为4个byte，</span></span><br><span class="line">  <span class="comment">// 所以METASIZE长度为16。下面是计算buffer中最多有多少byte来存元数据</span></span><br><span class="line">  <span class="comment">// 此时maxMemUsage是METASIZE的整数倍</span></span><br><span class="line">  maxMemUsage -= maxMemUsage % METASIZE;</span><br><span class="line">  <span class="comment">// 元数据数组  以byte为单位</span></span><br><span class="line">  kvbuffer = <span class="keyword">new</span> <span class="keyword">byte</span>[maxMemUsage];</span><br><span class="line">  bufvoid = kvbuffer.length;</span><br><span class="line">  <span class="comment">// 将kvbuffer转化为int型的kvmeta  以int为单位，也就是4byte</span></span><br><span class="line">  kvmeta = ByteBuffer.wrap(kvbuffer)</span><br><span class="line">     .order(ByteOrder.nativeOrder())</span><br><span class="line">     .asIntBuffer();</span><br><span class="line">  <span class="comment">// 设置buf和kvmeta的分界线</span></span><br><span class="line">  setEquator(<span class="number">0</span>);</span><br><span class="line">  bufstart = bufend = bufindex = equator;</span><br><span class="line">  kvstart = kvend = kvindex;</span><br><span class="line">  <span class="comment">// kvmeta中存放元数据实体的最大个数</span></span><br><span class="line">  maxRec = kvmeta.capacity() / NMETA;</span><br><span class="line">  <span class="comment">// buffer spill时的阈值（不单单是sortmb*spillper）</span></span><br><span class="line">  <span class="comment">// 更加精确的是kvbuffer.length*spiller</span></span><br><span class="line">  softLimit = (<span class="keyword">int</span>)(kvbuffer.length * spillper);</span><br><span class="line">  <span class="comment">// 此变量较为重要，作为spill的动态衡量标准</span></span><br><span class="line">  bufferRemaining = softLimit;</span><br><span class="line">  LOG.info(JobContext.IO_SORT_MB + <span class="string">": "</span> + sortmb);</span><br><span class="line">  LOG.info(<span class="string">"soft limit at "</span> + softLimit);</span><br><span class="line">  LOG.info(<span class="string">"bufstart = "</span> + bufstart + <span class="string">"; bufvoid = "</span> + bufvoid);</span><br><span class="line">  LOG.info(<span class="string">"kvstart = "</span> + kvstart + <span class="string">"; length = "</span> + maxRec);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// k/v serialization</span></span><br><span class="line">  comparator = job.getOutputKeyComparator();</span><br><span class="line">  keyClass = (Class&lt;K&gt;)job.getMapOutputKeyClass();</span><br><span class="line">  valClass = (Class&lt;V&gt;)job.getMapOutputValueClass();</span><br><span class="line">  serializationFactory = <span class="keyword">new</span> SerializationFactory(job);</span><br><span class="line">  keySerializer = serializationFactory.getSerializer(keyClass);</span><br><span class="line">  <span class="comment">// 将bb作为key序列化写入的output</span></span><br><span class="line">  keySerializer.open(bb);</span><br><span class="line">  valSerializer = serializationFactory.getSerializer(valClass);</span><br><span class="line">  <span class="comment">// 将bb作为value序列化写入的output</span></span><br><span class="line">  valSerializer.open(bb);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// combiner</span></span><br><span class="line">  ...</span><br><span class="line">  spillInProgress = <span class="keyword">false</span>;</span><br><span class="line">  <span class="comment">// 最后一次merge时，在有combiner的情况下，超过此阈值才执行combiner</span></span><br><span class="line">  minSpillsForCombine = job.getInt(JobContext.MAP_COMBINE_MIN_SPILLS, <span class="number">3</span>);</span><br><span class="line">  spillThread.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">  spillThread.setName(<span class="string">"SpillThread"</span>);</span><br><span class="line">  spillLock.lock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    spillThread.start();</span><br><span class="line">    <span class="keyword">while</span> (!spillThreadRunning) &#123;</span><br><span class="line">      spillDone.await();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Spill thread failed to initialize"</span>, e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    spillLock.unlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (sortSpillException != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Spill thread failed to initialize"</span>,</span><br><span class="line">        sortSpillException);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// setEquator(0)的代码如下</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setEquator</span><span class="params">(<span class="keyword">int</span> pos)</span> </span>&#123;</span><br><span class="line">  equator = pos;</span><br><span class="line">  <span class="comment">// set index prior to first entry, aligned at meta boundary</span></span><br><span class="line">  <span class="comment">// 第一个 entry的末尾位置，即元数据和kv数据的分界线   单位是byte</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> aligned = pos - (pos % METASIZE);</span><br><span class="line">  <span class="comment">// Cast one of the operands to long to avoid integer overflow</span></span><br><span class="line">  <span class="comment">// 元数据中存放数据的起始位置</span></span><br><span class="line">  kvindex = (<span class="keyword">int</span>)</span><br><span class="line">    (((<span class="keyword">long</span>)aligned - METASIZE + kvbuffer.length) % kvbuffer.length) / <span class="number">4</span>;</span><br><span class="line">  LOG.info(<span class="string">"(EQUATOR) "</span> + pos + <span class="string">" kvi "</span> + kvindex +</span><br><span class="line">      <span class="string">"("</span> + (kvindex * <span class="number">4</span>) + <span class="string">")"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时环形缓冲区已被初始化，但其具体结构及其使用还不太明了，继续看下面的代码，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MapOutputBuffer.collect</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">collect</span><span class="params">(K key, V value, <span class="keyword">final</span> <span class="keyword">int</span> partition</span></span></span><br><span class="line"><span class="function"><span class="params">                                 )</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 新数据collect时，先将剩余的空间减去元数据的长度，之后进行判断</span></span><br><span class="line">  bufferRemaining -= METASIZE;</span><br><span class="line">  <span class="keyword">if</span> (bufferRemaining &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// start spill if the thread is not running and the soft limit has been</span></span><br><span class="line">    <span class="comment">// reached</span></span><br><span class="line">    spillLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">// 首次spill时，spillInProgress是false</span></span><br><span class="line">        <span class="keyword">if</span> (!spillInProgress) &#123;</span><br><span class="line">          <span class="comment">// 得到kvindex的byte位置</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> kvbidx = <span class="number">4</span> * kvindex;</span><br><span class="line">          <span class="comment">// 得到kvend的byte位置</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> kvbend = <span class="number">4</span> * kvend;</span><br><span class="line">          <span class="comment">// serialized, unspilled bytes always lie between kvindex and</span></span><br><span class="line">          <span class="comment">// bufindex, crossing the equator. Note that any void space</span></span><br><span class="line">          <span class="comment">// created by a reset must be included in "used" bytes</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> bUsed = distanceTo(kvbidx, bufindex);</span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">boolean</span> bufsoftlimit = bUsed &gt;= softLimit;</span><br><span class="line">          <span class="keyword">if</span> ((kvbend + METASIZE) % kvbuffer.length !=</span><br><span class="line">              equator - (equator % METASIZE)) &#123;</span><br><span class="line">            <span class="comment">// spill finished, reclaim space</span></span><br><span class="line">            resetSpill();</span><br><span class="line">            bufferRemaining = Math.min(</span><br><span class="line">                distanceTo(bufindex, kvbidx) - <span class="number">2</span> * METASIZE,</span><br><span class="line">                softLimit - bUsed) - METASIZE;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125; <span class="keyword">else</span> <span class="keyword">if</span> (bufsoftlimit &amp;&amp; kvindex != kvend) &#123;</span><br><span class="line">            <span class="comment">// spill records, if any collected; check latter, as it may</span></span><br><span class="line">            <span class="comment">// be possible for metadata alignment to hit spill pcnt</span></span><br><span class="line">            startSpill();</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> avgRec = (<span class="keyword">int</span>)</span><br><span class="line">              (mapOutputByteCounter.getCounter() /</span><br><span class="line">              mapOutputRecordCounter.getCounter());</span><br><span class="line">            <span class="comment">// leave at least half the split buffer for serialization data</span></span><br><span class="line">            <span class="comment">// ensure that kvindex &gt;= bufindex</span></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> distkvi = distanceTo(bufindex, kvbidx);</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> newPos = (bufindex +</span><br><span class="line">              Math.max(<span class="number">2</span> * METASIZE - <span class="number">1</span>,</span><br><span class="line">                      Math.min(distkvi / <span class="number">2</span>,</span><br><span class="line">                               distkvi / (METASIZE + avgRec) * METASIZE)))</span><br><span class="line">              % kvbuffer.length;</span><br><span class="line">            setEquator(newPos);</span><br><span class="line">            bufmark = bufindex = newPos;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> serBound = <span class="number">4</span> * kvend;</span><br><span class="line">            <span class="comment">// bytes remaining before the lock must be held and limits</span></span><br><span class="line">            <span class="comment">// checked is the minimum of three arcs: the metadata space, the</span></span><br><span class="line">            <span class="comment">// serialization space, and the soft limit</span></span><br><span class="line">            bufferRemaining = Math.min(</span><br><span class="line">                <span class="comment">// metadata max</span></span><br><span class="line">                distanceTo(bufend, newPos),</span><br><span class="line">                Math.min(</span><br><span class="line">                  <span class="comment">// serialization max</span></span><br><span class="line">                  distanceTo(newPos, serBound),</span><br><span class="line">                  <span class="comment">// soft limit</span></span><br><span class="line">                  softLimit)) - <span class="number">2</span> * METASIZE;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">while</span> (<span class="keyword">false</span>);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      spillLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将key value 及元数据信息写入缓冲区</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// serialize key bytes into buffer</span></span><br><span class="line">    <span class="keyword">int</span> keystart = bufindex;</span><br><span class="line">    <span class="comment">// 将key序列化写入kvbuffer中，并移动bufindex</span></span><br><span class="line">    keySerializer.serialize(key);</span><br><span class="line">    <span class="keyword">if</span> (bufindex &lt; keystart) &#123;</span><br><span class="line">      <span class="comment">// wrapped the key; must make contiguous</span></span><br><span class="line">      bb.shiftBufferedKey();</span><br><span class="line">      keystart = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// serialize value bytes into buffer</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> valstart = bufindex;</span><br><span class="line">    valSerializer.serialize(value);</span><br><span class="line">    <span class="comment">// It's possible for records to have zero length, i.e. the serializer</span></span><br><span class="line">    <span class="comment">// will perform no writes. To ensure that the boundary conditions are</span></span><br><span class="line">    <span class="comment">// checked and that the kvindex invariant is maintained, perform a</span></span><br><span class="line">    <span class="comment">// zero-length write into the buffer. The logic monitoring this could be</span></span><br><span class="line">    <span class="comment">// moved into collect, but this is cleaner and inexpensive. For now, it</span></span><br><span class="line">    <span class="comment">// is acceptable.</span></span><br><span class="line">    bb.write(b0, <span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the record must be marked after the preceding write, as the metadata</span></span><br><span class="line">    <span class="comment">// for this record are not yet written</span></span><br><span class="line">    <span class="keyword">int</span> valend = bb.markRecord();</span><br><span class="line"></span><br><span class="line">    mapOutputRecordCounter.increment(<span class="number">1</span>);</span><br><span class="line">    mapOutputByteCounter.increment(</span><br><span class="line">        distanceTo(keystart, valend, bufvoid));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// write accounting info</span></span><br><span class="line">    kvmeta.put(kvindex + PARTITION, partition);</span><br><span class="line">    kvmeta.put(kvindex + KEYSTART, keystart);</span><br><span class="line">    kvmeta.put(kvindex + VALSTART, valstart);</span><br><span class="line">    kvmeta.put(kvindex + VALLEN, distanceTo(valstart, valend));</span><br><span class="line">    <span class="comment">// advance kvindex</span></span><br><span class="line">    kvindex = (kvindex - NMETA + kvmeta.capacity()) % kvmeta.capacity();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (MapBufferTooSmallException e) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Record too large for in-memory buffer: "</span> + e.getMessage());</span><br><span class="line">    spillSingleRecord(key, value, partition);</span><br><span class="line">    mapOutputRecordCounter.increment(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>每次map的结果partition之后来到collect时，先从剩余的空间中减去此条数据元数据的长度<code>bufferRemaining -= METASIZE</code>，然后判断<code>bufferRemaining</code>是否小于0，</p>
<ul>
<li><p>大于0则直接将key/value对和元数据信息写入缓冲区中，key和value是通过<code>keySerializer.serialize</code>序列化并通过一系列的方法调用，最终调用<em>MapOutputBuffer</em>的内部类<code>Buffer.write</code>方法将其内容写入<em>kvbuffer</em>中。接下来是将元数据信息写入kvmeta中，元数据信息包括partition、key的起始位置、value的起始位置以及value的长度。</p>
</li>
<li><p>首次小于等于0进入if语句，此时剩余的空间不足，将启动spill线程。先得到<strong>可重入锁</strong>spillLock的锁，并且此时并无有任何spill线程运行，所以<code>spillInProgress=false</code>，进入<code>else if</code>语句中，执行<code>startSpill()</code>，唤醒SpillThread线程，重新设置<em>equator</em>和<em>bufferRemaining</em>。随后正常将key/value对写入kvbuffer中，如果没有足够的空间存储则在<code>Buffer.write</code>中阻塞。<code>write</code>和<code>startSpill</code>的代码如下：</p>
</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// must always verify the invariant that at least METASIZE bytes are</span></span><br><span class="line">  <span class="comment">// available beyond kvindex, even when len == 0</span></span><br><span class="line">  bufferRemaining -= len;</span><br><span class="line">  <span class="keyword">if</span> (bufferRemaining &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// writing these bytes could exhaust available buffer space or fill</span></span><br><span class="line">    <span class="comment">// the buffer to soft limit. check if spill or blocking are necessary</span></span><br><span class="line">    <span class="keyword">boolean</span> blockwrite = <span class="keyword">false</span>;</span><br><span class="line">    spillLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">do</span> &#123;</span><br><span class="line">        checkSpillException();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> kvbidx = <span class="number">4</span> * kvindex;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> kvbend = <span class="number">4</span> * kvend;</span><br><span class="line">        <span class="comment">// ser distance to key index</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> distkvi = distanceTo(bufindex, kvbidx);</span><br><span class="line">        <span class="comment">// ser distance to spill end index</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> distkve = distanceTo(bufindex, kvbend);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// if kvindex is closer than kvend, then a spill is neither in</span></span><br><span class="line">        <span class="comment">// progress nor complete and reset since the lock was held. The</span></span><br><span class="line">        <span class="comment">// write should block only if there is insufficient space to</span></span><br><span class="line">        <span class="comment">// complete the current write, write the metadata for this record,</span></span><br><span class="line">        <span class="comment">// and write the metadata for the next record. If kvend is closer,</span></span><br><span class="line">        <span class="comment">// then the write should block if there is too little space for</span></span><br><span class="line">        <span class="comment">// either the metadata or the current write. Note that collect</span></span><br><span class="line">        <span class="comment">// ensures its metadata requirement with a zero-length write</span></span><br><span class="line">        blockwrite = distkvi &lt;= distkve</span><br><span class="line">          ? distkvi &lt;= len + <span class="number">2</span> * METASIZE</span><br><span class="line">          : distkve &lt;= len || distanceTo(bufend, kvbidx) &lt; <span class="number">2</span> * METASIZE;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!spillInProgress) &#123;</span><br><span class="line">          <span class="keyword">if</span> (blockwrite) &#123;</span><br><span class="line">            <span class="keyword">if</span> ((kvbend + METASIZE) % kvbuffer.length !=</span><br><span class="line">                equator - (equator % METASIZE)) &#123;</span><br><span class="line">              <span class="comment">// spill finished, reclaim space</span></span><br><span class="line">              <span class="comment">// need to use meta exclusively; zero-len rec &amp; 100% spill</span></span><br><span class="line">              <span class="comment">// pcnt would fail</span></span><br><span class="line">              resetSpill(); <span class="comment">// resetSpill doesn't move bufindex, kvindex</span></span><br><span class="line">              bufferRemaining = Math.min(</span><br><span class="line">                  distkvi - <span class="number">2</span> * METASIZE,</span><br><span class="line">                  softLimit - distanceTo(kvbidx, bufindex)) - len;</span><br><span class="line">              <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// we have records we can spill; only spill if blocked</span></span><br><span class="line">            <span class="keyword">if</span> (kvindex != kvend) &#123;</span><br><span class="line">              startSpill();</span><br><span class="line">              <span class="comment">// Blocked on this write, waiting for the spill just</span></span><br><span class="line">              <span class="comment">// initiated to finish. Instead of repositioning the marker</span></span><br><span class="line">              <span class="comment">// and copying the partial record, we set the record start</span></span><br><span class="line">              <span class="comment">// to be the new equator</span></span><br><span class="line">              setEquator(bufmark);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              <span class="comment">// We have no buffered records, and this record is too large</span></span><br><span class="line">              <span class="comment">// to write into kvbuffer. We must spill it directly from</span></span><br><span class="line">              <span class="comment">// collect</span></span><br><span class="line">              <span class="keyword">final</span> <span class="keyword">int</span> size = distanceTo(bufstart, bufindex) + len;</span><br><span class="line">              setEquator(<span class="number">0</span>);</span><br><span class="line">              bufstart = bufend = bufindex = equator;</span><br><span class="line">              kvstart = kvend = kvindex;</span><br><span class="line">              bufvoid = kvbuffer.length;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> MapBufferTooSmallException(size + <span class="string">" bytes"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 没有足够的空间，则阻塞等待spill</span></span><br><span class="line">        <span class="keyword">if</span> (blockwrite) &#123;</span><br><span class="line">          <span class="comment">// wait for spill</span></span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (spillInProgress) &#123;</span><br><span class="line">              reporter.progress();</span><br><span class="line">              spillDone.await();</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">              <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">                  <span class="string">"Buffer interrupted while waiting for the writer"</span>, e);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">while</span> (blockwrite);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      spillLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// here, we know that we have sufficient space to write</span></span><br><span class="line">  <span class="keyword">if</span> (bufindex + len &gt; bufvoid) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> gaplen = bufvoid - bufindex;</span><br><span class="line">    System.arraycopy(b, off, kvbuffer, bufindex, gaplen);</span><br><span class="line">    len -= gaplen;</span><br><span class="line">    off += gaplen;</span><br><span class="line">    bufindex = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  System.arraycopy(b, off, kvbuffer, bufindex, len);</span><br><span class="line">  bufindex += len;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startSpill</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  kvend = (kvindex + NMETA) % kvmeta.capacity();</span><br><span class="line">  bufend = bufmark;</span><br><span class="line">  spillInProgress = <span class="keyword">true</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 唤醒SpillThread</span></span><br><span class="line">  spillReady.signal();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>spillReady.signal()</code>唤醒SpillThread线程，SpillThread的run方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  spillLock.lock();</span><br><span class="line">  spillThreadRunning = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">      spillDone.signal();</span><br><span class="line">      <span class="comment">// 判断是否在spill，false则挂起SpillThread线程，等待唤醒</span></span><br><span class="line">      <span class="keyword">while</span> (!spillInProgress) &#123;</span><br><span class="line">        spillReady.await();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        spillLock.unlock();</span><br><span class="line">        <span class="comment">// 唤醒之后，进行排序和溢写到磁盘</span></span><br><span class="line">        sortAndSpill();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">        sortSpillException = t;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        spillLock.lock();</span><br><span class="line">        <span class="keyword">if</span> (bufend &lt; bufstart) &#123;</span><br><span class="line">          bufvoid = kvbuffer.length;</span><br><span class="line">        &#125;</span><br><span class="line">        kvstart = kvend;</span><br><span class="line">        bufstart = bufend;</span><br><span class="line">        spillInProgress = <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    Thread.currentThread().interrupt();</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    spillLock.unlock();</span><br><span class="line">    spillThreadRunning = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sortAndSpill</span><span class="params">()</span> <span class="keyword">throws</span> IOException, ClassNotFoundException,</span></span><br><span class="line"><span class="function">                                   InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">//approximate the length of the output file to be the length of the</span></span><br><span class="line">  <span class="comment">//buffer + header lengths for the partitions</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> size = distanceTo(bufstart, bufend, bufvoid) +</span><br><span class="line">              partitions * APPROX_HEADER_LENGTH;</span><br><span class="line">  FSDataOutputStream out = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// create spill file</span></span><br><span class="line">    <span class="keyword">final</span> SpillRecord spillRec = <span class="keyword">new</span> SpillRecord(partitions);</span><br><span class="line">    <span class="keyword">final</span> Path filename =</span><br><span class="line">        mapOutputFile.getSpillFileForWrite(numSpills, size);</span><br><span class="line">    out = rfs.create(filename);</span><br><span class="line">    <span class="comment">// kvend/4 是截止到当前位置能存放多少个元数据实体</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> mstart = kvend / NMETA;</span><br><span class="line">    <span class="comment">// kvstart 处能存放多少个元数据实体</span></span><br><span class="line">    <span class="comment">// 元数据则在mstart和mend之间，(mstart - mend)则是元数据的个数</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> mend = <span class="number">1</span> + <span class="comment">// kvend is a valid record</span></span><br><span class="line">      (kvstart &gt;= kvend</span><br><span class="line">      ? kvstart</span><br><span class="line">      : kvmeta.capacity() + kvstart) / NMETA;</span><br><span class="line">    <span class="comment">// 排序  只对元数据进行排序,只调整元数据在kvmeta中的顺序</span></span><br><span class="line">    <span class="comment">// 排序规则是MapOutputBuffer.compare， </span></span><br><span class="line">    <span class="comment">// 先对partition进行排序其次对key值排序</span></span><br><span class="line">    sorter.sort(MapOutputBuffer.<span class="keyword">this</span>, mstart, mend, reporter);</span><br><span class="line">    <span class="keyword">int</span> spindex = mstart;</span><br><span class="line">    <span class="keyword">final</span> IndexRecord rec = <span class="keyword">new</span> IndexRecord();</span><br><span class="line">    <span class="keyword">final</span> InMemValBytes value = <span class="keyword">new</span> InMemValBytes();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; partitions; ++i) &#123;</span><br><span class="line">      <span class="comment">// 临时文件是IFile格式的</span></span><br><span class="line">      IFile.Writer&lt;K, V&gt; writer = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">long</span> segmentStart = out.getPos();</span><br><span class="line">        FSDataOutputStream partitionOut = CryptoUtils.wrapIfNecessary(job, out);</span><br><span class="line">        writer = <span class="keyword">new</span> Writer&lt;K, V&gt;(job, partitionOut, keyClass, valClass, codec,</span><br><span class="line">                                  spilledRecordsCounter);</span><br><span class="line">        <span class="comment">// 往磁盘写数据时先判断是否有combiner</span></span><br><span class="line">        <span class="keyword">if</span> (combinerRunner == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// spill directly</span></span><br><span class="line">          DataInputBuffer key = <span class="keyword">new</span> DataInputBuffer();</span><br><span class="line">          <span class="keyword">while</span> (spindex &lt; mend &amp;&amp;</span><br><span class="line">              kvmeta.get(offsetFor(spindex % maxRec) + PARTITION) == i) &#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">int</span> kvoff = offsetFor(spindex % maxRec);</span><br><span class="line">            <span class="keyword">int</span> keystart = kvmeta.get(kvoff + KEYSTART);</span><br><span class="line">            <span class="keyword">int</span> valstart = kvmeta.get(kvoff + VALSTART);</span><br><span class="line">            key.reset(kvbuffer, keystart, valstart - keystart);</span><br><span class="line">            getVBytesForOffset(kvoff, value);</span><br><span class="line">            writer.append(key, value);</span><br><span class="line">            ++spindex;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">int</span> spstart = spindex;</span><br><span class="line">          <span class="keyword">while</span> (spindex &lt; mend &amp;&amp;</span><br><span class="line">              kvmeta.get(offsetFor(spindex % maxRec)</span><br><span class="line">                        + PARTITION) == i) &#123;</span><br><span class="line">            ++spindex;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// Note: we would like to avoid the combiner if we've fewer</span></span><br><span class="line">          <span class="comment">// than some threshold of records for a partition</span></span><br><span class="line">          <span class="keyword">if</span> (spstart != spindex) &#123;</span><br><span class="line">            combineCollector.setWriter(writer);</span><br><span class="line">            RawKeyValueIterator kvIter =</span><br><span class="line">              <span class="keyword">new</span> MRResultIterator(spstart, spindex);</span><br><span class="line">            combinerRunner.combine(kvIter, combineCollector);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// close the writer</span></span><br><span class="line">        writer.close();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// record offsets</span></span><br><span class="line">        rec.startOffset = segmentStart;</span><br><span class="line">        rec.rawLength = writer.getRawLength() + CryptoUtils.cryptoPadding(job);</span><br><span class="line">        rec.partLength = writer.getCompressedLength() + CryptoUtils.cryptoPadding(job);</span><br><span class="line">        spillRec.putIndex(rec, i);</span><br><span class="line"></span><br><span class="line">        writer = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != writer) writer.close();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 判断内存中的index文件是否超出阈值，超出则将index文件写入磁盘</span></span><br><span class="line">    <span class="comment">// 当超出阈值时只是把当前index和之后的index写入磁盘</span></span><br><span class="line">    <span class="keyword">if</span> (totalIndexCacheMemory &gt;= indexCacheMemoryLimit) &#123;</span><br><span class="line">      <span class="comment">// create spill index file</span></span><br><span class="line">      Path indexFilename =</span><br><span class="line">          mapOutputFile.getSpillIndexFileForWrite(numSpills, partitions</span><br><span class="line">              * MAP_OUTPUT_INDEX_RECORD_LENGTH);</span><br><span class="line">      spillRec.writeToFile(indexFilename, job);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      indexCacheList.add(spillRec);</span><br><span class="line">      totalIndexCacheMemory +=</span><br><span class="line">        spillRec.size() * MAP_OUTPUT_INDEX_RECORD_LENGTH;</span><br><span class="line">    &#125;</span><br><span class="line">    LOG.info(<span class="string">"Finished spill "</span> + numSpills);</span><br><span class="line">    ++numSpills;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (out != <span class="keyword">null</span>) out.close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当用户自定义的map过程结束之后，代码回到<code>runNewMapper</code>中继续执行，进入SORT阶段，也可以说是Merge阶段。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runNewMapper</span><span class="params">(<span class="keyword">final</span> JobConf job,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">final</span> TaskSplitIndex splitIndex,</span></span></span><br><span class="line"><span class="function"><span class="params">                  <span class="keyword">final</span> TaskUmbilicalProtocol umbilical,</span></span></span><br><span class="line"><span class="function"><span class="params">                  TaskReporter reporter</span></span></span><br><span class="line"><span class="function"><span class="params">                  )</span> <span class="keyword">throws</span> IOException, ClassNotFoundException,</span></span><br><span class="line"><span class="function">                           InterruptedException </span>&#123;</span><br><span class="line">  ...<span class="comment">// 完整代码看上文，此处只列出关键点</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    input.initialize(split, mapperContext);</span><br><span class="line">    mapper.run(mapperContext);</span><br><span class="line">    <span class="comment">// 用户自定义的map结束后，继续执行</span></span><br><span class="line">    mapPhase.complete();</span><br><span class="line">    <span class="comment">// 开启SORT阶段，此处的SORT我感觉用merge可能更加准确</span></span><br><span class="line">    <span class="comment">// 此阶段将spill的临时文件进行堆排序merge成一个最终文件输出</span></span><br><span class="line">    setPhase(TaskStatus.Phase.SORT);</span><br><span class="line">    statusUpdate(umbilical);</span><br><span class="line">    input.close();</span><br><span class="line">    input = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 堆排序merge临时文件的入口</span></span><br><span class="line">    output.close(mapperContext);</span><br><span class="line">    output = <span class="keyword">null</span>;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    closeQuietly(input);</span><br><span class="line">    closeQuietly(output, mapperContext);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// NewOutputCollector.close</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(TaskAttemptContext context</span></span></span><br><span class="line"><span class="function"><span class="params">                  )</span> <span class="keyword">throws</span> IOException,InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    collector.flush();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (ClassNotFoundException cnf) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"can't find class "</span>, cnf);</span><br><span class="line">  &#125;</span><br><span class="line">  collector.close();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MapOutputBuffer.flush</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flush</span><span class="params">()</span> <span class="keyword">throws</span> IOException, ClassNotFoundException,</span></span><br><span class="line"><span class="function">       InterruptedException </span>&#123;</span><br><span class="line">  LOG.info(<span class="string">"Starting flush of map output"</span>);</span><br><span class="line">  spillLock.lock();</span><br><span class="line">  <span class="comment">// 首先将内存中残留的map结果spill到磁盘</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (spillInProgress) &#123;</span><br><span class="line">      reporter.progress();</span><br><span class="line">      spillDone.await();</span><br><span class="line">    &#125;</span><br><span class="line">    checkSpillException();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> kvbend = <span class="number">4</span> * kvend;</span><br><span class="line">    <span class="keyword">if</span> ((kvbend + METASIZE) % kvbuffer.length !=</span><br><span class="line">        equator - (equator % METASIZE)) &#123;</span><br><span class="line">      <span class="comment">// spill finished</span></span><br><span class="line">      resetSpill();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (kvindex != kvend) &#123;</span><br><span class="line">      kvend = (kvindex + NMETA) % kvmeta.capacity();</span><br><span class="line">      bufend = bufmark;</span><br><span class="line">      LOG.info(<span class="string">"Spilling map output"</span>);</span><br><span class="line">      LOG.info(<span class="string">"bufstart = "</span> + bufstart + <span class="string">"; bufend = "</span> + bufmark +</span><br><span class="line">               <span class="string">"; bufvoid = "</span> + bufvoid);</span><br><span class="line">      LOG.info(<span class="string">"kvstart = "</span> + kvstart + <span class="string">"("</span> + (kvstart * <span class="number">4</span>) +</span><br><span class="line">               <span class="string">"); kvend = "</span> + kvend + <span class="string">"("</span> + (kvend * <span class="number">4</span>) +</span><br><span class="line">               <span class="string">"); length = "</span> + (distanceTo(kvend, kvstart,</span><br><span class="line">                     kvmeta.capacity()) + <span class="number">1</span>) + <span class="string">"/"</span> + maxRec);</span><br><span class="line">      sortAndSpill();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Interrupted while waiting for the writer"</span>, e);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    spillLock.unlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">assert</span> !spillLock.isHeldByCurrentThread();</span><br><span class="line">  <span class="comment">// shut down spill thread and wait for it to exit. Since the preceding</span></span><br><span class="line">  <span class="comment">// ensures that it is finished with its work (and sortAndSpill did not</span></span><br><span class="line">  <span class="comment">// throw), we elect to use an interrupt instead of setting a flag.</span></span><br><span class="line">  <span class="comment">// Spilling simultaneously from this thread while the spill thread</span></span><br><span class="line">  <span class="comment">// finishes its work might be both a useful way to extend this and also</span></span><br><span class="line">  <span class="comment">// sufficient motivation for the latter approach.</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    spillThread.interrupt();</span><br><span class="line">    spillThread.join();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Spill failed"</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// release sort buffer before the merge</span></span><br><span class="line">  kvbuffer = <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// merge临时文件（使用堆排序）</span></span><br><span class="line">  mergeParts();</span><br><span class="line">  Path outputPath = mapOutputFile.getOutputFile();</span><br><span class="line">  fileOutputByteCounter.increment(rfs.getFileStatus(outputPath).getLen());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// MapOutputBuffer.mergeParts</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">mergeParts</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, </span></span><br><span class="line"><span class="function">                                 ClassNotFoundException </span>&#123;</span><br><span class="line">  <span class="comment">// get the approximate size of the final output/index files</span></span><br><span class="line">  <span class="keyword">long</span> finalOutFileSize = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">long</span> finalIndexFileSize = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">final</span> Path[] filename = <span class="keyword">new</span> Path[numSpills];</span><br><span class="line">  <span class="keyword">final</span> TaskAttemptID mapId = getTaskID();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numSpills; i++) &#123;</span><br><span class="line">    filename[i] = mapOutputFile.getSpillFile(i);</span><br><span class="line">    finalOutFileSize += rfs.getFileStatus(filename[i]).getLen();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 只有一个spill则直接将文件进行重命名，不进行merge</span></span><br><span class="line">  <span class="keyword">if</span> (numSpills == <span class="number">1</span>) &#123; <span class="comment">//the spill is the final output</span></span><br><span class="line">    ...</span><br><span class="line">    sortPhase.complete();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// read in paged indices</span></span><br><span class="line">  <span class="comment">// 将磁盘中的index文件加载到内存</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = indexCacheList.size(); i &lt; numSpills; ++i) &#123;</span><br><span class="line">    Path indexFileName = mapOutputFile.getSpillIndexFile(i);</span><br><span class="line">    indexCacheList.add(<span class="keyword">new</span> SpillRecord(indexFileName, job));</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">//The output stream for the final single output file</span></span><br><span class="line">  FSDataOutputStream finalOut = rfs.create(finalOutputFile, <span class="keyword">true</span>, <span class="number">4096</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (numSpills == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">//create dummy files</span></span><br><span class="line">    ...</span><br><span class="line">    sortPhase.complete();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  &#123;</span><br><span class="line">    sortPhase.addPhases(partitions); <span class="comment">// Divide sort phase into sub-phases</span></span><br><span class="line">    </span><br><span class="line">    IndexRecord rec = <span class="keyword">new</span> IndexRecord();</span><br><span class="line">    <span class="keyword">final</span> SpillRecord spillRec = <span class="keyword">new</span> SpillRecord(partitions);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> parts = <span class="number">0</span>; parts &lt; partitions; parts++) &#123;</span><br><span class="line">      <span class="comment">//create the segments to be merged</span></span><br><span class="line">      List&lt;Segment&lt;K,V&gt;&gt; segmentList =</span><br><span class="line">        <span class="keyword">new</span> ArrayList&lt;Segment&lt;K, V&gt;&gt;(numSpills);</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numSpills; i++) &#123;</span><br><span class="line">        <span class="comment">// 从spill的index文件中得到当前spill中某个partition的信息</span></span><br><span class="line">        IndexRecord indexRecord = indexCacheList.get(i).getIndex(parts);</span><br><span class="line"></span><br><span class="line">        Segment&lt;K,V&gt; s =</span><br><span class="line">          <span class="keyword">new</span> Segment&lt;K,V&gt;(job, rfs, filename[i], indexRecord.startOffset,</span><br><span class="line">                           indexRecord.partLength, codec, <span class="keyword">true</span>);</span><br><span class="line">        segmentList.add(i, s);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">          LOG.debug(<span class="string">"MapId="</span> + mapId + <span class="string">" Reducer="</span> + parts +</span><br><span class="line">              <span class="string">"Spill ="</span> + i + <span class="string">"("</span> + indexRecord.startOffset + <span class="string">","</span> +</span><br><span class="line">              indexRecord.rawLength + <span class="string">", "</span> + indexRecord.partLength + <span class="string">")"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 临时文件超过mapreduce.task.io.sort.factor 时进行排序</span></span><br><span class="line">      <span class="keyword">int</span> mergeFactor = job.getInt(JobContext.IO_SORT_FACTOR, <span class="number">100</span>);</span><br><span class="line">      <span class="comment">// sort the segments only if there are intermediate merges</span></span><br><span class="line">      <span class="comment">// 是否按照长度对segment进行排序</span></span><br><span class="line">      <span class="keyword">boolean</span> sortSegments = segmentList.size() &gt; mergeFactor;</span><br><span class="line">      <span class="comment">//merge</span></span><br><span class="line">      <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">      <span class="comment">// 堆排序（小顶堆） </span></span><br><span class="line">      <span class="comment">// sortSegments为true时先将segments按照文件大小进行排序然后进行堆排序</span></span><br><span class="line">      <span class="comment">// 堆排序是使用优先级队列</span></span><br><span class="line">      <span class="comment">// kvIter依然是键值对的形式存在</span></span><br><span class="line">      RawKeyValueIterator kvIter = Merger.merge(job, rfs,</span><br><span class="line">                     keyClass, valClass, codec,</span><br><span class="line">                     segmentList, mergeFactor,</span><br><span class="line">                     <span class="keyword">new</span> Path(mapId.toString()),</span><br><span class="line">                     job.getOutputKeyComparator(), reporter, sortSegments,</span><br><span class="line">                     <span class="keyword">null</span>, spilledRecordsCounter, sortPhase.phase(),</span><br><span class="line">                     TaskType.MAP);</span><br><span class="line"></span><br><span class="line">      <span class="comment">//write merged output to disk</span></span><br><span class="line">      <span class="keyword">long</span> segmentStart = finalOut.getPos();</span><br><span class="line">      FSDataOutputStream finalPartitionOut = CryptoUtils.wrapIfNecessary(job, finalOut);</span><br><span class="line">      Writer&lt;K, V&gt; writer =</span><br><span class="line">          <span class="keyword">new</span> Writer&lt;K, V&gt;(job, finalPartitionOut, keyClass, valClass, codec,</span><br><span class="line">                           spilledRecordsCounter);</span><br><span class="line">      <span class="comment">// merge 往磁盘写数据时也会检查下是否有combiner </span></span><br><span class="line">      <span class="comment">// 注意此处不只是简单检查下是否有combiner，假如有combiner也不一定执行</span></span><br><span class="line">      <span class="comment">// 需在numSpills&gt;mapreduce.map.combine.minspills(默认3) 且有combiner时才执行combiner</span></span><br><span class="line">      <span class="comment">// (map阶段只要往磁盘上写数据都会检查下是否有combiner)</span></span><br><span class="line">      <span class="keyword">if</span> (combinerRunner == <span class="keyword">null</span> || numSpills &lt; minSpillsForCombine) &#123;</span><br><span class="line">        Merger.writeFile(kvIter, writer, reporter, job);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        combineCollector.setWriter(writer);</span><br><span class="line">        combinerRunner.combine(kvIter, combineCollector);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//close</span></span><br><span class="line">      writer.close();</span><br><span class="line"></span><br><span class="line">      sortPhase.startNextPhase();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// record offsets</span></span><br><span class="line">      rec.startOffset = segmentStart;</span><br><span class="line">      rec.rawLength = writer.getRawLength() + CryptoUtils.cryptoPadding(job);</span><br><span class="line">      rec.partLength = writer.getCompressedLength() + CryptoUtils.cryptoPadding(job);</span><br><span class="line">      spillRec.putIndex(rec, parts);</span><br><span class="line">    &#125;</span><br><span class="line">    spillRec.writeToFile(finalIndexFile, job);</span><br><span class="line">    finalOut.close();</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numSpills; i++) &#123;</span><br><span class="line">      rfs.delete(filename[i],<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至此map整个阶段结束。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>整个Map阶段的流程是inputFile通过split被切分为多个split文件，通过Record按行读取内容给map（用户自己实现的）进行处理，数据被map处理结束之后交给<code>context.write</code>，然后调用<code>NewOutputCollector.write</code>，对其结果key进行分区（默认使用hash分区），然后传给<code>MapOutputBuffer.collect</code>进行key、value的序列化写入buffer，由<code>bufferRemaining</code>记录剩余的字节大小，小于等于0时，开始进行spill，spill时先对buffer中key/value的元数据进行快排，之后开始写入磁盘的临时文件（写之前判断是否有combiner），当整个数据处理结束之后开始对磁盘中的临时文件进行merge，merge时使用的是堆排序（使用优先级队列实现），排序结束之后准备作为最终文件写入磁盘，<strong>在写入之前依然会判断是否有combiner，但此处会多一个条件，并不是只要有combiner就会执行，在有combiner的情况下还需满足numSpills&gt;mapreduce.map.combine.minspills才会执行combiner</strong></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce </tag>
            
            <tag> Map </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce源码解析--TotalOrderPartitioner]]></title>
      <url>http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--TotalOrderPartitioner.html</url>
      <content type="html"><![CDATA[<p>MR本身就具有排序功能，但是其分布式的特性使其无法较理想的进行全局排序。难道要想使用MR进行全局排序时只能将其结果都输入到一个reduce中？那这不就违背了其分布式的特性了嘛。于是大牛们想到了在map分区时保证分区的有序性，使其分配到第一个reduce中的key一定小于分配到第二个reduce中的key，此功能就是本篇要解析的分区类<code>TotalOrderPartitioner</code>。</p>
<p><a href="http://bigdatadecode.club/MapReduce应用实例--二次排序之全局有序.html">上篇</a>从应用的角度展示了<code>TotalOrderPartitioner</code>如何进行全局排序。本篇从代码的角度解析下<code>TotalOrderPartitioner</code>是怎么实现的，其中又用到了哪些黑科技。。。</p>
<p><em>TotalOrderPartitioner之所以能够实现全局排序，是因为其在分区时依赖一个分区文件，其文件中记录了将key进行分区的分界点，是这些分界点起到了关键作用。这些分界点保证了某一区间的key分到同一个reduce中，而TotalOrderPartitioner只是将key和分界点比较的过程进行了优化，使其在大数据规模下能够高效的进行。</em></p>
<a id="more"></a>
<h2 id="TotalOrderPartitioner实现高速查询架构"><a href="#TotalOrderPartitioner实现高速查询架构" class="headerlink" title="TotalOrderPartitioner实现高速查询架构"></a>TotalOrderPartitioner实现高速查询架构</h2><p>TotalOrderPartitioner对不同Key的数据类型提供了两种方案：</p>
<ul>
<li><p>对于只能WritableComparable而不能BinaryComparable类型的key，也可以理解成数值类型的数据(<em>如IntWritable，在实现时只实现了WritableComparable接口</em>)，TotalOrderPartitioner采用二分查找来确定当前key所在的reduce index。<em>其二分查找是通过调用Arrays.binarySearch实现的</em>。其时间复杂度是O(log(reduce num))。</p>
</li>
<li><p>对于可以BinaryComparable的key，也可以理解为字符串类型数据(<em>如Text，BytesWritable，在实现时继承了BinaryComparable父类</em>)，则构建一个<strong>Trie树</strong>，使字符串按照字典序进行排序。Trie树的查找时间复杂度是O(d)，d为树的深度(<em>根的深度为1</em>)，空间复杂度是O(255^(d-1))。</p>
</li>
</ul>
<h2 id="TotalOrderPartitioner源码解析"><a href="#TotalOrderPartitioner源码解析" class="headerlink" title="TotalOrderPartitioner源码解析"></a>TotalOrderPartitioner源码解析</h2><p>TotalOrderPartitioner实现了<em>Configurable</em>接口，在<code>setConf</code>中进行初始化，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setConf</span><span class="params">(Configuration conf)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">this</span>.conf = conf;</span><br><span class="line">        String parts = getPartitionFile(conf);</span><br><span class="line">        <span class="keyword">final</span> Path partFile = <span class="keyword">new</span> Path(parts);</span><br><span class="line">        <span class="keyword">final</span> FileSystem fs = (DEFAULT_PATH.equals(parts))</span><br><span class="line">                ? FileSystem.getLocal(conf)     <span class="comment">// assume in DistributedCache</span></span><br><span class="line">                : partFile.getFileSystem(conf);</span><br><span class="line"></span><br><span class="line">        Job job = <span class="keyword">new</span> Job(conf);</span><br><span class="line">        <span class="comment">// 得到map output key的类型，</span></span><br><span class="line">        <span class="comment">// 将partition file中key读取为keyClass类型</span></span><br><span class="line">        Class&lt;K&gt; keyClass = (Class&lt;K&gt;)job.getMapOutputKeyClass();</span><br><span class="line">        <span class="comment">// 读取partition file，此文件为sequenceFile</span></span><br><span class="line">        K[] splitPoints = readPartitions(fs, partFile, keyClass, conf);</span><br><span class="line">        <span class="keyword">if</span> (splitPoints.length != job.getNumReduceTasks() - <span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Wrong number of partitions in keyset"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 得到job中设置的比较器，</span></span><br><span class="line">        <span class="comment">// 此比较器用在判断partition file中key是否按照升序排列，</span></span><br><span class="line">        <span class="comment">// 其次是在二分查找中用，</span></span><br><span class="line">        RawComparator&lt;K&gt; comparator =</span><br><span class="line">                (RawComparator&lt;K&gt;) job.getSortComparator();</span><br><span class="line">        <span class="comment">// 判断key是否升序</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; splitPoints.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (comparator.compare(splitPoints[i], splitPoints[i+<span class="number">1</span>]) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Split points are out of order"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">boolean</span> natOrder =</span><br><span class="line">                conf.getBoolean(NATURAL_ORDER, <span class="keyword">true</span>);</span><br><span class="line">        <span class="comment">// 可BinaryComparable并且按照字典序比较则构建Trie树进行查找</span></span><br><span class="line">        <span class="comment">// 否则使用二分查找</span></span><br><span class="line">        <span class="keyword">if</span> (natOrder &amp;&amp; BinaryComparable.class.isAssignableFrom(keyClass)) &#123;</span><br><span class="line">            partitions = buildTrie((BinaryComparable[])splitPoints, <span class="number">0</span>,</span><br><span class="line">                    splitPoints.length, <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">0</span>],</span><br><span class="line">                    <span class="comment">// Now that blocks of identical splitless trie nodes are</span></span><br><span class="line">                    <span class="comment">// represented reentrantly, and we develop a leaf for any trie</span></span><br><span class="line">                    <span class="comment">// node with only one split point, the only reason for a depth</span></span><br><span class="line">                    <span class="comment">// limit is to refute stack overflow or bloat in the pathological</span></span><br><span class="line">                    <span class="comment">// case where the split points are long and mostly look like bytes</span></span><br><span class="line">                    <span class="comment">// iii...iixii...iii   .  Therefore, we make the default depth</span></span><br><span class="line">                    <span class="comment">// limit large but not huge.</span></span><br><span class="line">                    conf.getInt(MAX_TRIE_DEPTH, <span class="number">200</span>));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            partitions = <span class="keyword">new</span> BinarySearchNode(splitPoints, comparator);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Can't read partitions file"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>TotalOrderPartitioner构建成功用于查找的数据结构之后，在map中调用<code>getPartition</code>就ok了，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(K key, V value, <span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> partitions.findPartition(key);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过getPartition这个入口，可以根据key在不同的数据结构中快速查找。下面就来看下两种数据结构是如何实现的。先看较简单的二分查找。</p>
<h3 id="二分查找"><a href="#二分查找" class="headerlink" title="二分查找"></a>二分查找</h3><p>partitions是Node类型的，在setConf中通过<em>构造一个BinarySearchNode</em>来对其赋值，由此可见BinarySearchNode肯定实现了Node接口。BinarySearchNode比较简单，在此贴了全部代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">BinarySearchNode</span> <span class="keyword">implements</span> <span class="title">Node</span>&lt;<span class="title">K</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> K[] splitPoints;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> RawComparator&lt;K&gt; comparator;</span><br><span class="line">    BinarySearchNode(K[] splitPoints, RawComparator&lt;K&gt; comparator) &#123;</span><br><span class="line">        <span class="keyword">this</span>.splitPoints = splitPoints;</span><br><span class="line">        <span class="keyword">this</span>.comparator = comparator;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findPartition</span><span class="params">(K key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> pos = Arrays.binarySearch(splitPoints, key, comparator1) + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> (pos &lt; <span class="number">0</span>) ? -pos : pos;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其构造方法将<em>分界点数组和比较器传入</em>，然后在<code>findPartition</code>中调用Arrays.binarySearch对目标key进行查找。则查找逻辑主要在Arrays.binarySearch中实现，我们看下其源码实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> &lt;T&gt; <span class="function"><span class="keyword">int</span> <span class="title">binarySearch0</span><span class="params">(T[] a, <span class="keyword">int</span> fromIndex, <span class="keyword">int</span> toIndex,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     T key, Comparator&lt;? <span class="keyword">super</span> T&gt; c)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 比较器c为null，则使用Arrays的默认比较器</span></span><br><span class="line">    <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> binarySearch0(a, fromIndex, toIndex, key);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> low = fromIndex;</span><br><span class="line">    <span class="keyword">int</span> high = toIndex - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (low &lt;= high) &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = (low + high) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        T midVal = a[mid];</span><br><span class="line">        <span class="keyword">int</span> cmp = c.compare(midVal, key);</span><br><span class="line">        <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)</span><br><span class="line">            low = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)</span><br><span class="line">            high = mid - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">return</span> mid; <span class="comment">// key found</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -(low + <span class="number">1</span>);  <span class="comment">// key not found.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这是jdk的默认实现，需要注意的是未找到目标key时返回<code>-(low+1)</code>，其中low是该元素要插入的位置，也就是low索引之前的元素都比目标key要小，但是之所以返回<code>-(low+1)</code>而不是<code>-low</code>，<em>是因为假如目标key比所有的元素都小时，那么最后一次比较是停留在index=0的位置，这时候low=0,那么我们返回给调用者的值就是0了，<strong>而不是一个负数</strong>，这样我们拿到0并不知道他是没匹配到，还是该元素就在第一个元素。所以我们要保证如果找不到就返回一个负数。所以就多减个1 这样-1就表示没找到并且该元素必须插到0的位置上</em>。</p>
<p>对于可以进行数值比较的key使用二分查找比较简单高效，但对于字符类型的key比较时可以使用更高效的Trie树比较。下面看下Trie树。</p>
<h3 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h3><p>Trie树又称字典树、前缀树，是一种有序树。跟HashMap的功能相似，都是key-value映射，<em>只不过Trie常用于有公共前缀的字符串映射，并且key只能是字符串</em>。<br>Trie树的查询效率较高，时间复杂度为O(n)，<em>n为字符串的长度</em>也可以理解成Trie树的深度，<em>与Trie树中保存的字符串个数无关</em>。只是其空间复杂度较大，是一个典型的拿空间换时间的数据结构。</p>
<p>Trie树的基本性质如下：</p>
<ul>
<li>根节点不包含字符，除根节点之外所有的节点<em>最多</em>包含<em>一个字符</em>(不是一个字符串)。</li>
<li>把根节点到某一节点的路径上的字符连接起来就是该节点对应的字符串。</li>
<li>每个节点的所有子节点包含的字符都不相同，并且每个节点的所有子节点都有相同的前缀。</li>
<li>如果字符的种类是n，则每个节点<em>不管其子节点上是否有对应的value</em>都会有n个子节点。(这就浪费了很多空间)</li>
<li>插入和查找的复杂度是O(n)，n为字符串的长度。</li>
</ul>
<p>在对TotalOrderPartition中Trie树的构造过程进行解析之前，先对其中相关的内部类进行下介绍。</p>
<p>Node是一个接口，TrieNode是抽象类，扩展了Node接口(<em>BinarySearchNode实现了Node接口，作为数值型数据比较节点</em>)，作为Trie树中抽象出的节点类。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Node</span>&lt;<span class="title">T</span>&gt; </span>&#123;</span><br><span class="line"><span class="comment">// 所有方法的访问权限自动被声明为public。</span></span><br><span class="line"><span class="comment">// 确切的说只能为public，当然你可以显示的声明为protected、private，但是编译会出错</span></span><br><span class="line"><span class="comment">// 接口中可以定义"成员变量"，或者说是不可变的常量，</span></span><br><span class="line"><span class="comment">// 因为接口中的"成员变量"会自动变为public static final</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">findPartition</span><span class="params">(T key)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 抽象类实现接口时，不用必须实现接口中的方法</span></span><br><span class="line"><span class="comment">// TrieNode 并没有实现Node接口中的findPartition方法</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">TrieNode</span> <span class="keyword">implements</span> <span class="title">Node</span>&lt;<span class="title">BinaryComparable</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> level;</span><br><span class="line">    TrieNode(<span class="keyword">int</span> level) &#123;</span><br><span class="line">        <span class="keyword">this</span>.level = level;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">getLevel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> level;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接口和抽象类介绍完就剩下Trie树中<em>标识各个节点状态的对象类</em>了，包括<code>InnerTrieNode</code>(有key的节点)、<code>UnsplitTrieNode</code>()、<code>SinglySplitTrieNode</code>(单个切分节点，存放value值的节点)和<code>LeafTrieNode</code>()。</p>
<p>对Trie树有了初步的了解，下面看下Trie树的构造过程。TotalOrderPartition中Trie树的构造是类似深度遍历那样递归的对树进行构建。</p>
<p>在构建过程中需要注意几点：</p>
<ul>
<li><p><em>Trie树中节点分两种情况，一种是不存放字符的节点，一种是存放字符的情况</em>。对于不存放字符的节点不用为其构建子树，对于本例中的情况，由于此节点不存放字符也就不用切分，则这类情况的节点的状态是<code>UnsplitTrieNode</code>。对于存放字符的节点则根据是否是叶子节点又分为<code>InnerTrieNode</code>(根节点也是InnerTrieNode)和<code>SinglySplitTrieNode</code>。</p>
</li>
<li><p>由于本例中比较的是字符，则每个节点最多有256(ascii码0-255表示字符)个子树，从左到右依次0-255，每个字符存放在对应ascii码的子树上，如字符1的ascii码是49，则存放在标号为49的子树上。</p>
</li>
<li><p>partition file中的key是按照升序排好的，<em>相邻的字符会有部分前缀相同，则无需分别对单个key中的字符进行构建，而是每次对所有key的第i个字符进行构建</em>，用<code>currentBound</code>标识是对第几个key中的字符进行构建。</p>
</li>
</ul>
<p>构建代码入口如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 参数为 splitPoints, 0, splitPoints.length, new byte[0], conf.getInt(MAX_TRIE_DEPTH, 200)</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> TrieNode <span class="title">buildTrieRec</span><span class="params">(BinaryComparable[] splits, <span class="keyword">int</span> lower,</span></span></span><br><span class="line"><span class="function"><span class="params">                              <span class="keyword">int</span> upper, <span class="keyword">byte</span>[] prefix, <span class="keyword">int</span> maxDepth, CarriedTrieNodeRef ref)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 可见代码中树的深度不包括根节点</span></span><br><span class="line">    <span class="comment">// 前缀数组标识了当前Trie树的深度</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> depth = prefix.length;</span><br><span class="line">    <span class="comment">// We generate leaves for a single split point as well as for</span></span><br><span class="line">    <span class="comment">// no split points.</span></span><br><span class="line">    <span class="comment">// 为单个切分点生成叶子节点，就像为那些无法切分点生成叶子节点一样</span></span><br><span class="line">    <span class="comment">// 当前节点只有一个子节点有值时，不用循环设置子节点的状态，直接将此节点变为叶子节点</span></span><br><span class="line">    <span class="comment">// 当前节点有几个子节点有值，是由upper-lower来标识的</span></span><br><span class="line">    <span class="comment">// 叶子节点包括 UnsplitTrieNode、SinglySplitTrieNode和LeafTrieNode</span></span><br><span class="line">    <span class="keyword">if</span> (depth &gt;= maxDepth || lower &gt;= upper - <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// If we have two consecutive requests for an unsplit trie node, we</span></span><br><span class="line">        <span class="comment">// can deliver the same one the second time.</span></span><br><span class="line">        <span class="keyword">if</span> (lower == upper &amp;&amp; ref.content != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> ref.content;</span><br><span class="line">        &#125;</span><br><span class="line">        TrieNode  result = LeafTrieNodeFactory(depth, splits, lower, upper);</span><br><span class="line">        <span class="comment">// 为 ref.content 重新赋值</span></span><br><span class="line">        ref.content = lower == upper ? result : <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 有数值的节点声明为InnerTrieNode</span></span><br><span class="line">    InnerTrieNode result = <span class="keyword">new</span> InnerTrieNode(depth);</span><br><span class="line">    <span class="comment">// 实验数组</span></span><br><span class="line">    <span class="keyword">byte</span>[] trial = Arrays.copyOf(prefix, prefix.length + <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// append an extra byte on to the prefix</span></span><br><span class="line">    <span class="keyword">int</span> currentBound = lower;</span><br><span class="line">    <span class="comment">// 0xFF为int的255，是byte类型的-1</span></span><br><span class="line">    <span class="comment">// 为当前节点生成0-254子节点的状态</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> ch = <span class="number">0</span>; ch &lt; <span class="number">0xFF</span>; ++ch) &#123;</span><br><span class="line">        trial[depth] = (<span class="keyword">byte</span>) (ch + <span class="number">1</span>);</span><br><span class="line">        lower = currentBound;</span><br><span class="line">        <span class="keyword">while</span> (currentBound &lt; upper) &#123;</span><br><span class="line">        	<span class="comment">// 对第currentBound个key第trial.length个字符进行比较</span></span><br><span class="line">        	<span class="comment">// 当splits[currentBound]大时，当前节点无字符，跳出while循环，</span></span><br><span class="line">        	<span class="comment">// 将此节点变为UnsplitTrieNode状态</span></span><br><span class="line">        	<span class="comment">// 当splits[currentBound]小时，比较splits中下一个key的第trial.length字符</span></span><br><span class="line">            <span class="keyword">if</span> (splits[currentBound].compareTo(trial, <span class="number">0</span>, trial.length) &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            currentBound += <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 存储当前字符所在的节点索引</span></span><br><span class="line">        trial[depth] = (<span class="keyword">byte</span>) ch;</span><br><span class="line">        <span class="comment">// 递归的对其节点构建子节点</span></span><br><span class="line">        result.child[<span class="number">0xFF</span> &amp; ch]</span><br><span class="line">                = buildTrieRec(splits, lower, currentBound, trial, maxDepth, ref);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// pick up the rest</span></span><br><span class="line">    <span class="comment">// 重置最后一层的值，便于构造第255个节点的值</span></span><br><span class="line">    <span class="comment">// for循环只是对0-254进行构建</span></span><br><span class="line">    trial[depth] = (<span class="keyword">byte</span>)<span class="number">0xFF</span>;</span><br><span class="line">    result.child[<span class="number">0xFF</span>]</span><br><span class="line">            = buildTrieRec(splits, lower, currentBound, trial, maxDepth, ref);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首次<code>buildTrieRec</code>是通过<code>buildTrie</code>，传入的参数是存放key的数组splitPoints、<strong>开始索引lower为0、结束索引upper为splitPoints.length</strong>、prefix前缀数组byte[0]和最大深度默认是200。<em>其中开始索引和结束索引是指splitPoints中第i个字符比当前子树节点的标号小的那些key的索引值，开始索引是指小于此标号的第一个key的索引，结束索引是指小于此标号的最后一个key的索引。</em></p>
<p>首次调用<code>buildTrieRec</code>时，如果splitPoints的长度大于2，则创建一个根节点，根节点的状态是<code>InnerTrieNode</code>，<em>但是不存放任何字符</em>。根节点创建之后由一个for循环为其254个子树创建节点的状态，第255个子树作为边界值在for循环之外进行创建。<em>在构建子树时是按照深度优先遍历的方式进行构建，而子树的构建是由字符比较所决定的，对不同深度的子树比较的字符也不一样，则需要记录子树的深度和此时比较的字符，又由于Trie树是一层一个字符，则将当前比较字符及其前缀字符保存到数组，这样数组的长度就是子树的深度，数组中的元素值就是所需比较的字符。</em>上面的代码中则是在for循环之前将前缀数组复制到trial数组(<em>实验数组</em>)中，将lower做为字符比较的第一个key，将其赋值给currentBound，由currentBound来标识比较的是当前集合中的第几个key。</p>
<p>每个节点有256个子树，从0开始标号，将第255个子树作为边界单独处理，则在for循环中对0-254子树进行处理(<code>for(int ch=0; ch&lt;0xFF; ch++)</code>)，由currentBound决定比较的是第几个key，由trial数组的长度决定比较key中的第几个字符，trial数组中的最后一个变量是<code>ch</code>，在for中的while循环里通过比较key的第trial.length个字符与ch的大小，找到这个字符在子树中的合适位置，并通过currentBound的值来统计当前key的集合中有多少个key中第trial.length个字符可以放在此子树上。然后对该节点进行递归的创建子树节点。<br>随后跳出for循环，设置trial的值，0xFF(byte类型为数值-1)，然后对255节点进行构建</p>
<p>用lowe和upper的值来判断build的逻辑，是创建子树或者Unsplit或者SinglySplit。build逻辑如下：</p>
<ul>
<li>当lower和upper的差值小于等于1时，则进行是构建Unsplit(upper-lower==0)还是SinglySplit(upper-lower==1)。</li>
<li>当大于1时，则利用for循环构建子树。</li>
</ul>
<p>下面看下<code>UnsplitTrieNode</code>和<code>SinglySplitTrieNode</code>两个类。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">UnsplitTrieNode</span> <span class="keyword">extends</span> <span class="title">TrieNode</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> result;</span><br><span class="line"></span><br><span class="line">    UnsplitTrieNode(<span class="keyword">int</span> level, <span class="keyword">int</span> value) &#123;</span><br><span class="line">        <span class="keyword">super</span>(level);</span><br><span class="line">        <span class="keyword">this</span>.result = value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 返回该节点上的key被分配到的reduce id</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findPartition</span><span class="params">(BinaryComparable key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>UnsplitTrieNode中<em>result属性记录了该分支上的key应该被分配到哪个分区</em>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">SinglySplitTrieNode</span> <span class="keyword">extends</span> <span class="title">TrieNode</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span>               lower;</span><br><span class="line">    <span class="keyword">final</span> BinaryComparable  mySplitPoint;</span><br><span class="line"></span><br><span class="line">    SinglySplitTrieNode(<span class="keyword">int</span> level, BinaryComparable[] splitPoints, <span class="keyword">int</span> lower) &#123;</span><br><span class="line">        <span class="keyword">super</span>(level);</span><br><span class="line">        <span class="keyword">this</span>.lower = lower;</span><br><span class="line">        <span class="keyword">this</span>.mySplitPoint = splitPoints[lower];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里决定了当key等于mySplitPoint时，会分配到下一个reduce中</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findPartition</span><span class="params">(BinaryComparable key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> lower + (key.compareTo(mySplitPoint) &lt; <span class="number">0</span> ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>SinglySplitTrieNode中lower属性记录了当前key在key集合中的索引，属性mySplitPoint记录了分界点的值。</em></p>
<p>至此buildTrie的主要逻辑已分析完毕，接下来我们来个例子实践下。<br>切分节点为1983、1995、1999、2996，利用此4个切分节点构建Trie树如下图：</p>
<p><img src="/blogimgs/TotalOrderPartition/Trie.png" alt="Trie树结构图" title="Trie树结构图"></p>
<blockquote>
<p>其中节点上的数字表示每个节点的标号，范围是0-255，也是每个字符的ascii码。</p>
</blockquote>
<p>假如key为1973，则经过root-&gt;49-&gt;57，然后197比198小，则将其分配给reduce 0<br>假如key为1983，则经过root-&gt;49-&gt;57-&gt;56，将其分配给reduce 1<br>假如key为3，将其分配给reduce 3</p>
<h2 id="NOTE"><a href="#NOTE" class="headerlink" title="NOTE"></a>NOTE</h2><p>partition file中<em>key是升序的</em>，因为二分查找需要数据集是有序的和Trie树的构建需要数据是有序的<br>partition file中key的数据类型和map output key、reduce input key 相同<br>partition file中key的分布尽量均匀避免数据倾斜</p>
<h2 id="彩蛋"><a href="#彩蛋" class="headerlink" title="彩蛋"></a>彩蛋</h2><p>Hadoop中提供的partition方法</p>
<ol>
<li>HashPartitioner是mapreduce的默认partitioner。根据key的hash结果选择reduce。</li>
<li>BinaryPatitioner继承于Partitioner<binarycomparable ,v="">，是Partitioner的偏特化子类。该类提供leftOffset和rightOffset，在计算which reducer时仅对键值K的[rightOffset，leftOffset]这个区间取hash。</binarycomparable></li>
<li>KeyFieldBasedPartitioner也是基于hash的个partitioner。KeyFieldBasedPartitioner可以灵活设置key中用于partition的字段，而不是把整个key都用来做partition。</li>
<li>TotalOrderPartitioner这个类可以实现输出的全排序。不同于以上3个partitioner，这个类并不是基于hash的。</li>
</ol>
<!--
num.map.output.key.fields 设置map输出的前几个字段作为key
map.output.field.separator 设置map输出的字段分隔符
mapred.text.key.partitioner.options=-k2,3 #用第二和第三个field进行分区
-->
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce </tag>
            
            <tag> 全局排序 </tag>
            
            <tag> TotalOrderPartitioner </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce源码解析--JobSplit]]></title>
      <url>http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--JobSplit.html</url>
      <content type="html"><![CDATA[<p>MapReduce就是将一个大job切分为n个task，由map和reduce分别去执行，但是切分规则是什么呢？<em>其实job的切分也就是job所需文件的切分</em>。</p>
<p>下面就从源码的角度简单分析下。</p>
<h2 id="文件切分"><a href="#文件切分" class="headerlink" title="文件切分"></a>文件切分</h2><p>MR是通过JobSubmitter.submitJobInternal提交给RM的，在submitJobInternal中通过<code>writeSplits(JobContext job, Path jobSubmitDir)</code>将job的输入文件进行split，writeSplit只是对新旧api进行了下封装，根据你的代码选择新旧api，这里调用<code>writeNewSplits</code>使用新API对file进行split<br><a id="more"></a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T extends InputSplit&gt;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">writeNewSplits</span><span class="params">(JobContext job, Path jobSubmitDir)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">    InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class="line">  Configuration conf = job.getConfiguration();</span><br><span class="line">  <span class="comment">// 创建一个InputFormat，用于指定文件的格式化格式，默认是FileInputFormat</span></span><br><span class="line">  InputFormat&lt;?, ?&gt; input =</span><br><span class="line">    ReflectionUtils.newInstance(job.getInputFormatClass(), conf);</span><br><span class="line">  <span class="comment">// 从JobContext中的INPUT_DIR中拿到files，然后根据splitSize对文件进行切分</span></span><br><span class="line">  List&lt;InputSplit&gt; splits = input.getSplits(job);</span><br><span class="line">  T[] array = (T[]) splits.toArray(<span class="keyword">new</span> InputSplit[splits.size()]);</span><br><span class="line">  <span class="comment">// sort the splits into order based on size, so that the biggest</span></span><br><span class="line">  <span class="comment">// go first</span></span><br><span class="line">  <span class="comment">// 对splits进行排序，按照split的大小进行逆序排序，先处理大的</span></span><br><span class="line">  Arrays.sort(array, <span class="keyword">new</span> SplitComparator());</span><br><span class="line">  <span class="comment">// 将split信息固化到文件中</span></span><br><span class="line">  JobSplitWriter.createSplitFiles(jobSubmitDir, conf, </span><br><span class="line">      jobSubmitDir.getFileSystem(conf), array);</span><br><span class="line">  <span class="keyword">return</span> array.length;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>writeNewSplits根据得到的InputFormat实例，调用getSplits对文件进行切分，这也是切分的主要逻辑，看下代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;InputSplit&gt; <span class="title">getSplits</span><span class="params">(JobContext job)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 得到split的大小，由mapreduce.input.fileinputformat.split.minsize控制</span></span><br><span class="line">  <span class="keyword">long</span> minSize = Math.max(getFormatMinSplitSize(), getMinSplitSize(job));</span><br><span class="line">  <span class="comment">// split的最大值，默认是Long.MAX_VALUE</span></span><br><span class="line">  <span class="keyword">long</span> maxSize = getMaxSplitSize(job);</span><br><span class="line">  <span class="comment">// generate splits</span></span><br><span class="line">  List&lt;InputSplit&gt; splits = <span class="keyword">new</span> ArrayList&lt;InputSplit&gt;();</span><br><span class="line">  <span class="comment">// 多线程得到输入路径中的文件状态</span></span><br><span class="line">  List&lt;FileStatus&gt; files = listStatus(job);</span><br><span class="line">  <span class="comment">// 以文件为单位进行切分</span></span><br><span class="line">  <span class="keyword">for</span> (FileStatus file: files) &#123;</span><br><span class="line">    Path path = file.getPath();</span><br><span class="line">    <span class="keyword">long</span> length = file.getLen();</span><br><span class="line">    <span class="keyword">if</span> (length != <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 得到file所有block的locations信息，详情请看BlockLocations类</span></span><br><span class="line">      BlockLocation[] blkLocations;</span><br><span class="line">      <span class="keyword">if</span> (file <span class="keyword">instanceof</span> LocatedFileStatus) &#123;</span><br><span class="line">        blkLocations = ((LocatedFileStatus) file).getBlockLocations();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        FileSystem fs = path.getFileSystem(job.getConfiguration());</span><br><span class="line">        blkLocations = fs.getFileBlockLocations(file, <span class="number">0</span>, length);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 判断是否可以切分，压缩文件不能切分</span></span><br><span class="line">      <span class="keyword">if</span> (isSplitable(job, path)) &#123;</span><br><span class="line">      	<span class="comment">// 得到当前file的block大小</span></span><br><span class="line">        <span class="keyword">long</span> blockSize = file.getBlockSize();</span><br><span class="line">        <span class="comment">// 计算切分值 max(minSize, min(blockSize,maxSize))</span></span><br><span class="line">        <span class="comment">// 出与对MR的优化，minSize配置的一般都等于blockSize或者是blockSize的整数倍</span></span><br><span class="line">        <span class="comment">// 如果大blockSize，会有别的block通过网络传输到map节点，造成网络压力</span></span><br><span class="line">        <span class="keyword">long</span> splitSize = computeSplitSize(blockSize, minSize, maxSize);</span><br><span class="line">        <span class="comment">// 循环切分，这里有个小优化，在大数据中避免出现小文件，</span></span><br><span class="line">        <span class="comment">// 将最后剩下一个比splitSize稍微大一点不再进行切分，</span></span><br><span class="line">        <span class="comment">// 因为SPLIT_SLOP = 1.1，而不是 1</span></span><br><span class="line">        <span class="keyword">long</span> bytesRemaining = length;</span><br><span class="line">        <span class="keyword">while</span> (((<span class="keyword">double</span>) bytesRemaining)/splitSize &gt; SPLIT_SLOP) &#123;</span><br><span class="line">          <span class="comment">// 根据偏移量length-bytesRemaining，在blkLocations中找到偏移量所在block的index</span></span><br><span class="line">          <span class="comment">// 这里只是起始block的index，该split可能包含多个block</span></span><br><span class="line">          <span class="comment">// length为1100，block为128，splitSize为500，则第一个split的index为0，第二个则是4</span></span><br><span class="line">          <span class="keyword">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class="line">          <span class="comment">// 将文件的切分信息通过makeSplit写入FileSplit对象中</span></span><br><span class="line">          <span class="comment">// 只是将当前blkIndex的block的相关信息放入FileSplit中</span></span><br><span class="line">          splits.add(makeSplit(path, length-bytesRemaining, splitSize,</span><br><span class="line">                      blkLocations[blkIndex].getHosts(),</span><br><span class="line">                      blkLocations[blkIndex].getCachedHosts()));</span><br><span class="line">          bytesRemaining -= splitSize;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (bytesRemaining != <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">int</span> blkIndex = getBlockIndex(blkLocations, length-bytesRemaining);</span><br><span class="line">          splits.add(makeSplit(path, length-bytesRemaining, bytesRemaining,</span><br><span class="line">                     blkLocations[blkIndex].getHosts(),</span><br><span class="line">                     blkLocations[blkIndex].getCachedHosts()));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123; <span class="comment">// not splitable</span></span><br><span class="line">        splits.add(makeSplit(path, <span class="number">0</span>, length, blkLocations[<span class="number">0</span>].getHosts(),</span><br><span class="line">                    blkLocations[<span class="number">0</span>].getCachedHosts()));</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; </span><br><span class="line">      <span class="comment">//Create empty hosts array for zero length files</span></span><br><span class="line">      splits.add(makeSplit(path, <span class="number">0</span>, length, <span class="keyword">new</span> String[<span class="number">0</span>]));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Save the number of input files for metrics/loadgen</span></span><br><span class="line">  job.getConfiguration().setLong(NUM_INPUT_FILES, files.size());</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> splits;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getSplits主要是将files的进行切片，将文件路径path、偏移量(即起始位置，是该split在整个文件中的起始位置)、切分大小splitSize、偏移量所在block的locations信息Host和在内存中的host信息写入<code>FileSplit</code>对象中，一个split对应一个对象，最后放入splits中返回。</p>
<p>其它详细信息已在代码中进行注释，<strong>这里需要注意的是由于splitSize可能大于blockSize，则切分的split可能有多个block组成，代码中得到的blockIndex只是偏移量所在block的index，而记录在FileSplit中的Hosts信息也只是偏移量所在block的副本所在hosts</strong>。</p>
<p>writeNewSplits中input.getSplits将files进行切分放入list中，然后将list转换为array，对array中的元素根据长度进行逆序排序。最后调用<code>JobSplitWriter.createSplitFiles</code>将保存切分信息的array落地到文件，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T extends InputSplit&gt; <span class="function"><span class="keyword">void</span> <span class="title">createSplitFiles</span><span class="params">(Path jobSubmitDir, </span></span></span><br><span class="line"><span class="function"><span class="params">    Configuration conf, FileSystem fs, T[] splits)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">// 通过createFile创建分片文件并获取文件系统数据输出流FSDataOutputStream实例out，</span></span><br><span class="line">  FSDataOutputStream out = createFile(fs, </span><br><span class="line">      JobSubmissionFiles.getJobSplitFile(jobSubmitDir), conf);</span><br><span class="line">  <span class="comment">// 将分片数据FileSplit对象写入分片文件，并返回split的元数据</span></span><br><span class="line">  SplitMetaInfo[] info = writeNewSplits(conf, splits, out);</span><br><span class="line">  out.close();</span><br><span class="line">  <span class="comment">// 将split的元数据写入分片元数据文件中</span></span><br><span class="line">  writeJobSplitMetaInfo(fs,JobSubmissionFiles.getJobSplitMetaFile(jobSubmitDir), </span><br><span class="line">      <span class="keyword">new</span> FsPermission(JobSubmissionFiles.JOB_FILE_PERMISSION), splitVersion,</span><br><span class="line">      info);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>createSplitFiles创建的文件包括两个，分别是记录切片的切片文件和记录切片元数据的切片元数据文件，这两个文件分别记录的是什么内容继续分析代码。</p>
<p>先看下<code>createFile</code>，该方法通过<code>JobSubmissionFiles.getJobSplitFile(jobSubmitDir)</code>得到切片文件的路径，根据其路径创建一个数据输出流<code>FileSystem.create</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> FSDataOutputStream <span class="title">createFile</span><span class="params">(FileSystem fs, Path splitFile, </span></span></span><br><span class="line"><span class="function"><span class="params">    Configuration job)</span>  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 根据jobSubmitDir/job.split的路径创建数据输出流</span></span><br><span class="line">  FSDataOutputStream out = FileSystem.create(fs, splitFile, </span><br><span class="line">      <span class="keyword">new</span> FsPermission(JobSubmissionFiles.JOB_FILE_PERMISSION));</span><br><span class="line">  <span class="comment">// 设置切片文件的副本数，默认是10</span></span><br><span class="line">  <span class="keyword">int</span> replication = job.getInt(Job.SUBMIT_REPLICATION, <span class="number">10</span>);</span><br><span class="line">  fs.setReplication(splitFile, (<span class="keyword">short</span>)replication);</span><br><span class="line">  <span class="comment">// 将切片文件的头信息写入切片文件中</span></span><br><span class="line">  <span class="comment">// 头信息为 SPLIT_FILE_HEADER(值为SPL) 和 splitVersion(值为JobSplit.META_SPLIT_VERSION  1)</span></span><br><span class="line">  writeSplitHeader(out);</span><br><span class="line">  <span class="keyword">return</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将数据输出流返回，接着调用<code>writeNewSplits</code>将split数据写入切片文件(<em>job.split</em>)中，并返回切片的元数据信息，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> &lt;T extends InputSplit&gt; </span><br><span class="line">SplitMetaInfo[] writeNewSplits(Configuration conf, </span><br><span class="line">    T[] array, FSDataOutputStream out)</span><br><span class="line"><span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">  <span class="comment">// new 出用于存放元数据信息的数组</span></span><br><span class="line">  SplitMetaInfo[] info = <span class="keyword">new</span> SplitMetaInfo[array.length];</span><br><span class="line">  <span class="keyword">if</span> (array.length != <span class="number">0</span>) &#123;</span><br><span class="line">    SerializationFactory factory = <span class="keyword">new</span> SerializationFactory(conf);</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// mapreduce.job.max.split.locations</span></span><br><span class="line">    <span class="comment">// 该split中多个block副本所在的host个数不能超过该值</span></span><br><span class="line">    <span class="keyword">int</span> maxBlockLocations = conf.getInt(MRConfig.MAX_BLOCK_LOCATIONS_KEY,</span><br><span class="line">        MRConfig.MAX_BLOCK_LOCATIONS_DEFAULT);</span><br><span class="line">    <span class="keyword">long</span> offset = out.getPos();</span><br><span class="line">    <span class="keyword">for</span>(T split: array) &#123;</span><br><span class="line">      <span class="keyword">long</span> prevCount = out.getPos();</span><br><span class="line">      <span class="comment">// 将split的类名 这里就是FileSplit写入job.split文件中</span></span><br><span class="line">      Text.writeString(out, split.getClass().getName());</span><br><span class="line">      Serializer&lt;T&gt; serializer = </span><br><span class="line">        factory.getSerializer((Class&lt;T&gt;) split.getClass());</span><br><span class="line">      serializer.open(out);</span><br><span class="line">      <span class="comment">// 将split数据序列化写入job.split中</span></span><br><span class="line">      serializer.serialize(split);</span><br><span class="line">      <span class="keyword">long</span> currCount = out.getPos();</span><br><span class="line">      <span class="comment">// 此处得到的locations只是offset所在block的locations？</span></span><br><span class="line">      <span class="comment">// 应该拿到的是job.split中数据的position</span></span><br><span class="line">      <span class="comment">// 加入该split有多个block组成，其余block的location在哪合并的？</span></span><br><span class="line">      String[] locations = split.getLocations();</span><br><span class="line">      <span class="keyword">if</span> (locations.length &gt; maxBlockLocations) &#123;</span><br><span class="line">        LOG.warn(<span class="string">"Max block location exceeded for split: "</span></span><br><span class="line">            + split + <span class="string">" splitsize: "</span> + locations.length +</span><br><span class="line">            <span class="string">" maxsize: "</span> + maxBlockLocations);</span><br><span class="line">        locations = Arrays.copyOf(locations, maxBlockLocations);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 将split元数据信息写入SplitMetaInfo的数组中</span></span><br><span class="line">      <span class="comment">// 元数据包括locations、offset和length</span></span><br><span class="line">      info[i++] = </span><br><span class="line">        <span class="keyword">new</span> JobSplit.SplitMetaInfo( </span><br><span class="line">            locations, offset,</span><br><span class="line">            split.getLength());</span><br><span class="line">      offset += currCount - prevCount;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> info;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从代码中得知job.split文件中的内容为头信息(<em>SPLIT_FILE_HEADER</em> 值为SPL 和 <em>splitVersion</em> 值为JobSplit.META_SPLIT_VERSION  1)和若干个split数据，split数据为split类名+FileSplit对象序列化后的内容。</p>
<p>写入job.split之后将split元数据信息返回，继续调用<code>writeJobSplitMetaInfo</code>将元数据信息写入job.splitmetainfo中。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">writeJobSplitMetaInfo</span><span class="params">(FileSystem fs, Path filename, </span></span></span><br><span class="line"><span class="function"><span class="params">    FsPermission p, <span class="keyword">int</span> splitMetaInfoVersion, </span></span></span><br><span class="line"><span class="function"><span class="params">    JobSplit.SplitMetaInfo[] allSplitMetaInfo)</span> </span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// write the splits meta-info to a file for the job tracker</span></span><br><span class="line">  <span class="comment">// 通过JobSubmissionFiles.getJobSplitMetaFile得到元数据的文件路径job.splitmetainfo</span></span><br><span class="line">  <span class="comment">// 打开数据输出流</span></span><br><span class="line">  FSDataOutputStream out = </span><br><span class="line">    FileSystem.create(fs, filename, p);</span><br><span class="line">  <span class="comment">// 将头信息写入 "META-SPL"</span></span><br><span class="line">  out.write(JobSplit.META_SPLIT_FILE_HEADER);</span><br><span class="line">  <span class="comment">// 和job.split一个版本号</span></span><br><span class="line">  WritableUtils.writeVInt(out, splitMetaInfoVersion);</span><br><span class="line">  <span class="comment">// split元数据的个数也就是split分片的个数</span></span><br><span class="line">  WritableUtils.writeVInt(out, allSplitMetaInfo.length);</span><br><span class="line">  <span class="comment">// 将元数据信息SplitMetaInfo对象写入</span></span><br><span class="line">  <span class="keyword">for</span> (JobSplit.SplitMetaInfo splitMetaInfo : allSplitMetaInfo) &#123;</span><br><span class="line">    splitMetaInfo.write(out);</span><br><span class="line">  &#125;</span><br><span class="line">  out.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>split元数据信息写入job.splitmetainfo，数据格式为头信息(<em>META_SPLIT_FILE_HEADER</em> 值为META-SPL、版本号1)、元数据个数和元数据SplitMetaInfo对象。</p>
<p>文件切分完之后，就是启动task进行处理，也就是job的切分，下面看下job切分。</p>
<h2 id="job切分"><a href="#job切分" class="headerlink" title="job切分"></a>job切分</h2><p>MR切分的代码在JobImpl.java中，首先由事件<code>JobEventType.JOB_INIT</code>触发调用<code>InitTransition.transition</code>对job进行init(<em>对于yarn的事件调用和状态转换可以看<a href="http://bigdatadecode.club/YARN源码分析之AsyncDispatcher事件调度器.html">AsyncDispatcher事件调度器</a>和<a href="http://bigdatadecode.club/YARN源码分析之StateMachineFactory状态机.html">StateMachineFactory状态机</a>这两篇文章</em>)，transition调用createSplits对job进行切分，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> TaskSplitMetaInfo[] createSplits(JobImpl job, JobId jobId) &#123;</span><br><span class="line">  TaskSplitMetaInfo[] allTaskSplitMetaInfo;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// 读取split的job.split和job.splitmetainfo进行切分</span></span><br><span class="line">    allTaskSplitMetaInfo = SplitMetaInfoReader.readSplitMetaInfo(</span><br><span class="line">        job.oldJobId, job.fs, </span><br><span class="line">        job.conf, </span><br><span class="line">        job.remoteJobSubmitDir);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(e);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> allTaskSplitMetaInfo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过SplitMetaInfoReader.readSplitMetaInfo读取split的切片信息，对job进行切分，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> JobSplit.TaskSplitMetaInfo[] readSplitMetaInfo(</span><br><span class="line">    JobID jobId, FileSystem fs, Configuration conf, Path jobSubmitDir) </span><br><span class="line"><span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="keyword">long</span> maxMetaInfoSize = conf.getLong(MRJobConfig.SPLIT_METAINFO_MAXSIZE,</span><br><span class="line">      MRJobConfig.DEFAULT_SPLIT_METAINFO_MAXSIZE);</span><br><span class="line">  <span class="comment">// 得到job.splitmetainfo和job.split的路径</span></span><br><span class="line">  Path metaSplitFile = JobSubmissionFiles.getJobSplitMetaFile(jobSubmitDir);</span><br><span class="line">  String jobSplitFile = JobSubmissionFiles.getJobSplitFile(jobSubmitDir).toString();</span><br><span class="line">  FileStatus fStatus = fs.getFileStatus(metaSplitFile);</span><br><span class="line">  <span class="keyword">if</span> (maxMetaInfoSize &gt; <span class="number">0</span> &amp;&amp; fStatus.getLen() &gt; maxMetaInfoSize) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Split metadata size exceeded "</span> +</span><br><span class="line">        maxMetaInfoSize +<span class="string">". Aborting job "</span> + jobId);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 打开job.splitmetainfo的读取数据流</span></span><br><span class="line">  FSDataInputStream in = fs.open(metaSplitFile);</span><br><span class="line">  <span class="keyword">byte</span>[] header = <span class="keyword">new</span> <span class="keyword">byte</span>[JobSplit.META_SPLIT_FILE_HEADER.length];</span><br><span class="line">  <span class="comment">// 读取头文件</span></span><br><span class="line">  in.readFully(header);</span><br><span class="line">  <span class="keyword">if</span> (!Arrays.equals(JobSplit.META_SPLIT_FILE_HEADER, header)) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Invalid header on split file"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 版本号</span></span><br><span class="line">  <span class="keyword">int</span> vers = WritableUtils.readVInt(in);</span><br><span class="line">  <span class="keyword">if</span> (vers != JobSplit.META_SPLIT_VERSION) &#123;</span><br><span class="line">    in.close();</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unsupported split version "</span> + vers);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 切片的个数</span></span><br><span class="line">  <span class="keyword">int</span> numSplits = WritableUtils.readVInt(in); <span class="comment">//<span class="doctag">TODO:</span> check for insane values</span></span><br><span class="line">  JobSplit.TaskSplitMetaInfo[] allSplitMetaInfo = </span><br><span class="line">    <span class="keyword">new</span> JobSplit.TaskSplitMetaInfo[numSplits];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numSplits; i++) &#123;</span><br><span class="line">    JobSplit.SplitMetaInfo splitMetaInfo = <span class="keyword">new</span> JobSplit.SplitMetaInfo();</span><br><span class="line">    <span class="comment">// 切片的元数据信息</span></span><br><span class="line">    splitMetaInfo.readFields(in);</span><br><span class="line">    <span class="comment">// 根据元数据和split数据信息对job进行切分</span></span><br><span class="line">    JobSplit.TaskSplitIndex splitIndex = <span class="keyword">new</span> JobSplit.TaskSplitIndex(</span><br><span class="line">        jobSplitFile, </span><br><span class="line">        splitMetaInfo.getStartOffset());</span><br><span class="line">    <span class="comment">// 将切分之后的task元数据放入数组</span></span><br><span class="line">    allSplitMetaInfo[i] = <span class="keyword">new</span> JobSplit.TaskSplitMetaInfo(splitIndex, </span><br><span class="line">        splitMetaInfo.getLocations(), </span><br><span class="line">        splitMetaInfo.getInputDataLength());</span><br><span class="line">  &#125;</span><br><span class="line">  in.close();</span><br><span class="line">  <span class="keyword">return</span> allSplitMetaInfo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将切分之后的tasks返回，在transtion中调用</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">createMapTasks(job, inputLength, taskSplitMetaInfo);</span><br><span class="line">createReduceTasks(job);</span><br></pre></td></tr></table></figure>
<p>进行task的创建，先看下createMapTasks的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">createMapTasks</span><span class="params">(JobImpl job, <span class="keyword">long</span> inputLength,</span></span></span><br><span class="line"><span class="function"><span class="params">                            TaskSplitMetaInfo[] splits)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; job.numMapTasks; ++i) &#123;</span><br><span class="line">  	<span class="comment">// 根据task的元数据信息进行TaskImpl的实例化</span></span><br><span class="line">    TaskImpl task =</span><br><span class="line">        <span class="keyword">new</span> MapTaskImpl(job.jobId, i,</span><br><span class="line">            job.eventHandler, </span><br><span class="line">            job.remoteJobConfFile, </span><br><span class="line">            job.conf, splits[i], </span><br><span class="line">            job.taskAttemptListener, </span><br><span class="line">            job.jobToken, job.jobCredentials,</span><br><span class="line">            job.clock,</span><br><span class="line">            job.applicationAttemptId.getAttemptId(),</span><br><span class="line">            job.metrics, job.appContext);</span><br><span class="line">    <span class="comment">// 将task信息保存到jobImpl中</span></span><br><span class="line">    job.addTask(task);</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.info(<span class="string">"Input size for job "</span> + job.jobId + <span class="string">" = "</span> + inputLength</span><br><span class="line">      + <span class="string">". Number of splits = "</span> + splits.length);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>addTask的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">addTask</span><span class="params">(Task task)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (tasksSyncHandle) &#123;</span><br><span class="line">    <span class="keyword">if</span> (lazyTasksCopyNeeded) &#123;</span><br><span class="line">      Map&lt;TaskId, Task&gt; newTasks = <span class="keyword">new</span> LinkedHashMap&lt;TaskId, Task&gt;();</span><br><span class="line">      newTasks.putAll(tasks);</span><br><span class="line">      tasks = newTasks;</span><br><span class="line">      lazyTasksCopyNeeded = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将task和taskID作为映射放入tasks的map中</span></span><br><span class="line">  tasks.put(task.getID(), task);</span><br><span class="line">  <span class="comment">// 将taskID放入set中</span></span><br><span class="line">  <span class="keyword">if</span> (task.getType() == TaskType.MAP) &#123;</span><br><span class="line">    mapTasks.add(task.getID());</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (task.getType() == TaskType.REDUCE) &#123;</span><br><span class="line">    reduceTasks.add(task.getID());</span><br><span class="line">  &#125;</span><br><span class="line">  metrics.waitingTask(task);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>将task切分好之后就是等待调度了，代码为<code>job.scheduleTasks(job.mapTasks, job.numReduceTasks == 0);</code>，这个也是由事件触发的，这里就不展开了，随后可能会单独介绍。</p>
<!-- 
## 疑惑
可以设置“mapred.min.split.size”参数，使得Split的大小大于一个Block，这时候FileInputFormat会将连续的若干个Block分在一个Split中、也可能会将一个Block分别划在不同的Split中（但是前提是一个Split必须在一个文件中）。Split的Start、Length都好说，都是划分前就定好的。而Split的Location就需要对所有划在其中的Block的Location进行整合，尽量寻找它们共有的Location。而这些Block很可能并没有共同的Location，那么就需要找一个距离这些Block最近的Location作为Split的Location。   

*代码在哪？？？？  切入点   TaskImpl task = new MapTaskImpl*
-->]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce </tag>
            
            <tag> JobSplit </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mac/linux下自动输入密码登录服务器/跳板机脚本]]></title>
      <url>http://bigdatadecode.club/mac%E4%B8%8B%E8%87%AA%E5%8A%A8%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81%E7%99%BB%E5%BD%95%E8%B7%B3%E6%9D%BF%E6%9C%BA%E8%84%9A%E6%9C%AC.html</url>
      <content type="html"><![CDATA[<p>用win时，有xshell之类的工具帮你记录服务器或者跳板机的密码，但到mac/linux上时虽然也有这样的软件，但mac本身就有终端，再用这样软件使用shell，感觉不太舒服(我有个怪癖，就是电脑能不装的软件决不安装)。于是就想自己写个脚本实现这样的功能。</p>
<p>那就开始干吧，这里自己给自己埋了个坑，那就是当初在win上生成rsa时，输入了密码，结果在mac上执行ssh-add添加密钥时需要输入密码，这就使脚本不太自动化，需要手动输入密码。<br>于是只能求助google了，发现了expect，于是就把脚本升级了下，内容如下：</p>
<blockquote>
<p>没有expect则利用brew安装，命令<code>brew install expect</code></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/expect</span></span><br><span class="line"></span><br><span class="line">spawn ssh -A -p port username@ip</span><br><span class="line"></span><br><span class="line">expect &#123;</span><br><span class="line">    <span class="string">"*?ermission denied"</span> &#123;</span><br><span class="line">        <span class="built_in">set</span> password <span class="string">"生成rsa时的密码"</span></span><br><span class="line">        spawn ssh-add /Users/hadoop/.ssh/id_rsa_2048</span><br><span class="line">        expect <span class="string">"passphrase"</span></span><br><span class="line">        send <span class="string">"<span class="variable">$password</span>\n"</span></span><br><span class="line">        interact</span><br><span class="line">        spawn ssh -A -p port username@ip</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="string">"*?ast login*"</span> &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">interact</span><br></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> mac/linux </tag>
            
            <tag> 自动输入密码 </tag>
            
            <tag> ssh脚本 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[hive outer join 之谓词下放]]></title>
      <url>http://bigdatadecode.club/hive%20outer%20join%20%E4%B9%8B%E8%B0%93%E8%AF%8D%E4%B8%8B%E6%94%BE.html</url>
      <content type="html"><![CDATA[<p>join是sql中常用的关键字，同样在hive中，join语句也经常被用到，尤其是一些outer join语句，但在使用这样outer join语句时，不小心就会踩到坑里，使结果与预期的不一样，或者使sql执行不够高效。</p>
<p>这里就详细介绍下hive outer join。</p>
<p>下面先看几个概念：</p>
<ul>
<li>保留表(Preserved Row table)</li>
</ul>
<p>在outer join中需要<em>返回所有数据的表</em>叫做保留表，也就是说在left outer join中，左表需要返回所有数据，则左表是保留表；right outer join中右表则是保留表；在full outer join中左表和右表都要返回所有数据，则左右表都是保留表。</p>
<ul>
<li>Null Supplying table(这个怎么翻译？ 支持null的表？？？？)</li>
</ul>
<p>在outer join中对于没有匹配到的行需要用null来填充的表称为Null Supplying table。在left outer join中，左表的数据全返回，对于左表在右表中无法匹配的数据的相应列用null表示，则此时右表是Null Supplying table，相应的如果是right outer join的话，左表是Null Supplying table。<em>但是在full outer join中左表和右表都是Null Supplying table</em>，因为左表和右表都会用null来填充无法匹配的数据。</p>
<blockquote>
<p>此时你会发现full outer join就是个矛盾体，因为此时的左表和右表即使保留表又是Null Supplying table，这就导致在outer join中谓词下放时有一些问题。 </p>
</blockquote>
<ul>
<li>Join中的谓词 </li>
</ul>
<p>Join中的谓词是指 Join On语句中的谓词。如：’R1 join R2 on R1.x = 5’ the predicate ‘R1.x = 5’是Join中的谓词</p>
<ul>
<li>Join之后的谓词</li>
</ul>
<p>where语句中的谓词称之为Join之后的谓词</p>
<a id="more"></a>
<p><strong>最好使用子查询的方式进行join</strong></p>
<h2 id="谓词下放"><a href="#谓词下放" class="headerlink" title="谓词下放"></a>谓词下放</h2><blockquote>
<p>谓词：谓词是一个属性或是一个表示“持有”或“不持有”的表达式，换句话说，也就是取值为 TRUE、FALSE 或 UNKNOWN 的表达式。谓词用于 WHERE 子句和 HAVING 子句的搜索条件中，还用于 FROM 子句的联接条件以及需要布尔值的其他构造中。</p>
</blockquote>
<p>对于outer join中的坑，主要是对谓词下放的规则不熟悉，导致理解的不够全面，造成一些坑。<br>谓词下放的规则有两个，分别为</p>
<ol>
<li>Join中谓词如果是保留表的，则不会下放。</li>
<li>Join之后的谓词如果是Null Supplying tables的，则不会下放。</li>
</ol>
<p>下面来看写例子来加深理解。</p>
<h2 id="栗子"><a href="#栗子" class="headerlink" title="栗子"></a>栗子</h2><blockquote>
<p>创建两个表</p>
</blockquote>
<p>create table t1 (id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY “,”;<br>create table t2 (id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY “,”;</p>
<p>t1里的数据如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1,a</span><br><span class="line">1,b</span><br><span class="line">2,a</span><br><span class="line">2,b</span><br><span class="line">3,a</span><br><span class="line">3,b</span><br><span class="line">4,b</span><br></pre></td></tr></table></figure>
<p>t2里的数据如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1,aa</span><br><span class="line">4,dd</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在执行例子之前，避免map join影响到各个例子的执行计划，先关闭map join，<code>set hive.auto.convert.join=false;</code></p>
</blockquote>
<ul>
<li>case 1，sql如下：<br><code>select t1.*,t2.name as name_t2 from t1 left outer join t2 on (t1.id=t2.id) where t1.name=&#39;a&#39; and t2.name=&#39;aa&#39;;</code><br>此sql中，保留表为t1，Null Supplying table为t2，join中谓词在此sql中没有，where中的两个谓词都是join之后的谓词。<br>则根据谓词下放规则，<code>t1.name=&#39;a&#39;</code>是保留表的字段，则被下放，而<code>t2.name=&#39;aa&#39;</code>是Null Supplying table的，Null Supplying table不支持join之后的谓词下放。<br>那么此时的sql就等同于</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> t.*,t2.name <span class="keyword">as</span> name_t2 </span><br><span class="line"><span class="keyword">from</span> (</span><br><span class="line">	<span class="keyword">select</span> <span class="keyword">id</span>, <span class="keyword">name</span> <span class="keyword">from</span> t1 <span class="keyword">where</span> t1.name=<span class="string">'a'</span></span><br><span class="line">) <span class="keyword">as</span> t <span class="keyword">left</span> <span class="keyword">outer</span> <span class="keyword">join</span> t2 <span class="keyword">on</span></span><br><span class="line">(t.id=t2.id) <span class="keyword">where</span> t2.name=<span class="string">'aa'</span>;</span><br></pre></td></tr></table></figure>
<p>其<strong>结果</strong>为<code>1 a aa</code>，<strong>可能你的期望结果是</strong></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	a	aa</span><br><span class="line">2	a	NULL</span><br><span class="line">3	a	NULL</span><br></pre></td></tr></table></figure>
<p>造成这样的结果是因为hive中outer join谓词下放的规则。<br>case1 sql中的<code>t2.name=&#39;aa&#39;</code>是join之后的谓词，不会被下放到t2中(t2是Null Supplying table)，而是对<em>t1和t2 join的结果</em>进行filter，filter的条件是<code>t2.name=&#39;aa&#39;</code>，于是就出现了<code>1 a aa</code>结果，因为其余数据的t2.name的值都为NULL。</p>
<p>现在来解析下case1的执行过程。<br>首先sql中有两个<em>join之后的谓词</em>，分别为<code>t1.name=&#39;a&#39; and t2.name=&#39;aa&#39;</code>，其中t1.name是保留表t1的，会谓词下放，在scan t1表时，对t1中的数据进行过滤，t2.name是t2的，<em>t2不是保留表，谓词无法下放</em>，而where又是在join之后执行的(<strong>Joins occur BEFORE WHERE CLAUSES</strong>)。看下sql的执行计划：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t1</span><br><span class="line">            Statistics: Num rows: 5 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate: (name = <span class="string">'a'</span>) (<span class="built_in">type</span>: boolean)</span><br><span class="line">              Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">                sort order: +</span><br><span class="line">                Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">                Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t2</span><br><span class="line">            Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Reduce Output Operator</span><br><span class="line">              key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">              sort order: +</span><br><span class="line">              Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">      Reduce Operator Tree:</span><br><span class="line">        Join Operator</span><br><span class="line">          condition map:</span><br><span class="line">               Left Outer Join0 to 1</span><br><span class="line">          keys:</span><br><span class="line">            0 id (<span class="built_in">type</span>: int)</span><br><span class="line">            1 id (<span class="built_in">type</span>: int)</span><br><span class="line">          outputColumnNames: _col0, _col6</span><br><span class="line">          Statistics: Num rows: 2 Data size: 12 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">          Filter Operator</span><br><span class="line">            predicate: (_col6 = <span class="string">'aa'</span>) (<span class="built_in">type</span>: boolean)</span><br><span class="line">            Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Select Operator</span><br><span class="line">              expressions: _col0 (<span class="built_in">type</span>: int), <span class="string">'a'</span> (<span class="built_in">type</span>: string), <span class="string">'aa'</span> (<span class="built_in">type</span>: string)</span><br><span class="line">              outputColumnNames: _col0, _col1, _col2</span><br><span class="line">              Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              File Output Operator</span><br><span class="line">                compressed: <span class="literal">false</span></span><br><span class="line">                Statistics: Num rows: 1 Data size: 6 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">                table:</span><br><span class="line">                    input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      <span class="built_in">limit</span>: -1</span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>
<p>从sql的执行计划上也可以看出，TableScan t1时使用了<code>predicate: (name = &#39;a&#39;) (type: boolean)</code>对数据进行过滤，(则进入mr的t1数据不是全表数据，而是过滤过的数据)。而where对应的filter operator是在join之后才执行的。</p>
<ul>
<li>case 2，sql如下：<br><code>select t1.*,t2.name as name_t2 from t1 left outer join t2 on (t1.id=t2.id and t2.name=&#39;aa&#39;) where t1.name=&#39;a&#39;;</code><br>执行结果为</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	a	aa</span><br><span class="line">2	a	NULL</span><br><span class="line">3	a	NULL</span><br></pre></td></tr></table></figure>
<p>其中t2.name是join中谓词，t1.name是join之后谓词，根据规则join中谓词能下放到t2中，join之后的谓词能下放到t1中，则上面sql的意思是将t1中name为a的数据与t2中name为aa的数据进行join，<em>t1和t2都会在table scan时进行数据过滤</em>。sql的执行计划如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t1</span><br><span class="line">            Statistics: Num rows: 5 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate: (name = <span class="string">'a'</span>) (<span class="built_in">type</span>: boolean)</span><br><span class="line">              Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">                sort order: +</span><br><span class="line">                Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">                Statistics: Num rows: 2 Data size: 11 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t2</span><br><span class="line">            Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate: (name = <span class="string">'aa'</span>) (<span class="built_in">type</span>: boolean)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">                sort order: +</span><br><span class="line">                Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">                Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">                value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">      Reduce Operator Tree:</span><br><span class="line">        Join Operator</span><br><span class="line">          condition map:</span><br><span class="line">               Left Outer Join0 to 1</span><br><span class="line">          keys:</span><br><span class="line">            0 id (<span class="built_in">type</span>: int)</span><br><span class="line">            1 id (<span class="built_in">type</span>: int)</span><br><span class="line">          outputColumnNames: _col0, _col6</span><br><span class="line">          Statistics: Num rows: 2 Data size: 12 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">          Select Operator</span><br><span class="line">            expressions: _col0 (<span class="built_in">type</span>: int), <span class="string">'a'</span> (<span class="built_in">type</span>: string), _col6 (<span class="built_in">type</span>: string)</span><br><span class="line">            outputColumnNames: _col0, _col1, _col2</span><br><span class="line">            Statistics: Num rows: 2 Data size: 12 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            File Output Operator</span><br><span class="line">              compressed: <span class="literal">false</span></span><br><span class="line">              Statistics: Num rows: 2 Data size: 12 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              table:</span><br><span class="line">                  input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      <span class="built_in">limit</span>: -1</span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>
<p>从执行计划上可以看出t1和t2的TableScan中都存在Filter Operator操作，对数据进行过滤。</p>
<ul>
<li>case 3，sql如下：<br><code>select t1.*,t2.name as name_t2 from t1 left outer join t2 on (t1.id=t2.id and t1.name=&#39;a&#39; ) where t2.name=&#39;aa&#39;;</code><br>此sql中有两个谓词，一个是join中谓词<code>t1.name=&#39;a&#39;</code>和join之后谓词<code>t2.name=&#39;aa&#39;</code>。<br>这里需要明白一点，<strong>join中谓词决定了进行join的数据，join之后谓词决定了最终要呈现的数据</strong>。也就是说join中谓词<code>t1.name=&#39;a&#39;</code>决定了t1表中name为a的数据才去和t2进行join，而join之后谓词<code>t2.name=&#39;aa&#39;</code>决定了最终的结果。<br>执行结果为：<code>1    a    aa</code>。</li>
</ul>
<p>这里的结果随便和case 1的结果一样，但是执行的内部逻辑是不一样的，case3在执行where filter之前返回的数据是t1全表的数据，而case1在执行where filter之前返回的数据是t1中name为a的数据，因为case3中join中谓词<code>t1.name=&#39;a&#39;</code>并不能对t1进行下放，这里的语义是<em>对t1进行全表扫描，只拿name为a的数据和t2进行join，id匹配成功则为t2.name的值，匹配不成功和name不为a的数据中t2.name的值都为NULL</em>，join结束之后由where filter过滤<code>t2.name=&#39;aa&#39;</code>，因此就出现了上面的结果(因为没有匹配成功的和没有进行匹配的数据都是NULL，被过滤)。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t1</span><br><span class="line">            Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Reduce Output Operator</span><br><span class="line">              key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">              sort order: +</span><br><span class="line">              Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t2</span><br><span class="line">            Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Reduce Output Operator</span><br><span class="line">              key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">              sort order: +</span><br><span class="line">              Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">      Reduce Operator Tree:</span><br><span class="line">        Join Operator</span><br><span class="line">          condition map:</span><br><span class="line">               Left Outer Join0 to 1</span><br><span class="line">          filter predicates:</span><br><span class="line">            0 &#123;(VALUE._col0 = <span class="string">'a'</span>)&#125;</span><br><span class="line">            1</span><br><span class="line">          keys:</span><br><span class="line">            0 id (<span class="built_in">type</span>: int)</span><br><span class="line">            1 id (<span class="built_in">type</span>: int)</span><br><span class="line">          outputColumnNames: _col0, _col1, _col6</span><br><span class="line">          Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">          Filter Operator</span><br><span class="line">            predicate: (_col6 = <span class="string">'aa'</span>) (<span class="built_in">type</span>: boolean)</span><br><span class="line">            Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Select Operator</span><br><span class="line">              expressions: _col0 (<span class="built_in">type</span>: int), _col1 (<span class="built_in">type</span>: string), <span class="string">'aa'</span> (<span class="built_in">type</span>: string)</span><br><span class="line">              outputColumnNames: _col0, _col1, _col2</span><br><span class="line">              Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              File Output Operator</span><br><span class="line">                compressed: <span class="literal">false</span></span><br><span class="line">                Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">                table:</span><br><span class="line">                    input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      <span class="built_in">limit</span>: -1</span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>
<p>上面是case3的执行计划，可以看出两个表在TableScan时都是全表扫描，没有进行filter，在join时有个filter<code>filter predicates</code>，join结束之后又有个<code>Filter Operator</code>对join的结果进行过滤。</p>
<ul>
<li>case 4，sql如下:<br><code>select t1.*,t2.name as name_t2 from t1 left outer join t2 on (t1.id=t2.id and t1.name=&#39;a&#39; and t2.name=&#39;aa&#39;);</code><br>此sql中只有join中谓词，根据规则t1.name=’a’不能下放到t1中，而t2.name=’aa’能够下放到t2中，那就是说扫t1的全表数据，然后拿t1.name为a的数据去和t2中t2.name为aa的数据(t2在table scan时会过滤name为aa的数据)进行join，那么t1中name不为a的数据不和t2进行join，直接将t2.name置为NULL，而t1中name为a却没有和t2进行join成功的数据也为NULL，所以其结果如下：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	b	NULL</span><br><span class="line">1	a	aa</span><br><span class="line">2	b	NULL</span><br><span class="line">2	a	NULL</span><br><span class="line">3	b	NULL</span><br><span class="line">3	a	NULL</span><br><span class="line">4	b	NULL</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这里需要说明下，t1是保留表，join之后要返回其表中所有的数据，因为在join之后没有where对其结果进行过滤，所以此处显示的是t1表的所有数据，上面的case之所以没有返回t1的所有数据是因为他们要么在table scan时进行了过滤要么就是在join之后通过where进行了过滤。  </p>
</blockquote>
<p>为了验证下t1中只有那么为a的数据与t2进行了join，我对t2中的数据进行了修改，添加一条数据<code>4,aa</code>，其执行结果按照上面的逻辑应该不会发生变化，再次执行case4，看下返回的结果是否一致。其结果如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1	b	NULL</span><br><span class="line">1	a	aa</span><br><span class="line">2	b	NULL</span><br><span class="line">2	a	NULL</span><br><span class="line">3	b	NULL</span><br><span class="line">3	a	NULL</span><br><span class="line">4	b	NULL</span><br></pre></td></tr></table></figure>
<p>与上面的结果一致。<br>此sql的执行计划如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">STAGE DEPENDENCIES:</span><br><span class="line">  Stage-1 is a root stage</span><br><span class="line">  Stage-0 depends on stages: Stage-1</span><br><span class="line"></span><br><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t1</span><br><span class="line">            Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Reduce Output Operator</span><br><span class="line">              key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">              sort order: +</span><br><span class="line">              Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t2</span><br><span class="line">            Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Filter Operator</span><br><span class="line">              predicate: (name = <span class="string">'aa'</span>) (<span class="built_in">type</span>: boolean)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              Reduce Output Operator</span><br><span class="line">                key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">                sort order: +</span><br><span class="line">                Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">                Statistics: Num rows: 1 Data size: 10 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">                value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">      Reduce Operator Tree:</span><br><span class="line">        Join Operator</span><br><span class="line">          condition map:</span><br><span class="line">               Left Outer Join0 to 1</span><br><span class="line">          filter predicates:</span><br><span class="line">            0 &#123;(VALUE._col0 = <span class="string">'a'</span>)&#125;</span><br><span class="line">            1</span><br><span class="line">          keys:</span><br><span class="line">            0 id (<span class="built_in">type</span>: int)</span><br><span class="line">            1 id (<span class="built_in">type</span>: int)</span><br><span class="line">          outputColumnNames: _col0, _col1, _col6</span><br><span class="line">          Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">          Select Operator</span><br><span class="line">            expressions: _col0 (<span class="built_in">type</span>: int), _col1 (<span class="built_in">type</span>: string), _col6 (<span class="built_in">type</span>: string)</span><br><span class="line">            outputColumnNames: _col0, _col1, _col2</span><br><span class="line">            Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            File Output Operator</span><br><span class="line">              compressed: <span class="literal">false</span></span><br><span class="line">              Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              table:</span><br><span class="line">                  input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      <span class="built_in">limit</span>: -1</span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>
<p>这四个case介绍了left outer join的情况，right outer join与left类似，只是保留表和Null Supplying table换下位置，比较特殊的是<strong>full outer join</strong>，在full outer join中join中谓词和join之后谓词都不会被下放，(<strong>这里说不会下放可能不太准备，会下放，但是下放的位置不对，下放前和下放后的位置是一样的，开启log可以查看。</strong>)</p>
<p>下放前的与下放后的结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TS[0]-RS[2]-JOIN[4]-FIL[5]-SEL[6]-FS[7]</span><br><span class="line">TS[1]-RS[3]-JOIN[4]</span><br><span class="line"></span><br><span class="line">TS[0]-RS[2]-JOIN[4]-FIL[8]-SEL[6]-FS[7]</span><br><span class="line">TS[1]-RS[3]-JOIN[4]</span><br></pre></td></tr></table></figure>
<p>因为full outer join中的两个表既是保留表也是Null Supplying table。来看个full outer join的例子，<br><code>select t1.*,t2.name as name_t2 from t1 full outer join t2 on (t1.id=t2.id and t2.name=&#39;aa&#39;) where t1.name=&#39;a&#39;;</code><br>其结果为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1	a	aa</span><br><span class="line">2	a	NULL</span><br><span class="line">3	a	NULL</span><br></pre></td></tr></table></figure>
<!--
select t1.*,t2.name as name_t2 from t1 full outer join t2 on (t1.id=t2.id and t2.name='aa')
1    b    aa
1    a    aa
2    b    NULL
2    a    NULL
3    b    NULL
3    a    NULL
4    b    aa
NULL    NULL    dd
-->
<p>其sql的执行计划如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">STAGE PLANS:</span><br><span class="line">  Stage: Stage-1</span><br><span class="line">    Map Reduce</span><br><span class="line">      Map Operator Tree:</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t1</span><br><span class="line">            Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Reduce Output Operator</span><br><span class="line">              key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">              sort order: +</span><br><span class="line">              Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 28 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">          TableScan</span><br><span class="line">            <span class="built_in">alias</span>: t2</span><br><span class="line">            Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Reduce Output Operator</span><br><span class="line">              key expressions: id (<span class="built_in">type</span>: int)</span><br><span class="line">              sort order: +</span><br><span class="line">              Map-reduce partition columns: id (<span class="built_in">type</span>: int)</span><br><span class="line">              Statistics: Num rows: 1 Data size: 15 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              value expressions: name (<span class="built_in">type</span>: string)</span><br><span class="line">      Reduce Operator Tree:</span><br><span class="line">        Join Operator</span><br><span class="line">          condition map:</span><br><span class="line">               Outer Join 0 to 1</span><br><span class="line">          filter predicates:</span><br><span class="line">            0</span><br><span class="line">            1 &#123;(VALUE._col0 = <span class="string">'aa'</span>)&#125;</span><br><span class="line">          keys:</span><br><span class="line">            0 id (<span class="built_in">type</span>: int)</span><br><span class="line">            1 id (<span class="built_in">type</span>: int)</span><br><span class="line">          outputColumnNames: _col0, _col1, _col6</span><br><span class="line">          Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">          Filter Operator</span><br><span class="line">            predicate: (_col1 = <span class="string">'a'</span>) (<span class="built_in">type</span>: boolean)</span><br><span class="line">            Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">            Select Operator</span><br><span class="line">              expressions: _col0 (<span class="built_in">type</span>: int), <span class="string">'a'</span> (<span class="built_in">type</span>: string), _col6 (<span class="built_in">type</span>: string)</span><br><span class="line">              outputColumnNames: _col0, _col1, _col2</span><br><span class="line">              Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">              File Output Operator</span><br><span class="line">                compressed: <span class="literal">false</span></span><br><span class="line">                Statistics: Num rows: 1 Data size: 30 Basic stats: COMPLETE Column stats: NONE</span><br><span class="line">                table:</span><br><span class="line">                    input format: org.apache.hadoop.mapred.TextInputFormat</span><br><span class="line">                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat</span><br><span class="line">                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span><br><span class="line"></span><br><span class="line">  Stage: Stage-0</span><br><span class="line">    Fetch Operator</span><br><span class="line">      <span class="built_in">limit</span>: -1</span><br><span class="line">      Processor Tree:</span><br><span class="line">        ListSink</span><br></pre></td></tr></table></figure>
<p>从执行计划中可以看出t1和t2在scan时都没有进行filter过滤，也就是说join中谓词和join之后的谓词都没有进行下放，join中谓词是在<code>Join Operator</code>时通过<code>filter predicates</code>进行过滤join，而join之后谓词是在join之后通过<code>Filter Operator</code>进行过滤的。</p>
<p>如果t1和t2某个表是分区表，此时想只full outer join某个分区的数据，应该怎么过滤更高效呢？<br>此时应该使用子查询，sql为<code>select t1.*,t2.name as name_t2 from t1 full outer join t2 on (t1.id=t2.id and t2.name=&#39;aa&#39;)</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> t.*,t2.name <span class="keyword">as</span> name_t2 </span><br><span class="line"><span class="keyword">from</span></span><br><span class="line">    （<span class="keyword">select</span> * <span class="keyword">from</span> t1 <span class="keyword">where</span> <span class="keyword">day</span>=<span class="string">'20170411'</span>) t</span><br><span class="line">     <span class="keyword">full</span> <span class="keyword">outer</span> <span class="keyword">join</span>  t2</span><br><span class="line">     <span class="keyword">on</span> t.id=t2.id</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这篇文章其实想说的有两点，</p>
<ol>
<li>outer join中谓词的下放规则</li>
<li>join on和where的区别，以及执行顺序</li>
</ol>
<p>根据上面的四个case总结下outer join中谓词的下放规则<br>|  | 保留表 | Null Supplying table |<br>|———-|———-|——–|<br>| join中谓词 | case3和case4不下放 | case2和case4下放 |<br>| join之后谓词 | case1和case2下放 | case1和case3不下放 |</p>
<p>join on和where的区别是join on决定的是什么数据去进行join操作，符合条件的数据才会进行join，不符合条件的数据直接赋值为NULL，而where是对join之后的结果进行过滤，决定最终展示的内容。<br>where中的谓词如果没有被下放则在join之后执行。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://cwiki.apache.org/confluence/display/Hive/OuterJoinBehavior#OuterJoinBehavior-Examples" target="_blank" rel="noopener">Hive Outer Join Behavior</a><br><a href="https://community.mapr.com/docs/DOC-1193" target="_blank" rel="noopener">Understanding Hive Outer Join Behavior</a></p>
<h2 id="附加"><a href="#附加" class="headerlink" title="附加"></a>附加</h2><p>hive开启debug的方式：</p>
<ol>
<li>启动hive cli时，执行<code>hive --hiveconf hive.root.logger=DEBUG,console</code></li>
<li>修改hive的log4j文件，在${HIVE_HOME}/conf/hive-log4j.properties文件中找到hive.root.logger属性，并将其修改为<code>hive.root.logger=DEBUG,console</code></li>
</ol>
]]></content>
      
        <categories>
            
            <category> Hive </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hive </tag>
            
            <tag> outer join </tag>
            
            <tag> PredicatePushDown </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[mac下编译Hadoop]]></title>
      <url>http://bigdatadecode.club/mac%E4%B8%8B%E7%BC%96%E8%AF%91Hadoop.html</url>
      <content type="html"><![CDATA[<p>以前都是win下装个centos虚拟机编译hadoop，最近换了Mac，不用再装虚拟机了，直接编译Hadoop，很爽。但需要配置下hadoop的编译环境。在此记录下。</p>
<a id="more"></a>
<blockquote>
<p>findbugs安装</p>
</blockquote>
<p>下载findbugs-3.0.1.tar.gz，解压<code>tar -zvxf findbugs-3.0.1.tar.gz</code>，配置环境变量。<br>在<code>.bash_profile</code>中添加<code>FINDBUGS_HOME</code>，并export</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FINDBUGS_HOME=/Users/hadoop/soft/findbugs-3.0.1</span><br><span class="line">PATH=<span class="variable">$FINDBUGS_HOME</span>/bin</span><br><span class="line"><span class="built_in">export</span> FINDBUGS_HOME</span><br></pre></td></tr></table></figure>
<blockquote>
<p>protobuf安装</p>
</blockquote>
<p>安装protobuf之前验证下是否有gcc，命令<code>gcc --version</code><br>进入protobuf-2.5.0目录执行<code>./configure --prefix=/Users/hadoop/soft/protobuf-2.5.0</code><br>然后安装就可以了，命令<code>make &amp;&amp; make install</code><br>为了使用protoc命令方便，将bin目录添加到<code>.bash_porfile</code>中<br><code>PATH=/Users/hadoop/soft/protobuf-2.5.0/bin</code></p>
<blockquote>
<p>cmake安装</p>
</blockquote>
<p>解压cmake-3.0.0，进入目录中，执行<code>./bootstrap --prefix=/Users/hadoop/soft/cmake-3.0.0</code>进行编译<br>执行<code>make &amp;&amp; make install</code>进行<br>为了使用cmake命令方便，将bin目录添加到<code>.bash_porfile</code>中<br><code>PATH=/Users/hadoop/soft/cmake-3.0.0/bin</code></p>
<p>mac环境中由于已经安装了xcode-select则，不用额外安装zlib-devel</p>
<blockquote>
<p>openssl-devel安装</p>
</blockquote>
<p>这个在mac上没有这个依赖包，只是装了openssl，但是编译不过去，报错，内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (make) on project hadoop-pipes: An Ant BuildException has occured: <span class="built_in">exec</span> returned: 1</span><br><span class="line">[ERROR] around Ant part ...&lt;<span class="built_in">exec</span> dir=<span class="string">"/Users/hadoop/bigdata/hadoop-2.6.0-src-eclipse/hadoop-tools/hadoop-pipes/target/native"</span> executable=<span class="string">"cmake"</span> failonerror=<span class="string">"true"</span>&gt;... @ 5:141 <span class="keyword">in</span> /Users/hadoop/bigdata/hadoop-2.6.0-src-eclipse/hadoop-tools/hadoop-pipes/target/antrun/build-main.xml</span><br></pre></td></tr></table></figure>
<p>网上大部分都说是缺少openssl-devel依赖包，但苦逼的是mac上没有此依赖包，然后就下载了openssl源码进行自编译安装吧，可是就是编译不过去，下载了各个版本的openssl就是无法编译成功。然后看error信息，貌似是和ant和cmake有关，hadoop现在的版本已经不用ant了呀，而且contos上的编译环境也没有ant呀，难道是cmake的原因？首先想到cmake版本问题，换了个新版也不成功，最后快要绝望时搜到了<a href="http://stackoverflow.com/questions/36818957/mac-hadoop-2-7-failed-to-execute-goal-org-apache-maven-pluginsmaven-antrun" target="_blank" rel="noopener">一篇文章</a></p>
<p><em>上面说可以去build-main.xml中查看具体出错的行，用cmake单独执行下，看报什么错</em></p>
<p>当我执行<code>cmake /Users/hadoop/bigdata/hadoop-2.6.0-src-eclipse/hadoop-tools/hadoop-pipes/src/ -DJVM_ARCH_DATA_MODEL = 64</code>时，错误信息显示出来了，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Could NOT find OpenSSL, try to <span class="built_in">set</span> the path to OpenSSL root folder <span class="keyword">in</span> the System variable OPENSSL_ROOT_DIR (missing: OPENSSL_INCLUDE_DIR), suggesting that not found openssl suggested that the need to add environment variables</span><br></pre></td></tr></table></figure>
<p>然后我就按照文章中介绍的将<code>OPENSSL_INCLUDE_DIR</code>和<code>OPENSSL_ROOT_DIR</code>export出，再次编译就成功了。</p>
<p>由于我并不知道mac默认的openssl的安装目录，所以我使用<code>brew install openssl</code>重新安装了下，安装成功会提示openssl的安装目录</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">brew install openssl</span><br><span class="line">==&gt; Downloading https://homebrew.bintray.com/bottles/openssl-1.0.2k.sierra.bottle.tar.gz</span><br><span class="line">Already downloaded: /Users/netease/Library/Caches/Homebrew/openssl-1.0.2k.sierra.bottle.tar.gz</span><br><span class="line">==&gt; Pouring openssl-1.0.2k.sierra.bottle.tar.gz</span><br><span class="line">==&gt; Using the sandbox</span><br><span class="line">==&gt; Caveats</span><br><span class="line">A CA file has been bootstrapped using certificates from the SystemRoots</span><br><span class="line">keychain. To add additional certificates (e.g. the certificates added <span class="keyword">in</span></span><br><span class="line">the System keychain), place .pem files <span class="keyword">in</span></span><br><span class="line">  /usr/<span class="built_in">local</span>/etc/openssl/certs</span><br><span class="line"></span><br><span class="line">and run</span><br><span class="line">  /usr/<span class="built_in">local</span>/opt/openssl/bin/c_rehash</span><br><span class="line"></span><br><span class="line">This formula is keg-only, <span class="built_in">which</span> means it was not symlinked into /usr/<span class="built_in">local</span>.</span><br><span class="line"></span><br><span class="line">Apple has deprecated use of OpenSSL <span class="keyword">in</span> favor of its own TLS and crypto libraries</span><br><span class="line"></span><br><span class="line">If you need to have this software first <span class="keyword">in</span> your PATH run:</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">'export PATH="/usr/local/opt/openssl/bin:$PATH"'</span> &gt;&gt; ~/.zshrc</span><br><span class="line"></span><br><span class="line">For compilers to find this software you may need to <span class="built_in">set</span>:</span><br><span class="line">    LDFLAGS:  -L/usr/<span class="built_in">local</span>/opt/openssl/lib</span><br><span class="line">    CPPFLAGS: -I/usr/<span class="built_in">local</span>/opt/openssl/include</span><br><span class="line">For pkg-config to find this software you may need to <span class="built_in">set</span>:</span><br><span class="line">    PKG_CONFIG_PATH: /usr/<span class="built_in">local</span>/opt/openssl/lib/pkgconfig</span><br><span class="line"></span><br><span class="line">==&gt; Summary</span><br><span class="line">🍺  /usr/<span class="built_in">local</span>/Cellar/openssl/1.0.2k: 1,696 files, 12MB</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">If you need to have this software first <span class="keyword">in</span> your PATH run:</span><br><span class="line">  <span class="built_in">echo</span> <span class="string">'export PATH="/usr/local/opt/openssl/bin:$PATH"'</span> &gt;&gt; ~/.zshrc</span><br></pre></td></tr></table></figure>
<!--
export OPENSSL_ROOT_DIR=/usr/local/Cellar/openssl/1.0.2k
export OPENSSL_INCLUDE_DIR=/usr/local/Cellar/openssl/1.0.2k/include
-->
<blockquote>
<p>编译hadoop</p>
</blockquote>
<p>所需的依赖组件都安装好之后就可以正确的编译hadoop了，在hadoop_home目录下执行命令<br><code>mvn clean package -DskipTests -Pdist,native -Dtar  -X</code></p>
<p>这里还有个小插曲，就是会报个找不类的错，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Exception <span class="keyword">in</span> thread “main” Java.lang.AssertionError: Missing tools.jar at: /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home/Classes/classes.jar. Expression: file.exists()</span><br></pre></td></tr></table></figure>
<p>解决办法就是在JAVA_HOME，也即/Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home路径下<em>新建目录Class</em>，并执行创建软符号链接命令：<br><code>sudo ln -s $JAVA_HOME/lib/tools.jar $JAVA_HOME/Classes/classes.jar</code></p>
<!--
编译2.6时删除了一个类

Exception in thread "main" java.lang.AssertionError: Missing tools.jar at: /Library/Java/JavaVirtualMachines/jdk1.7.0_80.jdk/Contents/Home/Classes/classes.jar. Expression: file.exists()
-->]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> build </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ganglia部署监控flume]]></title>
      <url>http://bigdatadecode.club/ganglia%E9%83%A8%E7%BD%B2%E7%9B%91%E6%8E%A7flume.html</url>
      <content type="html"><![CDATA[<p>debian环境下编译部署ganglia，用于监控flume。</p>
<h2 id="ganglia编译部署"><a href="#ganglia编译部署" class="headerlink" title="ganglia编译部署"></a>ganglia编译部署</h2><p>ganglia主要包括gmond和gmeta，</p>
<ul>
<li>gmond用于收集监测数据，可以发送也可以接收在同一个组播或单播通道上的统计信息。gmond有两个角色，一个是发送者，另一个是接收者。当<code>mute=no</code>时，gmond是发送者，会收集本节点上的基本指标，比如系统负载(load_one)、cpu和memory利用率等，也可以发送用户通过添加C/Python模块来自定义的指标。当<code>deaf=no</code>是接收者，主要用来聚合所有从别的节点上发来的指标(如flume agent发来的metrics信息)，并把他们都保存在内存缓冲区中。<em>gmond节点之间通过UDP收集数据，gmetad通过TCP从gmond节点获取数据</em></li>
<li>gmeta定期检查gmond，拉取gmond上的数据，并将他们的指标存储在RRD存储引擎中。</li>
</ul>
<p>除此之外还有个web组件用于显示监控图，ganglia-web(或者ganglia-webfrontend)</p>
<p>下面开始编译ganglia，官网上gmond、gmeta和ganglia-web是分开的两个安装包。ganglia中只包括gmond和gmeta。</p>
<a id="more"></a>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p><code>apt-get install make gawk gcc g++ pkg-config python-libxml2 libcogl-pango-dev python-dev libxml2-dev libxslt-dev libaprutil1-dev libpcre* libconfuse*</code><br>可能不全，但也差不多。</p>
<p>上面的依赖包都安装之后还需要<em>confuse</em>和<em>rrdtool</em>，这两个需要编译安装，所以单独说明下。</p>
<p>安装confuse</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.savannah.gnu.org/releases/confuse/confuse-2.7.tar.gz</span><br><span class="line">tar -zxvf confuse-2.7.tar.gz </span><br><span class="line"><span class="built_in">cd</span> confuse-2.7 </span><br><span class="line">./configure CFLAGS=-fPIC --<span class="built_in">disable</span>-nls --prefix=/home/hadoop/confuse-2.7</span><br><span class="line">make &amp;&amp; make install     <span class="comment">#root用户执行</span></span><br></pre></td></tr></table></figure>
<p>安装rrdtool</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wget http://oss.oetiker.ch/rrdtool/pub/rrdtool-1.6.0.tar.gz</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>   <span class="comment"># 貌似安装到别的目录，需要将bin下的命令加到环境变量中，否则后面编译ganglia会报错</span></span><br><span class="line">make &amp;&amp; make install     <span class="comment">#root用户执行</span></span><br></pre></td></tr></table></figure>
<p>依赖安装完毕，进入<code>ganglia-3.7.2.tar.gz</code>的解压目录中，执行编译命令</p>
<p><code>./configure --prefix=/usr/local/ganglia --with-gmetad --with-librrd=/usr/local/lib --sysconfdir=/etc/ganglia --enable-gexec --enable-status</code></p>
<p><code>--prefix</code>用于指定ganglia编译之后的目录，<code>--with-gmetad</code>包含gmeta组件，<code>--with-librrd=/usr/local/lib</code>包含rrd数据库，<code>--sysconfdir=/etc/ganglia</code>将gmeta和gmond的配置文件放在此目录。</p>
<p>成功之后就可以执行<code>make &amp;&amp; make install</code>安装ganglia了。</p>
<blockquote>
<p>还需要安装<code>apt-get install ganglia-modules-linux ganglia-monitor ganglia-monitor-python ganglia-webfrontend libganglia1 libganglia1-dev</code>，要不然无法收集机器的基础属性，也不能正常显示图片(<em>ganglia-webfrontend不安装无法正常显示图片</em>)。</p>
</blockquote>
<p>下面来编译ganglia-web，其实下载的<code>ganglia-web-3.7.2.tar.gz</code>已经是编译好的，直接执行安装命令(<em>make &amp;&amp; make install</em>)就行了。但是ganglia-web需要依赖apache作为服务器，则还需要安装依赖<code>apt-get install apache2.2-bin apache2.2-common apache2 libapache2-mod-php5 php5</code><br><!--mini-httpd--></p>
<blockquote>
<p>这里也可以对ganglia-web的安装目录进行稍许的配置，配置在<em>Makefile</em>中</p>
</blockquote>
<p>主要改的配置选项如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Location where gweb should be installed to (excluding conf, dwoo dirs).</span></span><br><span class="line"><span class="comment"># web页面文件，需要放在apache web文件夹里</span></span><br><span class="line">GDESTDIR = /usr/share/ganglia-webfrontend</span><br><span class="line"></span><br><span class="line"><span class="comment"># Location where default apache configuration should be installed to.</span></span><br><span class="line">GCONFDIR = /etc/ganglia-web</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gweb statedir (where conf dir and Dwoo templates dir are stored)</span></span><br><span class="line">GWEB_STATEDIR = /var/lib/ganglia-web</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gmetad rootdir (parent location of rrd folder)</span></span><br><span class="line">GMETAD_ROOTDIR = /var/lib/ganglia</span><br></pre></td></tr></table></figure>
<p>上面的目录配置的有点散，可以对其进行修改，使其便于管理，修改如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">GDESTDIR = /var/lib/ganglia/web</span><br><span class="line"></span><br><span class="line"><span class="comment"># Location where default apache configuration should be installed to.</span></span><br><span class="line">GCONFDIR = /var/lib/ganglia/etc/</span><br><span class="line"><span class="comment">#GCONFDIR = /etc/ganglia-web</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Gweb statedir (where conf dir and Dwoo templates dir are stored)</span></span><br><span class="line">GWEB_STATEDIR = var/lib/ganglia</span><br><span class="line"></span><br><span class="line"><span class="comment"># Gmetad rootdir (parent location of rrd folder)</span></span><br><span class="line">GMETAD_ROOTDIR = /var/lib/ganglia</span><br><span class="line"><span class="comment"># 可改可不改，默认是www-data</span></span><br><span class="line">APACHE_USER = hadoop_portal</span><br></pre></td></tr></table></figure>
<p>之所以选择<code>/var/lib/ganglia</code>这个目录，是因为<em>rrd</em>在此目录中。<strong>如果你用的版本和我一样，可能会遇到个小bug，将GDESTDIR和GWEB_STATEDIR路径中的第一个/去掉</strong></p>
<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>部署比较简单，修改两个配置文件就行，分别是gmond.conf和gmeta.conf，在目录<code>/etc/ganglia</code>(此路径是在编译ganglia时指定的)中。</p>
<p>gmeta.conf中只需添加数据源和gmod节点就可以了，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 说明：这里的 "flume" 表示的是集群的名称，与gmod中的cluster名字一样，后面的内容是这个集群中所包含的主机信息，也就是要监控的主机ip</span></span><br><span class="line"><span class="comment"># 这里采用单播方式，则只有一个节点，并配上端口，如果不指定端口，默认是8649</span></span><br><span class="line">data_source <span class="string">"flume"</span> 127.0.0.1:8666</span><br><span class="line"><span class="comment"># 由于setuid默认是开启的，而setuid_username默认是nobody，可能会遇到权限问题，则改为启动用户hadoop</span></span><br><span class="line">setuid_username <span class="string">"hadoop"</span></span><br></pre></td></tr></table></figure>
<p>启动之前需要改下rrd所在目录的权限，改为启动gmeta的用户，命令<code>chown -R hadoop:hadoop /var/lib/ganglia</code>(如果rrds目录不存在，则新建/var/lib/ganglia/rrds目录)</p>
<p>现在就可以启动gmeta了，命令<code>/usr/local/ganglia/sbin/gmetad start</code>。(/usr/local/ganglia/是在编译时由–prefix=指定的)</p>
<p>然后通过<code>ps -ef | grep gm</code>查看是否有gmeta进程，如果没有就代表没有启动成功，可以使用<code>gmetad --debug=4</code>(或者gmeta debug=10 log message)进来debug启动。</p>
<p>gmond.conf文件修改</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">globals &#123;</span><br><span class="line">  daemonize = yes</span><br><span class="line">  setuid = yes</span><br><span class="line">  <span class="comment"># 与gmeta中setuid_username相同，启动gmond的用户</span></span><br><span class="line">  user = hadoop</span><br><span class="line">  debug_level = 0</span><br><span class="line">  max_udp_msg_len = 1472</span><br><span class="line">  <span class="comment"># 发送者开关</span></span><br><span class="line">  mute = no</span><br><span class="line">  <span class="comment"># 接收者开关</span></span><br><span class="line">  deaf = no</span><br><span class="line">  host_dmax = 0 /*secs */</span><br><span class="line">  cleanup_threshold = 300 /*secs */</span><br><span class="line">  gexec = no</span><br><span class="line">  send_metadata_interval = 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cluster &#123;</span><br><span class="line">  <span class="comment"># gmeta中data_source中的cluster名字</span></span><br><span class="line">  name = <span class="string">"flume"</span></span><br><span class="line">  owner = <span class="string">"unspecified"</span></span><br><span class="line">  latlong = <span class="string">"unspecified"</span></span><br><span class="line">  url = <span class="string">"unspecified"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">#发送者channel</span></span><br><span class="line"><span class="comment"># 如果不用监视本节点基础指标则不用配置，并设置mute为yes</span></span><br><span class="line">udp_send_channel &#123;</span><br><span class="line">  <span class="comment"># 多播方式</span></span><br><span class="line">  /*mcast_join = 239.2.11.71 */</span><br><span class="line">  host = 127.0.0.1</span><br><span class="line">  port = 8666</span><br><span class="line">  ttl = 1</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 接收者channel</span></span><br><span class="line">udp_recv_channel &#123;</span><br><span class="line">  /* mcast_join = 239.2.11.71 */</span><br><span class="line">  port = 8666</span><br><span class="line">  <span class="built_in">bind</span> = 127.0.0.1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tcp_accept_channel &#123;</span><br><span class="line">  port = 8666</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>启动gmond，命令<code>/usr/local/ganglia/sbin/gmond start</code>，没有启动则用上面介绍的debug模式启动，查找错误原因。</p>
<p>最后就是启动ganglia-web，这个比较简单，只需要将<em>GDESTDIR</em>所指定的目录放到<code>/var/www</code>目录中就可以了。我在这建了个软连<code>cd /var/www/ &amp;&amp; ln -s /usr/share/ganglia-webfrontend ganglia</code></p>
<p>启动apache就可以访问了，apache启动命令<code>apache2ctl -k start</code><br><!-- 查看apache监听哪个端口 netstat -lnp |grep apache --></p>
<p>输入<code>127.0.0.1/ganglia</code>就可以查看监控指标了。</p>
<p>如果服务器在本地不能访问，可以使用<code>telnet localhost 8651</code>来验证下gmeta是否成功(gmeta默认是8651端口)。</p>
<blockquote>
<p>更改Apache的默认端口</p>
</blockquote>
<p>在debian系统下apache默认安装目录是<code>/etc/apache2/</code><br>更改默认端口需要修改两个配置文件，分别为<code>/etc/apache2/ports.conf</code>和<code>/etc/apache2/sites-available/default</code></p>
<p>更改内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#ports.conf</span></span><br><span class="line">NameVirtualHost *:8001</span><br><span class="line">Listen 8001</span><br><span class="line"><span class="comment">#default</span></span><br><span class="line">VirtualHost *:8001</span><br></pre></td></tr></table></figure>
<p>然后重启就ok了。可以使用命令<code>netstat -lnp |grep apache</code>查看配置是否生效。显示内容如下则表示生效<br><code>tcp6       0      0 :::8001                 :::*                    LISTEN      8647/apache2</code></p>
<!--
### 防火墙转接口
要外网可以访问还需要给防火墙开个80端口，
/sbin/iptables -L --line-number
iptables -I net2fw 15 -p tcp --dport 80 -j ACCEPT
iptables-save
iptables restart
-->
<h2 id="flume-监控"><a href="#flume-监控" class="headerlink" title="flume 监控"></a>flume 监控</h2><p>使用ganglia监控flume较为简单，只要在启动agent时指定ganglia中gmond的地址和端口就ok了，命令如下：<br><code>/bin/bash ${FLUME_PATH}/bin/flume-ng agent -n a1 -c ${FLUME_PATH}/conf -f ${FLUME_PATH}/conf/flume.conf -Dflume.monitoring.type=ganglia -Dflume.monitoring.hosts=127.0.0.1:8666 &amp;</code></p>
]]></content>
      
        <categories>
            
            <category> Flume </category>
            
        </categories>
        
        
        <tags>
            
            <tag> Flume </tag>
            
            <tag> ganglia </tag>
            
            <tag> debian </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[单例模式引发的思考]]></title>
      <url>http://bigdatadecode.club/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%E5%BC%95%E5%8F%91%E7%9A%84%E6%80%9D%E8%80%83.html</url>
      <content type="html"><![CDATA[<p>单例是个老生常谈的话题，有很多种写法，每一种写起来代码都比较简单，但是每一种背后蕴含的知识可谓是一层套一层，套路很深呀。。。</p>
<p>本篇主要是记录下我对单例的理解。</p>
<p>熟悉单例的人都知道单例一般会有五种写法，分别为<em>懒汉法(线程非安全)、线程安全的懒汉法、饿汉法、内部类法和枚举法</em>。</p>
<a id="more"></a>
<h2 id="饿汉法"><a href="#饿汉法" class="headerlink" title="饿汉法"></a>饿汉法</h2><p>先说个intellij idea中单例模板代码(饿汉法)：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonStatic</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> SingletonStatic singletonStatic = <span class="keyword">new</span> SingletonStatic();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonStatic <span class="title">getSingletonThink</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> singletonStatic;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SingletonStatic</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"construct function"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>IDE中推荐的是饿汉法，代码是不是很简单。别看代码简单，但功能齐全，此代码是<strong>线程安全</strong>的。</p>
<blockquote>
<p>线程安全是什么？<br>线程安全是指在多线程中，当多条语句在操作同一个线程的共享数据时，一个线程对多条语句只执行了一部分，还没执行完，另一个线程参与进来执行，导致共享数据出错。<br>解决方法：保证多条共享数据的语句，在一个线程完全执行完之前，其他线程不参与执行过程，也就是加锁或者叫同步。</p>
</blockquote>
<p>此方式的线程安全是依赖<strong>类的加载和初始化</strong>实现的。</p>
<blockquote>
<p>类加载与初始化<br><strong>一个类在JVM中被实例化成一个对象，需要经历三个过程：加载、链接和初始化</strong>。</p>
</blockquote>
<ul>
<li>_加载_  类在jvm中的加载都是<em>动态加载</em>的，在被<em>首次调用</em>时加载到jvm中，由类加载器将<code>.class</code>文件加载jvm中。</li>
<li>_链接_  链接简单地说，就是将已经加载的<code>.class</code>组合到JVM运行状态中去。包括<em>验证、准备和解析</em></li>
<li><em>初始化</em>  执行类的static块和初始化类内部的静态属性(<strong>static块和静态属性是按照声明的顺序初始化的，且仅执行一次</strong>)，然后是类内部属性，最后是类构造方法。</li>
</ul>
<!-- 类实例化的对象通过new操作创建，Java虚拟机保证一个类在new操作实例化其对象之前已经完成了类的加载、链接和初始化。之后Java虚拟机会调用<init>方法完成类实例化对象的初始化。这个方法会优先按照代码中顺序完成对类内部个属性的初始化，之后再调用类的构造函数（如果有父类，则优先调用父类的构造函数）。 -->
<p>明白了类的加载和初始化再看上面的代码是不是感觉有点感觉了。</p>
<p>当<code>SingletonStatic.getSingletonThink()</code>在jvm中被第一次调用时，<code>SingletonStatic.class</code>被加载到jvm中，然后进行初始化，由于<code>singletonStatic</code>是静态属性，则先被初始化，此时singletonStatic就被实例化，通过getSingletonThink返回。</p>
<p>在多线程中，假如thread1调用<code>SingletonStatic.getSingletonThink()</code>，在其未返回时，thread2也调用<code>SingletonStatic.getSingletonThink()</code>，此时，因为thread1先调用<code>SingletonStatic</code>，被加载到jvm中，初始化之后<code>singletonStatic</code>被实例化，此刻thread2也调用<code>SingletonStatic.getSingletonThink()</code>，jvm发现<code>SingletonStatic</code>已被加载，并且<code>singletonStatic</code>是静态属性，只能被初始化一次并且已在thread1调用时被初始化，则thread2调用时并不会对singletonStatic进行再次初始化，thread1和thread2使用的singletonStatic对象都是同一个，所以线程安全。</p>
<p>代码验证如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainThread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Thread thread1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName());</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                   SingletonStatic.getSingletonThink(Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Thread thread2 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName());</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                   SingletonStatic.getSingletonThink(Thread.currentThread().getName());</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        thread1.start();</span><br><span class="line">        thread2.start();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>执行结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Thread-1</span><br><span class="line">Thread-0</span><br><span class="line">construct <span class="keyword">function</span></span><br><span class="line">Thread-1 invoke</span><br><span class="line">Thread-0 invoke</span><br></pre></td></tr></table></figure>
<p>其结果显示构造方法只被调用了一次，也就是说singletonStatic被初始化了一次。</p>
<h2 id="懒汉式"><a href="#懒汉式" class="headerlink" title="懒汉式"></a>懒汉式</h2><p>上面的代码短小精悍，但其是饿汉式的，单例singletonStatic会在加载SingletonStatic类一开始就被初始化，即使客户端没有调用getSingletonThink()方法，也会被初始化，这就有点不太高效。其实我们是想在用的时候才加载，下面就说下懒汉式。</p>
<p>懒汉式代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonLazy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> SingletonLazy singletonLazy ;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SingletonLazy</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"construct function"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonLazy <span class="title">getSingletonLazy</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (singletonLazy == <span class="keyword">null</span>)&#123;</span><br><span class="line">           singletonLazy = <span class="keyword">new</span> SingletonLazy();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> singletonLazy;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码也挺短的啊。饿汉式是线程安全的，那我们也来个多线程来测试下，它是否安全。测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MainThread</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Thread thread1 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName());</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                   SingletonLazy.getSingletonLazy();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        Thread thread2 = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName());</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                   SingletonLazy.getSingletonLazy();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                    e.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        thread1.start();</span><br><span class="line">        thread2.start();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Thread-0</span><br><span class="line">Thread-1</span><br><span class="line">construct <span class="keyword">function</span></span><br><span class="line">construct <span class="keyword">function</span></span><br></pre></td></tr></table></figure>
<p>构造方法被调用了两次，非线程安全。那么可以加锁来实现线程安全。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonLazy</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> SingletonLazy singletonLazy ;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SingletonLazy</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"construct function"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonLazy <span class="title">getSingletonLazy</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (SingletonLazy.class)&#123;</span><br><span class="line">            <span class="keyword">if</span> (singletonLazy == <span class="keyword">null</span>)&#123;</span><br><span class="line">                singletonLazy = <span class="keyword">new</span> SingletonLazy();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> singletonLazy;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样能保证线程安全，但是在每次调用<code>getSingletonLazy</code>时，都会加个锁去判断singletonLazy是否为null，有点不高效呀。</p>
<p>你说每次判断是否为null都加锁，不高效，那就把synchronized放到if里面，这样就不用每次多加锁去判断是否为null了，但是这样并不是线程安全的，有可能thread1和thread2同时判断singletonLazy为null，然后分别对singletonLazy进行实例化。</p>
<p>还有一种方法是在synchronized外面再加个if判断语句，这样每次判断singletonLazy是否为null就不用加锁了，而且当thread1和thread2同时判断singletonLazy为null，而进去最外层的if语句时，当thread1拿到锁之后，会再次判断此时singletonLazy是否依然为null，为null则进行实例化，待singletonLazy实例化之后，释放锁，thread2拿到锁，判断singletonLazy是否为null，singletonLazy已在thread1中被实例化，非null，则在thread2中不会进行实例化，所以线程安全了。此种方法也叫<strong>双重校验锁</strong>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonLazy <span class="title">getSingletonLazy</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (singletonLazy == <span class="keyword">null</span>)&#123;</span><br><span class="line">       <span class="keyword">synchronized</span> (SingletonLazy.class)&#123;</span><br><span class="line">           <span class="keyword">if</span> (singletonLazy == <span class="keyword">null</span>)&#123;</span><br><span class="line">               singletonLazy = <span class="keyword">new</span> SingletonLazy();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> singletonLazy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时就万事大吉了吗？非也！</p>
<p><code>singletonLazy = new SingletonLazy();</code>这句语义并不是一个原子操作，大概包括3件事，分别为：</p>
<ol>
<li>给singletonLazy分配内存</li>
<li>调用singletonLazy的构造函数来初始化成员变量</li>
<li>将singletonLazy对象指向分配的内存空间(<em>执行完这步singletonLazy就为非null了</em>)</li>
</ol>
<p>但是在JVM的即时编译器中存在<strong>指令重排序</strong>的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是1-2-3也可能是1-3-2。如果是后者，则thread1在3执行完毕、2 未执行之前，被thread2抢占了，这时singletonLazy已经是非null了(但却没有初始化)，所以thread2会直接返回singletonLazy，然后使用，但此时singletonLazy并没有被初始化成功，不能正常使用。</p>
<p>可以在声明singletonLazy静态变量时，使用<code>volatile</code>关键字，volatile是一个轻量的synchronized，具有两重语义，第一是<strong>可见性</strong>，是指共享变量被修改之后，立马会从本地缓存中写入主内存，以对其它线程可见。第二是<strong>禁止指令重排序优化</strong>。(<em>这里其实有点以偏概全的意思，当对volatile写时，无论前面的操作是什么，都不能重排序，有的场景中是可以重排序的，具体在这里就不展开了，只是对volatile的写时，前面的代码禁止重排序。</em>)这里使用的就是第二种语义，禁止重排序。</p>
<blockquote>
<p>线程安全懒汉式需要注意的几点：</p>
</blockquote>
<ul>
<li>synchronized声明为静态属性，且用volatile修饰</li>
<li>双重校验锁(先if判断是否为null，然后加锁，最后再次判断是否为null)</li>
<li>构造方法是私有的</li>
</ul>
<h2 id="内部类"><a href="#内部类" class="headerlink" title="内部类"></a>内部类</h2><p>将懒汉式的代码修补成线程安全之后，发现代码也不短了，而且还比较绕，那么饿汉法能不能优化为懒汉式的呢？答案肯定是可以的，那就是使用<em>内部类</em>，之所以要改成懒汉式，是因为某些场景饿汉式不能使用，如singletonStatic实例的创建是依赖参数或者配置文件的，在getSingletonStatic()之前必须调用某个方法设置参数给它，那样这种单例写法就无法使用了。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonInner</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> SingletonInner singletonInner = <span class="keyword">new</span> SingletonInner();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> SingletonInner <span class="title">getSingletonInner</span><span class="params">()</span></span>&#123;</span><br><span class="line">    	System.out.println(<span class="string">"SingletonInner 已被初始化"</span>);</span><br><span class="line">        <span class="keyword">return</span> Singleton.singletonInner;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">SingletonInner</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"SingletonInner construct function"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码是不是依然很短，而且思路也比较清晰。将<code>singletonInner</code>放在<code>Singleton</code>内部类中，使其不会在SingletonInner初始化时，被实例化，以达到懒加载的效果。</p>
<p>多线程测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Thread-<span class="number">0</span></span><br><span class="line">Thread-<span class="number">1</span></span><br><span class="line">SingletonInner 已被初始化</span><br><span class="line">SingletonInner 已被初始化</span><br><span class="line">SingletonInner construct function</span><br></pre></td></tr></table></figure>
<p>由结果可以推断，SingletonInner被加载并初始化时，singletonInner并没有被实例化，singletonInner的实例化是在调用getSingletonInner之后才调用构造方法进行的实例化，确实是懒加载模式。并且是线程安全的。</p>
<h2 id="枚举式"><a href="#枚举式" class="headerlink" title="枚举式"></a>枚举式</h2><p>枚举应该是最简单的，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> EasySingleton&#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>枚举还是线程安全的，因为默认枚举实例的创建是线程安全的，<em>但是在枚举中的其他任何方法由程序员自己负责</em>。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>实现单例的途径这么多，那么应该首选哪个呢？我比较推荐饿汉式(也是IDE默认推荐的)，如果使用场景中需要懒加载，那么可以使用内部类来实现单例。但是线程安全的懒汉式也应该记住。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.oschina.net/question/2273217_217864" target="_blank" rel="noopener">https://www.oschina.net/question/2273217_217864</a><br><a href="http://www.cnblogs.com/yahokuma/p/3668138.html" target="_blank" rel="noopener">http://www.cnblogs.com/yahokuma/p/3668138.html</a><br><a href="http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/" target="_blank" rel="noopener">http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/</a></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> 单例 </tag>
            
            <tag> 设计模式 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce应用实例--二次排序之全局有序]]></title>
      <url>http://bigdatadecode.club/MapReduce%E5%BA%94%E7%94%A8%E5%AE%9E%E4%BE%8B--%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E4%B9%8B%E5%85%A8%E5%B1%80%E6%9C%89%E5%BA%8F.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/MapReduce应用实例--二次排序之reduce内有序.html">上篇</a>介绍了二次排序的场景和解决方案，但是无法做到全局有序，本篇就介绍下如何进行全局二次排序。</p>
<a id="more"></a>
<h2 id="全局排序"><a href="#全局排序" class="headerlink" title="全局排序"></a>全局排序</h2><p>让整个MR结果做到全局有序，其难点在partition上，也就是要保证分配给reducei的key一定比分配给reducej的key小(i小于j)。<em>那么难点就在partition边界的设定上，边界值设置的不恰当，可能会导致每个reduce上分配的记录数不均匀，发生数据倾斜会导致整个job会被个别task拖慢</em>。</p>
<p>那么最理想的方式是每个reduce上得到的record尽可能的均匀，并且在决定某个record被分配到哪个reduce的时间应尽可能的快，也就是partition方法需要尽可能的满足<em>使record平均分配</em>和<em>分配算法高效</em>。</p>
<p>Hadoop本身提供了<code>TotalOrderPartitioner</code>类，此分区方法保证了相同key分配到同一个reduce的前提下更保证了key的全局有序。只是此方法依赖一个partition file，该file是一个sequence file，里面存放这每个reduce中key的分界点，如果我们设置的reducer个数是N，那么这个文件包含(N-1)个key分割点，<em>并且是基于key comparator排好序的</em>。TotalOrderPartitioner将partition file中的key按照是<code>BinaryComparable</code>类型的，如果是则将key构建一个trie树(查找的时间复杂度是O(n)，n为trie树的深度)。如果是非<code>BinaryComparable</code>类型的，则使用二分查找(时间复杂度为O(log(n))，n为reduce个数)。当查找的数据结构构建好之后，TotalOrderPartitioner会检查每一个key属于哪一个reducer的范围内，然后决定分发给哪一个reducer。</p>
<!-- partition file通过**？？？**来distribute keys，也就是怎么将查找的数据结构广播到各个map节点的 -->
<p>那么面对大量的数据，partition file如何得到？Hadoop帮我们提供了<em>采样器</em>帮我们预估整个边界，以使数据的分配尽量平均。Hadoop提供的采样工具有<em>RandomSampler、InputSampler和IntervalSampler</em>。</p>
<p>其中</p>
<ul>
<li>RandomSampler&lt;K,V&gt;为遍历所有数据，随机采样，效率有点低。</li>
<li>SplitSampler&lt;K,V&gt;是对前n个记录进行采样，效率是这三个里最高的。</li>
<li>IntervalSampler&lt;K,V&gt;是对固定间隔采样，效率较高，但比较适合有序的数据集。</li>
</ul>
<p>对于partition file的值除了用上面的采样方法之外，还可以根据特定需求自己写MR对数据进行划分。本篇采用<code>RandomSampler</code>对数据进行划分。</p>
<p>示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TotalSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = Logger.getLogger(TotalSort.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span></span></span><br><span class="line"><span class="class">            <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Text</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Text key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">        )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        	<span class="comment">// key 和 value形成组合键，后期二次排序</span></span><br><span class="line">            context.write(<span class="keyword">new</span> Text(key.toString() + <span class="string">" "</span> + value.toString()), </span><br><span class="line">            	<span class="keyword">new</span> IntWritable(Integer.parseInt(value.toString())));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span></span></span><br><span class="line"><span class="class">            <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">NullWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Context context</span></span></span><br><span class="line"><span class="function"><span class="params">        )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">                <span class="comment">// 将内容key value作为复合key输出</span></span><br><span class="line">                context.write(key, NullWritable.get());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://192.168.244.131:9000"</span>);</span><br><span class="line">        <span class="comment">// 设置源文件中字段之间的分隔符，默认是\t</span></span><br><span class="line">        <span class="comment">// 此分隔符在 KeyValueTextInputFormat 中使用</span></span><br><span class="line">        conf.set(<span class="string">"mapreduce.input.keyvaluelinerecordreader.key.value.separator"</span>, <span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;"</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// partition file 在hdfs上的存储路径</span></span><br><span class="line">        Path partitionFile = <span class="keyword">new</span> Path(<span class="string">"hdfs://192.168.244.131:9000/secondPartition"</span>);</span><br><span class="line">        <span class="comment">// 使用 RandomSampler 采集器对数据进行抽样划分界限</span></span><br><span class="line">        <span class="comment">// 这里 RandomSampler&lt;&gt; 内K V的数据类型在本例中无用，可以随便写也可不写</span></span><br><span class="line">        <span class="comment">// 因为在代码中使用的数据类型是 InputFormat 的数据类型</span></span><br><span class="line">        InputSampler.RandomSampler&lt;NullWritable, NullWritable&gt; randomSampler</span><br><span class="line">                = <span class="keyword">new</span> InputSampler.RandomSampler&lt;NullWritable, NullWritable&gt;(<span class="number">0.5</span>, <span class="number">3</span>);</span><br><span class="line">        <span class="comment">// RandomSampler的另一个构造方法，当split较多时，可以使用</span></span><br><span class="line"><span class="comment">//                = new InputSampler.RandomSampler&lt;Text, Text&gt;(0.5, 3, 2);</span></span><br><span class="line">        TotalOrderPartitioner.setPartitionFile(conf, partitionFile);</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(conf, <span class="string">"TotalSort"</span>);</span><br><span class="line">        <span class="comment">// 使用KeyValueTextInputFormat，默认是FileInputFormat</span></span><br><span class="line">        job.setInputFormatClass(KeyValueTextInputFormat.class);</span><br><span class="line"></span><br><span class="line">        job.setJarByClass(SecondSort.class);</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        <span class="comment">// 模拟全局排序，设置reduce个数大于1</span></span><br><span class="line">        job.setNumReduceTasks(<span class="number">2</span>);</span><br><span class="line">        job.setMapOutputKeyClass(Text.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(NullWritable.class);</span><br><span class="line">        <span class="comment">// 全局排序分区</span></span><br><span class="line">        job.setPartitionerClass(TotalOrderPartitioner.class);</span><br><span class="line">        <span class="comment">// 重写排序方法</span></span><br><span class="line">        job.setSortComparatorClass(KeyComparator.class);</span><br><span class="line">        job.setGroupingComparatorClass(GroupComparator.class);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[i]));</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputFormat.setOutputPath(job,</span><br><span class="line">                <span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">if</span> (fs.exists(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>])))&#123;</span><br><span class="line">            fs.delete(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]), <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将数据的分界点写入partition file中</span></span><br><span class="line">        InputSampler.writePartitionFile(job, randomSampler);</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面的demo是在之前二次排序的基础上加上了全局排序，二次排序的思路在上篇文章中介绍过，全局排序使用的是Hadoop自带的<code>TotalOrderPartitioner</code>分区方法。</p>
<p>这里的难点是使用采集器RandomSampler生成partition file，<em>这里容易出现类型不匹配的error</em>。<br>之前介绍partition file中存储的是key的分界点，根据分界点的值对map的输出进行分区。则partition file中存储的key应该和map output的key是同一类型(<em>因为要让两者进行比较</em>)，而map的output key又是reduce的input key，<strong>则partition file中的key应该和map output key、reduce input key的类型一样</strong>。那么partition file中的key是怎么产生的呢？本demo是用RandomSampler来生成partition file，<em>那么久应该让RandomSampler生成的partition file中的key的类型和map output key、reduce input key的类型一样</em>。<br>在new RandomSampler的时候，可以设置K V的数据类型，这里你可能会认为这个K V的数据类型应该就是输出到partition file中的数据类型吧，然而并不是。<em>翻看代码发现输出到partition file的K的数据类型是由InputFormat的K决定的，V的数据类型在代码中写死的为NullWritable</em>。又因为InputFormat K的数据类型决定了map input key的数据类型，<em>则partition file中key的数据类型应该和InputFormat K、map input key的数据类型一样</em>。<strong>这也就是代码中设置InputFormat类型为<code>KeyValueTextInputFormat.class</code>的原因</strong>。</p>
<p>综上所述，<em>如果使用RandomSampler生成partition file，则必须保证partition file key、InputFormat K、map input key、map output key和reduce input key的类型一样</em>。如果<strong>不</strong>使用RandomSampler生成partition file(可能是自己写的MR)，<em>则只需保证partition file key、map output key和reduce input key的类型一样即可</em>，因为在读partition file时，会调用<code>job.getMapOutputKeyClass()</code>设置读取的数据类型。</p>
<p>运行上面的代码会先将key的分界点写入partition file中，因为partition file是sequence file，使用hadoop命令查看<code>hadoop dfs -text /secondPartition</code>，结果为</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># value 为null是因为在代码中设置为NullWritable类型</span></span><br><span class="line">1993	(null)</span><br></pre></td></tr></table></figure>
<p>然后根据其分界点对map的结果进行分区，查看全局排序的结果为：<br>part-r-00000<br>1990 10<br>1990 17<br>1990 22<br>1990 31<br>1991 18<br>1991 20<br>1991 27<br>1991 33<br>1992 22<br>1992 31<br>part-r-00001<br>1993 18<br>1993 33</p>
<p>可见其结果是全局排序并且是先按照key然后按照value排序的。只是由于分界点选择的问题，导致两个reduce处理的数据量不一样，出现了数据倾斜。</p>
<h2 id="自定义InputFormatClass全局排序"><a href="#自定义InputFormatClass全局排序" class="headerlink" title="自定义InputFormatClass全局排序"></a>自定义InputFormatClass全局排序</h2><p>上面的demo为了保证key的数据类型一致，使用了KeyValueTextInputFormat.class设置InputFormatClass，但是如果map output key为自定义的数据类型的话，那么InputFormatClass也必须自定义。自定义InputFormat时要重写<code>getSplits</code>和<code>createRecordReader</code>方法，本例中的InputFormat方法继承自<code>FileInputFormat</code>，因为split的规则没有发生变化，所以只是重写了<code>createRecordReader</code>方法，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntityPairInputFormat</span> <span class="keyword">extends</span> <span class="title">FileInputFormat</span>&lt;<span class="title">EntityPair</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> RecordReader&lt;EntityPair, Text&gt; createRecordReader</span><br><span class="line">            (InputSplit inputSplit, TaskAttemptContext taskAttemptContext)</span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        String delimiter = taskAttemptContext.getConfiguration().get(</span><br><span class="line">                <span class="string">"textinputformat.record.delimiter"</span>);</span><br><span class="line">        <span class="keyword">byte</span>[] recordDelimiterBytes = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != delimiter)</span><br><span class="line">            recordDelimiterBytes = delimiter.getBytes(Charsets.UTF_8);</span><br><span class="line">        <span class="comment">// 模仿 TextInputFormat 的实现方式 并改写 LineRecordReader</span></span><br><span class="line">        <span class="comment">// 自定义了行读取方法</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> EntitypairLineRecordReader(recordDelimiterBytes);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// EntitypairLineRecordReader.java</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntitypairLineRecordReader</span> <span class="keyword">extends</span> <span class="title">RecordReader</span>&lt;<span class="title">EntityPair</span>, <span class="title">Text</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Log LOG = LogFactory.getLog(EntitypairLineRecordReader.class);</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAX_LINE_LENGTH =</span><br><span class="line">            <span class="string">"mapreduce.input.linerecordreader.line.maxlength"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> start;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> pos;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> end;</span><br><span class="line">    <span class="keyword">private</span> SplitLineReader in;</span><br><span class="line">    <span class="keyword">private</span> FSDataInputStream fileIn;</span><br><span class="line">    <span class="keyword">private</span> Seekable filePosition;</span><br><span class="line">    <span class="keyword">private</span> EntityPair key;</span><br><span class="line">    <span class="keyword">private</span> Text value;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> maxLineLength;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">boolean</span> isCompressedInput;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">byte</span>[] recordDelimiterBytes;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">EntitypairLineRecordReader</span><span class="params">(<span class="keyword">byte</span>[] recordDelimiterBytes)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.recordDelimiterBytes = recordDelimiterBytes;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> initialize</span><br><span class="line">            (InputSplit inputSplit, TaskAttemptContext taskAttemptContext)</span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">        FileSplit split = (FileSplit) inputSplit;</span><br><span class="line">        Configuration job = taskAttemptContext.getConfiguration();</span><br><span class="line">        <span class="keyword">this</span>.maxLineLength = job.getInt(MAX_LINE_LENGTH, Integer.MAX_VALUE);</span><br><span class="line">        start = split.getStart();</span><br><span class="line">        end = start + split.getLength();</span><br><span class="line">        <span class="keyword">final</span> Path file = split.getPath();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// open the file and seek to the start of the split</span></span><br><span class="line">        <span class="keyword">final</span> FileSystem fs = file.getFileSystem(job);</span><br><span class="line">        fileIn = fs.open(file);</span><br><span class="line"></span><br><span class="line">        fileIn.seek(start);</span><br><span class="line"></span><br><span class="line">        in = <span class="keyword">new</span> SplitLineReader(fileIn, job, <span class="keyword">this</span>.recordDelimiterBytes);</span><br><span class="line">        filePosition = fileIn;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// If this is not the first split, we always throw away first record</span></span><br><span class="line">        <span class="comment">// because we always (except the last split) read one extra line in</span></span><br><span class="line">        <span class="comment">// next() method.</span></span><br><span class="line">        <span class="keyword">if</span> (start != <span class="number">0</span>) &#123;</span><br><span class="line">            start += in.readLine(<span class="keyword">new</span> Text(), <span class="number">0</span>, maxBytesToConsume(start));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.pos = start;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">maxBytesToConsume</span><span class="params">(<span class="keyword">long</span> pos)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> isCompressedInput</span><br><span class="line">                ? Integer.MAX_VALUE</span><br><span class="line">                : (<span class="keyword">int</span>) Math.max(Math.min(Integer.MAX_VALUE, end - pos), maxLineLength);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 给key和value赋值</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span>) &#123;</span><br><span class="line">            key = <span class="keyword">new</span> EntityPair();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (value == <span class="keyword">null</span>) &#123;</span><br><span class="line">            value = <span class="keyword">new</span> Text();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> newSize = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (getFilePosition() &lt;= end || in.needAdditionalRecordAfterSplit()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pos == <span class="number">0</span>) &#123;</span><br><span class="line">                newSize = skipUtfByteOrderMark();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                newSize = in.readLine(value, maxLineLength, maxBytesToConsume(pos));</span><br><span class="line">                pos += newSize;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> ((newSize == <span class="number">0</span>) || (newSize &lt; maxLineLength)) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// line too long. try again</span></span><br><span class="line">            LOG.info(<span class="string">"Skipped line of size "</span> + newSize + <span class="string">" at pos "</span> +</span><br><span class="line">                    (pos - newSize));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (newSize == <span class="number">0</span>) &#123;</span><br><span class="line">            key = <span class="keyword">null</span>;</span><br><span class="line">            value = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 打印value的值，可以看出value就是源文件中的数据</span></span><br><span class="line">            LOG.info(<span class="string">"====EntitypairLineRecordReader.value : "</span> + value.toString());</span><br><span class="line">            key.set(<span class="keyword">new</span> Text(value.toString().split(<span class="string">" "</span>)[<span class="number">0</span>]),</span><br><span class="line">                    <span class="keyword">new</span> IntWritable(Integer.parseInt(value.toString().split(<span class="string">" "</span>)[<span class="number">1</span>])));</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">skipUtfByteOrderMark</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">// Strip BOM(Byte Order Mark)</span></span><br><span class="line">        <span class="comment">// Text only support UTF-8, we only need to check UTF-8 BOM</span></span><br><span class="line">        <span class="comment">// (0xEF,0xBB,0xBF) at the start of the text stream.</span></span><br><span class="line">        <span class="keyword">int</span> newMaxLineLength = (<span class="keyword">int</span>) Math.min(<span class="number">3L</span> + (<span class="keyword">long</span>) maxLineLength,</span><br><span class="line">                Integer.MAX_VALUE);</span><br><span class="line">        <span class="keyword">int</span> newSize = in.readLine(value, newMaxLineLength, maxBytesToConsume(pos));</span><br><span class="line">        <span class="comment">// Even we read 3 extra bytes for the first line,</span></span><br><span class="line">        <span class="comment">// we won't alter existing behavior (no backwards incompat issue).</span></span><br><span class="line">        <span class="comment">// Because the newSize is less than maxLineLength and</span></span><br><span class="line">        <span class="comment">// the number of bytes copied to Text is always no more than newSize.</span></span><br><span class="line">        <span class="comment">// If the return size from readLine is not less than maxLineLength,</span></span><br><span class="line">        <span class="comment">// we will discard the current line and read the next line.</span></span><br><span class="line">        pos += newSize;</span><br><span class="line">        <span class="keyword">int</span> textLength = value.getLength();</span><br><span class="line">        <span class="keyword">byte</span>[] textBytes = value.getBytes();</span><br><span class="line">        <span class="keyword">if</span> ((textLength &gt;= <span class="number">3</span>) &amp;&amp; (textBytes[<span class="number">0</span>] == (<span class="keyword">byte</span>)<span class="number">0xEF</span>) &amp;&amp;</span><br><span class="line">                (textBytes[<span class="number">1</span>] == (<span class="keyword">byte</span>)<span class="number">0xBB</span>) &amp;&amp; (textBytes[<span class="number">2</span>] == (<span class="keyword">byte</span>)<span class="number">0xBF</span>)) &#123;</span><br><span class="line">            <span class="comment">// find UTF-8 BOM, strip it.</span></span><br><span class="line">            LOG.info(<span class="string">"Found UTF-8 BOM and skipped it"</span>);</span><br><span class="line">            textLength -= <span class="number">3</span>;</span><br><span class="line">            newSize -= <span class="number">3</span>;</span><br><span class="line">            <span class="keyword">if</span> (textLength &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">// It may work to use the same buffer and not do the copyBytes</span></span><br><span class="line">                textBytes = value.copyBytes();</span><br><span class="line">                value.set(textBytes, <span class="number">3</span>, textLength);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                value.clear();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> newSize;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> EntityPair <span class="title">getCurrentKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.key;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Text <span class="title">getCurrentValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">float</span> <span class="title">getProgress</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (start == end) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0.0f</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> Math.min(<span class="number">1.0f</span>, (getFilePosition() - start) / (<span class="keyword">float</span>)(end - start));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">getFilePosition</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">long</span> retVal;</span><br><span class="line">        <span class="keyword">if</span> (isCompressedInput &amp;&amp; <span class="keyword">null</span> != filePosition) &#123;</span><br><span class="line">            retVal = filePosition.getPos();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            retVal = pos;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> retVal;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        in.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在EntityPairInputFormat中又new了个新的<code>RecordReader</code>，用来读取record形成EntityPair(K)和Text(V)。新的RecordReader为<code>EntitypairLineRecordReader</code>。</p>
<p>下面看下全局二次排序的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EntitySecondSort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger log = Logger.getLogger(EntitySecondSort.class);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyMapper</span></span></span><br><span class="line"><span class="class">            <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">EntityPair</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context</span></span></span><br><span class="line"><span class="function"><span class="params">        )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            String[] arr = value.toString().split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 将内容key value作为复合key输出</span></span><br><span class="line">            context.write(<span class="keyword">new</span> EntityPair(<span class="keyword">new</span> Text(arr[<span class="number">0</span>]), <span class="keyword">new</span> IntWritable(Integer.parseInt(arr[<span class="number">1</span>]))),</span><br><span class="line">                    <span class="keyword">new</span> IntWritable(Integer.parseInt(arr[<span class="number">1</span>])));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyReducer</span></span></span><br><span class="line"><span class="class">            <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">EntityPair</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(EntityPair key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Context context</span></span></span><br><span class="line"><span class="function"><span class="params">        )</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">            <span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 分组之后</span></span><br><span class="line">                context.write(<span class="keyword">new</span> Text(key.getFirstKey()), val);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://192.168.244.131:9000"</span>);</span><br><span class="line"></span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">            System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;"</span>);</span><br><span class="line">            System.exit(<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        Path partitionFile = <span class="keyword">new</span> Path(<span class="string">"hdfs://192.168.244.131:9000/secondPartition"</span>);</span><br><span class="line">        InputSampler.RandomSampler randomSampler</span><br><span class="line">                = <span class="keyword">new</span> InputSampler.RandomSampler(<span class="number">0.5</span>, <span class="number">3</span>, <span class="number">2</span>);</span><br><span class="line">        TotalOrderPartitioner.setPartitionFile(conf, partitionFile);</span><br><span class="line"></span><br><span class="line">        Job job = Job.getInstance(conf, <span class="string">"EntitySecondSort"</span>);</span><br><span class="line">        <span class="comment">// 自定义输入类型</span></span><br><span class="line">        job.setInputFormatClass(EntityPairInputFormat.class);</span><br><span class="line">        job.setJarByClass(EntitySecondSort.class);</span><br><span class="line">        job.setMapperClass(MyMapper.class);</span><br><span class="line">        job.setReducerClass(MyReducer.class);</span><br><span class="line">        job.setNumReduceTasks(<span class="number">2</span>);</span><br><span class="line">        job.setMapOutputKeyClass(EntityPair.class);</span><br><span class="line">        job.setMapOutputValueClass(IntWritable.class);</span><br><span class="line">        job.setOutputKeyClass(Text.class);</span><br><span class="line">        job.setOutputValueClass(IntWritable.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 全局排序分区</span></span><br><span class="line">        job.setPartitionerClass(TotalOrderPartitioner.class);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 重写排序方法</span></span><br><span class="line">        job.setSortComparatorClass(EntityComparator.class);</span><br><span class="line">        <span class="comment">// 自定义分组算法</span></span><br><span class="line">        job.setGroupingComparatorClass(EntityGroup.class);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;</span><br><span class="line">            FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[i]));</span><br><span class="line">        &#125;</span><br><span class="line">        FileOutputFormat.setOutputPath(job,</span><br><span class="line">                <span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">        FileSystem fs = FileSystem.get(conf);</span><br><span class="line">        <span class="keyword">if</span> (fs.exists(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>])))&#123;</span><br><span class="line">            fs.delete(<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]), <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        InputSampler.writePartitionFile(job, randomSampler);</span><br><span class="line"></span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其结果为：<br>part-r-00000<br>1990    10<br>1990    17<br>1990    22<br>1990    31<br>part-r-00001<br>1991    18<br>1991    20<br>1991    27<br>1991    33<br>1992    22<br>1992    31<br>1993    18<br>1993    33</p>
<p>上面讲过使用RandomSampler生成partition file时必须保证partition file key、InputFormat K、map input key、map output key和reduce input key的类型一样，则partition file中存放的数据也是EntityPair类型的key，此时如果用<code>hadoop dfs -text /secondPartition</code>命令查看partition file时，会报错，因为无法解析EntityPair对象。那么如何去验证key的分界点是1991呢？</p>
<p>我并没有去手动反序列partition file，而是在<code>InputSampler</code>中写入partition file的代码处打了下log，将写入的key打印出来了，日志中显示分界点key为<code>1991 27</code>(之所以显示这个格式，是因为我重写了EntityPair的toString方法)。这就验证了分区的结果。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇主要是利用MR进行全局排序，而<strong>全局排序的难点是如果对数据进行分区，并且尽量避免数据倾斜</strong>。<br>本例使用的是Hadoop自身的<code>TotalOrderPartitioner</code>对数据进行分区，TotalOrderPartitioner会根据分界点的key形成一个利于查找的数据结构，使map的输出key在此数据结构中能够快速的定位到相应的reduce中，关于TotalOrderPartitioner的更多内容随后会有一篇文章来从源码的角度展开分析。<br>而分界点key是通过RandomSampler从源文件中随机抽取的。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce应用实例 </tag>
            
            <tag> 二次排序 </tag>
            
            <tag> 全局排序 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之leetcode Reverse Integer]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bleetcode%20Reverse%20Integer.html</url>
      <content type="html"><![CDATA[<p>将一个int数翻转数字，只翻转数字，符号不做处理。</p>
<p>example：<br>x = 123, return 321<br>x = -123, return -321</p>
<blockquote>
<p>数据越界则返回0</p>
</blockquote>
<p>这个比较简单，就是将int的最高位和最低位依次进行调换，如果int中的每个字符都能拿到其索引值，那么就可以根据索引值进行依次对调。但在求每位上的数字时发现得到个位、十位、百位等上的数字的顺序其实就是在给int进行反转，那我只需要将每次得到的值进行依次记录，然后顺序输出就ok了。</p>
<a id="more"></a>
<p>按照这个思路，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">reverse</span><span class="params">(<span class="keyword">int</span> x)</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 其实这个思路还有一种更简单的，直接将int转为string，</span></span><br><span class="line">	<span class="comment">// 然后利用string中字符的索引进行交换得到反转字符串，然后再判断是否越界</span></span><br><span class="line">    <span class="keyword">if</span> (x == <span class="number">0</span> || x == Integer.MIN_VALUE)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    StringBuffer stringBuffer = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    <span class="keyword">if</span> (x &lt; <span class="number">0</span>)&#123;</span><br><span class="line">        stringBuffer.append(<span class="string">"-"</span>);</span><br><span class="line">        x = <span class="number">0</span> - x;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">while</span> (x &gt; <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="keyword">int</span> last = x % <span class="number">10</span>;</span><br><span class="line">        x = x / <span class="number">10</span>;</span><br><span class="line">        stringBuffer.append(last);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (Double.parseDouble(stringBuffer.toString()) &gt; Integer.MAX_VALUE</span><br><span class="line">            || Double.parseDouble(stringBuffer.toString()) &lt; Integer.MIN_VALUE)&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> Integer.parseInt(stringBuffer.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码中将符号位单独拿出来，因为符号位不需要反转。但初版是有bug的，函数传入的参数是int，这虽然能保证原始数据不越界，但不能保证反转之后的数值不越界，所以此处用double类型来接受反转之后的数值，然后进行判断是否越界。</p>
<p>其实判断数值是否越界也不用这么麻烦，因为<em>一个int数值越界之后会返回正常位数以内的数值</em>。那么判断一个int数值操作的结果集是否越界只需判断操作之后的结果值按照<em>逆操作</em>而得到的值与操作之前的值是否一样就可以了。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">reverse</span><span class="params">(<span class="keyword">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> result = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (x != <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> tail = x % <span class="number">10</span>;</span><br><span class="line">        <span class="comment">// int操作之后的值如果越界怎么处理,什么原则</span></span><br><span class="line">        <span class="keyword">int</span> newResult = result * <span class="number">10</span> + tail;</span><br><span class="line">        <span class="keyword">if</span> ((newResult - tail) / <span class="number">10</span> != result)</span><br><span class="line">        &#123; <span class="keyword">return</span> <span class="number">0</span>; &#125;</span><br><span class="line">        result = newResult;</span><br><span class="line">        x = x / <span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><p>int最大值为<code>2147483647</code>，用二进制表示为<code>0111 1111 1111 1111 1111 1111 1111 1111</code>，使最大值加1运算，其结果用二进制表示为<code>1000 0000 0000 0000 0000 0000 0000 0000</code>，由于int的最高位是符号位，那么这个结果的最高位是1，编码之后的值为<code>-2147483648</code>。</p>
<p>如果不考虑越界<code>2147483647 + 1</code>应该是<code>2147483648</code>，但是越界了，按照编码规则，<code>2147483648</code>被编码为<code>-2147483648</code>，那么将<code>-2147483648</code>逆运算也就是减1得到的结果肯定不是<code>2147483647</code></p>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
            <tag> Reverse Integer </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之leetcode ZigZag Conversion]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bleetcode%20ZigZag%20Conversion.html</url>
      <content type="html"><![CDATA[<p>ZigZag转换就是将字符串按之字排列，然后按行输出。如字符串”PAYPALISHIRING”，ZigZag转换之后是</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P   A   H   N</span><br><span class="line">A P L S I I G</span><br><span class="line">Y   I   R</span><br></pre></td></tr></table></figure>
<p>按行输出之后的字符串是”PAHNAPLSIIGYIR”。</p>
<p>用算法实现，参数为字符串和行数，返回按行输出的字符串。</p>
<a id="more"></a>
<p>题中给出了行数是奇数的排列方式，那么其对立面就是偶数，写出偶数的排列方式</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">P     I     I</span><br><span class="line">A   L S   R N</span><br><span class="line">Y A   H I</span><br><span class="line">P     I</span><br></pre></td></tr></table></figure>
<p>然后结合奇数和偶数的排列方式并未<em>每个字符按照在原字符串中的顺序标上号之后</em>，<em>（其实使用数字作为字符串进行ZigZag转换看的更清晰）</em>发现其有一个数学规律，每两个主列上字符索引的差值为2*row-2，而斜线上字符的索引不难看出是<strong>下一个字符的索引减去两个当前字符所在行索引的值</strong>。</p>
<p>发现这个普遍规律之后就万事大吉，可以写代码了吗？</p>
<p><strong>我们发现了普遍的规律还应该去关注下特殊情况，也就是常说的边界值</strong>。</p>
<p>边界值考虑：</p>
<ul>
<li>第一行和最后一行不存在斜线上的数据</li>
<li>最后的一个之字可能不完整，如只有斜线上的数据</li>
</ul>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">convert</span><span class="params">(String str, <span class="keyword">int</span> numRows)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (numRows == <span class="number">1</span>)&#123;</span><br><span class="line">        <span class="keyword">return</span> str;</span><br><span class="line">    &#125;</span><br><span class="line">    StringBuffer stringBuffer = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;numRows; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span> ((str.length()-<span class="number">1</span>) &gt;= i) &#123;</span><br><span class="line">            stringBuffer.append(str.charAt(i));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> index = i;</span><br><span class="line">        <span class="keyword">while</span> ((str.length()-<span class="number">1</span>) &gt;= (index+numRows+(numRows-<span class="number">2</span>)))&#123;</span><br><span class="line">            <span class="comment">// 首行 &amp;&amp; 尾行</span></span><br><span class="line">            <span class="comment">// 注意边界值</span></span><br><span class="line">            <span class="keyword">if</span> ((index+numRows+(numRows-<span class="number">2</span>) &gt; (index+numRows+(numRows-<span class="number">2</span>)-i-i)) &amp;&amp; ((index+numRows+(numRows-<span class="number">2</span>)-i-i) &gt; index) )&#123;</span><br><span class="line">                stringBuffer.append(str.charAt(index+numRows+(numRows-<span class="number">2</span>)-i-i));</span><br><span class="line">            &#125;</span><br><span class="line">            stringBuffer.append(str.charAt(index + numRows + (numRows - <span class="number">2</span>)));</span><br><span class="line">            index = index+numRows+(numRows-<span class="number">2</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (((str.length()-<span class="number">1</span>) &gt;= (index+numRows+(numRows-<span class="number">2</span>)-i-i)) &amp;&amp; ((index+numRows+(numRows-<span class="number">2</span>)-i-i) != index))&#123;</span><br><span class="line">            stringBuffer.append(str.charAt(index+numRows+(numRows-<span class="number">2</span>)-i-i));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> stringBuffer.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此方法感觉就是简单粗暴，从排列中归纳出规律，按照公式进行编码。</p>
<p>但是总感觉应该有更好的方法或者更加高大上一点，然后并没有找到什么好的算法，普遍都是这种<em>利用规律</em>来解答。</p>
<p>前面说没有好的算法并不代表没有那些特立独行的方法，如下面这个就是如此的<em>简单直接和自信</em>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">conv</span><span class="params">(String str, <span class="keyword">int</span> row)</span></span>&#123;</span><br><span class="line">    StringBuffer[] sbArr = <span class="keyword">new</span> StringBuffer[row];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;row; i++)&#123;</span><br><span class="line">        sbArr[i] = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; str.length())&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> rowIndex=<span class="number">0</span>;rowIndex&lt;row &amp;&amp; i&lt;str.length();rowIndex++)&#123;</span><br><span class="line">            sbArr[rowIndex].append(str.charAt(i++));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> rowIndex=row-<span class="number">2</span>;rowIndex&gt;=<span class="number">1</span> &amp;&amp; i&lt;str.length(); rowIndex--)&#123;</span><br><span class="line">            sbArr[rowIndex].append(str.charAt(i++));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> r=<span class="number">1</span>; r&lt;row; r++)&#123;</span><br><span class="line">        sbArr[<span class="number">0</span>].append(sbArr[r]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> sbArr[<span class="number">0</span>].toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>之所以说这个代码写出来很自信，就貌似有人让你打印10遍<code>hello world</code>，而你就直接写了10遍的<code>System.out.println(&quot;hello world&quot;);</code></p>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
            <tag> igZag Conversion </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[实时抓取MySQL的更新数据到Hadoop]]></title>
      <url>http://bigdatadecode.club/%E5%AE%9E%E6%97%B6%E6%8A%93%E5%8F%96MySQL%E7%9A%84%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E5%88%B0Hadoop.html</url>
      <content type="html"><![CDATA[<p>关系型数据库和Hadoop生态的沟通越来越密集，时效要求也越来越高。本篇就来调研下实时抓取MySQL更新数据到HDFS。</p>
<blockquote>
<p>本篇仅作为调研报告。</p>
</blockquote>
<p>初步调研了canal(Ali)+kafka connect+kafka、maxwell(Zendesk)+kafka和mysql_streamer(Yelp)+kafka。<em>这几个工具抓取MySQL的方式都是通过扫描binlog，模拟MySQL master和slave(Mysql Replication架构–解决了：数据多点备份，提高数据可用性；读写分流，提高集群的并发能力。（并非是负载均衡）；让一些非实时的数据操作，转移到slaves上进行。)之间的协议来实现实时更新的</em>。</p>
<a id="more"></a>
<p>先科普下Canal</p>
<h2 id="Canal简介"><a href="#Canal简介" class="headerlink" title="Canal简介"></a>Canal简介</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p><img src="/blogimgs/mysqlToHdfs/canal原理图.jpg" alt="Canal原理图" title="Canal原理图"><br>原理相对比较简单：</p>
<ol>
<li>canal模拟mysql slave的交互协议，伪装自己为mysql slave，向mysql master发送dump协议</li>
<li>mysql master收到dump请求，开始推送(<em>slave拉取，不是master主动push给slaves</em>)binary log给slave(也就是canal)</li>
<li>canal解析binary log对象(原始为byte流)</li>
</ol>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/blogimgs/mysqlToHdfs/canal架构图.jpg" alt="Canal架构图" title="Canal架构图"></p>
<p>组件说明：</p>
<ol>
<li>server代表一个canal运行实例，对应于一个jvm</li>
<li>instance对应于一个数据队列(1个server对应1..n个instance)</li>
</ol>
<p>而instance模块又由eventParser(数据源接入，模拟slave协议和master进行交互，协议解析)、eventSink(Parser和Store连接器，进行数据过滤，加工，分发的工作)、eventStore(数据存储)和metaManager(增量订阅&amp;消费信息管理器)组成。</p>
<ul>
<li><p>EventParser在向mysql发送dump命令之前会先从Log Position中获取上次解析成功的位置(如果是第一次启动，则<strong>获取初始指定位置</strong>或者当前数据段binlog位点)。mysql接受到dump命令后，由EventParser从mysql上pull binlog数据进行解析并传递给EventSink(<em>传递给EventSink模块进行数据存储，是一个阻塞操作，直到存储成功</em>)，传送成功之后更新Log Position。流程图如下：<br><img src="/blogimgs/mysqlToHdfs/eventParser.jpg" alt="EventParser流程图" title="EventParser流程图"></p>
</li>
<li><p>EventSink起到一个类似channel的功能，可以对数据进行<em>过滤、分发/路由(1:n)、归并(n:1)和加工</em>。EventSink是连接EventParser和EventStore的桥梁。</p>
</li>
<li><p>EventStore实现模式是内存模式，内存结构为环形队列，由三个指针(Put、Get和Ack)标识数据存储和读取的位置。</p>
</li>
<li><p>MetaManager是增量订阅&amp;消费信息管理器，增量订阅和消费之间的协议包括get/ack/rollback，分别为：</p>
</li>
</ul>
<blockquote>
<p>Message getWithoutAck(int batchSize)，允许指定batchSize，一次可以获取多条，每次返回的对象为Message，包含的内容为：batch id[唯一标识]和entries[具体的数据对象]<br>void rollback(long batchId)，顾命思议，回滚上次的get请求，重新获取数据。基于get获取的batchId进行提交，避免误操作<br>void ack(long batchId)，顾命思议，确认已经消费成功，通知server删除数据。基于get获取的batchId进行提交，避免误操作</p>
</blockquote>
<p>增量订阅和消费之间的协议交互如下：<br><img src="/blogimgs/mysqlToHdfs/publishSubscribe.jpg" alt="增量订阅和消费协议" title="增量订阅和消费协议"></p>
<p>canal的get/ack/rollback协议和常规的jms协议有所不同，<em>允许get/ack异步处理</em>，比如可以连续调用get多次，后续异步按顺序提交ack/rollback，项目中称之为流式api.</p>
<p>流式api设计的好处：</p>
<ul>
<li>get/ack异步化，减少因ack带来的网络延迟和操作成本 (99%的状态都是处于正常状态，异常的rollback属于个别情况，没必要为个别的case牺牲整个性能)</li>
<li>get获取数据后，业务消费存在瓶颈或者需要多进程/多线程消费时，可以不停的轮询get数据，不停的往后发送任务，提高并行化. (在实际业务中的一个case：业务数据消费需要跨中美网络，所以一次操作基本在200ms以上，为了减少延迟，所以需要实施并行化)</li>
</ul>
<p>流式api设计示意图如下：<br><img src="/blogimgs/mysqlToHdfs/流式api.jpg" alt="流式api" title="流式api"></p>
<ul>
<li>每次get操作都会在meta中产生一个mark，mark标记会递增，保证运行过程中mark的唯一性</li>
<li>每次的get操作，都会在上一次的mark操作记录的cursor继续往后取，如果mark不存在，则在last ack cursor继续往后取</li>
<li>进行ack时，需要按照mark的顺序进行数序ack，不能跳跃ack. ack会删除当前的mark标记，并将对应的mark位置更新为last ack cusor</li>
<li>一旦出现异常情况，客户端可发起rollback情况，重新置位：删除所有的mark, 清理get请求位置，下次请求会从last ack cursor继续往后取</li>
</ul>
<blockquote>
<p>这个流式api是不是类似hdfs write在pipeline中传输packet的形式，先将packet放入dataQueue，然后向下游传输，此时将packet放入ackQueue等到下游返回的ack，这也是异步的。</p>
</blockquote>
<h3 id="HA机制"><a href="#HA机制" class="headerlink" title="HA机制"></a>HA机制</h3><p>canal是支持HA的，其实现机制也是依赖zookeeper来实现的，用到的特性有watcher和EPHEMERAL节点(和session生命周期绑定)，与HDFS的HA类似。</p>
<p>canal的ha分为两部分，<em>canal server和canal client分别有对应的ha实现</em></p>
<ul>
<li>canal server: 为了减少对mysql dump的请求，<em>不同</em>server上的instance(<em>不同server上的相同instance</em>)要求同一时间只能有一个处于running，其他的处于standby状态(standby是instance的状态)。</li>
<li><em>canal client</em>: 为了保证有序性，一份instance同一时间只能由一个canal client进行get/ack/rollback操作，否则客户端接收无法保证有序。</li>
</ul>
<p>server ha的架构图如下：<br><img src="/blogimgs/mysqlToHdfs/ha.jpg" alt="ha" title="ha"><br>大致步骤：</p>
<ol>
<li>canal server要启动某个<em>canal instance</em>时都先向zookeeper_进行一次尝试启动判断_(实现：创建EPHEMERAL节点，谁创建成功就允许谁启动)</li>
<li>创建zookeeper节点成功后，对应的canal server就启动对应的canal instance，<em>没有创建成功的canal instance就会处于standby状态</em>。</li>
<li>一旦zookeeper发现canal server A创建的<em>instance节点</em>消失后，立即通知其他的canal server再次进行步骤1的操作，重新选出一个canal server启动instance。</li>
<li>canal client每次进行connect时，会首先向zookeeper询问当前是谁启动了canal instance，然后和其建立链接，一旦链接不可用，会重新尝试connect。</li>
</ol>
<p><strong>Canal Client的方式和canal server方式类似，也是利用zookeeper的抢占EPHEMERAL节点的方式进行控制.</strong></p>
<h2 id="Canal部署及使用"><a href="#Canal部署及使用" class="headerlink" title="Canal部署及使用"></a>Canal部署及使用</h2><h3 id="MySQL配置"><a href="#MySQL配置" class="headerlink" title="MySQL配置"></a>MySQL配置</h3><p>canal同步数据需要扫描MySQL的binlog日志，而binlog默认是关闭的，需要开启，并且为了保证<em>同步数据的一致性</em>，使用的日志格式为<em>row-based replication(RBR)</em>，在<code>my.conf</code>中开启binlog，</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line"><span class="built_in">log</span>-bin=mysql-bin <span class="comment">#添加这一行就ok</span></span><br><span class="line">binlog-format=ROW <span class="comment">#选择row模式</span></span><br><span class="line">server_id=1 <span class="comment">#配置mysql replaction需要定义，不能和canal的slaveId重复</span></span><br></pre></td></tr></table></figure>
<p>更改my.conf之后，需要<em>重启MySQL</em>，重启的方式有很多找到合适自己的就行。</p>
<h3 id="Canal配置"><a href="#Canal配置" class="headerlink" title="Canal配置"></a>Canal配置</h3><p>由上面的介绍得知Canal由<code>Server</code>和<code>Instance</code>组成，而Server中又可以包含很多个Instance，<em>一个Instance对应一个数据库实例</em>，则Canal将配置分为两类，一类是server的配置，名字为<code>canal.properties</code>，另一类是instance的配置，名字为<code>instance.properties</code>，一般会在conf目录下新建一个instance同名的目录，将其放入此目录中。</p>
<p>先介绍canal.properties中的几个关键属性</p>
<table>
<thead>
<tr>
<th>参数名字</th>
<th>参数说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>canal.destinations</td>
<td>当前server上部署的instance列表</td>
<td>无</td>
</tr>
<tr>
<td>canal.conf.dir</td>
<td>conf/目录所在的路径</td>
<td>../conf</td>
</tr>
<tr>
<td>canal.instance.global.spring.xml</td>
<td>全局的spring配置方式的组件文件</td>
<td>classpath:spring/file-instance.xml <br> (spring目录相对于canal.conf.dir)</td>
</tr>
<tr>
<td>canal.zkServers</td>
<td>canal server链接zookeeper集群的链接信息</td>
<td>无</td>
</tr>
<tr>
<td>canal.zookeeper.flush.period</td>
<td>canal持久化数据到zookeeper上的更新频率，单位毫秒</td>
<td>1000</td>
</tr>
<tr>
<td>canal.file.data.dir</td>
<td>canal持久化数据到file上的目录</td>
<td>../conf (默认和instance.properties为同一目录，方便运维和备份)</td>
</tr>
<tr>
<td>canal.file.flush.period</td>
<td>canal持久化数据到file上的更新频率，单位毫秒</td>
<td>1000</td>
</tr>
<tr>
<td>canal.instance.memory.batch.mode</td>
<td>canal内存store中数据缓存模式 <br> 1. ITEMSIZE : 根据buffer.size进行限制，只限制记录的数量 <br> 2. MEMSIZE : 根据buffer.size * buffer.memunit的大小，限制缓存记录的大小</td>
<td>MEMSIZE</td>
</tr>
<tr>
<td>canal.instance.memory.buffer.size</td>
<td>canal内存store中可缓存buffer记录数，需要为2的指数</td>
<td>16384</td>
</tr>
<tr>
<td>canal.instance.memory.buffer.memunit</td>
<td>内存记录的单位大小，默认1KB，和buffer.size组合决定最终的内存使用大小</td>
<td>1024</td>
</tr>
</tbody>
</table>
<p>下面看下instance.properties，这里的属性较少：</p>
<table>
<thead>
<tr>
<th>参数名字</th>
<th>参数说明</th>
<th>默认值</th>
</tr>
</thead>
<tbody>
<tr>
<td>canal.instance.mysql.slaveId</td>
<td>mysql集群配置中的serverId概念，需要保证和当前mysql集群中id唯一</td>
<td>1234</td>
</tr>
<tr>
<td>canal.instance.master.address</td>
<td>mysql主库链接地址</td>
<td>127.0.0.1:3306</td>
</tr>
<tr>
<td>canal.instance.master.journal.name</td>
<td>mysql主库链接时起始的binlog文件</td>
<td>无</td>
</tr>
<tr>
<td>canal.instance.master.position</td>
<td>mysql主库链接时起始的binlog偏移量</td>
<td>无</td>
</tr>
<tr>
<td>canal.instance.master.timestamp</td>
<td>mysql主库链接时起始的binlog的时间戳</td>
<td>无</td>
</tr>
<tr>
<td>canal.instance.dbUsername</td>
<td>mysql数据库帐号</td>
<td>canal</td>
</tr>
<tr>
<td>canal.instance.dbPassword</td>
<td>mysql数据库密码</td>
<td>canal</td>
</tr>
<tr>
<td>canal.instance.defaultDatabaseName</td>
<td>mysql链接时默认schema</td>
<td>无</td>
</tr>
<tr>
<td>canal.instance.connectionCharset</td>
<td>mysql 数据解析编码</td>
<td>UTF-8</td>
</tr>
<tr>
<td>canal.instance.filter.regex</td>
<td>mysql 数据解析关注的表，Perl正则表达式. <br> 多个正则之间以逗号(,)分隔，转义符需要双斜杠</td>
<td>.*\\..*</td>
</tr>
</tbody>
</table>
<p>除了上面两个配置文件，conf目录下还有一个目录需要强调下，那就是spring目录，里面存放的是instance.xml配置文件，目前默认支持的instance.xml有<em>memory-instance.xml、file-instance.xml、default-instance.xml和group-instance.xml</em>。这里主要维护的增量订阅和消费的关系信息(<em>解析位点和消费位点</em>)。</p>
<p>对应的两个位点组件，目前都有几种实现：</p>
<ul>
<li>memory (memory-instance.xml中使用)</li>
<li>zookeeper</li>
<li>mixed</li>
<li>file (file-instance.xml中使用，集合了file+memory模式，先写内存，定时刷新数据到本地file上)</li>
<li>period (default-instance.xml中使用，集合了zookeeper+memory模式，先写内存，定时刷新数据到zookeeper上)</li>
</ul>
<blockquote>
<p>分别介绍下这几种配置的功能</p>
</blockquote>
<ul>
<li>memory-instance.xml：</li>
</ul>
<p><em>所有的组件(parser , sink , store)都选择了内存版模式</em>，记录位点的都选择了memory模式，重启后又会回到初始位点进行解析</p>
<p>特点：速度最快，依赖最少(不需要zookeeper)</p>
<p>场景：一般应用在quickstart，或者是出现问题后，进行数据分析的场景，不应该将其应用于生产环境</p>
<ul>
<li>file-instance.xml：</li>
</ul>
<p>所有的组件(parser , sink , store)都选择了基于file持久化模式(<em>组件内容持久化的file存在哪里？？？</em>)，注意，不支持HA机制.</p>
<p>特点：支持单机持久化</p>
<p>场景：生产环境，无HA需求，简单可用.</p>
<ul>
<li>default-instance.xml：</li>
</ul>
<p>所有的组件(parser , sink , store)都选择了持久化模式，目前持久化的方式主要是写入zookeeper，保证数据集群共享.(<em>所有组件持久化的内容只有位置信息吧？？？</em>)</p>
<p>特点：支持HA</p>
<p>场景：生产环境，集群化部署.</p>
<ul>
<li>group-instance.xml：</li>
</ul>
<p>主要针对需要进行多库合并时，可以将多个物理instance合并为一个逻辑instance，提供客户端访问。</p>
<p>场景：分库业务。 比如产品数据拆分了4个库，每个库会有一个instance，如果不用group，业务上要消费数据时，需要启动4个客户端，分别链接4个instance实例。使用group后，可以在canal server上合并为一个逻辑instance，只需要启动1个客户端，链接这个逻辑instance即可.</p>
<h3 id="canal-example-部署"><a href="#canal-example-部署" class="headerlink" title="canal example 部署"></a>canal example 部署</h3><ul>
<li>在需要同步的MySQL数据库中创建一个用户，用来replica数据，这里新建的用户名和密码都为<code>canal</code>，命令如下：</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CREATE USER canal IDENTIFIED BY <span class="string">'canal'</span>;  </span><br><span class="line">GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO <span class="string">'canal'</span>@<span class="string">'%'</span>;</span><br><span class="line">-- GRANT ALL PRIVILEGES ON *.* TO <span class="string">'canal'</span>@<span class="string">'%'</span> ;</span><br><span class="line">FLUSH PRIVILEGES;</span><br></pre></td></tr></table></figure>
<ul>
<li>Mysql创建<code>canal</code>用户并为其赋所需权限之后，需要对Canal的配置文件(<em>canal.properties和instance.properties</em>)进行设置。</li>
</ul>
<p>canal.properties和instance.properties里采用默认配置即可(<em>这里只是运行个样例，生产中可以参考具体的参数属性进行设置</em>)，</p>
<ul>
<li>Canal配置好之后，启动Canal client(<em>client的作用是将Canal里的解析的binlog日志固化到存储介质中</em>)。</li>
</ul>
<p>client组件Canal本身是不提供的，需要根据api进行开发，这里将官方提供的client代码打包成jar进行消费Canal信息。</p>
<h3 id="canal-HA配置"><a href="#canal-HA配置" class="headerlink" title="canal HA配置"></a>canal HA配置</h3><p>canal的HA机制是依赖zk来实现的，需要更改canal.properties文件，修改内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># zk集群地址</span></span><br><span class="line">canal.zkServers=10.20.144.51:2181</span><br><span class="line"><span class="comment"># 选择记录方式</span></span><br><span class="line">canal.instance.global.spring.xml = classpath:spring/default-instance.xml</span><br></pre></td></tr></table></figure>
<p>更改两台canal机器上instance实例的配置instance.properties，修改内容如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">canal.instance.mysql.slaveId = 1234 <span class="comment">##另外一台机器改成1235，保证slaveId不重复即可</span></span><br><span class="line">canal.instance.master.address = 10.20.144.15:3306</span><br></pre></td></tr></table></figure>
<p>配置好之后启动canal进程，在两台服务器上执行<code>sh bin/startup.sh</code></p>
<p>client进行消费时，可以直接指定zookeeper地址和instance name，也可以让canal client会自动从zookeeper中的running节点，获取当前服务的工作节点，然后与其建立链接。</p>
<h2 id="maxwell简介"><a href="#maxwell简介" class="headerlink" title="maxwell简介"></a>maxwell简介</h2><p>maxwell实时抓取mysql数据的原理也是基于binlog，和canal相比，maxwell更像是<code>canal server + 实时client</code>。(数据抽取 + 数据转换)</p>
<p>maxwell集成了kafka producer，直接从binlog获取数据更新并写入kafka，而canal则<strong>需要自己开发实时client将canal读取的binlog内容写入kafka中</strong>。</p>
<p>maxwell特色：</p>
<ul>
<li>支持bootstrap启动，同步历史数据</li>
<li>集成kafka，直接将数据落地到kafka</li>
<li>已将binlog中的DML和DDL进行了模式匹配，将其解码为有schema的json(<em>有利于后期将其重组为nosql支持的语言</em>)<br>{“database”:”test”,”table”:”e”,”type”:”update”,”ts”:1488857869,”xid”:8924,”commit”:true,”data”:{“id”:1,”m”:5.556666,”torvalds”:null},”old”:{“m”:5.55}}</li>
</ul>
<p>缺点：</p>
<ul>
<li>一个MySQL实例需要对应一个maxwell进程</li>
<li>bootstrap的方案使用的是<code>select *</code></li>
</ul>
<p>maxwell的配置文件只有一个<em>config.properties</em>，在home目录。其中除了需要配置mysql master的地址、kafka地址还需要配置一个用于存放maxwell相关信息的mysql地址，maxwell会把读取binlog关系的信息，如binlog name、position。</p>
<h2 id="工具对比"><a href="#工具对比" class="headerlink" title="工具对比"></a>工具对比</h2><p>以上是Canal的原理及部署，其余类似maxwell和mysql_streamer对mysql进行实时数据抓取的原理一样就不再进行一一介绍，这里只对他们进行下对比：</p>
<table>
<thead>
<tr>
<th>特色</th>
<th>Canal</th>
<th>Maxwell</th>
<th>mysql_streamer</th>
</tr>
</thead>
<tbody>
<tr>
<td>语言</td>
<td>Java</td>
<td>Java</td>
<td>Python</td>
</tr>
<tr>
<td>活跃度</td>
<td>活跃</td>
<td>活跃</td>
<td>不活跃</td>
</tr>
<tr>
<td>HA</td>
<td>支持</td>
<td>定制</td>
<td>支持</td>
</tr>
<tr>
<td>数据落地</td>
<td>定制</td>
<td>落地到kafka</td>
<td>落地到kafka</td>
</tr>
<tr>
<td>分区</td>
<td>支持</td>
<td>不支持</td>
<td>不支持</td>
</tr>
<tr>
<td>bootstrap</td>
<td>不支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>数据格式</td>
<td>格式自由</td>
<td>json(格式固定)</td>
<td>json(格式固定)</td>
</tr>
<tr>
<td>文档</td>
<td>较详细</td>
<td>较详细</td>
<td>略粗</td>
</tr>
<tr>
<td>随机读</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
</tbody>
</table>
<p><strong>以上只是将mysql里的实时变化数据的binlog以同种形式同步到kafka，但要实时更新到hadoop还需要使用一个实时数据库来存储数据，并自定制开发将kafka中数据解析为nosql数据库可以识别的DML进行实时更新Nosql数据库，使其与MySQL里的数据实时同步。</strong></p>
<h2 id="基础架构"><a href="#基础架构" class="headerlink" title="基础架构"></a>基础架构</h2><p>架构图如下：<br><img src="/blogimgs/mysqlToHdfs/基础架构图.png" alt="基础架构图" title="基础架构图"></p>
<blockquote>
<p>虚线框是可选的方案</p>
</blockquote>
<h3 id="方案对比"><a href="#方案对比" class="headerlink" title="方案对比"></a>方案对比</h3><ol>
<li><em>方案1</em>使用阿里开源的Canal进行Mysql binlog数据的抽取，另需<strong>开发一个数据转换工具将从binlog中解析出的数据转换成自带schema的json数据并写入kafka中</strong>。而<em>方案2</em>使用maxwell可<strong>直接完成</strong>对mysql binlog数据的抽取和转换成自带schema的json数据写入到kafka中。</li>
<li><em>方案1</em>中不支持表中已存在的历史数据进行同步，此功能需要开发(如果使用sqoop进行历史数据同步，不够灵活，会使结果表与原始表结构相同，有区别于数据交换平台所需的schema)。<em>方案2</em>提供同步历史数据的解决方案。</li>
<li><em>方案1</em>支持HA部署，而<em>方案2</em>不支持HA</li>
</ol>
<p>方案1和方案2的区别只在于kafka之前，当数据缓存到kafka之后，需要一个<strong>定制的数据路由组件</strong>来将自带schema的数据解析到目标存储中。<br>数据路由组件主要负责将kafka中的数据实时读出，写入到目标存储中。(如将所有日志数据保存到HDFS中，也可以将数据落地到所有支持jdbc的数据库，落地到HBase，Elasticsearch等。)</p>
<!-- 开发bootstrap功能(或者使用sqoop将历史数据进行同步，缺点是什么？不够灵活，在hbase之类的数据库中存储的内容会有一个标识属性，防止重复操作) -->
<p>综上，<br>方案1需要开发的功能有：</p>
<ul>
<li>bootstrap功能</li>
<li>实时数据转换工具</li>
<li>数据路由工具</li>
</ul>
<p>方案2需要开发的功能有：</p>
<ul>
<li>数据路由工具</li>
<li>HA模块(初期可暂不支持HA，所以开发紧急度不高)</li>
</ul>
<p>数据路由工具是两个方案都需要开发的，则我比较偏向于第二种方案，因为在初期试水阶段可以短期出成果，可以较快的验证想法，并在尝试中能够较快的发现问题，好及时的调整方案。即使方案2中maxwell最终不能满足需求，而使用canal的话，我们也可能将实时数据转换工具的数据输出模式与maxwell一致，这样初始投入人力开发的数据路由工具依然可以继续使用，而不需要重新开发。</p>
<p>把增量的Log作为一切系统的基础。后续的数据使用方，通过订阅kafka来消费log。</p>
<p>比如：<br>大数据的使用方可以将数据保存到Hive表或者Parquet文件给Hive或Spark查询；<br>提供搜索服务的使用方可以保存到Elasticsearch或HBase 中；<br>提供缓存服务的使用方可以将日志缓存到Redis或alluxio中；<br>数据同步的使用方可以将数据保存到自己的数据库中；<br>由于kafka的日志是可以重复消费的，并且缓存一段时间，各个使用方可以通过消费kafka的日志来达到既能保持与数据库的一致性，也能保证实时性；</p>
<p>{“database”:”test”,”table”:”e”,”type”:”update”,”ts”:1488857869,”xid”:8924,”commit”:true,”data”:{“id”:1,”m”:5.556666,”torvalds”:null},”old”:{“m”:5.55}}</p>
<p>{“database”:”test”,”table”:”e”,”type”:”insert”,”ts”:1488857922,”xid”:8932,”commit”:true,”data”:{“id”:2,”m”:4.2,”torvalds”:null}}</p>
<h2 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h2><p><a href="https://github.com/alibaba/canal/wiki" target="_blank" rel="noopener">canal</a><br><a href="http://maxwells-daemon.io/" target="_blank" rel="noopener">maxwell</a><br><a href="https://github.com/Yelp/mysql_streamer" target="_blank" rel="noopener">mysql_streamer</a></p>
]]></content>
      
        <categories>
            
            <category> BigData </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> MySQL </tag>
            
            <tag> canal </tag>
            
            <tag> 实时 </tag>
            
            <tag> 更新数据 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HUE编译与部署]]></title>
      <url>http://bigdatadecode.club/HUE%E7%BC%96%E8%AF%91%E4%B8%8E%E9%83%A8%E7%BD%B2.html</url>
      <content type="html"><![CDATA[<p>Hue是一个开源的Apache Hadoop UI系统，是基于Python Web框架Django实现的。Hue可以使开发者在浏览器端的Web控制台上与Hadoop集群进行交互来分析处理数据，例如操作HDFS上的数据，运行MapReduce Job等等。</p>
<p>本篇中使用的HUE版本是3.9.0。(在实际生产中最好别使用3.9这个版本，因为这个版本的代码结构和3.7和3.10的代码都不一样)</p>
<a id="more"></a>
<h2 id="HUE-build"><a href="#HUE-build" class="headerlink" title="HUE build"></a>HUE build</h2><!-- 在centos虚拟机里编译，也就是hadoop的伪分布环境下-->
<p>HUE在使用之前要先对其进行编译，编译时需要安装一些依赖包，我的环境是centos，安装的依赖包如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install gcc gcc-c++ libffi-devel libxml2-devel libxslt-devel openldap-devel python-devel sqlite-devel openssl-devel gmp-devel cyrus-sasl-devel cyrus-sasl-gssapi cyrus-sasl-plain krb5-devel</span><br></pre></td></tr></table></figure>
<blockquote>
<p>mvn mysql mysql-devel JDK make 之前已离线安装<br>查看依赖包是否安装可以使用命令<code>rpm -q 依赖包名</code></p>
</blockquote>
<p>更详细的依赖包可以参考<a href="https://github.com/cloudera/hue" target="_blank" rel="noopener">此处</a></p>
<p>依赖包安装好之后，解压HUE的代码包，进入HUE_HOME，执行命令<code>make apps</code>。</p>
<blockquote>
<p>HUE默认是使用python2.6进行编译，如果你想使用别的版本python进行编译，只需更改HUE_HOME目录下的<code>Makefile.vars</code>，给变量<code>SYS_PYTHON</code>赋值为<code>python2.7</code>，代码为<code>SYS_PYTHON := python2.7</code></p>
</blockquote>
<h3 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h3><p>编译过程中遇到几个问题，都不是什么大问题，都是因为缺少依赖，安装相应的依赖即可。错误如下：</p>
<ul>
<li>src/_fastmath.c:36:18: error: gmp.h: No such file or directory </li>
</ul>
<p>执行命令 <code>sudo yum install gmp gmp-devel</code></p>
<ul>
<li>src/connection.h:33:21: error: sqlite3.h: No such file or directory</li>
</ul>
<p>执行命令 <code>sudo yum install sqlite-devel</code></p>
<ul>
<li>Modules/errors.h:8:18: error: lber.h: No such file or directory<br>Modules/errors.h:9:18: error: ldap.h: No such file or directory</li>
</ul>
<p>执行命令 <code>sudo yum install openldap-devel</code></p>
<h2 id="HUE-部署"><a href="#HUE-部署" class="headerlink" title="HUE 部署"></a>HUE 部署</h2><p>HUE的部署也比较简单，HUE的配置文件在<code>~/hue-3.9.0/desktop/conf</code>中，由于版本不一样，有的配置文件名是<em>pseudo-distributed.ini</em>，有的则是<em>hue.ini</em>，3.9.0的配置文件是hue.ini。</p>
<p>需要配置的属性如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line">[desktop]</span><br><span class="line">  <span class="comment"># Set this to a random string, the longer the better.</span></span><br><span class="line">  <span class="comment"># This is used for secure hashing in the session store.</span></span><br><span class="line">  <span class="comment"># 随意输入的字符，长度是30-60</span></span><br><span class="line">  secret_key=iowerwerwjdsfkjfksjdfiowjeiorujfklsjdf234</span><br><span class="line">  <span class="comment"># HUE所在机器的ip，也就是访问HUE的ip和端口</span></span><br><span class="line">  http_host=192.168.244.131</span><br><span class="line">  http_port=8888</span><br><span class="line">  <span class="comment"># Time zone name</span></span><br><span class="line">  time_zone=Asia/Shanghai</span><br><span class="line">  <span class="comment"># 运行hue进程的linux用户   </span></span><br><span class="line">  server_user=hadoop</span><br><span class="line">  server_group=hadoop</span><br><span class="line">  <span class="comment"># This should be the Hue admin and proxy user</span></span><br><span class="line">  default_user=hadoop</span><br><span class="line">  <span class="comment"># Hadoop集群的管理员用户</span></span><br><span class="line">  default_hdfs_superuser=hadoop</span><br><span class="line"></span><br><span class="line">[hadoop]</span><br><span class="line">  <span class="comment"># Configuration for HDFS NameNode</span></span><br><span class="line">  <span class="comment"># ------------------------------------------------------------------------</span></span><br><span class="line">  [[hdfs_clusters]]</span><br><span class="line">    <span class="comment"># HA support by using HttpFs</span></span><br><span class="line">    [[[default]]]</span><br><span class="line">      <span class="comment"># Enter the filesystem uri</span></span><br><span class="line">      <span class="comment"># core-site.xml里设置</span></span><br><span class="line">      fs_defaultfs=hdfs://centos:9000</span><br><span class="line">      <span class="comment"># Use WebHdfs/HttpFs as the communication mechanism.</span></span><br><span class="line">      <span class="comment"># Domain should be the NameNode or HttpFs host.</span></span><br><span class="line">      <span class="comment"># Default port is 14000 for HttpFs.</span></span><br><span class="line">      webhdfs_url=http://192.168.244.131:50070/webhdfs/v1</span><br><span class="line">      hadoop_conf_dir=<span class="variable">$HADOOP_CONF_DIR</span></span><br><span class="line">  [[yarn_clusters]]</span><br><span class="line">    [[[default]]]</span><br><span class="line">      <span class="comment"># Enter the host on which you are running the ResourceManager</span></span><br><span class="line">      resourcemanager_host=192.168.244.131</span><br><span class="line">      <span class="comment"># The port where the ResourceManager IPC listens on</span></span><br><span class="line">      resourcemanager_port=8032</span><br><span class="line">      <span class="comment"># Whether to submit jobs to this cluster</span></span><br><span class="line">      submit_to=True</span><br><span class="line"></span><br><span class="line">      <span class="comment"># URL of the ResourceManager API</span></span><br><span class="line">      resourcemanager_api_url=http://192.168.244.131:8088</span><br><span class="line">      <span class="comment"># URL of the HistoryServer API</span></span><br><span class="line">      history_server_api_url=http://192.168.244.131:19888</span><br><span class="line"></span><br><span class="line">[beeswax]</span><br><span class="line">  <span class="comment"># Host where HiveServer2 is running.</span></span><br><span class="line">  <span class="comment"># If Kerberos security is enabled, use fully-qualified domain name (FQDN).</span></span><br><span class="line">  <span class="comment"># hiveServer2所在的机器ip</span></span><br><span class="line">  hive_server_host=192.168.244.131</span><br><span class="line">  <span class="comment"># Port where HiveServer2 Thrift server runs on.</span></span><br><span class="line">  hive_server_port=10000</span><br><span class="line">  <span class="comment"># Hive configuration directory, where hive-site.xml is located</span></span><br><span class="line">  hive_conf_dir=/home/hadoop/hive/conf</span><br><span class="line"></span><br><span class="line">[zookeeper]</span><br><span class="line">  [[clusters]]</span><br><span class="line">    [[[default]]]</span><br><span class="line">      <span class="comment"># Zookeeper ensemble. Comma separated list of Host/Port.</span></span><br><span class="line">      <span class="comment"># e.g. localhost:2181,localhost:2182,localhost:2183</span></span><br><span class="line">      host_ports=192.168.244.131:2181</span><br></pre></td></tr></table></figure>
<p>配置好之后，并且hiveServer2也已经启动，则可以启动HUE，命令为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># HUE_HOME目录下</span></span><br><span class="line">build/env/bin/supervisor</span><br></pre></td></tr></table></figure>
<p>则可以通过192.168.244.131:8888访问。</p>
<h3 id="HUE数据库切换到Mysql"><a href="#HUE数据库切换到Mysql" class="headerlink" title="HUE数据库切换到Mysql"></a>HUE数据库切换到Mysql</h3><p>HUE中的信息，比如账号信息，默认是存储在sqlite3中的，在实际的生产环境中为了安全一般都会切换成Mysql数据库。切换mysql数据库的步骤如下：</p>
<p>1、先停止HUE，改配置文件</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[desktop]</span><br><span class="line">  [[database]]</span><br><span class="line">    <span class="comment"># Database engine is typically one of:</span></span><br><span class="line">    <span class="comment"># postgresql_psycopg2, mysql, sqlite3 or oracle.</span></span><br><span class="line">    <span class="comment">#</span></span><br><span class="line">    <span class="comment"># Note that for sqlite3, 'name', below is a path to the filename. For other backends, it is the database name.</span></span><br><span class="line">    <span class="comment"># Note for Oracle, options=&#123;"threaded":true&#125; must be set in order to avoid crashes.</span></span><br><span class="line">    <span class="comment"># Note for Oracle, you can use the Oracle Service Name by setting "port=0" and then "name=&lt;host&gt;:&lt;port&gt;/&lt;service_name&gt;".</span></span><br><span class="line">    <span class="comment"># Note for MariaDB use the 'mysql' engine.</span></span><br><span class="line">    engine=mysql</span><br><span class="line">    host=127.0.0.1</span><br><span class="line">    port=3306</span><br><span class="line">    user=root</span><br><span class="line">    password=root</span><br><span class="line">    <span class="comment">## 用于存放hue信息的数据库名</span></span><br><span class="line">    name=hue</span><br></pre></td></tr></table></figure>
<p>2、备份sqlite3中的数据库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## HUE_HOME目录下，备份的文件必须是json格式的</span></span><br><span class="line">sudo build/env/bin/hue dumpdata &gt; hue.json</span><br></pre></td></tr></table></figure>
<p>备份之后，打开hue.json并删除<em>model字段中带有useradmin.userprofile的所有JSON对象</em>。</p>
<p>3、在Mysql中创建配置文件中的hue数据库<code>create database hue;</code><br>4、同步表结构</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo build/env/bin/hue syncdb --noinput </span><br><span class="line">sudo build/env/bin/hue migrate</span><br></pre></td></tr></table></figure>
<p>5、查看是否需要删除外键<br>在mysql命令行中，先查看下<em>auth_permission</em>的建表语句，使用命令<code>show create table auth_permission;</code>，如果此表是InnoDB，则删除外键，命令为<em>ALTER TABLE auth_permission DROP FOREIGN KEY content_type_id_refs_id_XXXXXX;</em></p>
<p>6、删除<em>django_content_type</em>表中的数据，<code>DELETE FROM hue.django_content_type;</code></p>
<p>7、加载数据<code>build/env/bin/hue loaddata hue.json</code></p>
<p>8、如果步骤5中删除了外键，则需要添加外键，命令<code>ALTER TABLE auth_permission ADD FOREIGN KEY (</code>content_type_id<code>) REFERENCES</code>django_content_type<code>(</code>id<code>);</code></p>
<p>操作完并没有出现错误则启动HUE，此时数据库从sqlite切换到了Mysql中。</p>
<h3 id="部署Mysql-Editor"><a href="#部署Mysql-Editor" class="headerlink" title="部署Mysql Editor"></a>部署Mysql Editor</h3><p>HUE不仅可以操作Hadoop生态圈里的组件，还可以操作关系型数据库。</p>
<p>操作关系型数据库只需修改配置文件即可，以Mysql为例：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[librdbms]</span><br><span class="line">  [[databases]]</span><br><span class="line">     [[[mysql]]]</span><br><span class="line">      <span class="comment"># Name to show in the UI.</span></span><br><span class="line">      nice_name=<span class="string">"My SQL DB"</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># For MySQL and PostgreSQL, name is the name of the database.</span></span><br><span class="line">      <span class="comment"># For Oracle, Name is instance of the Oracle server. For express edition</span></span><br><span class="line">      <span class="comment"># this is 'xe' by default.</span></span><br><span class="line">      <span class="comment">## name=mysqldb</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># Database backend to use. This can be:</span></span><br><span class="line">      <span class="comment"># 1. mysql</span></span><br><span class="line">      <span class="comment"># 2. postgresql</span></span><br><span class="line">      <span class="comment"># 3. oracle</span></span><br><span class="line">      engine=mysql</span><br><span class="line"></span><br><span class="line">      <span class="comment"># IP or hostname of the database to connect to.</span></span><br><span class="line">      <span class="comment">## host=localhost</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># Port the database server is listening to. Defaults are:</span></span><br><span class="line">      <span class="comment"># 1. MySQL: 3306</span></span><br><span class="line">      <span class="comment"># 2. PostgreSQL: 5432</span></span><br><span class="line">      <span class="comment"># 3. Oracle Express Edition: 1521</span></span><br><span class="line">      <span class="comment">## port=3306</span></span><br><span class="line">      <span class="comment"># Username to authenticate with when connecting to the database.</span></span><br><span class="line">      user=root</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Password matching the username to authenticate with when</span></span><br><span class="line">      <span class="comment"># connecting to the database.</span></span><br><span class="line">      password=root</span><br><span class="line"></span><br><span class="line">      <span class="comment"># Database options to send to the server when connecting.</span></span><br><span class="line">      <span class="comment"># https://docs.djangoproject.com/en/1.4/ref/databases/</span></span><br><span class="line">      <span class="comment">## options=&#123;&#125;</span></span><br></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> HUE </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> 部署 </tag>
            
            <tag> build </tag>
            
            <tag> HUE </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HUE开发环境部署及app二次开发]]></title>
      <url>http://bigdatadecode.club/HUE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%E5%8F%8Aapp%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91.html</url>
      <content type="html"><![CDATA[<p>最近组里有个小需求要管理数字字典，数仓的字典在HUE中能够查看，但Mysql的字典呢？于是就想对HUE进行二次开发，增加一个App使其对Mysql的数字字典进行管理，也就是一个类似METASTORE TABLE的功能。</p>
<a id="more"></a>
<h2 id="准备开发环境"><a href="#准备开发环境" class="headerlink" title="准备开发环境"></a>准备开发环境</h2><blockquote>
<p>导入IDE的HUE工程不是源代码，而是已经build成功的HUE工程。</p>
</blockquote>
<h3 id="eclipse-pydev插件安装"><a href="#eclipse-pydev插件安装" class="headerlink" title="eclipse pydev插件安装"></a>eclipse pydev插件安装</h3><p>本来想用Intellij idea的，由于Intellij是在物理机(windows)上安装的，但HUE在windows下编译比较费劲，而之前HUE已在虚拟机中编译成功，虚机中又刚好有个eclipse，就选择用eclipse进行开发了。</p>
<p>IDE选好，就是为eclipse安装插件使其能够进行python开发，安装的插件是<a href="http://pydev.org/updates" target="_blank" rel="noopener">pydev</a>，安装方法分为<em>在线</em>和<em>离线</em>两种，在线在虚机中的eclipse总是有点问题，显示插件安装成功可是总是找不到，换了n个版本的eclipse依然不行。就只好离线安装了，在<a href="http://sourceforge.net/projects/pydev/files/pydev/" target="_blank" rel="noopener">http://sourceforge.net/projects/pydev/files/pydev/</a>下载安装包，解压之后将<em>features</em>和<em>plugins</em>复制到eclipse的home目录下。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp -r /pydev_home/features /eclipse_home/</span><br><span class="line">cp -r /pydev_home/plugins /eclipse_home/</span><br></pre></td></tr></table></figure>
<h3 id="将HUE导入IDE-eclipse"><a href="#将HUE导入IDE-eclipse" class="headerlink" title="将HUE导入IDE eclipse"></a>将HUE导入IDE eclipse</h3><p>1、python插件安装好之后，就是<em>为HUE单独设置python环境</em>，之所以单独设置python环境，是因为HUE在build的时候已经将所依赖的python包下载至/HUE_HOME/build/env/中，为HUE设置python环境</p>
<p>单击<code>Window-&gt;Preferences</code>，找到安装好的python插件<em>PyDev</em>，通过右侧的new选择<em>/home/hadoop/hue-3.9.0/build/env/bin/python</em>，如图<br><img src="/blogimgs/HUE App/HUE_Python.png" alt="HUE python环境" title="HUE python环境"></p>
<p>2、在eclipse中新建一个python django项目并导入HUE工程<br>选择django项目<br><img src="/blogimgs/HUE App/new_project.png" alt="新建django项目" title="新建django项目"></p>
<p>下一步选择HUE相关的设置，如下图：<br><img src="/blogimgs/HUE App/new_project_2.png" alt="导入HUE" title="导入HUE"><br>其中<code>1</code>是新建django项目的名字，由于要导入已有项目，则将<code>2</code>勾选去掉，接着在<code>3</code>处选择hue的安装目录(<em>我这编译目录和安装目录是同一个目录</em>)，别忘了在<code>4</code>处选择上一步中单独为hue设置的python环境。</p>
<p>3、设置myHue工程<br>设置项目属性，内容如下图(<em>设置的两个文件都提示未找到，不知何原因，是否有影响</em>)，<br><img src="/blogimgs/HUE App/new_project_3.png" alt="项目属性" title="项目属性"></p>
<p>4、debug启动HUE<br>单击<code>run-&gt;DEBUG Configurations</code>，双击<code>PyDev Django</code><br><img src="/blogimgs/HUE App/new_project_4.png" alt="debug启动" title="debug启动"></p>
<blockquote>
<p>主模块设为buid/env/bin/hue,在有些eclipse中会报找不到该文件的提示，此时可以将hue拷贝为hue.py,刷新项目后再用Main Module右边的Browse按扭选取该hue.py,或直接输入${workspace_loc:hue/build/env/bin/hue.py}做为主模块。</p>
</blockquote>
<p>启动hue时还需输入参数，在<em>Arguements</em>选项中输入<code>runcherrypyserver</code>，如图<br><img src="/blogimgs/HUE App/new_project_5.png" alt="debug启动" title="debug启动"></p>
<p>5、最后还得修改一处代码，在<code>desktop/core/src/desktop/appmanager.py</code>中的<code>_import_module_or_none</code>方法<code>my_file = re.sub(r&#39;\.pyc&#39;,&#39;.py&#39;, __file__)</code>处添加<code>return None</code>，将后面的内容注释掉，完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_import_module_or_none</span><span class="params">(module)</span>:</span></span><br><span class="line">  <span class="string">"""Like import_module, but returns None if the module does not exist.</span></span><br><span class="line"><span class="string">  This will properly handle nested ImportErrors in such a way that, if the</span></span><br><span class="line"><span class="string">  module should exist but throws ImportError, we *will* raise through</span></span><br><span class="line"><span class="string">  that error.</span></span><br><span class="line"><span class="string">  """</span></span><br><span class="line">  <span class="keyword">try</span>:</span><br><span class="line">    __import__(module)</span><br><span class="line">    <span class="keyword">return</span> sys.modules[module]</span><br><span class="line">  <span class="keyword">except</span> ImportError, ie:</span><br><span class="line">    <span class="comment"># If the exception came from us importing, we want to just</span></span><br><span class="line">    <span class="comment"># return None. We need to inspect the stack, though, so we properly</span></span><br><span class="line">    <span class="comment"># reraise in the case that the module we're importing triggered</span></span><br><span class="line">    <span class="comment"># an import error itself.</span></span><br><span class="line">    tb = sys.exc_info()[<span class="number">2</span>]</span><br><span class="line">    top_frame = traceback.extract_tb(tb)[<span class="number">-1</span>]</span><br><span class="line">    err_file = re.sub(<span class="string">r'\.pyc'</span>,<span class="string">'.py'</span>, top_frame[<span class="number">0</span>])</span><br><span class="line">    my_file = re.sub(<span class="string">r'\.pyc'</span>,<span class="string">'.py'</span>, __file__)</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">None</span></span><br><span class="line"><span class="comment">#    if err_file == my_file:</span></span><br><span class="line"><span class="comment">#      return None</span></span><br><span class="line"><span class="comment">#    else:</span></span><br><span class="line"><span class="comment">#      LOG.error("Failed to import '%s'" % (module,))</span></span><br><span class="line"><span class="comment">#      raise</span></span><br></pre></td></tr></table></figure>
<p><strong>随后就可以在python代码中设置断点，启动debug配置进行调试。</strong></p>
<h2 id="App开发demo实例"><a href="#App开发demo实例" class="headerlink" title="App开发demo实例"></a>App开发demo实例</h2><p>App开发其实也比较简单，文档说的还算详细，但往往实际操作时难免会遇到一些错误，下面就来看下我在开发这个demo的过程中遇到的一些问题，<em>我使用的版本是3.9.0，版本不一样遇到的问题可能也不一样</em>。</p>
<p>1、在HUE_HOME目录下cd到apps目录，<em>之所以要cd到apps目录，因为随后执行的创建app的命令会在当前目录下新建app目录，为了将所有的app放在apps目录下</em>，所以要先cd到apps目录。</p>
<p>2、在apps目录下执行新建命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">../build/env/bin/hue create_desktop_app mytest</span><br></pre></td></tr></table></figure>
<p>新建之后，文档的下一步是执行注册app，但是经我实测，3.9.0还需进行一些修改，如下：<br>3、修改新建App mytest目录下的Makefile，增加<code>APP_NAME = mytest</code></p>
<p>4、更改App mytest的static的目录结构。进入<code>/home/hadoop/hue-3.9.0/apps/mytest/src/mytest/static</code>目录，新建App同名的文件夹mytest，将原static目录下的文件移到新建的mytest文件夹中。如果此步没有执行的话，该App的<em>一些静态文件就会找不到，出现404错误</em>，<code>Http404: &quot;/home/hadoop/hue-3.9.0/build/static/mytest/art/icon_mytest_48.32900276221d.png&quot; 不存在</code></p>
<p>5、可以在App mytest目录下的setup.py文件中修改下该app的一些信息，比如 描述信息、作者等等。。。</p>
<p>6、修改代码。修改mytest中的shared_components.mako代码，将<code>&lt;img src=&quot;${ static(mytest + &#39;/art/icon_mytest_48.png&#39;) }&quot; class=&quot;app-icon&quot; /&gt;</code><br>中的mytest加上引号，否则会报<code>TypeError: unsupported operand type(s) for +: &#39;Undefined&#39; and &#39;str&#39;</code></p>
<p>7、接下来就是注册App，依然是在apps目录下执行命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">../build/env/bin/python ../tools/app_reg/app_reg.py --install mytest --relative-paths</span><br></pre></td></tr></table></figure>
<blockquote>
<p>可以使用命令<code>build/env/bin/python tools/app_reg/app_reg.py --list</code> 查看已安装app的信息。</p>
</blockquote>
<!-- build/env/bin/python tools/app_reg/app_reg.py --list 2>&1 | grep mytest -->
<p>现在就可以正常访问页面了。此时只是一个类似hello-world的功能，我们在此基础上再增加一点小功能，一个小小的计算器。</p>
<p>8、HUE的template语言是用mako写的，则修改<code>mytest/src/mytest/templates/index.mako</code>文件，内容如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;%!<span class="keyword">from</span> desktop.views <span class="keyword">import</span> commonheader, commonfooter %&gt;</span><br><span class="line">&lt;%namespace name=<span class="string">"shared"</span> file=<span class="string">"shared_components.mako"</span> /&gt;</span><br><span class="line"></span><br><span class="line">$&#123;commonheader(<span class="string">"mytest"</span>, <span class="string">"mytest"</span>, user, <span class="string">"100px"</span>) | n,unicode&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">## Main body</span></span><br><span class="line"></span><br><span class="line">&lt;div class="container-fluid"&gt;</span><br><span class="line">% <span class="keyword">if</span> op:</span><br><span class="line">&lt;span&gt;$&#123;a&#125; $&#123;op&#125; $&#123;b&#125; = $&#123;result&#125;&lt;/span&gt;</span><br><span class="line">% endif</span><br><span class="line">&lt;form action=$&#123;url(<span class="string">"mytest.views.index"</span>)&#125; method=POST&gt;</span><br><span class="line">    &lt;input name=<span class="string">"a"</span>&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="add"&gt;+&lt;/input&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="subtract"&gt;-&lt;/input&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="multiply"&gt;*&lt;/input&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="divide"&gt;/&lt;/input&gt;</span><br><span class="line">    &lt;input name=<span class="string">"b"</span>&gt;</span><br><span class="line">    &lt;input type=<span class="string">"submit"</span> value=<span class="string">"Calculate"</span>&gt;</span><br><span class="line">&lt;/form&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">$&#123;commonfooter(messages) | n,unicode&#125;</span><br></pre></td></tr></table></figure>
<p>现在页面已经写好，接下来就是views里的计算逻辑了，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> desktop.lib.django_util <span class="keyword">import</span> render</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line">OPS=dict(add=operator.add, subtract=operator.sub, multiply=operator.mul, divide=operator.truediv)</span><br><span class="line">OP_STRING=dict(add=<span class="string">"+"</span>, subtract=<span class="string">"-"</span>, multiply=<span class="string">"*"</span>, divide=<span class="string">"/"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">index</span><span class="params">(request)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="string">"op"</span> <span class="keyword">not</span> <span class="keyword">in</span> request.REQUEST:</span><br><span class="line">        <span class="keyword">return</span> render(<span class="string">'index.mako'</span>, request, dict())</span><br><span class="line">    a = float(request.REQUEST[<span class="string">"a"</span>])</span><br><span class="line">    b = float(request.REQUEST[<span class="string">"b"</span>])</span><br><span class="line">    op = request.REQUEST[<span class="string">"op"</span>]</span><br><span class="line">    result = OPS[op](a, b)</span><br><span class="line">    <span class="keyword">return</span> render(<span class="string">'index.mako'</span>, request,</span><br><span class="line">dict(a=a, b=b, op=OP_STRING[op], result=result))</span><br></pre></td></tr></table></figure>
<p>此时就可以去测试下mytest的新功能了，很不幸报错了，错误信息如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CSRF Error (403)</span><br><span class="line">Sorry, your session is invalid or has expired. Please go back, refresh the page, and try your submission again.</span><br></pre></td></tr></table></figure>
<p>CSRF(Cross-site request forgery 跨站请求伪造)失败，在index.mako中添加<code>${ csrf_token(request) | n,unicode }</code>即可，正确代码如下：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;form action=$&#123;url(<span class="string">"mytest.views.index"</span>)&#125; method=POST&gt;</span><br><span class="line">    $&#123; csrf_token(request) | n,unicode &#125;</span><br><span class="line">    &lt;input name=<span class="string">"a"</span>&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="add"&gt;+&lt;/input&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="subtract"&gt;-&lt;/input&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="multiply"&gt;*&lt;/input&gt;</span><br><span class="line">    &lt;input type="radio" name="op" value="divide"&gt;/&lt;/input&gt;</span><br><span class="line">    &lt;input name=<span class="string">"b"</span>&gt;</span><br><span class="line">    &lt;input type=<span class="string">"submit"</span> value=<span class="string">"Calculate"</span>&gt;</span><br><span class="line">&lt;/form&gt;</span><br></pre></td></tr></table></figure>
<p>最后看下页面吧，<br><img src="/blogimgs/HUE App/app_demo_done.png" alt="app_demo" title="app_demo"></p>
<p>Done。。。。</p>
<h2 id="Mysql元数据管理App开发"><a href="#Mysql元数据管理App开发" class="headerlink" title="Mysql元数据管理App开发"></a>Mysql元数据管理App开发</h2><p>Mysql元数据管理功能是一个类似hive元数据管理的管理模块，可以查看mysql数据库中的databases和tables以及修改他们的COMMENT信息。具体实现是拷贝hive元数据管理的代码，在此基础上进行了修改，完成此功能的，目前只支持mysql，且要使用此功能时需要配置DB query功能。</p>
<blockquote>
<p>此功能是在hue3.7版本上开发的。</p>
</blockquote>
<p>下面就看几个页面吧，代码随后整理下会把链接放出来。<br><img src="/blogimgs/HUE App/mysql_01.png" alt="msyql_01" title="mysql_01"><br><img src="/blogimgs/HUE App/mysql_02.png" alt="mysql_02" title="mysql_02"></p>
<p>开发起来难度不是很大，不能不说大神写的代码就是强，有些代码虽然看不懂，但一改就实现了想要的功能，接口性特别强。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://wanshi.iteye.com/blog/2173415" target="_blank" rel="noopener">http://wanshi.iteye.com/blog/2173415</a><br><a href="http://cloudera.github.io/hue/docs-3.7.0/sdk/sdk.html#fast-guide-to-creating-a-new-hue-application" target="_blank" rel="noopener">http://cloudera.github.io/hue/docs-3.7.0/sdk/sdk.html#fast-guide-to-creating-a-new-hue-application</a></p>
]]></content>
      
        <categories>
            
            <category> HUE </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> HUE </tag>
            
            <tag> 开发环境 </tag>
            
            <tag> app二次开发 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS租约解析]]></title>
      <url>http://bigdatadecode.club/HDFS%E7%A7%9F%E7%BA%A6%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p>租约(Lease)是一种广泛应用与分布式系统领域的协议，主要用来维护分布式系统的一致性。</p>
<p>租约是在解决缓存一致性时被提出的。所谓租约，其实就是一个_合同<em>，即服务器给予</em>客户端_在<em>一定期限</em>内可以<em>控制修改操作</em>的权力。<em>如果服务器要修改数据，首先要征求拥有这块数据的租约的客户端的同意，之后才可以修改。</em>客户端从服务器读取数据时往往就同时获取租约，在租约期限内，如果没有收到服务器的修改请求，就可以保证当前缓存中的内容就是最新的。如果在租约期限内收到了修改数据的请求并且同意了，就需要清空缓存。在租约过 期以后，客户端如果还要从缓存读取数据，就必须重新获取租约，我们称这个操作为续约。</p>
<a id="more"></a>
<h2 id="租约特性"><a href="#租约特性" class="headerlink" title="租约特性"></a>租约特性</h2><p>租约的一个重要的属性就是<em>期限</em>，一般情况下，应当选择较短的租约期限。与长租约相比，短租约有三个优点。首先，在失效情况下修改操作往往需要等待租约过期，因此短租约就意味着更短的失效延迟 。其次，<em>就算一个客户端已经不再需要读取数据，但在其租约过期前，任何的修改操作仍然需要征求它的同意，这种情况叫做“假共享”</em>，显然租约期限越长，这个问题就越严重。最后，短租约也使得服务器要维护的客户端信息更少。然而短租约也意味着更大的续约开销，因此对于要反复读取却很少修改的数据，长租约会更有效。因此，对租约期的选择要权衡失效延迟、假共享开销和续约开销等多个因素，服务器可以根据数据访问特性和客户端的性质灵活设置期限。事实上，如果我们把租约期限设为零，就相当于<em>轮询</em>，此时修改操作随时可以进行，而读取数据总是要联系服务器。如果把租约期 限设为无限长，就相当于<em>回调</em>。</p>
<p>除了期限的选择，还有很多管理选项。对客户端来说，可以选择是否续约、何时续约以及是否同意修改等。比如为了减少读取延迟，客户端可以在租约过期前就续约，不过这样可能加重服务器的负担。对服务器来说，可以选择是否发放租约、租约覆盖粒度以及对如何进行修改操作。比如在收到修改请求后，服务器可以不征求客户端同意，而是简单的等待所有租约过期（等待时不再发放新租约以避免无限期的延迟）。对于“安装文件”，也就是修改极少的文件（比如头文件、库文件），服务器可以用一个租约来覆盖一批文件，同时定期广播续约通知来节省开销，如果需要修改数据，就停止广播并等待租约过期即可。</p>
<p>在很多时候，租约的定义似乎很模糊，有的时候租约类似<em>心跳</em>，有的时候又类似于<em>锁(读锁和写锁)</em>。到底租约的本质是什么呢？<br>回到租约最原始的定义：<strong>租约就是在一定期限内给予持有者特定权力的协议</strong>。我觉得这里的期限就是租约的根本特性，正是这一特性使得租约可以容忍机器失效和网络分割。在期限之内，租约其实就是服务器和客户端之间的协议，而这个协议的内容可以五花八门。<em>如果协议内容是服务器确认客户端还存活，那么这个租约的功能就相当于心跳</em>；<em>如果协议内容是服务器保证内容不会被修改，那么这个租约就相当于读锁</em>；<em>如果协议内容是服务器保证内容只能被这个客户端修改，那么这个租约就相当于写锁</em>。租约这种灵活性和容错性，使其成为了维护分布式系统一致性的有效工具。</p>
<h2 id="租约在HDFS中的应用–写锁"><a href="#租约在HDFS中的应用–写锁" class="headerlink" title="租约在HDFS中的应用–写锁"></a>租约在HDFS中的应用–写锁</h2><p>hdfs支持write-once-read-many，也就是说不支持并行写，那么对读写的互斥同步就是靠Lease实现的。Lease说白了就是一个有时间约束的锁。客户端写文件时需要先申请一个Lease，持有该租约的客户端才可以对相应的文件进行块的添加。</p>
<p>与租约相关的类有：</p>
<p>Server端：<br>LeaseManager – 管理写文件相关的租约<br>LeaseManager.Monitor – 监控租约是否过期(主要检查hardLimit)<br>LeaseManager.Lease – 租约实体类，管理某个客户端持有的所以写锁</p>
<p>Client端：<br>LeaseRenewer – 客户端续约更新类<br>下面先简单介绍下各类的内部结构</p>
<h3 id="Lease"><a href="#Lease" class="headerlink" title="Lease"></a>Lease</h3><p>Lease是LeaseManager的内部类，其实例对应一个租约，租约中包含持有者信息、租约期限和该租约对应的文件。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Lease</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Lease</span>&gt; </span>&#123;</span><br><span class="line">  <span class="comment">// 租约持有者(持有租约的客户端名字)</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String holder;</span><br><span class="line">  <span class="comment">// 租约更新的时间</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> lastUpdate;</span><br><span class="line">  <span class="comment">// 该租约中包含的文件(包含持有该租约的客户端所打开的所有文件)</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Collection&lt;String&gt; paths = <span class="keyword">new</span> TreeSet&lt;String&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一个客户端对应一个租约，一个客户端可以同时写很多个文件，这些文件放在<code>paths</code>中，租约维护着这些文件的写权限，并<em>对这些文件统一续约，并不是对某个文件单独续约</em>，不需要对某个文件进行操作之后直接从<code>paths</code>中移除，如果<code>paths</code>为null，则回收此租约。</p>
<h3 id="LeaseManager"><a href="#LeaseManager" class="headerlink" title="LeaseManager"></a>LeaseManager</h3><p>LeaseManager是租约管理类，其内部主要维护了3个集合列表(leases、sortedLeases和sortedLeasesByPath)和两个变量(softLimit和hardLimit)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 软限制就是写文件时规定的租约超时时间，默认是60s</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> softLimit = HdfsConstants.LEASE_SOFTLIMIT_PERIOD;</span><br><span class="line"><span class="comment">// 硬限制则是考虑到文件close时未来得及释放lease的情况强制回收租约，默认是1h</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> hardLimit = HdfsConstants.LEASE_HARDLIMIT_PERIOD;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Used for handling lock-leases</span></span><br><span class="line"><span class="comment">// Mapping: leaseHolder -&gt; Lease</span></span><br><span class="line"><span class="comment">// 租约持有者和租约的映射</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> SortedMap&lt;String, Lease&gt; leases = <span class="keyword">new</span> TreeMap&lt;String, Lease&gt;();</span><br><span class="line"><span class="comment">// Set of: Lease</span></span><br><span class="line"><span class="comment">// 存储nn所发放的所有租约</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> SortedSet&lt;Lease&gt; sortedLeases = <span class="keyword">new</span> TreeSet&lt;Lease&gt;();</span><br><span class="line"></span><br><span class="line"><span class="comment">// </span></span><br><span class="line"><span class="comment">// Map path names to leases. It is protected by the sortedLeases lock.</span></span><br><span class="line"><span class="comment">// The map stores pathnames in lexicographical order.</span></span><br><span class="line"><span class="comment">// 路径和租约的映射</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> SortedMap&lt;String, Lease&gt; sortedLeasesByPath = <span class="keyword">new</span> TreeMap&lt;String, Lease&gt;();</span><br></pre></td></tr></table></figure>
<p>在softLimit期限内，该客户端拥有对这个文件的独立访问权，其他客户端不能剥夺该客户端独占写这个文件的权利。<br>softLimit过期后，任何一个客户端都可以回收lease，继而得到这个文件的lease，获得对这个文件的独占访问权。<br>hardLimit过期后，namenode强制关闭文件，撤销lease。</p>
<p>sortedLeases中存放这从nn发出的所有租约，其中Lease按照时间顺序排序，Monitor检查hardLimit时，从sortedLeases中按照顺序拿出Lease检查就可以了。</p>
<h3 id="Monitor"><a href="#Monitor" class="headerlink" title="Monitor"></a>Monitor</h3><p>Monitor是一个Runnable类，主要用来检测Lease<em>是否超过了hardLimit期限</em>。在run中调用LeaseManager.checkLeases方法进行检测。其周期性是(2s)</p>
<h3 id="LeaseRenewer"><a href="#LeaseRenewer" class="headerlink" title="LeaseRenewer"></a>LeaseRenewer</h3><p>LeaseRenewer是client端更新自己租约。其中有个<em>线程检测租约的softLimit期限</em>，其周期性(1s)的调用LeaseRenewer.run()方法对租约过半的lease进行续约。</p>
<p>LeaseRenewer是一个单例，并通过工厂来实例化。这里的单例是一个user一个LeaseRenewer，但是服务器端是一个DFSClient对应一个lease，<em>一个user可能会实例化多个DFSClient，则LeaseRenewer会有个list属性来存储多个DFSClient，这个list就是dfsclients</em>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LeaseRenewer</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">final</span> Log LOG = LogFactory.getLog(LeaseRenewer.class);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> LEASE_RENEWER_GRACE_DEFAULT = <span class="number">60</span>*<span class="number">1000L</span>;</span><br><span class="line">  <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> LEASE_RENEWER_SLEEP_DEFAULT = <span class="number">1000L</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** Get a &#123;<span class="doctag">@link</span> LeaseRenewer&#125; instance */</span></span><br><span class="line">  <span class="comment">// 通过静态方法调用工厂类得到一个user对应的LeaseRenewer实例</span></span><br><span class="line">  <span class="function"><span class="keyword">static</span> LeaseRenewer <span class="title">getInstance</span><span class="params">(<span class="keyword">final</span> String authority,</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">final</span> UserGroupInformation ugi, <span class="keyword">final</span> DFSClient dfsc)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> LeaseRenewer r = Factory.INSTANCE.get(authority, ugi);</span><br><span class="line">    r.addClient(dfsc);</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/** </span></span><br><span class="line"><span class="comment">   * A factory for sharing &#123;<span class="doctag">@link</span> LeaseRenewer&#125; objects</span></span><br><span class="line"><span class="comment">   * among &#123;<span class="doctag">@link</span> DFSClient&#125; instances</span></span><br><span class="line"><span class="comment">   * so that there is only one renewer per authority per user.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="comment">// 工厂类，实例化LeaseRenewer</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Factory</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Factory INSTANCE = <span class="keyword">new</span> Factory();</span><br><span class="line">    <span class="comment">// 由存放namenode信息的authority和user信息的ugi唯一标识LeaseRenewer实例</span></span><br><span class="line">    <span class="comment">// 即一个user一个LeaseRenewer</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Key</span> </span>&#123;</span><br><span class="line">      <span class="comment">/** Namenode info */</span></span><br><span class="line">      <span class="keyword">final</span> String authority;</span><br><span class="line">      <span class="comment">/** User info */</span></span><br><span class="line">      <span class="keyword">final</span> UserGroupInformation ugi;</span><br><span class="line"></span><br><span class="line">      <span class="function"><span class="keyword">private</span> <span class="title">Key</span><span class="params">(<span class="keyword">final</span> String authority, <span class="keyword">final</span> UserGroupInformation ugi)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (authority == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> HadoopIllegalArgumentException(<span class="string">"authority == null"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ugi == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> HadoopIllegalArgumentException(<span class="string">"ugi == null"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">this</span>.authority = authority;</span><br><span class="line">        <span class="keyword">this</span>.ugi = ugi;</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** A map for per user per namenode renewers. */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;Key, LeaseRenewer&gt; renewers = <span class="keyword">new</span> HashMap&lt;Key, LeaseRenewer&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Get a renewer. */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> LeaseRenewer <span class="title">get</span><span class="params">(<span class="keyword">final</span> String authority,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">final</span> UserGroupInformation ugi)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">final</span> Key k = <span class="keyword">new</span> Key(authority, ugi);</span><br><span class="line">      LeaseRenewer r = renewers.get(k);</span><br><span class="line">      <span class="keyword">if</span> (r == <span class="keyword">null</span>) &#123;</span><br><span class="line">        r = <span class="keyword">new</span> LeaseRenewer(k);</span><br><span class="line">        renewers.put(k, r);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> r;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/** Remove the given renewer. */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">(<span class="keyword">final</span> LeaseRenewer r)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">final</span> LeaseRenewer stored = renewers.get(r.factorykey);</span><br><span class="line">      <span class="comment">//Since a renewer may expire, the stored renewer can be different.</span></span><br><span class="line">      <span class="keyword">if</span> (r == stored) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!r.clientsRunning()) &#123;</span><br><span class="line">          renewers.remove(r.factorykey);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 单例模式中，构造方法私有</span></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="title">LeaseRenewer</span><span class="params">(Factory.Key factorykey)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.factorykey = factorykey;</span><br><span class="line">    unsyncSetGraceSleepPeriod(LEASE_RENEWER_GRACE_DEFAULT);</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="租约-–-写锁流程"><a href="#租约-–-写锁流程" class="headerlink" title="租约 – 写锁流程"></a>租约 – 写锁流程</h2><h3 id="新增写租约"><a href="#新增写租约" class="headerlink" title="新增写租约"></a>新增写租约</h3><p>充当写锁的租约是client发起写请求时，一起跟nn申请的(其具体的写操作流程请看之前的文章<a href="http://bigdatadecode.club/HDFS write解析.html">HDFS write解析</a>)，client向nn申请写操作的流程为：<br><code>FileSystem.create() --&gt; DistributedFileSystem.create() --&gt; FileSystemLinkResolver.resolve() --&gt; doCall() --&gt; dfs.create() --&gt; DFSOutputStream.newStreamForCreate() --&gt; dfsClient.namenode.create() --&gt; namesystem.startFile() -&gt; startFileInt() -&gt; startFileInternal()</code>。在startFileInternal中通过<code>newNode = dir.addFile(src, permissions, replication, blockSize, holder, clientMachine);</code>向namenode中添加一个文件，并将clientname对src的租约进行存储<code>leaseManager.addLease(newNode.getFileUnderConstructionFeature().getClientName(), src);</code>，这里addLease就是client申请租约，看下代码逻辑：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LeaseManager.class</span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> Lease <span class="title">addLease</span><span class="params">(String holder, String src)</span> </span>&#123;</span><br><span class="line">  Lease lease = getLease(holder);</span><br><span class="line">  <span class="keyword">if</span> (lease == <span class="keyword">null</span>) &#123;</span><br><span class="line">    lease = <span class="keyword">new</span> Lease(holder);</span><br><span class="line">    leases.put(holder, lease);</span><br><span class="line">    sortedLeases.add(lease);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    renewLease(lease);</span><br><span class="line">  &#125;</span><br><span class="line">  sortedLeasesByPath.put(src, lease);</span><br><span class="line">  lease.paths.add(src);</span><br><span class="line">  <span class="keyword">return</span> lease;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在nn端一个Lease对应一个DFSClient(DFSClient是由ugi构造的，不是指hadoop集群的client那台机器)，Lease是由holder标识的，holder的值就是DFSClient.clientName，clientName在DFSClient的构造函数中初始化，代码如下:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">taskId = conf.get(<span class="string">"mapreduce.task.attempt.id"</span>, <span class="string">"NONMAPREDUCE"</span>);</span><br><span class="line"><span class="keyword">this</span>.clientName = <span class="string">"DFSClient_"</span> + dfsClientConf.taskId + <span class="string">"_"</span> + </span><br><span class="line">        DFSUtil.getRandom().nextInt()  + <span class="string">"_"</span> + Thread.currentThread().getId();</span><br></pre></td></tr></table></figure>
<p>clientName是由taskId、随机数和currentThread.Id拼起来的，所以<em>每次写请求的clientName是不一样的，则Lease也是不一样的</em>。</p>
<p>addLease的逻辑是先从LeaseManager.leases(holder和lease映射)中查找是否存在holder对应的lease，不存在则由LeaseManager创建一个lease，存在则更新lease。LeaseManager通过实例化Lease类来创建租约，Lease的构造方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">Lease</span><span class="params">(String holder)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.holder = holder;</span><br><span class="line">  renew();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">renew</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.lastUpdate = now();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>new出lease后，将其放入LeaseManager中的三个集合中，并把此租约对应的path放入lease的paths中。</p>
<p>租约添加完成。</p>
<h3 id="客户端续约"><a href="#客户端续约" class="headerlink" title="客户端续约"></a>客户端续约</h3><p>客户端在dfs.create()中调用beginFileLease()对租约进行续约。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">beginFileLease</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> inodeId, <span class="keyword">final</span> DFSOutputStream out)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  getLeaseRenewer().put(inodeId, out, <span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端续约是通过LeaseRenewer来实现的，LeaseRenewer是由存放namenode信息的authority和user信息的ugi来实例化的。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DFSClient.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> LeaseRenewer <span class="title">getLeaseRenewer</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> LeaseRenewer.getInstance(authority, ugi, <span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// LeaseRenewer.class</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> LeaseRenewer <span class="title">getInstance</span><span class="params">(<span class="keyword">final</span> String authority,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> UserGroupInformation ugi, <span class="keyword">final</span> DFSClient dfsc)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> LeaseRenewer r = Factory.INSTANCE.get(authority, ugi);</span><br><span class="line">  r.addClient(dfsc);</span><br><span class="line">  <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// LeassRenewer.Factory.class</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> LeaseRenewer <span class="title">get</span><span class="params">(<span class="keyword">final</span> String authority,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> UserGroupInformation ugi)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> Key k = <span class="keyword">new</span> Key(authority, ugi);</span><br><span class="line">  LeaseRenewer r = renewers.get(k);</span><br><span class="line">  <span class="keyword">if</span> (r == <span class="keyword">null</span>) &#123;</span><br><span class="line">    r = <span class="keyword">new</span> LeaseRenewer(k);</span><br><span class="line">    renewers.put(k, r);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>LeaseRenewer的实例化是通过Factory实例化的，Factory先去renewers中查找是否有当前user的LeaseRenewer，没有则new一个，有则直接返回已有的LeaseRenewer，然后在getInstance中，将DFSClient的实例dfsc放入LeaseRenewer的dfsclients的list中。user对应的LeaseRenewer对象初始化完毕。</p>
<p>然后调用put方法将<em>文件标识Id、对应的文件流和DFSClient实例</em>传入LeaseRenewer中，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> inodeId, <span class="keyword">final</span> DFSOutputStream out,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DFSClient dfsc)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (dfsc.isClientRunning()) &#123;</span><br><span class="line">    <span class="comment">// 判断daemon是否在运行，</span></span><br><span class="line">    <span class="comment">// 或者检查dfsclients为空之后的时间是否超过了gracePeriod</span></span><br><span class="line">    <span class="comment">// 如果daemon没有运行或者为空的时间超过了gracePeriod则新new一个守护线程</span></span><br><span class="line">    <span class="keyword">if</span> (!isRunning() || isRenewerExpired()) &#123;</span><br><span class="line">      <span class="comment">//start a new deamon with a new id.</span></span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">int</span> id = ++currentId;</span><br><span class="line">      daemon = <span class="keyword">new</span> Daemon(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"Lease renewer daemon for "</span> + clientsString()</span><br><span class="line">                  + <span class="string">" with renew id "</span> + id + <span class="string">" started"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            LeaseRenewer.<span class="keyword">this</span>.run(id);</span><br><span class="line">          &#125; <span class="keyword">catch</span>(InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(LeaseRenewer.<span class="keyword">this</span>.getClass().getSimpleName()</span><br><span class="line">                  + <span class="string">" is interrupted."</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(LeaseRenewer.<span class="keyword">this</span>) &#123;</span><br><span class="line">              Factory.INSTANCE.remove(LeaseRenewer.<span class="keyword">this</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"Lease renewer daemon for "</span> + clientsString()</span><br><span class="line">                  + <span class="string">" with renew id "</span> + id + <span class="string">" exited"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> String.valueOf(LeaseRenewer.<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      daemon.start();</span><br><span class="line">    &#125;</span><br><span class="line">    dfsc.putFileBeingWritten(inodeId, out);</span><br><span class="line">    emptyTime = Long.MAX_VALUE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在put中有个守护线程，在守护线程中调用<code>LeaseRenewer.run</code>方法对租约进行check然后renew，这里<em>check的是softLimit</em>。<em>守护线程只有在daemon为null或者dfsclients为空的时间超过了gracePeriod时才需要重新new一个daemon线程</em>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> id)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">long</span> lastRenewed = Time.now(); !Thread.interrupted();</span><br><span class="line">      Thread.sleep(getSleepPeriod())) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">long</span> elapsed = Time.now() - lastRenewed;</span><br><span class="line">    <span class="comment">// 判断是否超过了softLimit的一半</span></span><br><span class="line">    <span class="keyword">if</span> (elapsed &gt;= getRenewalTime()) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">      	<span class="comment">// 续约</span></span><br><span class="line">        renew();</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// 更新续约时间</span></span><br><span class="line">        lastRenewed = Time.now();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (SocketTimeoutException ie) &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>run中调用renew()进行续约，这里续约是对当前user的所有DFSClient(<em>也就是当前user的所有Lease</em>)进行续约。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">renew</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> List&lt;DFSClient&gt; copies;</span><br><span class="line">  <span class="keyword">synchronized</span>(<span class="keyword">this</span>) &#123;</span><br><span class="line">    copies = <span class="keyword">new</span> ArrayList&lt;DFSClient&gt;(dfsclients);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//sort the client names for finding out repeated names.</span></span><br><span class="line">  Collections.sort(copies, <span class="keyword">new</span> Comparator&lt;DFSClient&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(<span class="keyword">final</span> DFSClient left, <span class="keyword">final</span> DFSClient right)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> left.getClientName().compareTo(right.getClientName());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">  String previousName = <span class="string">""</span>;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; copies.size(); i++) &#123;</span><br><span class="line">    <span class="keyword">final</span> DFSClient c = copies.get(i);</span><br><span class="line">    <span class="comment">//skip if current client name is the same as the previous name.</span></span><br><span class="line">    <span class="keyword">if</span> (!c.getClientName().equals(previousName)) &#123;</span><br><span class="line">      <span class="comment">// 续约	</span></span><br><span class="line">      <span class="keyword">if</span> (!c.renewLease()) &#123;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">          LOG.debug(<span class="string">"Did not renew lease for client "</span> +</span><br><span class="line">              c);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      previousName = c.getClientName();</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在renew中，先对dfsclients中的DFSClient进行排序，主要是为了将重复发clientName放在一起，renew时只对其中一个clientName进行更新，调用c.renewLease进行续约</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">renewLease</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (clientRunning &amp;&amp; !isFilesBeingWrittenEmpty()) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// rpc调用LeaseManager.renewLease</span></span><br><span class="line">      namenode.renewLease(clientName);</span><br><span class="line">      updateLastLeaseRenewal();</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      <span class="comment">// Abort if the lease has already expired. </span></span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">long</span> elapsed = Time.now() - getLastLeaseRenewal();</span><br><span class="line">      <span class="keyword">if</span> (elapsed &gt; HdfsConstants.LEASE_HARDLIMIT_PERIOD) &#123;</span><br><span class="line">        LOG.warn(<span class="string">"Failed to renew lease for "</span> + clientName + <span class="string">" for "</span></span><br><span class="line">            + (elapsed/<span class="number">1000</span>) + <span class="string">" seconds (&gt;= hard-limit ="</span></span><br><span class="line">            + (HdfsConstants.LEASE_HARDLIMIT_PERIOD/<span class="number">1000</span>) + <span class="string">" seconds.) "</span></span><br><span class="line">            + <span class="string">"Closing all files being written ..."</span>, e);</span><br><span class="line">        closeAllFilesBeingWritten(<span class="keyword">true</span>);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// Let the lease renewer handle it and retry.</span></span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在renewLease中远程调用LeaseManager.renewLease，其调用流程为<code>NameNodeRpcServer.renewLease --&gt; FSNamesystem.renewLease --&gt; LeaseManager.renewLease(holder)</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LeaseManager.class</span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">renewLease</span><span class="params">(String holder)</span> </span>&#123;</span><br><span class="line">  renewLease(getLease(holder));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">renewLease</span><span class="params">(Lease lease)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (lease != <span class="keyword">null</span>) &#123;</span><br><span class="line">    sortedLeases.remove(lease);</span><br><span class="line">    lease.renew();</span><br><span class="line">    sortedLeases.add(lease);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// LeaseManager.Lease.class</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">renew</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.lastUpdate = now();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>客户端通过LeaseRenewer调用LeaseManager.renewLease进行续约，续约逻辑是先从leases中get到clientName对应的lease，然后从sortedLeases中移除该lease，调用lease.renew对lease的lastUpdate进行更新，最后将lease再放入sortedLeases中。sortedLeases中的lease是按照lease的lastUpdate进行排序的，到此客户端续约的流程结束。</p>
<h3 id="nn端周期性check-lease"><a href="#nn端周期性check-lease" class="headerlink" title="nn端周期性check lease"></a>nn端周期性check lease</h3><p>nn端由LeaseManager.Monitor周期性check lease是否超期，这里check hardLimit。Monitor的逻辑比较简单，主要逻辑是在其run方法中。Monitor是一个Runnable类，在active nn启动的时候调用<code>leaseManager.startMonitor()</code>启动一个Monitor的守护线程。其run方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(; shouldRunMonitor &amp;&amp; fsnamesystem.isRunning(); ) &#123;</span><br><span class="line">    <span class="keyword">boolean</span> needSync = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      fsnamesystem.writeLockInterruptibly();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (!fsnamesystem.isInSafeMode()) &#123;</span><br><span class="line">          <span class="comment">// 检查是否超期</span></span><br><span class="line">          needSync = checkLeases();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        fsnamesystem.writeUnlock();</span><br><span class="line">        <span class="comment">// lease reassignments should to be sync'ed.</span></span><br><span class="line">        <span class="keyword">if</span> (needSync) &#123;</span><br><span class="line">          fsnamesystem.getEditLog().logSync();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// sleep NAMENODE_LEASE_RECHECK_INTERVAL后再次check，默认2000ms</span></span><br><span class="line">      Thread.sleep(HdfsServerConstants.NAMENODE_LEASE_RECHECK_INTERVAL);</span><br><span class="line">    &#125; <span class="keyword">catch</span>(InterruptedException ie) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>run中调用checkLeases进行hardLimit检查</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LeaseManager.class</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">checkLeases</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> needSync = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">assert</span> fsnamesystem.hasWriteLock();</span><br><span class="line">  <span class="keyword">for</span>(; sortedLeases.size() &gt; <span class="number">0</span>; ) &#123;</span><br><span class="line">  	<span class="comment">// 从sortedLeases中取出第一个lease，</span></span><br><span class="line">  	<span class="comment">// 也就是时间最久的lease</span></span><br><span class="line">    <span class="keyword">final</span> Lease oldest = sortedLeases.first();</span><br><span class="line">    <span class="comment">// 检查lease是否超过hardLimit</span></span><br><span class="line">    <span class="comment">// 没有超过则return，超过不进if</span></span><br><span class="line">    <span class="comment">// now() - lastUpdate &gt; hardLimit</span></span><br><span class="line">    <span class="keyword">if</span> (!oldest.expiredHardLimit()) &#123;</span><br><span class="line">      <span class="keyword">return</span> needSync;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    LOG.info(oldest + <span class="string">" has expired hard limit"</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> List&lt;String&gt; removing = <span class="keyword">new</span> ArrayList&lt;String&gt;();</span><br><span class="line">    <span class="comment">// need to create a copy of the oldest lease paths, becuase </span></span><br><span class="line">    <span class="comment">// internalReleaseLease() removes paths corresponding to empty files,</span></span><br><span class="line">    <span class="comment">// i.e. it needs to modify the collection being iterated over</span></span><br><span class="line">    <span class="comment">// causing ConcurrentModificationException</span></span><br><span class="line">    String[] leasePaths = <span class="keyword">new</span> String[oldest.getPaths().size()];</span><br><span class="line">    oldest.getPaths().toArray(leasePaths);</span><br><span class="line">    <span class="comment">// 对超过hardLimit的租约中的paths进行处理</span></span><br><span class="line">    <span class="keyword">for</span>(String p : leasePaths) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">      	<span class="comment">// 对超过hardLimit的租约中的文件进行释放</span></span><br><span class="line">        <span class="keyword">boolean</span> completed = fsnamesystem.internalReleaseLease(oldest, p,</span><br><span class="line">            HdfsServerConstants.NAMENODE_LEASE_HOLDER);</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// If a lease recovery happened, we need to sync later.</span></span><br><span class="line">        <span class="keyword">if</span> (!needSync &amp;&amp; !completed) &#123;</span><br><span class="line">          needSync = <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        LOG.error(<span class="string">"Cannot release the path "</span> + p + <span class="string">" in the lease "</span></span><br><span class="line">            + oldest, e);</span><br><span class="line">        removing.add(p);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(String p : removing) &#123;</span><br><span class="line">      removeLease(oldest, p);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> needSync;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="释放租约or租约回收or租约恢复"><a href="#释放租约or租约回收or租约恢复" class="headerlink" title="释放租约or租约回收or租约恢复"></a>释放租约or租约回收or租约恢复</h3><p>对于超过hardLimit的租约进行释放，对于租约的释放不能简单的remove掉，逻辑比较复杂，有的需要block恢复，其具体实现方法是<code>internalReleaseLease</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">internalReleaseLease</span><span class="params">(Lease lease, String src, </span></span></span><br><span class="line"><span class="function"><span class="params">    String recoveryLeaseHolder)</span> <span class="keyword">throws</span> AlreadyBeingCreatedException, </span></span><br><span class="line"><span class="function">    IOException, UnresolvedLinkException </span>&#123;</span><br><span class="line">  LOG.info(<span class="string">"Recovering "</span> + lease + <span class="string">", src="</span> + src);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 得到src对应的INodeFile信息</span></span><br><span class="line">  <span class="keyword">final</span> INodesInPath iip = dir.getLastINodeInPath(src);</span><br><span class="line">  <span class="keyword">final</span> INodeFile pendingFile = iip.getINode(<span class="number">0</span>).asFile();</span><br><span class="line">  <span class="keyword">int</span> nrBlocks = pendingFile.numBlocks();</span><br><span class="line">  BlockInfo[] blocks = pendingFile.getBlocks();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> nrCompleteBlocks;</span><br><span class="line">  BlockInfo curBlock = <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// 找到此file中未完成的block</span></span><br><span class="line">  <span class="keyword">for</span>(nrCompleteBlocks = <span class="number">0</span>; nrCompleteBlocks &lt; nrBlocks; nrCompleteBlocks++) &#123;</span><br><span class="line">    curBlock = blocks[nrCompleteBlocks];</span><br><span class="line">    <span class="keyword">if</span>(!curBlock.isComplete())</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">assert</span> blockManager.checkMinReplication(curBlock) :</span><br><span class="line">            <span class="string">"A COMPLETE block is not minimally replicated in "</span> + src;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If there are no incomplete blocks associated with this file,</span></span><br><span class="line">  <span class="comment">// then reap lease immediately and close the file.</span></span><br><span class="line">  <span class="comment">// 所以的block都完成，则直接关闭文件释放租约</span></span><br><span class="line">  <span class="keyword">if</span>(nrCompleteBlocks == nrBlocks) &#123;</span><br><span class="line">    finalizeINodeFileUnderConstruction(src, pendingFile,</span><br><span class="line">        iip.getLatestSnapshotId());</span><br><span class="line">    NameNode.stateChangeLog.warn(<span class="string">"BLOCK*"</span></span><br><span class="line">      + <span class="string">" internalReleaseLease: All existing blocks are COMPLETE,"</span></span><br><span class="line">      + <span class="string">" lease removed, file closed."</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;  <span class="comment">// closed!</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Only the last and the penultimate blocks may be in non COMPLETE state.</span></span><br><span class="line">  <span class="comment">// If the penultimate block is not COMPLETE, then it must be COMMITTED.</span></span><br><span class="line">  <span class="comment">// 假如存在未完成的block，则此block只能是最后一个block或者倒数第二个block</span></span><br><span class="line">  <span class="comment">// 当未完成的block是倒数第二个block时，倒数第二个block的状态必须是COMMITTED</span></span><br><span class="line">  <span class="comment">// 如果不是这两种情况，即存在别的block未完成，则抛出异常，在checkLeases中捕获</span></span><br><span class="line">  <span class="keyword">if</span>(nrCompleteBlocks &lt; nrBlocks - <span class="number">2</span> ||</span><br><span class="line">     nrCompleteBlocks == nrBlocks - <span class="number">2</span> &amp;&amp;</span><br><span class="line">       curBlock != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">       curBlock.getBlockUCState() != BlockUCState.COMMITTED) &#123;</span><br><span class="line">    <span class="keyword">final</span> String message = <span class="string">"DIR* NameSystem.internalReleaseLease: "</span></span><br><span class="line">      + <span class="string">"attempt to release a create lock on "</span></span><br><span class="line">      + src + <span class="string">" but file is already closed."</span>;</span><br><span class="line">    NameNode.stateChangeLog.warn(message);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(message);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// The last block is not COMPLETE, and</span></span><br><span class="line">  <span class="comment">// that the penultimate block if exists is either COMPLETE or COMMITTED</span></span><br><span class="line">  <span class="keyword">final</span> BlockInfo lastBlock = pendingFile.getLastBlock();</span><br><span class="line">  BlockUCState lastBlockState = lastBlock.getBlockUCState();</span><br><span class="line">  BlockInfo penultimateBlock = pendingFile.getPenultimateBlock();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If penultimate block doesn't exist then its minReplication is met</span></span><br><span class="line">  <span class="keyword">boolean</span> penultimateBlockMinReplication = penultimateBlock == <span class="keyword">null</span> ? <span class="keyword">true</span> :</span><br><span class="line">      blockManager.checkMinReplication(penultimateBlock);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">switch</span>(lastBlockState) &#123;</span><br><span class="line">  <span class="keyword">case</span> COMPLETE:</span><br><span class="line">    <span class="keyword">assert</span> <span class="keyword">false</span> : <span class="string">"Already checked that the last block is incomplete"</span>;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> COMMITTED:</span><br><span class="line">    <span class="comment">// Close file if committed blocks are minimally replicated</span></span><br><span class="line">    <span class="keyword">if</span>(penultimateBlockMinReplication &amp;&amp;</span><br><span class="line">        blockManager.checkMinReplication(lastBlock)) &#123;</span><br><span class="line">      finalizeINodeFileUnderConstruction(src, pendingFile,</span><br><span class="line">          iip.getLatestSnapshotId());</span><br><span class="line">      NameNode.stateChangeLog.warn(<span class="string">"BLOCK*"</span></span><br><span class="line">        + <span class="string">" internalReleaseLease: Committed blocks are minimally replicated,"</span></span><br><span class="line">        + <span class="string">" lease removed, file closed."</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;  <span class="comment">// closed!</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Cannot close file right now, since some blocks </span></span><br><span class="line">    <span class="comment">// are not yet minimally replicated.</span></span><br><span class="line">    <span class="comment">// This may potentially cause infinite loop in lease recovery</span></span><br><span class="line">    <span class="comment">// if there are no valid replicas on data-nodes.</span></span><br><span class="line">    String message = <span class="string">"DIR* NameSystem.internalReleaseLease: "</span> +</span><br><span class="line">        <span class="string">"Failed to release lease for file "</span> + src +</span><br><span class="line">        <span class="string">". Committed blocks are waiting to be minimally replicated."</span> +</span><br><span class="line">        <span class="string">" Try again later."</span>;</span><br><span class="line">    NameNode.stateChangeLog.warn(message);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> AlreadyBeingCreatedException(message);</span><br><span class="line">  <span class="keyword">case</span> UNDER_CONSTRUCTION:</span><br><span class="line">  <span class="keyword">case</span> UNDER_RECOVERY:</span><br><span class="line">    <span class="keyword">final</span> BlockInfoUnderConstruction uc = (BlockInfoUnderConstruction)lastBlock;</span><br><span class="line">    <span class="comment">// setup the last block locations from the blockManager if not known</span></span><br><span class="line">    <span class="keyword">if</span> (uc.getNumExpectedLocations() == <span class="number">0</span>) &#123;</span><br><span class="line">      uc.setExpectedLocations(blockManager.getStorages(lastBlock));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (uc.getNumExpectedLocations() == <span class="number">0</span> &amp;&amp; uc.getNumBytes() == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// There is no datanode reported to this block.</span></span><br><span class="line">      <span class="comment">// may be client have crashed before writing data to pipeline.</span></span><br><span class="line">      <span class="comment">// This blocks doesn't need any recovery.</span></span><br><span class="line">      <span class="comment">// We can remove this block and close the file.</span></span><br><span class="line">      pendingFile.removeLastBlock(lastBlock);</span><br><span class="line">      finalizeINodeFileUnderConstruction(src, pendingFile,</span><br><span class="line">          iip.getLatestSnapshotId());</span><br><span class="line">      NameNode.stateChangeLog.warn(<span class="string">"BLOCK* internalReleaseLease: "</span></span><br><span class="line">          + <span class="string">"Removed empty last block and closed file."</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// start recovery of the last block for this file</span></span><br><span class="line">    <span class="keyword">long</span> blockRecoveryId = nextGenerationStamp(isLegacyBlock(uc));</span><br><span class="line">    lease = reassignLease(lease, src, recoveryLeaseHolder, pendingFile);</span><br><span class="line">    uc.initializeBlockRecovery(blockRecoveryId);</span><br><span class="line">    leaseManager.renewLease(lease);</span><br><span class="line">    <span class="comment">// Cannot close file right now, since the last block requires recovery.</span></span><br><span class="line">    <span class="comment">// This may potentially cause infinite loop in lease recovery</span></span><br><span class="line">    <span class="comment">// if there are no valid replicas on data-nodes.</span></span><br><span class="line">    NameNode.stateChangeLog.warn(</span><br><span class="line">              <span class="string">"DIR* NameSystem.internalReleaseLease: "</span> +</span><br><span class="line">              <span class="string">"File "</span> + src + <span class="string">" has not been closed."</span> +</span><br><span class="line">             <span class="string">" Lease recovery is in progress. "</span> +</span><br><span class="line">              <span class="string">"RecoveryId = "</span> + blockRecoveryId + <span class="string">" for block "</span> + lastBlock);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此方法主要是检查是否需要真正的进入block recovery阶段，这个阶段需要datanode的参与。下面函数的主要逻辑</p>
<ol>
<li>先检查此file的block是否都是completed状态，如果都是completed，则直接调用finalizeINodeFileUnderConstruction(file正常关闭的逻辑，在下一节的租约关闭中会介绍)关闭file，return true。如果有未completed的，则执行第二步</li>
<li>判断未completed的block的索引。如果存在未完成的block，则此block只能是最后一个block或者倒数第二个block，当未完成的block是倒数第二个block时，倒数第二个block的状态必须是COMMITTED，符合此条件执行第三步。如果不是这两种情况，即存在别的block未完成，则抛出异常，在checkLeases中捕获。</li>
<li>在switch中判断最后一个block的状态，如果是<code>COMMITTED</code>，并且该文件的最后两个block都满足最小副本数要求，则调用finalizeINodeFileUnderConstruction关闭文件，return true。否则抛出异常。如果是<code>UNDER_CONSTRUCTION</code>或者<code>UNDER_RECOVERY</code>，并且最后一个block没有任何datanode汇报上来，很有可能是pipeline还没建立起来，客户端就宕机了，这种情况下，只需要把最后一个block从INode中移出，并且关闭文件。否则的话进入block recovery阶段(这一阶段再次处不展开，以后再分析)。</li>
</ol>
<h3 id="关闭租约"><a href="#关闭租约" class="headerlink" title="关闭租约"></a>关闭租约</h3><p>文件写完之后调用<code>FSDataOutputStream.close()</code>关闭写入流，FSDataOutputStream.close()的具体实现是由其几个子类实现的，这里看下<code>DFSOutputStream.close()</code>，close中调用<code>completeFile --&gt; NameNodeRpcServer.complete --&gt; FSNamesystem.completeFile --&gt; completeFileInternal --&gt; finalizeINodeFileUnderConstruction --&gt; leaseManager.removeLease</code>，在finalizeINodeFileUnderConstruction中调用leaseManager.removeLease关闭租约，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">removeLease</span><span class="params">(String holder, String src)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 得到该holder的lease</span></span><br><span class="line">  Lease lease = getLease(holder);</span><br><span class="line">  <span class="keyword">if</span> (lease != <span class="keyword">null</span>) &#123;</span><br><span class="line">  	<span class="comment">// 从集合中将该src的锁remove掉</span></span><br><span class="line">    removeLease(lease, src);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Removing non-existent lease! holder="</span> + holder +</span><br><span class="line">        <span class="string">" src="</span> + src);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">removeLease</span><span class="params">(Lease lease, String src)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 将该src从sortedLeasesByPath中移除 </span></span><br><span class="line">  sortedLeasesByPath.remove(src);</span><br><span class="line">  <span class="comment">// 将src从lease的paths中移除</span></span><br><span class="line">  <span class="keyword">if</span> (!lease.removePath(src)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(src + <span class="string">" not found in lease.paths (="</span> + lease.paths + <span class="string">")"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 如果lease的paths中移除该src后，paths为null</span></span><br><span class="line">  <span class="comment">// 则说明该租约中没有文件被打开，将该租约从leases中移除，</span></span><br><span class="line">  <span class="comment">// 也就是关闭该租约，关闭之后从sortedLeases中移除</span></span><br><span class="line">  <span class="keyword">if</span> (!lease.hasPath()) &#123;</span><br><span class="line">    leases.remove(lease.holder);</span><br><span class="line">    <span class="keyword">if</span> (!sortedLeases.remove(lease)) &#123;</span><br><span class="line">      LOG.error(lease + <span class="string">" not found in sortedLeases"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关闭租约的逻辑比较简单，只是关闭租约时并不是简单的把该租约从各个集合中移除，而是只是将关闭src的记录从各个集合中移除，<em>如果租约lease的paths中的src记录都被移除掉，则该租约就可以关闭</em>。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>正常情况下，客户端向集群写文件前需要向NameNode的LeaseManager申请Lease；写文件过程中定期更新Lease时间，以防Lease过期，周期与softLimit相关；写完数据后申请释放Lease。</p>
<p>整个过程可能发生两类问题：（1）写文件过程中客户端没有及时更新Lease时间；（2）写完文件后没有成功释放Lease。两个问题分别对应为softLimit和hardLimit。<em>两种场景都会触发LeaseManager对Lease超时强制回收</em>。如果客户端写文件过程中没有及时更新Lease超过softLimit时间后，另一客户端尝试对同一文件进行写操作时触发Lease软超时强制回收；如果客户端写文件完成但是没有成功释放Lease，则会由LeaseManager的后台线程LeaseManager.Monitor检查是否硬超时后统一触发超时回收。<em>不管是softLimit还是hardLimit超时触发的强制Lease回收，处理逻辑都一样：FSNamesystem.internalReleaseLease</em>，逻辑本身比较复杂，已在上面详细介绍。简单的说先对Lease过期前最后一次写入的Block进行检查和修复，之后释放超时持有的Lease，保证后面其他客户端的写入能够正常申请到该文件的Lease。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> Lease </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce源码解析--Reduce中values的Iterator的生成]]></title>
      <url>http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--Reduce%E4%B8%ADvalues%E7%9A%84Iterator%E7%9A%84%E7%94%9F%E6%88%90.html</url>
      <content type="html"><![CDATA[<p>众所周知Reduce中的values是一个Iterator，但是value的数据并不是一下全部加载到这个Iterator(<em>也就是对value根据key进行分组，这个分组比较器可以重写，二次排序中可能会需要重写，默认是按照key进行分组</em>)，那么values的Iterator是怎么形成的，是怎么被加载的呢？</p>
<p>下面从源码的角度去探秘一下吧，因为源码才是最好的教科书。</p>
<a id="more"></a>
<p>写Reduce函数时都会继承Reduce类然后重写reduce函数，在Reduce.run中循环调用reduce，reduce函数传进去的参数values已经是一个Iterator，则此Iterator的形成只能在调用reduce之前，开始循环调用reduce之后。看下run的代码可能更清晰一些：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  setup(context);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// while 循环调用reduce</span></span><br><span class="line">    <span class="keyword">while</span> (context.nextKey()) &#123;</span><br><span class="line">      <span class="comment">// reduce传入的参数context.getValues()只是返回一个Iterator</span></span><br><span class="line">      reduce(context.getCurrentKey(), context.getValues(), context);</span><br><span class="line">      <span class="comment">// If a back up store is used, reset it</span></span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    cleanup(context);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里代码很简单，context.nextKey检查是否有下一个key，有则进入循环，调用context.getValues返回一个ValueIterable对象，第一感觉就是找到这个ValueIterable对象在哪被赋值了，那么问题就解决了，但是并不是。这个ValueIterable对象由返回一个Iterator对象，而这个Iterator对象只是在ValueIterable中被初始化了一个空对象，那么Iterator对象中的数据是在呢被赋值的呢？难道是在context.nextKey()中？</p>
<p>下面看下context.nextKey()的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ReduceContextImpl.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException,InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (hasMore &amp;&amp; nextKeyIsSame) &#123;</span><br><span class="line">    nextKeyValue();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (hasMore) &#123;</span><br><span class="line">    <span class="keyword">if</span> (inputKeyCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">      inputKeyCounter.increment(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nextKeyValue();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里有两个属性<code>hasMore</code>和<code>nextKeyIsSame</code>，hasMore初次是在ReduceContextImpl的构造方法中被<code>hasMore = input.next()</code>赋值(<em>input是<code>RawKeyValueIterator</code>，是map端merge数据的输出类型</em>)，有下一行数据则为true。nextKeyIsSame初始化为false，随后会在nextKeyValue中被赋值。</p>
<p>则当reduce刚启动时，hasMore为true，nextKeyIsSame为false，不进while循环，进if语句，首先对key进行统计，然后调用<code>nextKeyValue</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 是否的一个值标识</span></span><br><span class="line">  firstValue = !nextKeyIsSame;</span><br><span class="line">  <span class="comment">// 从input中拿到key值</span></span><br><span class="line">  DataInputBuffer nextKey = input.getKey();</span><br><span class="line">  currentRawKey.set(nextKey.getData(), nextKey.getPosition(), </span><br><span class="line">                    nextKey.getLength() - nextKey.getPosition());</span><br><span class="line">  buffer.reset(currentRawKey.getBytes(), <span class="number">0</span>, currentRawKey.getLength());</span><br><span class="line">  <span class="comment">// key值反序列</span></span><br><span class="line">  key = keyDeserializer.deserialize(key);</span><br><span class="line">  <span class="comment">// 从input中拿到value值</span></span><br><span class="line">  DataInputBuffer nextVal = input.getValue();</span><br><span class="line">  buffer.reset(nextVal.getData(), nextVal.getPosition(), nextVal.getLength()</span><br><span class="line">      - nextVal.getPosition());</span><br><span class="line">  <span class="comment">// value反序列</span></span><br><span class="line">  value = valueDeserializer.deserialize(value);</span><br><span class="line"></span><br><span class="line">  currentKeyLength = nextKey.getLength() - nextKey.getPosition();</span><br><span class="line">  currentValueLength = nextVal.getLength() - nextVal.getPosition();</span><br><span class="line">  <span class="comment">// mark reset功能是否开启，开启之后可以多次遍历values中的值</span></span><br><span class="line">  <span class="keyword">if</span> (isMarked) &#123;</span><br><span class="line">    backupStore.write(nextKey, nextVal);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  hasMore = input.next();</span><br><span class="line">  <span class="keyword">if</span> (hasMore) &#123;</span><br><span class="line">    nextKey = input.getKey();</span><br><span class="line">    <span class="comment">// 判断当前key是否和下一个key相同</span></span><br><span class="line">    nextKeyIsSame = comparator.compare(currentRawKey.getBytes(), <span class="number">0</span>, </span><br><span class="line">                                   currentRawKey.getLength(),</span><br><span class="line">                                   nextKey.getData(),</span><br><span class="line">                                   nextKey.getPosition(),</span><br><span class="line">                                   nextKey.getLength() - nextKey.getPosition()</span><br><span class="line">                                       ) == <span class="number">0</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    nextKeyIsSame = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 对value的个数进行统计</span></span><br><span class="line">  inputValueCounter.increment(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>nextKeyValue并没有给Iterator赋值，但是令人高兴的是这里把key和value从input中读取出来，反序列化放入key和value中，那么value和key都是在哪被调用呢，查看代码发现是在<code>ValueIterator</code>的<code>next</code>方法中value被return，ValueIterator就是上文中返回的Iterator对象。ValueIterator是ReduceContextImpl的内部类实现了Iterator接口。看下next方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> VALUEIN <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// if this is the first record, we don't need to advance</span></span><br><span class="line">  <span class="comment">// 如果是第一个value，值直接返回在nextKeyValue中被赋值的value</span></span><br><span class="line">  <span class="keyword">if</span> (firstValue) &#123;</span><br><span class="line">    firstValue = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// if this isn't the first record and the next key is different, they</span></span><br><span class="line">  <span class="comment">// can't advance it here.</span></span><br><span class="line">  <span class="keyword">if</span> (!nextKeyIsSame) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException(<span class="string">"iterate past last value"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// otherwise, go to the next key/value pair</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// 如果不是第一个值，则调用nextKeyValue读取value值</span></span><br><span class="line">    nextKeyValue();</span><br><span class="line">    <span class="comment">// 将上面读取的value值返回</span></span><br><span class="line">    <span class="keyword">return</span> value;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"next value iterator failed"</span>, ie);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">    <span class="comment">// this is bad, but we can't modify the exception list of java.util</span></span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"next value iterator interrupted"</span>, ie);        </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由next方法可见，Iterator初期只是个null对象，通过<code>firstValue</code>和<code>nextKeyIsSame</code>来控制，是否还有值，并进行读取。每读取一次都是直接从input中读取值，这样减少了内存的利用，input可以在内存也可以在磁盘。</p>
<p>下面来说下Reduce读取value的整体流程。</p>
<blockquote>
<p>首先在Reduce.run中调用context.nextKey()决定是否进入while，nextKey对key的个数进行统计，然后调用nextKeyValue将key/value的值从input中读出，并对firstValue、hashMore和nextKeyIsSame的值进行更新。</p>
</blockquote>
<blockquote>
<p>其次通过context.getValues将Iterator传入reduce中，在reduce中通过Iterator.hasNext查看此key是否有下个value，然后通过Iterator.next调用nextKeyValue去input中读取value。</p>
</blockquote>
<p>hasNext代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (inReset &amp;&amp; backupStore.hasNext()) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; </span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    e.printStackTrace();</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"hasNext failed"</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 第一次调用hasNext时，firstValue在nextKeyValue中被赋值为true，</span></span><br><span class="line">  <span class="comment">// 并且如果和下一个key相同，则nextKeyIsSame也为true</span></span><br><span class="line">  <span class="comment">// 当调用过next()之后，firstValue会在next中被赋值为false，next方法直接返回</span></span><br><span class="line">  <span class="comment">// 此时nextKeyIsSame依然是在第一次调用nextKeyValue中被赋值的true</span></span><br><span class="line">  <span class="keyword">return</span> firstValue || nextKeyIsSame;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>然后循环迭代Iterator，读取input中相同key的value。</p>
</blockquote>
<p>读取当前key的value读取结束之后，再次调用context.nextKey。</p>
<p><strong>也就是说reduce中相同key的value值在Iterator.next中通过nextKeyValue读取的，每调用一次next就从input中读一个value。此时有的同学会问假如我在读Iterator的循环中中途break呢，剩下的value是在哪被消费呢？如果不消费我再次循环的时候怎么读到下一个key的value。</strong></p>
<p>下面看下context.nextKey的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException,InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (hasMore &amp;&amp; nextKeyIsSame) &#123;</span><br><span class="line">    nextKeyValue();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (hasMore) &#123;</span><br><span class="line">    <span class="keyword">if</span> (inputKeyCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">      inputKeyCounter.increment(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nextKeyValue();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有没有注意到方法开始有个while循环，当你中途break之后，再次进入run中的while循环时，nextKey会继续把没有读完的value读完，然后递增key的个数，调用nextKeyValue去读取下一个不同的key。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce </tag>
            
            <tag> Reduce </tag>
            
            <tag> Iterator </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MapReduce源码解析--Reduce解析]]></title>
      <url>http://bigdatadecode.club/MapReduce%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90--Reduce%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<h2 id="MapReduce–Reduce"><a href="#MapReduce–Reduce" class="headerlink" title="MapReduce–Reduce"></a>MapReduce–Reduce</h2><p><a href="http://bigdatadecode.club/MapReduce源码解析--Map解析.html">上篇</a>主要扒了下Map阶段的代码，并根据代码把Map阶段的流程串了下，本篇主要扒下Reduce阶段的代码，顺便串下Reduce阶段的流程。<br>Reduce大致分为copy、sort、reduce三个阶段，重点在前两个阶段。Reduce Task和Map Task一样，同样也有四中任务类型，分别为job setup、job cleanup、reduce task、task cleanup。Reduce阶段的代码入口是<code>ReduceTask.java</code>类中的<code>run</code>方法，代码如下：</p>
<a id="more"></a>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(JobConf job, <span class="keyword">final</span> TaskUmbilicalProtocol umbilical)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException, InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class="line">  job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());</span><br><span class="line">  <span class="comment">// Reduce阶段的三个小阶段</span></span><br><span class="line">  <span class="keyword">if</span> (isMapOrReduce()) &#123;</span><br><span class="line">    copyPhase = getProgress().addPhase(<span class="string">"copy"</span>);</span><br><span class="line">    sortPhase  = getProgress().addPhase(<span class="string">"sort"</span>);</span><br><span class="line">    reducePhase = getProgress().addPhase(<span class="string">"reduce"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// start thread that will handle communication with parent</span></span><br><span class="line">  TaskReporter reporter = startReporter(umbilical);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">boolean</span> useNewApi = job.getUseNewReducer();</span><br><span class="line">  initialize(job, getJobID(), reporter, useNewApi);</span><br><span class="line">  <span class="comment">// Reduce Task 的四种类型</span></span><br><span class="line">  <span class="comment">// check if it is a cleanupJobTask</span></span><br><span class="line">  <span class="keyword">if</span> (jobCleanup) &#123;</span><br><span class="line">    runJobCleanupTask(umbilical, reporter);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (jobSetup) &#123;</span><br><span class="line">    runJobSetupTask(umbilical, reporter);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (taskCleanup) &#123;</span><br><span class="line">    runTaskCleanupTask(umbilical, reporter);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Initialize the codec</span></span><br><span class="line">  <span class="comment">// 初始化压缩类型</span></span><br><span class="line">  codec = initCodec();</span><br><span class="line">  RawKeyValueIterator rIter = <span class="keyword">null</span>;</span><br><span class="line">  ShuffleConsumerPlugin shuffleConsumerPlugin = <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// reduce 阶段依然要用到combiner</span></span><br><span class="line">  Class combinerClass = conf.getCombinerClass();</span><br><span class="line">  CombineOutputCollector combineCollector = </span><br><span class="line">    (<span class="keyword">null</span> != combinerClass) ? </span><br><span class="line">   <span class="keyword">new</span> CombineOutputCollector(reduceCombineOutputCounter, reporter, conf) : <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// 得到shuffle阶段的插件（此处将shuffle阶段当做一个服务插件）</span></span><br><span class="line">  Class&lt;? extends ShuffleConsumerPlugin&gt; clazz =</span><br><span class="line">        job.getClass(MRConfig.SHUFFLE_CONSUMER_PLUGIN, Shuffle.class, ShuffleConsumerPlugin.class);</span><br><span class="line">				</span><br><span class="line">  shuffleConsumerPlugin = ReflectionUtils.newInstance(clazz, job);</span><br><span class="line">  LOG.info(<span class="string">"Using ShuffleConsumerPlugin: "</span> + shuffleConsumerPlugin);</span><br><span class="line"></span><br><span class="line">  ShuffleConsumerPlugin.Context shuffleContext = </span><br><span class="line">    <span class="keyword">new</span> ShuffleConsumerPlugin.Context(getTaskID(), job, FileSystem.getLocal(job), umbilical, </span><br><span class="line">                <span class="keyword">super</span>.lDirAlloc, reporter, codec, </span><br><span class="line">                combinerClass, combineCollector, </span><br><span class="line">                spilledRecordsCounter, reduceCombineInputCounter,</span><br><span class="line">                shuffledMapsCounter,</span><br><span class="line">                reduceShuffleBytes, failedShuffleCounter,</span><br><span class="line">                mergedMapOutputsCounter,</span><br><span class="line">                taskStatus, copyPhase, sortPhase, <span class="keyword">this</span>,</span><br><span class="line">                mapOutputFile, localMapFiles);</span><br><span class="line">  <span class="comment">// shuffleConsumerPlugin初始化</span></span><br><span class="line">  shuffleConsumerPlugin.init(shuffleContext);</span><br><span class="line">  <span class="comment">// copy sort merge都在此阶段执行</span></span><br><span class="line">  rIter = shuffleConsumerPlugin.run();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// free up the data structures</span></span><br><span class="line">  mapOutputFilesOnDisk.clear();</span><br><span class="line">  </span><br><span class="line">  sortPhase.complete();                         <span class="comment">// sort is complete</span></span><br><span class="line">  setPhase(TaskStatus.Phase.REDUCE); </span><br><span class="line">  statusUpdate(umbilical);</span><br><span class="line">  Class keyClass = job.getMapOutputKeyClass();</span><br><span class="line">  Class valueClass = job.getMapOutputValueClass();</span><br><span class="line">  RawComparator comparator = job.getOutputValueGroupingComparator();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (useNewApi) &#123;</span><br><span class="line">    runNewReducer(job, umbilical, reporter, rIter, comparator, </span><br><span class="line">                  keyClass, valueClass);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    runOldReducer(job, umbilical, reporter, rIter, comparator, </span><br><span class="line">                  keyClass, valueClass);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由上面的<code>run</code>代码段可以看出<em>copy</em>和<em>sort</em>是主要在<code>shuffleConsumerPlugin.run()</code>中执行，此方法结束之后则进入reduce阶段，执行<code>runNewReucer()</code>。则下面先看下<code>shuffleConsumerPlugin</code>的逻辑，从<code>shuffleConsumerPlugin.init(shuffleContext)</code>开始，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Shuffle.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">(ShuffleConsumerPlugin.Context context)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 主要用来存放map等相关信息，也包含fetcher相关的调度</span></span><br><span class="line">  scheduler = <span class="keyword">new</span> ShuffleSchedulerImpl&lt;K, V&gt;(jobConf, taskStatus, reduceId,</span><br><span class="line">      <span class="keyword">this</span>, copyPhase, context.getShuffledMapsCounter(),</span><br><span class="line">      context.getReduceShuffleBytes(), context.getFailedShuffleCounter());</span><br><span class="line">  <span class="comment">// new 出一个MergeManagerImpl对象，在该对象中创建</span></span><br><span class="line">  <span class="comment">// merge线程，包含inMemoryMerger（内存merge到磁盘）、onDiskMerger（磁盘merge）</span></span><br><span class="line">  merger = createMergeManager(context);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过<code>createMergeManager</code>new出一个MergeManagerImpl对象，该对象的构造函数主要构建几个Merge线程，并为一些参数设置阈值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">MergeManagerImpl</span><span class="params">(TaskAttemptID reduceId, JobConf jobConf, </span></span></span><br><span class="line"><span class="function"><span class="params">                    FileSystem localFS,</span></span></span><br><span class="line"><span class="function"><span class="params">                    LocalDirAllocator localDirAllocator,  </span></span></span><br><span class="line"><span class="function"><span class="params">                    Reporter reporter,</span></span></span><br><span class="line"><span class="function"><span class="params">                    CompressionCodec codec,</span></span></span><br><span class="line"><span class="function"><span class="params">                    Class&lt;? extends Reducer&gt; combinerClass,</span></span></span><br><span class="line"><span class="function"><span class="params">                    CombineOutputCollector&lt;K,V&gt; combineCollector,</span></span></span><br><span class="line"><span class="function"><span class="params">                    Counters.Counter spilledRecordsCounter,</span></span></span><br><span class="line"><span class="function"><span class="params">                    Counters.Counter reduceCombineInputCounter,</span></span></span><br><span class="line"><span class="function"><span class="params">                    Counters.Counter mergedMapOutputsCounter,</span></span></span><br><span class="line"><span class="function"><span class="params">                    ExceptionReporter exceptionReporter,</span></span></span><br><span class="line"><span class="function"><span class="params">                    Progress mergePhase, MapOutputFile mapOutputFile)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// SHUFFLE_INPUT_BUFFER_PERCENT = "mapreduce.reduce.shuffle.input.buffer.percent"</span></span><br><span class="line">  <span class="comment">// 默认是0.7 Reduce阶段内存缓冲区中用于shuffle的百分比</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">float</span> maxInMemCopyUse =</span><br><span class="line">    jobConf.getFloat(MRJobConfig.SHUFFLE_INPUT_BUFFER_PERCENT,</span><br><span class="line">        MRJobConfig.DEFAULT_SHUFFLE_INPUT_BUFFER_PERCENT);</span><br><span class="line">  <span class="keyword">if</span> (maxInMemCopyUse &gt; <span class="number">1.0</span> || maxInMemCopyUse &lt; <span class="number">0.0</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid value for "</span> +</span><br><span class="line">        MRJobConfig.SHUFFLE_INPUT_BUFFER_PERCENT + <span class="string">": "</span> +</span><br><span class="line">        maxInMemCopyUse);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Allow unit tests to fix Runtime memory</span></span><br><span class="line">  <span class="comment">// REDUCE_MEMORY_TOTAL_BYTES = "mapreduce.reduce.memory.totalbytes"</span></span><br><span class="line">  <span class="comment">// 用于shuffle的buffer大小</span></span><br><span class="line">  <span class="comment">// 此值是由Reduce运行时的内存*shuffle百分比得到的</span></span><br><span class="line">  <span class="keyword">this</span>.memoryLimit = </span><br><span class="line">    (<span class="keyword">long</span>)(jobConf.getLong(MRJobConfig.REDUCE_MEMORY_TOTAL_BYTES,</span><br><span class="line">        Math.min(Runtime.getRuntime().maxMemory(), Integer.MAX_VALUE))</span><br><span class="line">      * maxInMemCopyUse);</span><br><span class="line">  <span class="keyword">this</span>.ioSortFactor = jobConf.getInt(MRJobConfig.IO_SORT_FACTOR, <span class="number">100</span>);</span><br><span class="line">  <span class="comment">// SHUFFLE_MEMORY_LIMIT_PERCENT = "mapreduce.reduce.shuffle.memory.limit.percent"</span></span><br><span class="line">  <span class="comment">// 单个shuffle的内存限制，默认是0.25</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">float</span> singleShuffleMemoryLimitPercent =</span><br><span class="line">      jobConf.getFloat(MRJobConfig.SHUFFLE_MEMORY_LIMIT_PERCENT,</span><br><span class="line">          DEFAULT_SHUFFLE_MEMORY_LIMIT_PERCENT);</span><br><span class="line">  <span class="keyword">if</span> (singleShuffleMemoryLimitPercent &lt;= <span class="number">0.0f</span></span><br><span class="line">      || singleShuffleMemoryLimitPercent &gt; <span class="number">1.0f</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Invalid value for "</span></span><br><span class="line">        + MRJobConfig.SHUFFLE_MEMORY_LIMIT_PERCENT + <span class="string">": "</span></span><br><span class="line">        + singleShuffleMemoryLimitPercent);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  usedMemory = <span class="number">0L</span>;</span><br><span class="line">  commitMemory = <span class="number">0L</span>;</span><br><span class="line">  <span class="comment">// singleShuffleMemoryLimitPercent = mapreduce.reduce.shuffle.memory.limit.percent</span></span><br><span class="line">  <span class="comment">// 每次写入时的最大限制，超过则直接写入disk</span></span><br><span class="line">  <span class="keyword">this</span>.maxSingleShuffleLimit = </span><br><span class="line">    (<span class="keyword">long</span>)(memoryLimit * singleShuffleMemoryLimitPercent);</span><br><span class="line">  <span class="comment">// 在内存中merge的阈值，该阈值只有在开启内存merge功能才有用</span></span><br><span class="line">  <span class="comment">// 内存merge的开关是mapreduce.reduce.merge.memtomem.enabled，默认关闭</span></span><br><span class="line">  <span class="keyword">this</span>.memToMemMergeOutputsThreshold = </span><br><span class="line">          jobConf.getInt(MRJobConfig.REDUCE_MEMTOMEM_THRESHOLD, ioSortFactor);</span><br><span class="line">  <span class="comment">// SHUFFLE_MERGE_PERCENT = "mapreduce.reduce.shuffle.merge.percent"      </span></span><br><span class="line">  <span class="comment">// merge阈值，用于shuffle的内存*mapreduce.reduce.shuffle.merge.percent</span></span><br><span class="line">  <span class="keyword">this</span>.mergeThreshold = (<span class="keyword">long</span>)(<span class="keyword">this</span>.memoryLimit * </span><br><span class="line">                        jobConf.getFloat(MRJobConfig.SHUFFLE_MERGE_PERCENT, </span><br><span class="line">                                         <span class="number">0.90f</span>));</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 内存merge功能是否开启</span></span><br><span class="line">  <span class="keyword">boolean</span> allowMemToMemMerge = </span><br><span class="line">    jobConf.getBoolean(MRJobConfig.REDUCE_MEMTOMEM_ENABLED, <span class="keyword">false</span>);</span><br><span class="line">  <span class="keyword">if</span> (allowMemToMemMerge) &#123;</span><br><span class="line">    <span class="keyword">this</span>.memToMemMerger = </span><br><span class="line">      <span class="keyword">new</span> IntermediateMemoryToMemoryMerger(<span class="keyword">this</span>,</span><br><span class="line">                                           memToMemMergeOutputsThreshold);</span><br><span class="line">    <span class="keyword">this</span>.memToMemMerger.start();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">this</span>.memToMemMerger = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 启动内存merge到Disk的merger线程</span></span><br><span class="line">  <span class="keyword">this</span>.inMemoryMerger = createInMemoryMerger();</span><br><span class="line">  <span class="keyword">this</span>.inMemoryMerger.start();</span><br><span class="line">  <span class="comment">// 启动disk merge线程</span></span><br><span class="line">  <span class="keyword">this</span>.onDiskMerger = <span class="keyword">new</span> OnDiskMerger(<span class="keyword">this</span>);</span><br><span class="line">  <span class="keyword">this</span>.onDiskMerger.start();</span><br><span class="line">  <span class="keyword">this</span>.mergePhase = mergePhase;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>init结束之后，就是<code>shuffleConsumerPlugin.run()</code>也就是<code>Shuffle.run</code>。run的执行也标志着Reduce阶段的开始，run中启动一个抓取Completion Map的线程EventFetcher和copy数据的线程Fetcher，等copy结束之后数据进行merge sort。代码解析如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RawKeyValueIterator <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="comment">// Scale the maximum events we fetch per RPC call to mitigate OOM issues</span></span><br><span class="line">  <span class="comment">// on the ApplicationMaster when a thundering herd of reducers fetch events</span></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> This should not be necessary after HADOOP-8942</span></span><br><span class="line">  <span class="keyword">int</span> eventsPerReducer = Math.max(MIN_EVENTS_TO_FETCH,</span><br><span class="line">      MAX_RPC_OUTSTANDING_EVENTS / jobConf.getNumReduceTasks());</span><br><span class="line">  <span class="comment">// 每次从Completion Map的list中抓取多少个Map</span></span><br><span class="line">  <span class="keyword">int</span> maxEventsToFetch = Math.min(MAX_EVENTS_TO_FETCH, eventsPerReducer);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Start the map-completion events fetcher thread</span></span><br><span class="line">  <span class="comment">// 抓取Map线程</span></span><br><span class="line">  <span class="keyword">final</span> EventFetcher&lt;K,V&gt; eventFetcher = </span><br><span class="line">    <span class="keyword">new</span> EventFetcher&lt;K,V&gt;(reduceId, umbilical, scheduler, <span class="keyword">this</span>,</span><br><span class="line">        maxEventsToFetch);</span><br><span class="line">  eventFetcher.start();  </span><br><span class="line">  <span class="comment">// Start the map-output fetcher threads</span></span><br><span class="line">  <span class="keyword">boolean</span> isLocal = localMapFiles != <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// Fetcher线程的个数（分本地和远程两种情况）</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numFetchers = isLocal ? <span class="number">1</span> :</span><br><span class="line">    jobConf.getInt(MRJobConfig.SHUFFLE_PARALLEL_COPIES, <span class="number">5</span>);</span><br><span class="line">  Fetcher&lt;K,V&gt;[] fetchers = <span class="keyword">new</span> Fetcher[numFetchers];</span><br><span class="line">  <span class="keyword">if</span> (isLocal) &#123;</span><br><span class="line">  	<span class="comment">// 文件在本地则启动LocalFetcher线程</span></span><br><span class="line">    fetchers[<span class="number">0</span>] = <span class="keyword">new</span> LocalFetcher&lt;K, V&gt;(jobConf, reduceId, scheduler,</span><br><span class="line">        merger, reporter, metrics, <span class="keyword">this</span>, reduceTask.getShuffleSecret(),</span><br><span class="line">        localMapFiles);</span><br><span class="line">    fetchers[<span class="number">0</span>].start();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  	<span class="comment">// 循环启动远程Fetcher线程</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i &lt; numFetchers; ++i) &#123;</span><br><span class="line">      fetchers[i] = <span class="keyword">new</span> Fetcher&lt;K,V&gt;(jobConf, reduceId, scheduler, merger, </span><br><span class="line">                                     reporter, metrics, <span class="keyword">this</span>, </span><br><span class="line">                                     reduceTask.getShuffleSecret());</span><br><span class="line">      fetchers[i].start();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Wait for shuffle to complete successfully</span></span><br><span class="line">  <span class="keyword">while</span> (!scheduler.waitUntilDone(PROGRESS_FREQUENCY)) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  copyPhase.complete(); <span class="comment">// copy is already complete</span></span><br><span class="line">  taskStatus.setPhase(TaskStatus.Phase.SORT);</span><br><span class="line">  reduceTask.statusUpdate(umbilical);</span><br><span class="line">  <span class="comment">// Finish the on-going merges...</span></span><br><span class="line">  RawKeyValueIterator kvIter = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// copy结束之后进行merge sort</span></span><br><span class="line">    kvIter = merger.close();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ShuffleError(<span class="string">"Error while doing final merge "</span> , e);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> kvIter;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>run中主要完成了reduce前期的工作，其中先来看下<em>EventFetcher</em>线程的run代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> failures = <span class="number">0</span>;</span><br><span class="line">  LOG.info(reduce + <span class="string">" Thread started: "</span> + getName());  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (!stopped &amp;&amp; !Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> numNewMaps = getMapCompletionEvents();</span><br><span class="line">        failures = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (numNewMaps &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          LOG.info(reduce + <span class="string">": "</span> + <span class="string">"Got "</span> + numNewMaps + <span class="string">" new map-outputs"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        LOG.debug(<span class="string">"GetMapEventsThread about to sleep for "</span> + SLEEP_TIME);</span><br><span class="line">        <span class="keyword">if</span> (!Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">          Thread.sleep(SLEEP_TIME);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException e) </span><br><span class="line">        ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) </span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">int</span> <span class="title">getMapCompletionEvents</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> numNewMaps = <span class="number">0</span>;</span><br><span class="line">  TaskCompletionEvent events[] = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">  	<span class="comment">// rpc 调用</span></span><br><span class="line">    MapTaskCompletionEventsUpdate update =</span><br><span class="line">        umbilical.getMapCompletionEvents(</span><br><span class="line">            (org.apache.hadoop.mapred.JobID)reduce.getJobID(),</span><br><span class="line">            fromEventIdx,</span><br><span class="line">            maxEventsToFetch,</span><br><span class="line">            (org.apache.hadoop.mapred.TaskAttemptID)reduce);</span><br><span class="line">    events = update.getMapTaskCompletionEvents();</span><br><span class="line">    LOG.debug(<span class="string">"Got "</span> + events.length + <span class="string">" map completion events from "</span> +</span><br><span class="line">             fromEventIdx);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span> !update.shouldReset() : <span class="string">"Unexpected legacy state"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Update the last seen event ID</span></span><br><span class="line">    fromEventIdx += events.length;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Process the TaskCompletionEvents:</span></span><br><span class="line">    <span class="comment">// 1. Save the SUCCEEDED maps in knownOutputs to fetch the outputs.</span></span><br><span class="line">    <span class="comment">// 2. Save the OBSOLETE/FAILED/KILLED maps in obsoleteOutputs to stop</span></span><br><span class="line">    <span class="comment">//    fetching from those maps.</span></span><br><span class="line">    <span class="comment">// 3. Remove TIPFAILED maps from neededOutputs since we don't need their</span></span><br><span class="line">    <span class="comment">//    outputs at all.</span></span><br><span class="line">    <span class="keyword">for</span> (TaskCompletionEvent event : events) &#123;</span><br><span class="line">      scheduler.resolve(event);</span><br><span class="line">      <span class="keyword">if</span> (TaskCompletionEvent.Status.SUCCEEDED == event.getTaskStatus()) &#123;</span><br><span class="line">        ++numNewMaps;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">while</span> (events.length == maxEventsToFetch);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> numNewMaps;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>EventFetcher</code>主要是通过<code>getMapCompletionEvents</code>方法的rpc拿到Completion Map，然后对<em>scheduler</em>的相关list进行赋值。<code>umbilical</code>是rpc协议<code>TaskUmbilicalProtocol</code>，RPC的实现类是<code>TaskAttemptListenerImpl</code>，则<code>umbilical.getMapCompletionEvents</code>实际上调用的是<code>TaskAttemptListenerImpl.getMapCompletionEvents</code>,然后继续调用<code>JobImpl.getMapAttemptCompletionEvents</code>方法，得到已完成的events，并将其放入scheduler中相应的map映射中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 得到events</span></span><br><span class="line"><span class="keyword">public</span> TaskCompletionEvent[] getMapAttemptCompletionEvents(</span><br><span class="line">    <span class="keyword">int</span> startIndex, <span class="keyword">int</span> maxEvents) &#123;</span><br><span class="line">  TaskCompletionEvent[] events = EMPTY_TASK_COMPLETION_EVENTS;</span><br><span class="line">  readLock.lock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (mapAttemptCompletionEvents.size() &gt; startIndex) &#123;</span><br><span class="line">      <span class="comment">// 从mapAttemptCompletionEvents中截取maxEvent的map</span></span><br><span class="line">      <span class="keyword">int</span> actualMax = Math.min(maxEvents,</span><br><span class="line">          (mapAttemptCompletionEvents.size() - startIndex));</span><br><span class="line">      events = mapAttemptCompletionEvents.subList(startIndex,</span><br><span class="line">          actualMax + startIndex).toArray(events);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> events;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    readLock.unlock();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将得到的events放入scheduler对应的map映射中</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resolve</span><span class="params">(TaskCompletionEvent event)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">switch</span> (event.getTaskStatus()) &#123;</span><br><span class="line">  <span class="keyword">case</span> SUCCEEDED:</span><br><span class="line">    URI u = getBaseURI(reduceId, event.getTaskTrackerHttp());</span><br><span class="line">    addKnownMapOutput(u.getHost() + <span class="string">":"</span> + u.getPort(),</span><br><span class="line">        u.toString(),</span><br><span class="line">        event.getTaskAttemptId());</span><br><span class="line">    maxMapRuntime = Math.max(maxMapRuntime, event.getTaskRunTime());</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> FAILED:</span><br><span class="line">  <span class="keyword">case</span> KILLED:</span><br><span class="line">  <span class="keyword">case</span> OBSOLETE:</span><br><span class="line">    obsoleteMapOutput(event.getTaskAttemptId());</span><br><span class="line">    LOG.info(<span class="string">"Ignoring obsolete output of "</span> + event.getTaskStatus() +</span><br><span class="line">        <span class="string">" map-task: '"</span> + event.getTaskAttemptId() + <span class="string">"'"</span>);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> TIPFAILED:</span><br><span class="line">    tipFailed(event.getTaskAttemptId().getTaskID());</span><br><span class="line">    LOG.info(<span class="string">"Ignoring output of failed map TIP: '"</span> +</span><br><span class="line">        event.getTaskAttemptId() + <span class="string">"'"</span>);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>EventFetcher</code>到此分析完毕，接下来分析<code>Fetcher</code>线程。<code>Fetcher</code>线程有两种，分别是<code>LocalFetcher</code>和<code>Fetcher</code>,顾名思义<code>LocalFetcher</code>是fetcher本地文件用的，没有用到http服务。<code>Fethcer</code>是通过 http Get 从远程nodemanager上fetcher map输出。这里主要分析<code>Fetcher</code>线程。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (!stopped &amp;&amp; !Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">      MapHost host = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// If merge is on, block</span></span><br><span class="line">        <span class="comment">// 存在内存到磁盘的merge，则Fetcher被block</span></span><br><span class="line">        <span class="comment">// 不像mapper端的环形缓冲区一样，可以一边向磁盘写，一边继续向内存写数据</span></span><br><span class="line">        <span class="comment">// 这里当存在MemToDisk的merge时，fetch操作被阻塞</span></span><br><span class="line">        <span class="comment">// memToDisk触发的条件是内存中的占比超过90%</span></span><br><span class="line">        merger.waitForResource();</span><br><span class="line">        <span class="comment">// Get a host to shuffle from</span></span><br><span class="line">        <span class="comment">// 随机得到一个Host</span></span><br><span class="line">        host = scheduler.getHost();</span><br><span class="line">        metrics.threadBusy();</span><br><span class="line">        <span class="comment">// Shuffle</span></span><br><span class="line">        copyFromHost(host);</span><br><span class="line">      &#125; </span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; </span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">copyFromHost</span><span class="params">(MapHost host)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Get completed maps on 'host'</span></span><br><span class="line">  <span class="comment">// 得到map list，最多拿到MAX_MAPS_AT_ONCE（默认是20）</span></span><br><span class="line">  List&lt;TaskAttemptID&gt; maps = scheduler.getMapsForHost(host);</span><br><span class="line">  <span class="comment">// Sanity check to catch hosts with only 'OBSOLETE' maps, </span></span><br><span class="line">  <span class="comment">// especially at the tail of large jobs</span></span><br><span class="line">  <span class="keyword">if</span> (maps.size() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// List of maps to be fetched yet</span></span><br><span class="line">  Set&lt;TaskAttemptID&gt; remaining = <span class="keyword">new</span> HashSet&lt;TaskAttemptID&gt;(maps);</span><br><span class="line">  <span class="comment">// Construct the url and connect</span></span><br><span class="line">  DataInputStream input = <span class="keyword">null</span>;</span><br><span class="line">  URL url = getMapOutputURL(host, maps);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// 通过jetty服务器创建http连接</span></span><br><span class="line">    setupConnectionsWithRetry(host, remaining, url);</span><br><span class="line">    <span class="keyword">if</span> (stopped) &#123;</span><br><span class="line">      abortConnect(host, remaining);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 根据http创建一个input流</span></span><br><span class="line">  input = <span class="keyword">new</span> DataInputStream(connection.getInputStream()); </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// Loop through available map-outputs and fetch them</span></span><br><span class="line">    <span class="comment">// On any error, faildTasks is not null and we exit</span></span><br><span class="line">    <span class="comment">// after putting back the remaining maps to the </span></span><br><span class="line">    <span class="comment">// yet_to_be_fetched list and marking the failed tasks.</span></span><br><span class="line">    TaskAttemptID[] failedTasks = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">while</span> (!remaining.isEmpty() &amp;&amp; failedTasks == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">      	<span class="comment">// 复制map</span></span><br><span class="line">        failedTasks = copyMapOutput(host, input, remaining, fetchRetryEnabled);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// Setup connection again if disconnected by NM</span></span><br><span class="line">        connection.disconnect();</span><br><span class="line">        <span class="comment">// Get map output from remaining tasks only.</span></span><br><span class="line">        url = getMapOutputURL(host, remaining);        </span><br><span class="line">        <span class="comment">// Connect with retry as expecting host's recovery take sometime.</span></span><br><span class="line">        setupConnectionsWithRetry(host, remaining, url);</span><br><span class="line">        <span class="keyword">if</span> (stopped) &#123;</span><br><span class="line">          abortConnect(host, remaining);</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        input = <span class="keyword">new</span> DataInputStream(connection.getInputStream());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> TaskAttemptID[] copyMapOutput(MapHost host,</span><br><span class="line">                              DataInputStream input,</span><br><span class="line">                              Set&lt;TaskAttemptID&gt; remaining,</span><br><span class="line">                              <span class="keyword">boolean</span> canRetry) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  ...  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">long</span> startTime = Time.monotonicNow();</span><br><span class="line">    <span class="keyword">int</span> forReduce = -<span class="number">1</span>;</span><br><span class="line">    <span class="comment">//Read the shuffle header</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      ShuffleHeader header = <span class="keyword">new</span> ShuffleHeader();</span><br><span class="line">      <span class="comment">// 读取内容到input流中</span></span><br><span class="line">      header.readFields(input);</span><br><span class="line">      mapId = TaskAttemptID.forName(header.mapId);</span><br><span class="line">      compressedLength = header.compressedLength;</span><br><span class="line">      decompressedLength = header.uncompressedLength;</span><br><span class="line">      forReduce = header.forReduce;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IllegalArgumentException e) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">    InputStream is = input;</span><br><span class="line">    is = CryptoUtils.wrapIfNecessary(jobConf, is, compressedLength);</span><br><span class="line">    compressedLength -= CryptoUtils.cryptoPadding(jobConf);</span><br><span class="line">    decompressedLength -= CryptoUtils.cryptoPadding(jobConf);</span><br><span class="line">    ...    </span><br><span class="line">    <span class="comment">// Get the location for the map output - either in-memory or on-disk</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 根据内容大小申请资源，此处决定写入的目的地 mem or disk</span></span><br><span class="line">      mapOutput = merger.reserve(mapId, decompressedLength, id);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Check if we can shuffle *now* ...</span></span><br><span class="line">    <span class="comment">// 如果当前内存使用超过memoryLimit，则merger.reserve 返回null</span></span><br><span class="line">    <span class="comment">// 此时不能shuffle</span></span><br><span class="line">    <span class="keyword">if</span> (mapOutput == <span class="keyword">null</span>) &#123;</span><br><span class="line">        LOG.info(<span class="string">"fetcher#"</span> + id + <span class="string">" - MergeManager returned status WAIT ..."</span>);</span><br><span class="line">        <span class="comment">//Not an error but wait to process data.</span></span><br><span class="line">        <span class="keyword">return</span> EMPTY_ATTEMPT_ID_ARRAY;</span><br><span class="line">    &#125; </span><br><span class="line">       </span><br><span class="line">    <span class="comment">// The codec for lz0,lz4,snappy,bz2,etc. throw java.lang.InternalError</span></span><br><span class="line">    <span class="comment">// on decompression failures. Catching and re-throwing as IOException</span></span><br><span class="line">    <span class="comment">// to allow fetch failure logic to be processed</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// Go!</span></span><br><span class="line">      LOG.info(<span class="string">"fetcher#"</span> + id + <span class="string">" about to shuffle output of map "</span></span><br><span class="line">          + mapOutput.getMapId() + <span class="string">" decomp: "</span> + decompressedLength</span><br><span class="line">          + <span class="string">" len: "</span> + compressedLength + <span class="string">" to "</span> + mapOutput.getDescription());</span><br><span class="line">      <span class="comment">// 将数据写入mem 或者 disk</span></span><br><span class="line">      mapOutput.shuffle(host, is, compressedLength, decompressedLength,</span><br><span class="line">          metrics, reporter);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (java.lang.InternalError e) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"Failed to shuffle for fetcher#"</span>+id, e);</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Inform the shuffle scheduler</span></span><br><span class="line">    <span class="keyword">long</span> endTime = Time.monotonicNow();</span><br><span class="line">    <span class="comment">// Reset retryStartTime as map task make progress if retried before.</span></span><br><span class="line">    retryStartTime = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// </span></span><br><span class="line">    scheduler.copySucceeded(mapId, host, compressedLength, </span><br><span class="line">                            startTime, endTime, mapOutput);</span><br><span class="line">    <span class="comment">// Note successful shuffle</span></span><br><span class="line">    remaining.remove(mapId);</span><br><span class="line">    metrics.successFetch();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>Fetcher</code>线程的run方法中先判断是否有<em>merge</em>，如果有则block当前<code>Fetcher</code>线程，这里只判断是否<em>存在内存到磁盘的merge</em>。随后从<em>Host</em>列表中_随机_选出一个<em>Host</em>（随机方法可查看<code>scheduler.getHost()</code>代码），进行copy，copy的入口是<code>copyFromHost</code>，<code>copyFromHost</code>的主要工作是建立<em>http连接</em>，然后循环调用<code>copyMapOutput</code>对<em>某个map</em>的输出进行copy。在<code>copyMapOutput</code>中会判断当前的内容是输出到mem还是disk，此处的逻辑判断在<code>merger.reserve()</code>中，看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> MapOutput&lt;K,V&gt; <span class="title">reserve</span><span class="params">(TaskAttemptID mapId, </span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">long</span> requestedSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           <span class="keyword">int</span> fetcher</span></span></span><br><span class="line"><span class="function"><span class="params">                                           )</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 判断当前内容大小是否能写入Memory，不能则直接写入disk</span></span><br><span class="line">  <span class="comment">// requestedSize &lt; maxSingleShuffleLimit 为true</span></span><br><span class="line">  <span class="comment">// memoryLimit * mapreduce.reduce.shuffle.memory.limit.percent</span></span><br><span class="line">  <span class="keyword">if</span> (!canShuffleToMemory(requestedSize)) &#123;</span><br><span class="line">    LOG.info(mapId + <span class="string">": Shuffling to disk since "</span> + requestedSize + </span><br><span class="line">             <span class="string">" is greater than maxSingleShuffleLimit ("</span> + </span><br><span class="line">             maxSingleShuffleLimit + <span class="string">")"</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> OnDiskMapOutput&lt;K,V&gt;(mapId, reduceId, <span class="keyword">this</span>, requestedSize,</span><br><span class="line">                                    jobConf, mapOutputFile, fetcher, <span class="keyword">true</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Stall shuffle if we are above the memory limit</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 下面这段英语的意思是说：</span></span><br><span class="line">  <span class="comment">// 如果将(usedMemory &gt; memoryLimit) 改为 (usedMemory + requestedSize &gt; memoryLimit)</span></span><br><span class="line">  <span class="comment">// 会出现所有的Fetcher线程被死循环</span></span><br><span class="line">  <span class="comment">// 当used size &lt; mergeThreshold &amp;&amp; requested size &lt; singleShuffleLimit </span></span><br><span class="line">  <span class="comment">// &amp;&amp; usedMemory + requestedSize &gt; memoryLimit 则写操作暂停，但此时并没有</span></span><br><span class="line">  <span class="comment">// 超过mergeThreshold，并不会触发merge Thread，则假如所有的Fetcher的requested size 都满足</span></span><br><span class="line">  <span class="comment">// usedMemory + requestedSize &gt; memoryLimit，则此时all threads could just be stalling and not </span></span><br><span class="line">  <span class="comment">// make progress at all.</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// It is possible that all threads could just be stalling and not make</span></span><br><span class="line">  <span class="comment">// progress at all. This could happen when:</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// requested size is causing the used memory to go above limit &amp;&amp;</span></span><br><span class="line">  <span class="comment">// requested size &lt; singleShuffleLimit &amp;&amp;</span></span><br><span class="line">  <span class="comment">// current used size &lt; mergeThreshold (merge will not get triggered)</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// To avoid this from happening, we allow exactly one thread to go past</span></span><br><span class="line">  <span class="comment">// the memory limit. We check (usedMemory &gt; memoryLimit) and not</span></span><br><span class="line">  <span class="comment">// (usedMemory + requestedSize &gt; memoryLimit). When this thread is done</span></span><br><span class="line">  <span class="comment">// fetching, this will automatically trigger a merge thereby unlocking</span></span><br><span class="line">  <span class="comment">// all the stalled threads</span></span><br><span class="line">  <span class="comment">// 如果usedMemory &gt; memoryLimit 则返回null，暂定shuffle，等待memToDisk</span></span><br><span class="line">  <span class="keyword">if</span> (usedMemory &gt; memoryLimit) &#123;</span><br><span class="line">    LOG.debug(mapId + <span class="string">": Stalling shuffle since usedMemory ("</span> + usedMemory</span><br><span class="line">        + <span class="string">") is greater than memoryLimit ("</span> + memoryLimit + <span class="string">")."</span> + </span><br><span class="line">        <span class="string">" CommitMemory is ("</span> + commitMemory + <span class="string">")"</span>); </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Allow the in-memory shuffle to progress</span></span><br><span class="line">  LOG.debug(mapId + <span class="string">": Proceeding with shuffle since usedMemory ("</span></span><br><span class="line">      + usedMemory + <span class="string">") is lesser than memoryLimit ("</span> + memoryLimit + <span class="string">")."</span></span><br><span class="line">      + <span class="string">"CommitMemory is ("</span> + commitMemory + <span class="string">")"</span>);</span><br><span class="line">  <span class="comment">// usedMemory += requestedSize and new InMemoryMapOutput </span></span><br><span class="line">  <span class="keyword">return</span> unconditionalReserve(mapId, requestedSize, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由<code>merger.reserve()</code>得到<em>OnDiskMapOutput</em>或者<em>InMemoryMapOutput</em>之后，调用<code>mapOutput.shuffle</code>将内容通过输出流写入Memory或者Disk。随后由<code>scheduler.copySucceeded</code>进行收尾工作，主要包括将已完成copy的map状态设置为true（map copy的状态存储在<code>finishedMaps</code>的boolean数组中，mapIndex为数组的id，完成则为true），完成一些统计信息，以及由<code>output.commit()</code>提交并关闭mapOutput流，在关闭的过程中会判断是否需要<em>merge</em>。下面看下代码，重点看下<code>output.commit</code>：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">copySucceeded</span><span class="params">(TaskAttemptID mapId,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       MapHost host,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       <span class="keyword">long</span> bytes,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       <span class="keyword">long</span> startMillis,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       <span class="keyword">long</span> endMillis,</span></span></span><br><span class="line"><span class="function"><span class="params">                                       MapOutput&lt;K,V&gt; output</span></span></span><br><span class="line"><span class="function"><span class="params">                                       )</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 对完成的map进行一些状态修改                                      </span></span><br><span class="line">  failureCounts.remove(mapId);</span><br><span class="line">  hostFailures.remove(host.getHostName());</span><br><span class="line">  <span class="keyword">int</span> mapIndex = mapId.getTaskID().getId();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!finishedMaps[mapIndex]) &#123;</span><br><span class="line">    <span class="comment">// 提交并关闭mapOutput流 并 判断是否触发merge线程</span></span><br><span class="line">    output.commit();</span><br><span class="line">    <span class="comment">// finishedMaps中对应的map的状态设置为true</span></span><br><span class="line">    finishedMaps[mapIndex] = <span class="keyword">true</span>;</span><br><span class="line">    shuffledMapsCounter.increment(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">if</span> (--remainingMaps == <span class="number">0</span>) &#123;</span><br><span class="line">      notifyAll();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update single copy task status</span></span><br><span class="line">    <span class="comment">// 完成统计信息</span></span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// InMemoryMapOutput.commit</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  merger.closeInMemoryFile(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// OnDiskMapOutput.commit</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">commit</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  fs.rename(tmpOutputPath, outputPath);</span><br><span class="line">  CompressAwarePath compressAwarePath = <span class="keyword">new</span> CompressAwarePath(outputPath,</span><br><span class="line">      getSize(), <span class="keyword">this</span>.compressedSize);</span><br><span class="line">  merger.closeOnDiskFile(compressAwarePath);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由<code>merger.reserve()</code>得到mapOutput有两种情况，则先来看<code>InMemoryMapOutput.commit</code>，其内调用了<code>closeInMemoryFile</code>，观其代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">closeInMemoryFile</span><span class="params">(InMemoryMapOutput&lt;K,V&gt; mapOutput)</span> </span>&#123; </span><br><span class="line">  inMemoryMapOutputs.add(mapOutput);</span><br><span class="line">  LOG.info(<span class="string">"closeInMemoryFile -&gt; map-output of size: "</span> + mapOutput.getSize()</span><br><span class="line">      + <span class="string">", inMemoryMapOutputs.size() -&gt; "</span> + inMemoryMapOutputs.size()</span><br><span class="line">      + <span class="string">", commitMemory -&gt; "</span> + commitMemory + <span class="string">", usedMemory -&gt;"</span> + usedMemory);</span><br><span class="line">  <span class="comment">// 更新内存使用量</span></span><br><span class="line">  commitMemory+= mapOutput.getSize();</span><br><span class="line">  <span class="comment">// 判断当前使用量是否超过mergeThreshold  mapreduce.reduce.shuffle.merge.percent</span></span><br><span class="line">  <span class="comment">// Can hang if mergeThreshold is really low.</span></span><br><span class="line">  <span class="keyword">if</span> (commitMemory &gt;= mergeThreshold) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Starting inMemoryMerger's merge since commitMemory="</span> +</span><br><span class="line">        commitMemory + <span class="string">" &gt; mergeThreshold="</span> + mergeThreshold + </span><br><span class="line">        <span class="string">". Current usedMemory="</span> + usedMemory);</span><br><span class="line">    <span class="comment">// inMemoryMergedMapOutputs 是由memTomem更新的</span></span><br><span class="line">    inMemoryMapOutputs.addAll(inMemoryMergedMapOutputs);</span><br><span class="line">    inMemoryMergedMapOutputs.clear();</span><br><span class="line">    <span class="comment">// 触发MergeThread进行merge</span></span><br><span class="line">    inMemoryMerger.startMerge(inMemoryMapOutputs);</span><br><span class="line">    commitMemory = <span class="number">0L</span>;  <span class="comment">// Reset commitMemory.</span></span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (memToMemMerger != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (inMemoryMapOutputs.size() &gt;= memToMemMergeOutputsThreshold) &#123; </span><br><span class="line">      memToMemMerger.startMerge(inMemoryMapOutputs);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再来看下<code>OnDiskMapOutput.commit</code>，将输出的临时文件重命名，然后调用<code>closeOnDiskFile</code>，查其代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">closeOnDiskFile</span><span class="params">(CompressAwarePath file)</span> </span>&#123;</span><br><span class="line">  onDiskMapOutputs.add(file);</span><br><span class="line">  <span class="comment">// 是否满足Disk merge条件</span></span><br><span class="line">  <span class="keyword">if</span> (onDiskMapOutputs.size() &gt;= (<span class="number">2</span> * ioSortFactor - <span class="number">1</span>)) &#123;</span><br><span class="line">    <span class="comment">// 触发MergeThread进行merge</span></span><br><span class="line">    onDiskMerger.startMerge(onDiskMapOutputs);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在两个<code>commit</code>里都是通过<code>startMerge</code>触发MergeThread的，其代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MergeThread.startMerge</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">startMerge</span><span class="params">(Set&lt;T&gt; inputs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!closed) &#123;</span><br><span class="line">    <span class="comment">// 标识触发merge的次数</span></span><br><span class="line">    numPending.incrementAndGet();</span><br><span class="line">    List&lt;T&gt; toMergeInputs = <span class="keyword">new</span> ArrayList&lt;T&gt;();</span><br><span class="line">    Iterator&lt;T&gt; iter=inputs.iterator();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> ctr = <span class="number">0</span>; iter.hasNext() &amp;&amp; ctr &lt; mergeFactor; ++ctr) &#123;</span><br><span class="line">      toMergeInputs.add(iter.next());</span><br><span class="line">      iter.remove();</span><br><span class="line">    &#125;</span><br><span class="line">    LOG.info(getName() + <span class="string">": Starting merge with "</span> + toMergeInputs.size() + </span><br><span class="line">             <span class="string">" segments, while ignoring "</span> + inputs.size() + <span class="string">" segments"</span>);</span><br><span class="line">    <span class="keyword">synchronized</span>(pendingToBeMerged) &#123;</span><br><span class="line">      <span class="comment">// 将待merge的output放入pendingToBeMerged中</span></span><br><span class="line">      <span class="comment">// pendingToBeMerged 是LinkedList</span></span><br><span class="line">      pendingToBeMerged.addLast(toMergeInputs);</span><br><span class="line">      pendingToBeMerged.notifyAll();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先<code>numPending</code>记录了触发merge的次数，<em>numPending</em>会在<code>MergeThread.waitForMerge()</code>和<code>MergeThread.run</code>中用到，<code>MergeThread.waitForMerge()</code>在<code>Fetcher.run</code>通过<code>merger.waitForResource()</code> 调用，判断当前是否有merge线程，有则阻塞Fetcher线程。在<code>MergeThread.run</code>中如果merge成功则调用<code>numPending.decrementAndGet();notifyAll();</code>更新<em>numPending</em>的状态并通知所有被<code>MergeThread.wait()</code>阻塞的线程。<br><code>pendingToBeMerged</code>是<em>LinkedList</em>类型的，将需要merge的list添加到<em>pendingToBeMerged</em>末尾，在<code>MergeThread.run</code>中从链表的头取出需要merge的list。<code>MergeThread.run</code>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    List&lt;T&gt; inputs = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// Wait for notification to start the merge...</span></span><br><span class="line">      <span class="keyword">synchronized</span> (pendingToBeMerged) &#123;</span><br><span class="line">        <span class="comment">// pendingToBeMerged中没有时mergeThread阻塞</span></span><br><span class="line">        <span class="keyword">while</span>(pendingToBeMerged.size() &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">          pendingToBeMerged.wait();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Pickup the inputs to merge.</span></span><br><span class="line">        inputs = pendingToBeMerged.removeFirst();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Merge</span></span><br><span class="line">      <span class="comment">// 具体的merge，由InMemoryMapOutput和OnDiskMapOutput实现</span></span><br><span class="line">      merge(inputs);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">      numPending.set(<span class="number">0</span>);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Throwable t) &#123;</span><br><span class="line">      numPending.set(<span class="number">0</span>);</span><br><span class="line">      reporter.reportException(t);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">        <span class="comment">// merge成功并通知被阻塞的线程</span></span><br><span class="line">        numPending.decrementAndGet();</span><br><span class="line">        notifyAll();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由<code>MergeThread.startMerge</code>激活<code>MergeThread</code>线程之后，从<code>pendingToBeMerged</code>中取出链头的元素，通过不同类实现的<code>merge()</code>方法进行具体的merge过程，最后更新<em>mumPending</em>的状态。这里主要分析下<em>InMemoryMapOutput</em>和<em>OnDiskMapOutput</em>实现的merge方法。先看<code>InMemoryMapOutput.merge</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(List&lt;InMemoryMapOutput&lt;K,V&gt;&gt; inputs)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (inputs == <span class="keyword">null</span> || inputs.size() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//name this output file same as the name of the first file that is </span></span><br><span class="line">  <span class="comment">//there in the current list of inmem files (this is guaranteed to</span></span><br><span class="line">  <span class="comment">//be absent on the disk currently. So we don't overwrite a prev. </span></span><br><span class="line">  <span class="comment">//created spill). Also we need to create the output file now since</span></span><br><span class="line">  <span class="comment">//it is not guaranteed that this file will be present after merge</span></span><br><span class="line">  <span class="comment">//is called (we delete empty files as soon as we see them</span></span><br><span class="line">  <span class="comment">//in the merge method)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">//figure out the mapId </span></span><br><span class="line">  TaskAttemptID mapId = inputs.get(<span class="number">0</span>).getMapId();</span><br><span class="line">  TaskID mapTaskId = mapId.getTaskID();</span><br><span class="line"></span><br><span class="line">  List&lt;Segment&lt;K, V&gt;&gt; inMemorySegments = <span class="keyword">new</span> ArrayList&lt;Segment&lt;K, V&gt;&gt;();</span><br><span class="line">  <span class="keyword">long</span> mergeOutputSize = </span><br><span class="line">    createInMemorySegments(inputs, inMemorySegments,<span class="number">0</span>);</span><br><span class="line">  <span class="keyword">int</span> noInMemorySegments = inMemorySegments.size();</span><br><span class="line"></span><br><span class="line">  Path outputPath = </span><br><span class="line">    mapOutputFile.getInputFileForWrite(mapTaskId,</span><br><span class="line">                                       mergeOutputSize).suffix(</span><br><span class="line">                                           Task.MERGED_OUTPUT_PREFIX);</span><br><span class="line"></span><br><span class="line">  FSDataOutputStream out = CryptoUtils.wrapIfNecessary(jobConf, rfs.create(outputPath));</span><br><span class="line">  Writer&lt;K, V&gt; writer = <span class="keyword">new</span> Writer&lt;K, V&gt;(jobConf, out,</span><br><span class="line">      (Class&lt;K&gt;) jobConf.getMapOutputKeyClass(),</span><br><span class="line">      (Class&lt;V&gt;) jobConf.getMapOutputValueClass(), codec, <span class="keyword">null</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">  RawKeyValueIterator rIter = <span class="keyword">null</span>;</span><br><span class="line">  CompressAwarePath compressAwarePath;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    LOG.info(<span class="string">"Initiating in-memory merge with "</span> + noInMemorySegments + </span><br><span class="line">             <span class="string">" segments..."</span>);</span><br><span class="line">    </span><br><span class="line">    rIter = Merger.merge(jobConf, rfs,</span><br><span class="line">                         (Class&lt;K&gt;)jobConf.getMapOutputKeyClass(),</span><br><span class="line">                         (Class&lt;V&gt;)jobConf.getMapOutputValueClass(),</span><br><span class="line">                         inMemorySegments, inMemorySegments.size(),</span><br><span class="line">                         <span class="keyword">new</span> Path(reduceId.toString()),</span><br><span class="line">                         (RawComparator&lt;K&gt;)jobConf.getOutputKeyComparator(),</span><br><span class="line">                         reporter, spilledRecordsCounter, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == combinerClass) &#123;</span><br><span class="line">      Merger.writeFile(rIter, writer, reporter, jobConf);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      combineCollector.setWriter(writer);</span><br><span class="line">      combineAndSpill(rIter, reduceCombineInputCounter);</span><br><span class="line">    &#125;</span><br><span class="line">    writer.close();</span><br><span class="line">    compressAwarePath = <span class="keyword">new</span> CompressAwarePath(outputPath,</span><br><span class="line">        writer.getRawLength(), writer.getCompressedLength());</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123; </span><br><span class="line">    <span class="comment">//make sure that we delete the ondisk file that we created </span></span><br><span class="line">    <span class="comment">//earlier when we invoked cloneFileAttributes</span></span><br><span class="line">    localFS.delete(outputPath, <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Note the output of the merge</span></span><br><span class="line">  closeOnDiskFile(compressAwarePath);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>InMemoryMapOutput.merge</code>主要是调用了<code>Merger.merge</code>对各个文件进行堆排序，这里还要判断下是否有<code>combiner</code>（<strong>只有mem to disk时才会判断</strong>），方法的结尾会调用<code>closeOnDiskFile</code>，检查下内存的文件merge到disk之后，是否满足disk merge的条件。<code>InMemoryMapOutput.merge</code>到此结束，接下来看下<code>OnDiskMapOutput.merge</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(List&lt;CompressAwarePath&gt; inputs)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// sanity check</span></span><br><span class="line">  <span class="keyword">if</span> (inputs == <span class="keyword">null</span> || inputs.isEmpty()) &#123;</span><br><span class="line">    LOG.info(<span class="string">"No ondisk files to merge..."</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">long</span> approxOutputSize = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> bytesPerSum = </span><br><span class="line">    jobConf.getInt(<span class="string">"io.bytes.per.checksum"</span>, <span class="number">512</span>);</span><br><span class="line">  </span><br><span class="line">  LOG.info(<span class="string">"OnDiskMerger: We have  "</span> + inputs.size() + </span><br><span class="line">           <span class="string">" map outputs on disk. Triggering merge..."</span>);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// 1. Prepare the list of files to be merged. </span></span><br><span class="line">  <span class="keyword">for</span> (CompressAwarePath file : inputs) &#123;</span><br><span class="line">    approxOutputSize += localFS.getFileStatus(file).getLen();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// add the checksum length</span></span><br><span class="line">  approxOutputSize += </span><br><span class="line">    ChecksumFileSystem.getChecksumLength(approxOutputSize, bytesPerSum);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 2. Start the on-disk merge process</span></span><br><span class="line">  Path outputPath = </span><br><span class="line">    localDirAllocator.getLocalPathForWrite(inputs.get(<span class="number">0</span>).toString(), </span><br><span class="line">        approxOutputSize, jobConf).suffix(Task.MERGED_OUTPUT_PREFIX);</span><br><span class="line"></span><br><span class="line">  FSDataOutputStream out = CryptoUtils.wrapIfNecessary(jobConf, rfs.create(outputPath));</span><br><span class="line">  Writer&lt;K, V&gt; writer = <span class="keyword">new</span> Writer&lt;K, V&gt;(jobConf, out,</span><br><span class="line">      (Class&lt;K&gt;) jobConf.getMapOutputKeyClass(),</span><br><span class="line">      (Class&lt;V&gt;) jobConf.getMapOutputValueClass(), codec, <span class="keyword">null</span>, <span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">  RawKeyValueIterator iter  = <span class="keyword">null</span>;</span><br><span class="line">  CompressAwarePath compressAwarePath;</span><br><span class="line">  Path tmpDir = <span class="keyword">new</span> Path(reduceId.toString());</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    iter = Merger.merge(jobConf, rfs,</span><br><span class="line">                        (Class&lt;K&gt;) jobConf.getMapOutputKeyClass(),</span><br><span class="line">                        (Class&lt;V&gt;) jobConf.getMapOutputValueClass(),</span><br><span class="line">                        codec, inputs.toArray(<span class="keyword">new</span> Path[inputs.size()]), </span><br><span class="line">                        <span class="keyword">true</span>, ioSortFactor, tmpDir, </span><br><span class="line">                        (RawComparator&lt;K&gt;) jobConf.getOutputKeyComparator(), </span><br><span class="line">                        reporter, spilledRecordsCounter, <span class="keyword">null</span>, </span><br><span class="line">                        mergedMapOutputsCounter, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">    Merger.writeFile(iter, writer, reporter, jobConf);</span><br><span class="line">    writer.close();</span><br><span class="line">    compressAwarePath = <span class="keyword">new</span> CompressAwarePath(outputPath,</span><br><span class="line">        writer.getRawLength(), writer.getCompressedLength());</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    localFS.delete(outputPath, <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">throw</span> e;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  closeOnDiskFile(compressAwarePath);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>OnDiskMapOutput.merge</code>也是调用<code>Merger.merge</code>对文件进行堆排序，然后write到本地，最后依然会调用<code>closeOnDiskFile</code>检查merge之后是否依然满足disk merge条件。<br><em>Fetcher</em>线程分析结束，代码回到<code>Shuffle.run</code>中，此时copy阶段结束，执行<code>copyPhase.complete()</code>,标识<em>SORT</em>阶段，执行<code>taskStatus.setPhase(TaskStatus.Phase.SORT)</code>,真正的sort逻辑是在<code>merger.close()</code>，之所以把把此阶段称为<strong>SORT阶段</strong>，可能是因为在此阶段是纯粹的SORT吧，而不掺杂别的操作，这就可以解释为什么在之前的<em>COPY阶段</em>虽然也存在SORT，但并没有将SORT阶段从此处开始。下面跟下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> RawKeyValueIterator <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> finalMerge(jobConf, rfs, memory, disk);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> RawKeyValueIterator <span class="title">finalMerge</span><span class="params">(JobConf job, FileSystem fs,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     List&lt;InMemoryMapOutput&lt;K,V&gt;&gt; inMemoryMapOutputs,</span></span></span><br><span class="line"><span class="function"><span class="params">                                     List&lt;CompressAwarePath&gt; onDiskMapOutputs</span></span></span><br><span class="line"><span class="function"><span class="params">                                     )</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 每个reduce最大的buffer占百分比</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">float</span> maxRedPer =</span><br><span class="line">    job.getFloat(MRJobConfig.REDUCE_INPUT_BUFFER_PERCENT, <span class="number">0f</span>);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// reduce用于存储buffer的最大内存</span></span><br><span class="line">  <span class="keyword">int</span> maxInMemReduce = (<span class="keyword">int</span>)Math.min(</span><br><span class="line">      Runtime.getRuntime().maxMemory() * maxRedPer, Integer.MAX_VALUE);</span><br><span class="line">  <span class="comment">// merge config params</span></span><br><span class="line">  Class&lt;K&gt; keyClass = (Class&lt;K&gt;)job.getMapOutputKeyClass();</span><br><span class="line">  Class&lt;V&gt; valueClass = (Class&lt;V&gt;)job.getMapOutputValueClass();</span><br><span class="line">  <span class="keyword">boolean</span> keepInputs = job.getKeepFailedTaskFiles();</span><br><span class="line">  <span class="keyword">final</span> Path tmpDir = <span class="keyword">new</span> Path(reduceId.toString());</span><br><span class="line">  <span class="keyword">final</span> RawComparator&lt;K&gt; comparator =</span><br><span class="line">    (RawComparator&lt;K&gt;)job.getOutputKeyComparator();</span><br><span class="line">  <span class="comment">// segments required to vacate memory</span></span><br><span class="line">  List&lt;Segment&lt;K,V&gt;&gt; memDiskSegments = <span class="keyword">new</span> ArrayList&lt;Segment&lt;K,V&gt;&gt;();</span><br><span class="line">  <span class="keyword">long</span> inMemToDiskBytes = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 标识是否进行mergePhase是否完成，是否执行内部merge？？？？？</span></span><br><span class="line">  <span class="keyword">boolean</span> mergePhaseFinished = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">if</span> (inMemoryMapOutputs.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    TaskID mapId = inMemoryMapOutputs.get(<span class="number">0</span>).getMapId().getTaskID();</span><br><span class="line">    inMemToDiskBytes = createInMemorySegments(inMemoryMapOutputs, </span><br><span class="line">                                              memDiskSegments,</span><br><span class="line">                                              maxInMemReduce);</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> numMemDiskSegments = memDiskSegments.size();</span><br><span class="line">    <span class="comment">// 不符合条件就走到了if底</span></span><br><span class="line">    <span class="comment">// 内存中有数据，磁盘中的文件少，</span></span><br><span class="line">    <span class="keyword">if</span> (numMemDiskSegments &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">          ioSortFactor &gt; onDiskMapOutputs.size()) &#123;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// If we reach here, it implies that we have less than io.sort.factor</span></span><br><span class="line">      <span class="comment">// disk segments and this will be incremented by 1 (result of the </span></span><br><span class="line">      <span class="comment">// memory segments merge). Since this total would still be </span></span><br><span class="line">      <span class="comment">// &lt;= io.sort.factor, we will not do any more intermediate merges,</span></span><br><span class="line">      <span class="comment">// the merge of all these disk segments would be directly fed to the</span></span><br><span class="line">      <span class="comment">// reduce method</span></span><br><span class="line">      </span><br><span class="line">      mergePhaseFinished = <span class="keyword">true</span>;</span><br><span class="line">      <span class="comment">// must spill to disk, but can't retain in-mem for intermediate merge</span></span><br><span class="line">      <span class="keyword">final</span> Path outputPath = </span><br><span class="line">        mapOutputFile.getInputFileForWrite(mapId,</span><br><span class="line">                                           inMemToDiskBytes).suffix(</span><br><span class="line">                                               Task.MERGED_OUTPUT_PREFIX);</span><br><span class="line">      <span class="keyword">final</span> RawKeyValueIterator rIter = Merger.merge(job, fs,</span><br><span class="line">          keyClass, valueClass, memDiskSegments, numMemDiskSegments,</span><br><span class="line">          tmpDir, comparator, reporter, spilledRecordsCounter, <span class="keyword">null</span>, </span><br><span class="line">          mergePhase);</span><br><span class="line"></span><br><span class="line">      FSDataOutputStream out = CryptoUtils.wrapIfNecessary(job, fs.create(outputPath));</span><br><span class="line">      Writer&lt;K, V&gt; writer = <span class="keyword">new</span> Writer&lt;K, V&gt;(job, out, keyClass, valueClass,</span><br><span class="line">          codec, <span class="keyword">null</span>, <span class="keyword">true</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        Merger.writeFile(rIter, writer, reporter, job);</span><br><span class="line">        writer.close();</span><br><span class="line">        onDiskMapOutputs.add(<span class="keyword">new</span> CompressAwarePath(outputPath,</span><br><span class="line">            writer.getRawLength(), writer.getCompressedLength()));</span><br><span class="line">        writer = <span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">// add to list of final disk outputs.</span></span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != outputPath) &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            fs.delete(outputPath, <span class="keyword">true</span>);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">            <span class="comment">// NOTHING</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">null</span> != writer) &#123;</span><br><span class="line">          writer.close();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      LOG.info(<span class="string">"Merged "</span> + numMemDiskSegments + <span class="string">" segments, "</span> +</span><br><span class="line">               inMemToDiskBytes + <span class="string">" bytes to disk to satisfy "</span> +</span><br><span class="line">               <span class="string">"reduce memory limit"</span>);</span><br><span class="line">      inMemToDiskBytes = <span class="number">0</span>;</span><br><span class="line">      memDiskSegments.clear();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (inMemToDiskBytes != <span class="number">0</span>) &#123;</span><br><span class="line">      LOG.info(<span class="string">"Keeping "</span> + numMemDiskSegments + <span class="string">" segments, "</span> +</span><br><span class="line">               inMemToDiskBytes + <span class="string">" bytes in memory for "</span> +</span><br><span class="line">               <span class="string">"intermediate, on-disk merge"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// segments on disk</span></span><br><span class="line">  List&lt;Segment&lt;K,V&gt;&gt; diskSegments = <span class="keyword">new</span> ArrayList&lt;Segment&lt;K,V&gt;&gt;();</span><br><span class="line">  <span class="keyword">long</span> onDiskBytes = inMemToDiskBytes;</span><br><span class="line">  <span class="keyword">long</span> rawBytes = inMemToDiskBytes;</span><br><span class="line">  CompressAwarePath[] onDisk = onDiskMapOutputs.toArray(</span><br><span class="line">      <span class="keyword">new</span> CompressAwarePath[onDiskMapOutputs.size()]);</span><br><span class="line">  <span class="keyword">for</span> (CompressAwarePath file : onDisk) &#123;</span><br><span class="line">    <span class="keyword">long</span> fileLength = fs.getFileStatus(file).getLen();</span><br><span class="line">    onDiskBytes += fileLength;</span><br><span class="line">    rawBytes += (file.getRawDataLength() &gt; <span class="number">0</span>) ? file.getRawDataLength() : fileLength;</span><br><span class="line"></span><br><span class="line">    LOG.debug(<span class="string">"Disk file: "</span> + file + <span class="string">" Length is "</span> + fileLength);</span><br><span class="line">    diskSegments.add(<span class="keyword">new</span> Segment&lt;K, V&gt;(job, fs, file, codec, keepInputs,</span><br><span class="line">                                       (file.toString().endsWith(</span><br><span class="line">                                           Task.MERGED_OUTPUT_PREFIX) ?</span><br><span class="line">                                        <span class="keyword">null</span> : mergedMapOutputsCounter), file.getRawDataLength()</span><br><span class="line">                                      ));</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.info(<span class="string">"Merging "</span> + onDisk.length + <span class="string">" files, "</span> +</span><br><span class="line">           onDiskBytes + <span class="string">" bytes from disk"</span>);</span><br><span class="line">  <span class="comment">// 安装长度大小进行排序，方便进行最小堆排序？？？？？？</span></span><br><span class="line">  Collections.sort(diskSegments, <span class="keyword">new</span> Comparator&lt;Segment&lt;K,V&gt;&gt;() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Segment&lt;K, V&gt; o1, Segment&lt;K, V&gt; o2)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">if</span> (o1.getLength() == o2.getLength()) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> o1.getLength() &lt; o2.getLength() ? -<span class="number">1</span> : <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// build final list of segments from merged backed by disk + in-mem</span></span><br><span class="line">  List&lt;Segment&lt;K,V&gt;&gt; finalSegments = <span class="keyword">new</span> ArrayList&lt;Segment&lt;K,V&gt;&gt;();</span><br><span class="line">  <span class="keyword">long</span> inMemBytes = createInMemorySegments(inMemoryMapOutputs, </span><br><span class="line">                                           finalSegments, <span class="number">0</span>);</span><br><span class="line">  LOG.info(<span class="string">"Merging "</span> + finalSegments.size() + <span class="string">" segments, "</span> +</span><br><span class="line">           inMemBytes + <span class="string">" bytes from memory into reduce"</span>);</span><br><span class="line">  <span class="keyword">if</span> (<span class="number">0</span> != onDiskBytes) &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> numInMemSegments = memDiskSegments.size();</span><br><span class="line">    diskSegments.addAll(<span class="number">0</span>, memDiskSegments);</span><br><span class="line">    memDiskSegments.clear();</span><br><span class="line">    <span class="comment">// Pass mergePhase only if there is a going to be intermediate</span></span><br><span class="line">    <span class="comment">// merges. See comment where mergePhaseFinished is being set</span></span><br><span class="line">    Progress thisPhase = (mergePhaseFinished) ? <span class="keyword">null</span> : mergePhase; </span><br><span class="line">    RawKeyValueIterator diskMerge = Merger.merge(</span><br><span class="line">        job, fs, keyClass, valueClass, codec, diskSegments,</span><br><span class="line">        ioSortFactor, numInMemSegments, tmpDir, comparator,</span><br><span class="line">        reporter, <span class="keyword">false</span>, spilledRecordsCounter, <span class="keyword">null</span>, thisPhase);</span><br><span class="line">    diskSegments.clear();</span><br><span class="line">    <span class="keyword">if</span> (<span class="number">0</span> == finalSegments.size()) &#123;</span><br><span class="line">      <span class="keyword">return</span> diskMerge;</span><br><span class="line">    &#125;</span><br><span class="line">    finalSegments.add(<span class="keyword">new</span> Segment&lt;K,V&gt;(</span><br><span class="line">          <span class="keyword">new</span> RawKVIteratorReader(diskMerge, onDiskBytes), <span class="keyword">true</span>, rawBytes));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> Merger.merge(job, fs, keyClass, valueClass,</span><br><span class="line">               finalSegments, finalSegments.size(), tmpDir,</span><br><span class="line">               comparator, reporter, spilledRecordsCounter, <span class="keyword">null</span>,</span><br><span class="line">               <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此阶段的主要逻辑在<code>finalMerge</code>中实现，这里的代码逻辑是先判断内存中的数据和磁盘中的文件个数的多少（ioSortFactor &gt; onDiskMapOutputs.size()），符合条件则进行内存中的文件进行merge，输出到disk中。随后对disk中的文件进行merge，此处夹杂一行代码<code>Collections.sort</code>，对disk中的文件进行长度的排序，形成一个小顶堆进行merge，将内存和磁盘最终的merge文件放入finalSegments中进行最终的merge。则shuffle.run结束。准备进入下一阶段<em>Reduce阶段</em>。回到ReduceTask.run中，根据api执行<code>runNewReducer</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runNewReducer</span><span class="params">(JobConf job,</span></span></span><br><span class="line"><span class="function"><span class="params">                   <span class="keyword">final</span> TaskUmbilicalProtocol umbilical,</span></span></span><br><span class="line"><span class="function"><span class="params">                   <span class="keyword">final</span> TaskReporter reporter,</span></span></span><br><span class="line"><span class="function"><span class="params">                   RawKeyValueIterator rIter,</span></span></span><br><span class="line"><span class="function"><span class="params">                   RawComparator&lt;INKEY&gt; comparator,</span></span></span><br><span class="line"><span class="function"><span class="params">                   Class&lt;INKEY&gt; keyClass,</span></span></span><br><span class="line"><span class="function"><span class="params">                   Class&lt;INVALUE&gt; valueClass</span></span></span><br><span class="line"><span class="function"><span class="params">                   )</span> <span class="keyword">throws</span> IOException,InterruptedException, </span></span><br><span class="line"><span class="function">                            ClassNotFoundException </span>&#123;</span><br><span class="line">  <span class="comment">// wrap value iterator to report progress.</span></span><br><span class="line">  <span class="keyword">final</span> RawKeyValueIterator rawIter = rIter;</span><br><span class="line">  rIter = <span class="keyword">new</span> RawKeyValueIterator() &#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      rawIter.close();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> DataInputBuffer <span class="title">getKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> rawIter.getKey();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> Progress <span class="title">getProgress</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> rawIter.getProgress();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> DataInputBuffer <span class="title">getValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> rawIter.getValue();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">next</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">boolean</span> ret = rawIter.next();</span><br><span class="line">      reporter.setProgress(rawIter.getProgress().getProgress());</span><br><span class="line">      <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="comment">// make a task context so we can get the classes</span></span><br><span class="line">  org.apache.hadoop.mapreduce.TaskAttemptContext taskContext =</span><br><span class="line">    <span class="keyword">new</span> org.apache.hadoop.mapreduce.task.TaskAttemptContextImpl(job,</span><br><span class="line">        getTaskID(), reporter);</span><br><span class="line">  <span class="comment">// make a reducer</span></span><br><span class="line">  org.apache.hadoop.mapreduce.Reducer&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt; reducer =</span><br><span class="line">    (org.apache.hadoop.mapreduce.Reducer&lt;INKEY,INVALUE,OUTKEY,OUTVALUE&gt;)</span><br><span class="line">      ReflectionUtils.newInstance(taskContext.getReducerClass(), job);</span><br><span class="line">  org.apache.hadoop.mapreduce.RecordWriter&lt;OUTKEY,OUTVALUE&gt; trackedRW = </span><br><span class="line">    <span class="keyword">new</span> NewTrackingRecordWriter&lt;OUTKEY, OUTVALUE&gt;(<span class="keyword">this</span>, taskContext);</span><br><span class="line">  job.setBoolean(<span class="string">"mapred.skip.on"</span>, isSkipping());</span><br><span class="line">  job.setBoolean(JobContext.SKIP_RECORDS, isSkipping());</span><br><span class="line">  org.apache.hadoop.mapreduce.Reducer.Context </span><br><span class="line">       reducerContext = createReduceContext(reducer, job, getTaskID(),</span><br><span class="line">                                             rIter, reduceInputKeyCounter, </span><br><span class="line">                                             reduceInputValueCounter, </span><br><span class="line">                                             trackedRW,</span><br><span class="line">                                             committer,</span><br><span class="line">                                             reporter, comparator, keyClass,</span><br><span class="line">                                             valueClass);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    reducer.run(reducerContext);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    trackedRW.close(reducerContext);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在这里要说下reduce中的value-list是怎么形成的。<br>入口在<code>rudecer.run(reducerContext)</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  setup(context);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (context.nextKey()) &#123;</span><br><span class="line">      reduce(context.getCurrentKey(), context.getValues(), context);</span><br><span class="line">      <span class="comment">// If a back up store is used, reset it</span></span><br><span class="line">      Iterator&lt;VALUEIN&gt; iter = context.getValues().iterator();</span><br><span class="line">      <span class="keyword">if</span>(iter <span class="keyword">instanceof</span> ReduceContext.ValueIterator) &#123;</span><br><span class="line">        ((ReduceContext.ValueIterator&lt;VALUEIN&gt;)iter).resetBackupStore();        </span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    cleanup(context);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码在while循环处调用用户自定义的reduce，则value-list应该再while的判断语句中实现，则查看<code>context.nextKey</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// WrappedReducer.nextKey()</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> reduceContext.nextKey();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ReduceContextImpl.nextKey</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKey</span><span class="params">()</span> <span class="keyword">throws</span> IOException,InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (hasMore &amp;&amp; nextKeyIsSame) &#123;</span><br><span class="line">    nextKeyValue();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (hasMore) &#123;</span><br><span class="line">    <span class="keyword">if</span> (inputKeyCounter != <span class="keyword">null</span>) &#123;</span><br><span class="line">      inputKeyCounter.increment(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> nextKeyValue();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ReduceContextImpl.nextKeyValue</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">nextKeyValue</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!hasMore) &#123;</span><br><span class="line">    key = <span class="keyword">null</span>;</span><br><span class="line">    value = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  firstValue = !nextKeyIsSame;</span><br><span class="line">  DataInputBuffer nextKey = input.getKey();</span><br><span class="line">  currentRawKey.set(nextKey.getData(), nextKey.getPosition(), </span><br><span class="line">                    nextKey.getLength() - nextKey.getPosition());</span><br><span class="line">  buffer.reset(currentRawKey.getBytes(), <span class="number">0</span>, currentRawKey.getLength());</span><br><span class="line">  key = keyDeserializer.deserialize(key);</span><br><span class="line">  DataInputBuffer nextVal = input.getValue();</span><br><span class="line">  buffer.reset(nextVal.getData(), nextVal.getPosition(), nextVal.getLength()</span><br><span class="line">      - nextVal.getPosition());</span><br><span class="line">  value = valueDeserializer.deserialize(value);</span><br><span class="line"></span><br><span class="line">  currentKeyLength = nextKey.getLength() - nextKey.getPosition();</span><br><span class="line">  currentValueLength = nextVal.getLength() - nextVal.getPosition();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (isMarked) &#123;</span><br><span class="line">    backupStore.write(nextKey, nextVal);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  hasMore = input.next();</span><br><span class="line">  <span class="keyword">if</span> (hasMore) &#123;</span><br><span class="line">    nextKey = input.getKey();</span><br><span class="line">    nextKeyIsSame = comparator.compare(currentRawKey.getBytes(), <span class="number">0</span>, </span><br><span class="line">                                   currentRawKey.getLength(),</span><br><span class="line">                                   nextKey.getData(),</span><br><span class="line">                                   nextKey.getPosition(),</span><br><span class="line">                                   nextKey.getLength() - nextKey.getPosition()</span><br><span class="line">                                       ) == <span class="number">0</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    nextKeyIsSame = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  inputValueCounter.increment(<span class="number">1</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>主要功能是在<code>ReduceContextImpl.nextKey</code>代码中实现的。当有下一个键值对并且key值一样时（<code>hasMore &amp;&amp; nextKeyIsSame</code>），执行<code>nextKeyValue</code>，如果下一个键值对的key值不一样，则增加key的个数然后执行<code>nextKeyValue</code></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Reduce阶段大致分为copy、sort和reduce阶段，而<em>copy阶段又分为shuffle和merge阶段</em>，copy阶段包含一个eventFetcher来获取已完成的map列表，由Fetcher线程去copy数据，在此过程中会启动两个merge线程，分别为inMemoryMerger和onDiskMerger，分别将内存中的数据merge到磁盘和将磁盘中的数据进行merge，（其中还应注意merge的条件和数据往内存中写入时的情况）。带数据copy完成之后，copy阶段就完成了，开始进行sort阶段，sort阶段主要是执行finalMerge操作，纯粹的sort阶段，完成之后就是reduce阶段。</p>
<!-- Merger.merge
segment  IFile
一个segment对应一个map的partition输出
reduce的key输出不是有序的，为什么？ reduce的key输入是不是有序的？ 如果reduce的输入不是有序的，那相同的key又是怎么归到一起的

单个reduce内key的输出是有序的，只是value不是有序的，二次排序是对value中的某个值进行排序。
之所以reduce中key的输出是有序的，是因为reduce的key输入就是有序的，是经过Merger.merge排序之后的，排序之后才可以对其进行分组。
-->]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> MapReduce </tag>
            
            <tag> Reduce </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java同步锁解析]]></title>
      <url>http://bigdatadecode.club/Java%E5%90%8C%E6%AD%A5%E9%94%81%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p><em>synchronized是用来控制线程同步的，是一个同步锁</em>，防止在多线程的环境下，某些资源被多线程同时操作。将不能同时操作的资源用synchronized锁住，<em>当某个线程要执行被synchronized关键字锁住的代码片段的时候，将首先检查锁是否可用，然后获取锁，执行代码，最后释放锁。</em>synchronized可用于一段代码上(同步语句块)，也可用于方法上(同步方法)。</p>
<p><strong>synchronized锁住的是对象而不是某段代码</strong>，所以要将不能被同时访问的资源封装到一个对象里，然后将所有要访问这个资源的方法标记为synchronized。<br>如果某个线程处于一个对a对象中标记为synchronized的方法的调用中，那么在这个线程从该方法返回之前，其他所有要调用该对象中任何标记为synchronized方法的线程都会被阻塞。所有对象都自动含有单一的锁，当在对象上调用起任意synchronized方法的时候，此对象就被加锁，这时该对象上其他synchronized方法只有等到前一个带有synchronized的方法调用完毕并释放锁之后才能被调用。例如：</p>
<a id="more"></a>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">synchronized</span> <span class="title">f1</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">     <span class="function"><span class="keyword">synchronized</span> <span class="title">f2</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">A a = <span class="keyword">new</span> A();</span><br></pre></td></tr></table></figure>
<p>当thread1调用了a.f1，当thread2要调用a.f2时，就会被阻塞，得等到thread1完成对a.f1的调用之后才能调用a.f2。</p>
<blockquote>
<p>再看另一种情况：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">A</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">synchronized</span> <span class="title">f1</span><span class="params">()</span></span>&#123;</span><br><span class="line">     f2();</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="function"><span class="keyword">synchronized</span> <span class="title">f2</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line">A a = <span class="keyword">new</span> A();</span><br></pre></td></tr></table></figure>
<p>当thread1调用a.f1时，因为f1加了synchronized，则thread1获得了对象a的锁，而这时f1中又调用了f2，而f2是synchronized，也需要获得一个锁，因为此时的f1和f2都是A中的方法，所以当前线程thread1要获得的f2锁的对象也是a。由于当前线程thread1在执行f1时已经持有了a对象的锁，因此这个时候调用f2是没有任何影响的，相当于方法f2上没有加synchronized。</p>
<p>下面看个demo</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sync</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"test开始.."</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"test结束.."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Sync sync = <span class="keyword">new</span> Sync();</span><br><span class="line">        sync.test();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            Thread thread = <span class="keyword">new</span> MyThread();</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出是：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">test</span>开始..</span><br><span class="line"><span class="built_in">test</span>开始..</span><br><span class="line"><span class="built_in">test</span>开始..</span><br><span class="line"><span class="built_in">test</span>结束..</span><br><span class="line"><span class="built_in">test</span>结束..</span><br><span class="line"><span class="built_in">test</span>结束..</span><br></pre></td></tr></table></figure>
<p>由结果看出带synchronized的test方法并没有锁住(<em>其实不应该说没有锁住，而是这个锁并没有达到预计的目标</em>)。回看代码，发现main线程起了3线线程，<em>在线程的run方法中对test方法调用。在run中new了一个sync对象，这个sync对象每个线程都会new一个全新的，所以当调用sync.test时，每个线程调用的都不是同一个对象的test</em>，所以并没有起到预期锁的作用。</p>
<p>修改上述代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sync</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"test开始.."</span> + Thread.currentThread().getName());</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"test结束.."</span> + Thread.currentThread().getName());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Sync sync;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyThread</span><span class="params">(Sync sync, String nameNo)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sync = sync;</span><br><span class="line">        <span class="keyword">this</span>.setName(nameNo);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        sync.test();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        Sync sync = <span class="keyword">new</span> Sync();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">        	<span class="comment">// 3个线程都是同一个Sync对象</span></span><br><span class="line">            Thread thread = <span class="keyword">new</span> MyThread(sync, <span class="string">"name"</span> + i);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">test</span>开始..name0</span><br><span class="line"><span class="built_in">test</span>结束..name0</span><br><span class="line"><span class="built_in">test</span>开始..name2</span><br><span class="line"><span class="built_in">test</span>结束..name2</span><br><span class="line"><span class="built_in">test</span>开始..name1</span><br><span class="line"><span class="built_in">test</span>结束..name1</span><br></pre></td></tr></table></figure>
<p>修改之后的代码中，多个线程操作的是同一个对象的sync.test方法，所以当name0调用sync.test时，其它线程被阻塞。</p>
<p>可见在这种情况下synchronized锁住的是对象而不是test方法中的代码。当synchronized锁住一个对象后，别的线程如果也想拿到这个对象的锁，就必须等待这个线程执行完并释放锁，才能再次给对象加锁，这样才达到线程同步的目的。<em>即使不同的代码段，都要锁同一个对象，在调用该对象中这两个代码段时，这两个代码段也不能在多线程环境下同时运行</em>。</p>
<p><em>所以在用synchronized关键字的时候，能缩小代码段的范围就尽量缩小，能在代码段上加同步的就不要在整个方法上加同步</em>。这叫<strong>减小锁的粒度，使代码更大程度的并发</strong>。(如果在function中只有A代码需要加同步锁synchronized，而在A代码之前会有一些额外的操作如准备工作，而这段工作又需要一些时间，那么你将整个function锁住，那其他线程会都阻塞在function方法上，而你如果只将A代码锁住，那其它线程可以先将A代码之前的工作执行完，阻塞在A代码处，这样减少了程序执行的时间，<em>提高的代码的并发</em>。)</p>
<p>下面看个同步语句块的demo</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sync</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">			System.out.println(<span class="string">"test开始.."</span> + Thread.currentThread().getName());</span><br><span class="line">			<span class="keyword">try</span> &#123;</span><br><span class="line">				Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">			&#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">			System.out.println(<span class="string">"test结束.."</span> + Thread.currentThread().getName());</span><br><span class="line">    	&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">private</span> Sync sync;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="title">MyThread</span><span class="params">(Sync sync, String nameNo)</span></span>&#123;</span><br><span class="line">		<span class="keyword">this</span>.sync = sync;</span><br><span class="line"> 	    <span class="keyword">this</span>.setName(nameNo);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		sync.test();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		Sync sync = <span class="keyword">new</span> Sync();</span><br><span class="line"> 		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">			Thread thread = <span class="keyword">new</span> MyThread(sync, <span class="string">"name"</span> + i);</span><br><span class="line"> 			thread.start();</span><br><span class="line"> 		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和上面的代码几乎一样，只是将synchronized从方法上换到了代码块上，synchronized(this)锁住也是<em>对象本身</em>。输出结果与上面的一样。</p>
<p>以上加锁的方法都是将同步锁作用于一个实例对象上，任何时刻都只有一个线程进入<em>该对象</em>的实例同步方法或实例同步语句块。<em>当一个线程访问实例对象的一个实例同步方法或实例同步语句块时，其它线程对该实例中的其它所有实例同步方法和实例同步语句块的访问都被阻塞</em>。但是其它线程可以访问该类的<em>其它实例对象的实例同步方法和实例同步语句块</em>。</p>
<p>下面就来看一个在<strong>类中锁非本类的实例对象</strong>的demo</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Calulation</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Calulation</span><span class="params">(<span class="keyword">long</span> count)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.count = count;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 类中非本类的实例对象(也可以理解成一个专门的锁对象)</span></span><br><span class="line">    <span class="comment">// 也可以专门声明一个锁对象</span></span><br><span class="line">    <span class="keyword">private</span> Long count;   <span class="comment">// 这里是Long而不是long，synchronized锁住的是对象，不能用long int 。。</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">long</span> value)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>.count) &#123;</span><br><span class="line">            System.out.println(<span class="string">"count 开始 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name : "</span>+ Thread.currentThread().getName());</span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            <span class="keyword">this</span>.count += value;</span><br><span class="line">            System.out.println(<span class="string">"count 结束 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name :"</span> + Thread.currentThread().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sub</span><span class="params">(<span class="keyword">long</span> value)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>.count)&#123;</span><br><span class="line">            System.out.println(<span class="string">"count 开始 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name : "</span>+ Thread.currentThread().getName());</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            <span class="keyword">this</span>.count -= value;</span><br><span class="line">            System.out.println(<span class="string">"count 结束 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name :"</span> + Thread.currentThread().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CalculationTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Calulation cal = <span class="keyword">new</span> Calulation(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">long</span> i=<span class="number">0</span>; i&lt;<span class="number">2</span>; i++)&#123;</span><br><span class="line">            Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + <span class="string">"start..."</span>);</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        cal.add(<span class="number">5</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            thread.setName(<span class="string">"add"</span> + i);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">long</span> i=<span class="number">0</span>; i&lt;<span class="number">2</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> finalI = i;</span><br><span class="line">            Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + <span class="string">"start..."</span>);</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        cal.sub(finalI);  <span class="comment">// 这里必须传进去一个fianl类型的数据</span></span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            thread.setName(<span class="string">"sub"</span> + i);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">add0start...</span><br><span class="line">count 开始 : 0 name : add0</span><br><span class="line">add1start...</span><br><span class="line">sub0start...</span><br><span class="line">sub1start...</span><br><span class="line">count 结束 : 5 name :add0</span><br><span class="line">count 开始 : 5 name : sub1</span><br><span class="line">count 结束 : 4 name :sub1</span><br><span class="line">count 开始 : 4 name : sub0</span><br><span class="line">count 结束 : 4 name :sub0</span><br><span class="line">count 开始 : 4 name : add1</span><br><span class="line">count 结束 : 9 name :add1</span><br></pre></td></tr></table></figure>
<p>Calulation中有两个方法add和sub，这两个方法都对count加锁，那么如果某个线程调用需要得到count实例对象锁的某个方法时，<em>那么其它线程调用需要得到该对象锁的任何一个方法都将阻塞</em>。查看输出，add0线程start，调用cal.add，add中有sleep（模拟代码执行消耗的时间），sleep时，add1、sub0和sub1都相继start，但没有拿到count的锁，都被阻塞。</p>
<blockquote>
<p>思考：synchronized(this)与synchronized(实例对象属性)的区别？？</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Calulation</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Calulation</span><span class="params">(<span class="keyword">long</span> count)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.count = count;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> Long count;   <span class="comment">// 这里是Long而不是long，synchronized锁住的是对象，不能用long int 。。</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">add</span><span class="params">(<span class="keyword">long</span> value)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    	<span class="comment">// 得到实例对象count的锁</span></span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>.count) &#123;</span><br><span class="line">            System.out.println(<span class="string">"count 开始 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name : "</span>+ Thread.currentThread().getName());</span><br><span class="line">            Thread.sleep(<span class="number">10000</span>);</span><br><span class="line">            <span class="keyword">this</span>.count += value;</span><br><span class="line">            System.out.println(<span class="string">"count 结束 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name :"</span> + Thread.currentThread().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sub</span><span class="params">(<span class="keyword">long</span> value)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    	<span class="comment">// 得到本类对象的锁</span></span><br><span class="line">        <span class="keyword">synchronized</span> (<span class="keyword">this</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">"count 开始 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name : "</span>+ Thread.currentThread().getName());</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            <span class="keyword">this</span>.count -= value;</span><br><span class="line">            System.out.println(<span class="string">"count 结束 : "</span> + <span class="keyword">this</span>.count + <span class="string">" name :"</span> + Thread.currentThread().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CalculationTest</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Calulation cal = <span class="keyword">new</span> Calulation(<span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">long</span> i=<span class="number">0</span>; i&lt;<span class="number">2</span>; i++)&#123;</span><br><span class="line">            Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + <span class="string">"start..."</span>);</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        cal.add(<span class="number">5</span>);</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            thread.setName(<span class="string">"add"</span> + i);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">long</span> i=<span class="number">0</span>; i&lt;<span class="number">2</span>; i++)&#123;</span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> finalI = i;</span><br><span class="line">            Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + <span class="string">"start..."</span>);</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        cal.sub(finalI);  <span class="comment">// 这里必须传进去一个fianl类型的数据</span></span><br><span class="line">                    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            thread.setName(<span class="string">"sub"</span> + i);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">add1start...</span><br><span class="line">add0start...</span><br><span class="line">count 开始 : 0 name : add1</span><br><span class="line">sub0start...</span><br><span class="line">count 开始 : 0 name : sub0</span><br><span class="line">sub1start...</span><br><span class="line">count 结束 : 0 name :sub0</span><br><span class="line">count 开始 : 0 name : sub1</span><br><span class="line">count 结束 : -1 name :sub1</span><br><span class="line">count 结束 : 4 name :add1</span><br><span class="line">count 开始 : 4 name : add0</span><br><span class="line">count 结束 : 9 name :add0</span><br></pre></td></tr></table></figure>
<p>上述代码中add中是synchronized(this.count)，锁住的是count对象，而sub中是synchronized(this)，锁住的Calulation对象cal，则当add1.start时，得到了count的锁，将synchronized(this.count)的代码段锁住，则当add0 start之后无法得到count的锁，则add0阻塞。<br>然而sub0启动之后，调用的是cal.sub方法，在此方法中的同步代码块中需要的是对象cal的锁，而不是对象count的锁，所以并没有将sub0阻塞，但是sub0将cal锁住，导致sub1阻塞，同样对add也没有影响。</p>
<p>从上的实验可以得出，<em>一般锁定一个属性进行实例范围的同步，任何时刻只有一个线程可以进入锁定该属性实例的代码块，其他线程访问锁定同一个属性实例的代码块将被阻塞，同时该属性实例中的实例同步方法和实例同步代码块也将组塞</em>。</p>
<p>上述几个例子都是对实例对象加锁，下面展示几个对<em>类加锁</em>的例子(<em>也是一种全局锁</em>)。</p>
<p><em>对类加锁是指将同步作用于一个类上，则该类所有的实例对象，任何时刻都只有一个线程进入某个实例的类同步方法或类同步语句块</em>。常见的两种方法是：</p>
<ol>
<li>在<strong>静态方法</strong>上加synchronized关键字，声明这个静态方法是同步的</li>
<li>在同步语句块上添加synchronized(ClassName.class){}</li>
<li>同样也可以对某个属性进行类范围的同步synchronized(fieldName.getClass())</li>
</ol>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sync</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">synchronized</span> (Sync.class) &#123;</span><br><span class="line">            System.out.println(<span class="string">"test开始.."</span> + Thread.currentThread().getName());</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            System.out.println(<span class="string">"test结束.."</span> + Thread.currentThread().getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyThread</span> <span class="keyword">extends</span> <span class="title">Thread</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyThread</span><span class="params">( String nameNo)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.setName(nameNo);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    	<span class="comment">// 每个线程都是一个新的Sync对象</span></span><br><span class="line">        Sync sync = <span class="keyword">new</span> Sync();</span><br><span class="line">        sync.test();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Main</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">            Thread thread = <span class="keyword">new</span> MyThread(<span class="string">"name"</span> + i);</span><br><span class="line">            thread.start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">test</span>开始..name2</span><br><span class="line"><span class="built_in">test</span>结束..name2</span><br><span class="line"><span class="built_in">test</span>开始..name0</span><br><span class="line"><span class="built_in">test</span>结束..name0</span><br><span class="line"><span class="built_in">test</span>开始..name1</span><br><span class="line"><span class="built_in">test</span>结束..name1</span><br></pre></td></tr></table></figure>
<p>代码中虽然在<em>每个线程中都new了一个全新的Sync对象</em>，<strong>但是test中是对Sync.class类加锁，所以会阻塞其它线程对该类任何实例对象同步方法的调用</strong>。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> synchronized </tag>
            
            <tag> 同步锁 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java优先级队列解析]]></title>
      <url>http://bigdatadecode.club/Java%E4%BC%98%E5%85%88%E7%BA%A7%E9%98%9F%E5%88%97%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p>在看代码过程中，优先级队列(PriorityQueue)出现的次数很多，PriorityQueue是基于优先堆(完全二叉堆)的一个无界队列。</p>
<p>优先级队列是不同于先进先出队列的另一种队列。每次从队列中取出的是具有最高优先权的元素。每次都取最高优先权的原理是通过在内部维护一个堆来实现的。</p>
<p>下面先搞个小demo来感受下PriorityQueue，来个常见的面试题，<em>求topN</em>问题。</p>
<a id="more"></a>
<h2 id="求topN"><a href="#求topN" class="headerlink" title="求topN"></a>求topN</h2><p>一组数16,7,3,20,17,8,2,1,30，求top6。<br>使用PriorityQueue代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestPriorityQueue</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] arr = &#123;<span class="number">16</span>,<span class="number">7</span>,<span class="number">3</span>,<span class="number">20</span>,<span class="number">17</span>,<span class="number">8</span>,<span class="number">2</span>,<span class="number">1</span>,<span class="number">30</span>&#125;;</span><br><span class="line">        Object[] result = topN(arr, <span class="number">6</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=result.length-<span class="number">1</span>; i&gt;=<span class="number">0</span>; i--) &#123;</span><br><span class="line">            System.out.println(result[i].toString());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Object[] topN(<span class="keyword">int</span>[] arr,<span class="keyword">int</span> n)&#123;</span><br><span class="line">        PriorityQueue&lt;Integer&gt; priorityQueue = <span class="keyword">new</span> PriorityQueue&lt;Integer&gt;();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;arr.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (priorityQueue.size() &lt; n)&#123;</span><br><span class="line">                priorityQueue.add(arr[i]);</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span> (arr[i] &gt; priorityQueue.peek())&#123;</span><br><span class="line">                priorityQueue.poll();</span><br><span class="line">                priorityQueue.add(arr[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Object[] result = priorityQueue.toArray();</span><br><span class="line">        Arrays.sort(result);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="PriorityQueue必备知识"><a href="#PriorityQueue必备知识" class="headerlink" title="PriorityQueue必备知识"></a>PriorityQueue必备知识</h2><ul>
<li>优先队列中的元素可以默认自然排序或者通过提供的Comparator在队列实例化的时排序。</li>
<li>优先队列的大小是不受限制的，但在创建时可以指定初始大小。当我们向优先队列增加元素的时候，队列大小会自动增加。</li>
<li>优先队列不允许空值，而且不支持non-comparable的对象</li>
<li>不是线程安全的。如果多个线程中的任意线程从结构上修改了queue，则这些线程不应同时访问PriorityQueue 实例，这时请使用<em>线程安全的PriorityBlockingQueue类</em>。</li>
<li>add(offer)和poll方法提供O(log(n))时间；为remove(Object)和contains(Object)方法提供线性时间；为检索方法(peek、element和size)提供固定时间。</li>
<li>方法iterator()中提供的迭代器并不保证以有序的方式遍历优先级队列中的元素。如果需要按顺序遍历，请考虑使用 Arrays.sort(pq.toArray())。</li>
</ul>
<h2 id="PriorityQueue代码实现"><a href="#PriorityQueue代码实现" class="headerlink" title="PriorityQueue代码实现"></a>PriorityQueue代码实现</h2><p>下面代码层次解读下PriorityQueue。</p>
<p>首先来看下属性：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// PriorityQueue默认大小</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">11</span>;</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Priority queue represented as a balanced binary heap: the two</span></span><br><span class="line"><span class="comment"> * children of queue[n] are queue[2*n+1] and queue[2*(n+1)].  The</span></span><br><span class="line"><span class="comment"> * priority queue is ordered by comparator, or by the elements'</span></span><br><span class="line"><span class="comment"> * natural ordering, if comparator is null: For each node n in the</span></span><br><span class="line"><span class="comment"> * heap and each descendant d of n, n &lt;= d.  The element with the</span></span><br><span class="line"><span class="comment"> * lowest value is in queue[0], assuming the queue is nonempty.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="comment">// 数组来存放元素 </span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> Object[] queue;</span><br><span class="line"><span class="comment">// PriorityQueue中元素的个数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> size = <span class="number">0</span>;</span><br><span class="line"><span class="comment">// 初始化PriorityQueue时传入比较器的接收者</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Comparator&lt;? <span class="keyword">super</span> E&gt; comparator;</span><br><span class="line"><span class="comment">// PriorityQueue被操作的次数</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">transient</span> <span class="keyword">int</span> modCount = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<p>调用PriorityQueue的构造函数进行初始化，调用构造函数可以不传任何参数，此时用默认数组大小和默认排序方法初始化PriorityQueue，也可以传入初始化的大小或者自定义的比较器。</p>
<h3 id="add-入队列"><a href="#add-入队列" class="headerlink" title="add 入队列"></a>add 入队列</h3><p>初始化之后调用add将元素放入queue中，add又调用offer，在offer中调用siftUp对元素进行调整，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> offer(e);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="comment">// 每次操作modCount都会递增</span></span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">// i是即将插入元素的索引，size是queue中元素的个数</span></span><br><span class="line">    <span class="keyword">int</span> i = size;</span><br><span class="line">    <span class="comment">// 达到容量上限，则调用grow扩容</span></span><br><span class="line">    <span class="keyword">if</span> (i &gt;= queue.length)</span><br><span class="line">        grow(i + <span class="number">1</span>);</span><br><span class="line">    <span class="comment">// queue中元素的个数更新    </span></span><br><span class="line">    size = i + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">if</span> (i == <span class="number">0</span>)</span><br><span class="line">        queue[<span class="number">0</span>] = e;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment">// queue中已存在元素，则调用siftUp找到元素e在queue中的位置</span></span><br><span class="line">        siftUp(i, e);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftUp</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 根据比较策略选择不同的方法</span></span><br><span class="line">    <span class="keyword">if</span> (comparator != <span class="keyword">null</span>)</span><br><span class="line">        siftUpUsingComparator(k, x);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        siftUpComparable(k, x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PriorityQueue中的元素默认是按照小顶堆存放的，一个新的元素放入queue中，需要调整整个堆的顺序，PriorityQueue调用siftUp根据初始化时是否对比较器进行初始化来选择不同的调整策略，默认情况下安装对象本身的排序规则进行比较(<em>这就要求放入PriorityQueue中的元素必须是可比较的</em>)。</p>
<p>默认比较规则是siftUpComparable，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 参数k是queue中最后一个元素的下一个索引</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftUpComparable</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 元素x实现了Comparable接口</span></span><br><span class="line">    Comparable&lt;? <span class="keyword">super</span> E&gt; key = (Comparable&lt;? <span class="keyword">super</span> E&gt;) x;</span><br><span class="line">    <span class="comment">// 循环使key和k的父节点进行比较，则k只要大于0就存在父节点，</span></span><br><span class="line">    <span class="comment">// 小于等于0则不存在父节点，循环结束。</span></span><br><span class="line">    <span class="keyword">while</span> (k &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    	<span class="comment">// root的索引是0，求出k的父节点的索引</span></span><br><span class="line">        <span class="keyword">int</span> parent = (k - <span class="number">1</span>) &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        Object e = queue[parent];</span><br><span class="line">        <span class="comment">// 由于queue是小顶堆，则循环跳出的条件是key比父节点大</span></span><br><span class="line">        <span class="keyword">if</span> (key.compareTo((E) e) &gt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="comment">// key比父节点小则和父节点交换位置，继续查找</span></span><br><span class="line">        queue[k] = e;</span><br><span class="line">        k = parent;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将key放入合适的位置</span></span><br><span class="line">    queue[k] = key;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>放入新的元素对小顶堆的调整比较简单，就是假设将元素e放入queue中最后一个元素的下一个位置i，根据i找到其父节点的索引j，比较e和queue[j]的大小，如果e小，则将queue[j]从j换到i处，则j的位置就给e空了出来，然后继续循环找到j的父节点的索引，再次进行比较，<em>直到j没有父节点，或者e小于父节点的值</em>。</p>
<p><code>siftUpUsingComparator</code>和<code>siftUpComparable</code>逻辑一样，只是两个元素进行比较时调用的方法不一样，siftUpUsingComparator调用的是对应比较器<code>comparator.compare(x, (E) e)</code>的方法。</p>
<h3 id="grow-扩容"><a href="#grow-扩容" class="headerlink" title="grow 扩容"></a>grow 扩容</h3><p>add元素到队列当容量满时，调用grow进行扩容，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">grow</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> oldCapacity = queue.length;</span><br><span class="line">    <span class="comment">// Double size if small; else grow by 50%</span></span><br><span class="line">    <span class="comment">// oldCapacity小于64则容量翻倍；否则增长50%；</span></span><br><span class="line">    <span class="comment">// oldCapacity是放入新元素之前的大小，翻倍的话也应该加上新元素翻倍的个数2</span></span><br><span class="line">    <span class="keyword">int</span> newCapacity = oldCapacity + ((oldCapacity &lt; <span class="number">64</span>) ?</span><br><span class="line">                                     (oldCapacity + <span class="number">2</span>) :</span><br><span class="line">                                     (oldCapacity &gt;&gt; <span class="number">1</span>));</span><br><span class="line">    <span class="comment">// 扩容之后的容量大于MAX_ARRAY_SIZE，则将容量设为MAX_ARRAY_SIZE</span></span><br><span class="line">    <span class="comment">// 避免无限制的扩展</span></span><br><span class="line">    <span class="keyword">if</span> (newCapacity - MAX_ARRAY_SIZE &gt; <span class="number">0</span>)</span><br><span class="line">        newCapacity = hugeCapacity(minCapacity);</span><br><span class="line">    queue = Arrays.copyOf(queue, newCapacity);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hugeCapacity</span><span class="params">(<span class="keyword">int</span> minCapacity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (minCapacity &lt; <span class="number">0</span>) <span class="comment">// overflow</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> OutOfMemoryError();</span><br><span class="line">    <span class="keyword">return</span> (minCapacity &gt; MAX_ARRAY_SIZE) ?</span><br><span class="line">        Integer.MAX_VALUE :</span><br><span class="line">        MAX_ARRAY_SIZE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="poll-出队列"><a href="#poll-出队列" class="headerlink" title="poll 出队列"></a>poll 出队列</h3><p>出队列时调用poll，对queue中的size进行更新，将堆顶元素移除queue，调用siftDown进行调整。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">poll</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// queue中元素个数减一，也就是最后一个元素的索引</span></span><br><span class="line">    <span class="keyword">int</span> s = --size;</span><br><span class="line">    <span class="comment">// 操作次数递增</span></span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="comment">// 得到堆顶元素</span></span><br><span class="line">    E result = (E) queue[<span class="number">0</span>];</span><br><span class="line">    <span class="comment">// 得到queue中的最后一个元素</span></span><br><span class="line">    E x = (E) queue[s];</span><br><span class="line">    queue[s] = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// queue中的元素个数不为0，则调整堆</span></span><br><span class="line">    <span class="keyword">if</span> (s != <span class="number">0</span>)</span><br><span class="line">        siftDown(<span class="number">0</span>, x);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftDown</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (comparator != <span class="keyword">null</span>)</span><br><span class="line">        siftDownUsingComparator(k, x);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        siftDownComparable(k, x);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>siftDown的调整策略和siftUp一样也是两种，具体的调整思路是拿最后一个元素从上向下进行调整。默认调整策略的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 参数k始终是0，从上向下调整</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">siftDownComparable</span><span class="params">(<span class="keyword">int</span> k, E x)</span> </span>&#123;</span><br><span class="line">    Comparable&lt;? <span class="keyword">super</span> E&gt; key = (Comparable&lt;? <span class="keyword">super</span> E&gt;)x;</span><br><span class="line">    <span class="comment">// 只需循环节点个数的一半</span></span><br><span class="line">    <span class="keyword">int</span> half = size &gt;&gt;&gt; <span class="number">1</span>;        <span class="comment">// loop while a non-leaf</span></span><br><span class="line">    <span class="keyword">while</span> (k &lt; half) &#123;</span><br><span class="line">    	<span class="comment">// root为0，k乘以2加1找到k的左孩子</span></span><br><span class="line">        <span class="keyword">int</span> child = (k &lt;&lt; <span class="number">1</span>) + <span class="number">1</span>; <span class="comment">// assume left child is least</span></span><br><span class="line">        Object c = queue[child];</span><br><span class="line">        <span class="comment">// 右子数的索引</span></span><br><span class="line">        <span class="keyword">int</span> right = child + <span class="number">1</span>;</span><br><span class="line">        <span class="comment">// 在左右子树中找到较小的子树</span></span><br><span class="line">        <span class="comment">// 要注意right要小于size，避免越界</span></span><br><span class="line">        <span class="keyword">if</span> (right &lt; size &amp;&amp;</span><br><span class="line">            ((Comparable&lt;? <span class="keyword">super</span> E&gt;) c).compareTo((E) queue[right]) &gt; <span class="number">0</span>)</span><br><span class="line">            <span class="comment">// 初始假设queue[child]较小</span></span><br><span class="line">            <span class="comment">// 将较小值的索引赋值给child，并把元素值赋值给c</span></span><br><span class="line">            c = queue[child = right];</span><br><span class="line">        <span class="comment">// 将最后一个元素和较小的子树c进行比较，最后一个元素小则跳出循环</span></span><br><span class="line">        <span class="keyword">if</span> (key.compareTo((E) c) &lt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="comment">// 如果最后一个元素 比 较小的子树c大，</span></span><br><span class="line">        <span class="comment">// 则用较小的子树向上去填移出的父节点    </span></span><br><span class="line">        queue[k] = c;</span><br><span class="line">        k = child;</span><br><span class="line">    &#125;</span><br><span class="line">    queue[k] = key;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>siftDown时的调整思路有点绕，大致思路是堆顶元素移除之后，将最后一个元素作为指标对堆内的元素进行调整，调整时<em>先找到左右子树的较小值</em>，然后跟最后一个元素进行比较，子树的较小值比最后一个元素小则将较小值向上移动，否则将最后一个元素填补空缺的位置。</p>
<h3 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h3><p>移除queue中的指定元素，实现代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 调用indexOf找到o在queue中的索引</span></span><br><span class="line">    <span class="keyword">int</span> i = indexOf(o);</span><br><span class="line">    <span class="keyword">if</span> (i == -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">    	<span class="comment">// 移除第i个元素</span></span><br><span class="line">        removeAt(i);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>移除元素时先在queue中找到(<em>顺序遍历元素，因为queue中的元素并没有顺序，则只能顺序遍历</em>)o的索引，然后调用removeAt移除第i个元素。</p>
<p>indexOf的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">indexOf</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o != <span class="keyword">null</span>) &#123;</span><br><span class="line">    	<span class="comment">// for循环遍历，queue中的元素无序</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++)</span><br><span class="line">            <span class="keyword">if</span> (o.equals(queue[i]))</span><br><span class="line">                <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用removeAt移除第i个元素，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">removeAt</span><span class="params">(<span class="keyword">int</span> i)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">assert</span> i &gt;= <span class="number">0</span> &amp;&amp; i &lt; size;</span><br><span class="line">    modCount++;</span><br><span class="line">    <span class="keyword">int</span> s = --size;</span><br><span class="line">    <span class="comment">// 如果移除的元素是最后一个元素则直接对queue[i]赋值为null</span></span><br><span class="line">    <span class="keyword">if</span> (s == i) <span class="comment">// removed last element</span></span><br><span class="line">        queue[i] = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">    	<span class="comment">// 最后一个元素赋值给moved</span></span><br><span class="line">        E moved = (E) queue[s];</span><br><span class="line">        <span class="comment">// 将最后一个元素置null，也就是清除一个元素</span></span><br><span class="line">        queue[s] = <span class="keyword">null</span>;</span><br><span class="line">        siftDown(i, moved);</span><br><span class="line">        <span class="comment">// 如果moved比i的子树要小，将moved放在了i处，</span></span><br><span class="line">        <span class="comment">// 则存在moved可能比小于i的元素还要小，继续进行向上调整</span></span><br><span class="line">        <span class="keyword">if</span> (queue[i] == moved) &#123;</span><br><span class="line">            siftUp(i, moved);</span><br><span class="line">            <span class="keyword">if</span> (queue[i] != moved)</span><br><span class="line">                <span class="keyword">return</span> moved;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="知识扩展"><a href="#知识扩展" class="headerlink" title="知识扩展"></a>知识扩展</h2><h3 id="Comparable和Comparator的区别"><a href="#Comparable和Comparator的区别" class="headerlink" title="Comparable和Comparator的区别"></a>Comparable和Comparator的区别</h3><ul>
<li>Comparable和Comparator都是用来排序的。</li>
<li>Comparable只能提供一种比较方法，Comparator可以声明不同的比较器实现多种比较方法。</li>
<li>使用Comparable时，自定义的类必须实现该接口，而Comparator则不用让自定义的类实现Comparator接口，不用对自定义的类进行任何修改。</li>
<li>Comparable接口在java.lang包中，而Comparator接口在java.util包中。</li>
<li>使用Comparable时，不用在客户端进行修改，Arrays.sort()或者Collection.sort()自动调用Comparable.compareTo方法。而Comparator则需要修改，提供Comparator类，调用Comparator.compare()方法</li>
</ul>
<blockquote>
<p>Comparable</p>
</blockquote>
<p>关于自定义的类，如果想使用Arrays或者Collections的排序方法则自定义的类可以<em>实现Comparable接口，重写compareTo(T obj)方法</em>，该方法的返回值可以为正数(大于)、零(等于)或者负数(小于)。</p>
<p>demo如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Employee</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> salary;</span><br><span class="line">    ... <span class="comment">// getter setter method</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Employee</span><span class="params">(<span class="keyword">int</span> id, String name, <span class="keyword">int</span> age, <span class="keyword">int</span> salary)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">        <span class="keyword">this</span>.salary = salary;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Employee emp)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//let's sort the employee based on id in ascending order</span></span><br><span class="line">        <span class="comment">//returns a negative integer, zero, or a positive integer as this employee id</span></span><br><span class="line">        <span class="comment">//is less than, equal to, or greater than the specified object.</span></span><br><span class="line">        <span class="keyword">return</span> (<span class="keyword">this</span>.id - emp.id);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//this is required to print the user friendly information about the Employee</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"[id="</span> + <span class="keyword">this</span>.id + <span class="string">", name="</span> + <span class="keyword">this</span>.name + <span class="string">", age="</span> + <span class="keyword">this</span>.age + <span class="string">", salary="</span> +</span><br><span class="line">                <span class="keyword">this</span>.salary + <span class="string">"]"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// main method</span></span><br><span class="line"><span class="comment">//sorting object array</span></span><br><span class="line">Employee[] empArr = <span class="keyword">new</span> Employee[<span class="number">4</span>];</span><br><span class="line">empArr[<span class="number">0</span>] = <span class="keyword">new</span> Employee(<span class="number">10</span>, <span class="string">"Mikey"</span>, <span class="number">25</span>, <span class="number">10000</span>);</span><br><span class="line">empArr[<span class="number">1</span>] = <span class="keyword">new</span> Employee(<span class="number">20</span>, <span class="string">"Arun"</span>, <span class="number">29</span>, <span class="number">20000</span>);</span><br><span class="line">empArr[<span class="number">2</span>] = <span class="keyword">new</span> Employee(<span class="number">5</span>, <span class="string">"Lisa"</span>, <span class="number">35</span>, <span class="number">5000</span>);</span><br><span class="line">empArr[<span class="number">3</span>] = <span class="keyword">new</span> Employee(<span class="number">1</span>, <span class="string">"Pankaj"</span>, <span class="number">32</span>, <span class="number">50000</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//sorting employees array using Comparable interface implementation</span></span><br><span class="line">Arrays.sort(empArr);</span><br><span class="line">System.out.println(<span class="string">"Default Sorting of Employees list:\n"</span>+Arrays.toString(empArr));</span><br></pre></td></tr></table></figure>
<p>排序的结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Default Sorting of Employees list:</span><br><span class="line">[[id=1, name=Pankaj, age=32, salary=50000], [id=5, name=Lisa, age=35, salary=5000], [id=10, name=Mikey, age=25, salary=10000], [id=20, name=Arun, age=29, salary=20000]]</span><br></pre></td></tr></table></figure>
<p>使用Comparable接口可以实现自定义类的排序，<em>但是如果排序时可能不同的需求需要根据自定义类中的不同属性进行排序，以上面的Employees为例，有人想根据salary进行排序，有人想根据age排序，此时Comparable不能实现，因为Comparable.compareTo(Object o)不能选择自定义类的属性</em>。这里就用到了Comparator接口。</p>
<blockquote>
<p>Comparator</p>
</blockquote>
<p>使用Comparator接口时需要重写compare(Object o1, Object o2)方法，方法传入两个需要比较的对象，返回值可以为正数(o1大于o2)、零(等于)或者负数(小于)。</p>
<p>下面就来看下Employee类中不同Comparator的实现</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Comparator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> salary;</span><br><span class="line">    ... <span class="comment">// getter setter methods</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Employee</span><span class="params">(<span class="keyword">int</span> id, String name, <span class="keyword">int</span> age, <span class="keyword">int</span> salary)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.id = id;</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.age = age;</span><br><span class="line">        <span class="keyword">this</span>.salary = salary;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="comment">//this is required to print the user friendly information about the Employee</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">"[id="</span> + <span class="keyword">this</span>.id + <span class="string">", name="</span> + <span class="keyword">this</span>.name + <span class="string">", age="</span> + <span class="keyword">this</span>.age + <span class="string">", salary="</span> +</span><br><span class="line">                <span class="keyword">this</span>.salary + <span class="string">"]"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>main类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaObjectSorting</span> </span>&#123;</span><br><span class="line"><span class="comment">// 在客户端修改</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Comparator to sort employees list or array in order of Salary</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="comment">// salary比较器</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Comparator&lt;Employee&gt; SalaryComparator = <span class="keyword">new</span> Comparator&lt;Employee&gt;() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Employee e1, Employee e2)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> (<span class="keyword">int</span>) (e1.getSalary() - e2.getSalary());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Comparator to sort employees list or array in order of Age</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Comparator&lt;Employee&gt; AgeComparator = <span class="keyword">new</span> Comparator&lt;Employee&gt;() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Employee e1, Employee e2)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> e1.getAge() - e2.getAge();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Comparator to sort employees list or array in order of Name</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Comparator&lt;Employee&gt; NameComparator = <span class="keyword">new</span> Comparator&lt;Employee&gt;() &#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Employee e1, Employee e2)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> e1.getName().compareTo(e2.getName());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//sorting custom object array</span></span><br><span class="line">        Employee[] empArr = <span class="keyword">new</span> Employee[<span class="number">4</span>];</span><br><span class="line">        empArr[<span class="number">0</span>] = <span class="keyword">new</span> Employee(<span class="number">10</span>, <span class="string">"Mikey"</span>, <span class="number">25</span>, <span class="number">10000</span>);</span><br><span class="line">        empArr[<span class="number">1</span>] = <span class="keyword">new</span> Employee(<span class="number">20</span>, <span class="string">"Arun"</span>, <span class="number">29</span>, <span class="number">20000</span>);</span><br><span class="line">        empArr[<span class="number">2</span>] = <span class="keyword">new</span> Employee(<span class="number">5</span>, <span class="string">"Lisa"</span>, <span class="number">35</span>, <span class="number">5000</span>);</span><br><span class="line">        empArr[<span class="number">3</span>] = <span class="keyword">new</span> Employee(<span class="number">1</span>, <span class="string">"Pankaj"</span>, <span class="number">32</span>, <span class="number">50000</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//sort employees array using Comparator by Salary</span></span><br><span class="line">        <span class="comment">// 调用sort方法时，传入比较器</span></span><br><span class="line">        Arrays.sort(empArr, JavaObjectSorting.SalaryComparator);</span><br><span class="line">        System.out.println(<span class="string">"Employees list sorted by Salary:\n"</span>+Arrays.toString(empArr));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//sort employees array using Comparator by Age</span></span><br><span class="line">        Arrays.sort(empArr, JavaObjectSorting.AgeComparator);</span><br><span class="line">        System.out.println(<span class="string">"Employees list sorted by Age:\n"</span>+Arrays.toString(empArr));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//sort employees array using Comparator by Name</span></span><br><span class="line">        Arrays.sort(empArr, JavaObjectSorting.NameComparator);</span><br><span class="line">        System.out.println(<span class="string">"Employees list sorted by Name:\n"</span>+Arrays.toString(empArr));</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Java-transient关键字"><a href="#Java-transient关键字" class="headerlink" title="Java transient关键字"></a>Java transient关键字</h3><p>我们都知道一个对象只要实现了Serilizable接口，这个对象就可以被序列化，然而在实际开发过程中，我们常常会遇到这样的问题，<em>这个类的有些属性需要序列化，而其他属性不需要被序列化</em>，打个比方，如果一个用户有一些敏感信息（如密码，银行卡号等），为了安全起见，<em>不希望在网络操作（主要涉及到序列化操作，本地序列化缓存也适用）中被传输</em>，这些信息对应的变量就可以加上transient关键字。换句话说，<em>这个字段的生命周期仅存于调用者的内存中而不会写到磁盘里持久化</em>。</p>
<p>当对象被序列化时（写入字节序列到目标文件）时，<em>transient阻止实例中那些用此关键字声明的变量持久化</em>；当对象被反序列化时（从源文件读取字节序列进行重构），这样的实例变量值不会被持久化和恢复。</p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> PriorityQueue </tag>
            
            <tag> topN </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之动态规划]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8B%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92.html</url>
      <content type="html"><![CDATA[<p>动态规划的基本思想与分治法类似，也是将<em>待求解的问题分解为若干个子问题(阶段)</em>。按顺序求解子阶段，<em>前一子问题的解，为后一子问题的求解提供了有用的信息</em>。在<strong>求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部最优解</strong>。依次解决各子问题，最后一个子问题就是初始问题的解。</p>
<p>动态规划是通过<em>拆分问题</em>，定义<em>问题状态和状态之间的关系</em>，使得问题能够以<em>递推</em>的方式去解决。则<em>动态规划的本质</em>是<strong>状态的定义</strong>和<strong>状态转移方程</strong></p>
<p>动态规划通过拆分问题，将原始问题拆分为子问题，而各子问题之间的关系是<em>后一子问题的解往往由前一子问题的解求出</em>，则<strong>子问题之间是重叠的(则不是相互独立的)</strong>，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。</p>
<blockquote>
<p>动态规划与分治法<em>最大的差别</em>是:适合于用动态规划法求解的问题，经分解后得到的子问题往往<em>不是互相独立</em>的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。</p>
</blockquote>
<blockquote>
<p>动态规划与贪心法的区别</p>
</blockquote>
<p>动态规划其实是贪心法的一般情况，而<em>贪心法是动态规划的特殊情况</em>，为什么这么说呢，下面就来解释下，</p>
<a id="more"></a>
<p>用动态规划来求解时总是将问题拆分，找到递推公式，则将各个状态定义为dp[i],结果为result，动态规划求解的流程图如下：</p>
<p><img src="/blogimgs/dp/greedy.png" alt=""></p>
<p>但是在大多数动态规划求解的过程中后一子问题一般是从前面多个子问题中得出的(也可能是前面所有的子问题)，则流程图如下：</p>
<p><img src="/blogimgs/dp/dp.png" alt=""></p>
<p>而贪心算法往往只是有前一子问题而得出后一子问题的，则从上面的两个图中可以得出动态规划与贪心算法的关系，<strong>如果后一子问题只是由前一子问题推出，则为贪心，如果后一子问题由前面多个子问题推出，则为动态规划，所以说贪心是动态规划的特殊情况</strong>。</p>
<h2 id="动态规划常见问题"><a href="#动态规划常见问题" class="headerlink" title="动态规划常见问题"></a>动态规划常见问题</h2><h3 id="最长子串"><a href="#最长子串" class="headerlink" title="最长子串"></a>最长子串</h3><p>给定一个字符串，找到没有重复字符的最长子串的长度。</p>
<p>例如:<br>字符串”abcabcbb”, 最长非重复子串长度是3(“abc”).<br>字符串”pwwkew”, 最长非重复子串长度是3(“wke”).</p>
<p>具体解法移步<a href="http://bigdatadecode.club/数据结构算法之leetcode Longest Substring.html">数据结构算法之leetcode Longest Substring</a></p>
<h3 id="最长回文"><a href="#最长回文" class="headerlink" title="最长回文"></a>最长回文</h3><p>给定一个字符串，求最长回文子串(假设字符串中只有唯一的一个最长回文子串)。</p>
<p>例如：<br>字符串”bananas”, 最长回文为”anana”<br>字符串”aaa”, 最长回文为”aaa”</p>
<p>具体解法移步<a href="http://bigdatadecode.club/数据结构算法之leetcode Longest Palindromic.html">数据结构算法之leetcode Longest Palindromic</a></p>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> 动态规划 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark Streaming 消费kafka到HDFS]]></title>
      <url>http://bigdatadecode.club/Spark%20Streaming%20%E6%B6%88%E8%B4%B9kafka%E5%88%B0HDFS.html</url>
      <content type="html"><![CDATA[<p>先说下程序功能，使用Spark Streaming 实时消费kafka，并将message写入HDFS上指定的topic目录中。<br>消费kafka使用的是Spark提供的<em>Direct Approach</em>方法，然后利用HDFS API将不同topic下的message写到各自topic目录下。</p>
<a id="more"></a>
<h2 id="Spark-Streaming简介"><a href="#Spark-Streaming简介" class="headerlink" title="Spark Streaming简介"></a>Spark Streaming简介</h2><p>Spark Streaming是Spark的扩展，能够扩展的。高吞吐、容错的处理实时数据流。Spark Streaming的工作流程是将接受到实时的数据划分到不同的batch中，然后由Spark Engine处理并生成结果batch。如下图：<br><img src="/blogimgs/SparkStreamingconsumerKafka/streaming-flow.png" alt="Spark Streaming工作流" title="Spark Streaming工作流"></p>
<p>Spark Streaming提供了一个高级的抽象模型，叫做discretized stream或者叫做DStream,它代表了一个持续的数据流。</p>
<p>Saprk Streaming中的Context是StreamingContext，StreamingContext是所有功能的主入口，可以通过两种方法create，</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// first</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(appName).setMaster(master)</span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br><span class="line"><span class="comment">// second</span></span><br><span class="line"><span class="keyword">val</span> sc = ...                <span class="comment">// existing SparkContext</span></span><br><span class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sc, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p>然后由ssc(StreamingContext)创建一个DStream，DStream可以指定数据输入源（DStream支持很多数据源，如kakfa、flume、twitter、TCP socketd），这里来个简单的TCP socket例子</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create a DStream that will connect to hostname:port, like localhost:9999</span></span><br><span class="line"><span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</span><br></pre></td></tr></table></figure>
<p>lines的类型是DStream，代表从数据服务器上接受到的数据流。lines中的每一条记录是一行文本。可以对其进行一些高级操作如map、reduce、join和window，<em>需要注意的是有些RDD操作并没有对DStream开放，如果想使用那些API，则需要进行Transform Operation</em>，transform Operation就是讲DStream转换为RDD，方法调用为<code>dStream.transform</code>，代码示例</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> dStreamToRdd = dStream.transform(rdd =&gt; &#123;</span><br><span class="line">  ...</span><br><span class="line">  rdd</span><br><span class="line">&#125;)</span><br></pre></td></tr></table></figure>
<p>Spark Streaming仅仅设置这些计算， 它并没有马上被执行。当所有的计算设置完后，我们可以调用下面的代码启动处理</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssc.start()             <span class="comment">// Start the computation</span></span><br><span class="line">ssc.awaitTermination()  <span class="comment">// Wait for the computation to terminate</span></span><br></pre></td></tr></table></figure>
<h2 id="Spark-Streaming-Demo"><a href="#Spark-Streaming-Demo" class="headerlink" title="Spark Streaming Demo"></a>Spark Streaming Demo</h2><p>来个简单的Demo看看，此Demo可以在<code>${SPARK_HOME}/examples/src/main/scala/org/apache/spark/examples/streaming</code>中找到</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.storage.<span class="type">StorageLevel</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Counts words in UTF8 encoded, '\n' delimited text received from the network every second.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Usage: NetworkWordCount &lt;hostname&gt; &lt;port&gt;</span></span><br><span class="line"><span class="comment"> * &lt;hostname&gt; and &lt;port&gt; describe the TCP server that Spark Streaming would connect to receive data.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * To run this on your local machine, you need to first run a Netcat server</span></span><br><span class="line"><span class="comment"> *    `$ nc -lk 9999`</span></span><br><span class="line"><span class="comment"> * and then run the example</span></span><br><span class="line"><span class="comment"> *    `$ bin/run-example org.apache.spark.examples.streaming.NetworkWordCount localhost 9999`</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">NetworkWordCount</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (args.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="type">System</span>.err.println(<span class="string">"Usage: NetworkWordCount &lt;hostname&gt; &lt;port&gt;"</span>)</span><br><span class="line">      <span class="type">System</span>.exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">StreamingExamples</span>.setStreamingLogLevels()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create the context with a 1 second batch size</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"NetworkWordCount"</span>)</span><br><span class="line">    <span class="comment">// 得到一个spark streaming的context，为spark streaming的主入口</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create a socket stream on target ip:port and count the</span></span><br><span class="line">    <span class="comment">// words in input stream of \n delimited text (eg. generated by 'nc')</span></span><br><span class="line">    <span class="comment">// Note that no duplication in storage level only for running locally.</span></span><br><span class="line">    <span class="comment">// Replication necessary in distributed scenario for fault tolerance.</span></span><br><span class="line">    <span class="comment">// 由ssc创建一个TCP socket的DStream，DStream存放的就是接收的数据流</span></span><br><span class="line">    <span class="keyword">val</span> lines = ssc.socketTextStream(args(<span class="number">0</span>), args(<span class="number">1</span>).toInt, <span class="type">StorageLevel</span>.<span class="type">MEMORY_AND_DISK_SER</span>)</span><br><span class="line">    <span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))</span><br><span class="line">    <span class="keyword">val</span> wordCounts = words.map(x =&gt; (x, <span class="number">1</span>)).reduceByKey(_ + _)</span><br><span class="line">    wordCounts.print()</span><br><span class="line">    <span class="comment">// 调用start之后，才能进行真正的计算</span></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>打开两个终端AB，在A输入<code>nc -lk 9999</code>命令，在B进入spark的home目录运行<code>./bin/run-example streaming.NetworkWordCount localhost 9999</code>命令。在A中输入一些测试数据，就可以在B查看计算结果。</p>
<h2 id="Spark-Streaming-消费Kafka"><a href="#Spark-Streaming-消费Kafka" class="headerlink" title="Spark Streaming 消费Kafka"></a>Spark Streaming 消费Kafka</h2><p>Spark消费kafka有两种方式，这里主要介绍第二种<em>Direct Approach (No Receivers)</em></p>
<blockquote>
<p>Direct Approach将kafka数据源包裹成了一个KafkaRDD，RDD里的partition 对应的数据源为kafka的partition（有利于并行的读取kafka message）。<br>kafka message并不是立马被读入spark内存，而是在Kafka存着呢，直到有实际的Action被触发，才会去kafka主动拉数据。<br>Direct Approach使用的是kafka simple consumer api，这样可以指定从某个offset处进行读取，有利于故障恢复。</p>
</blockquote>
<h2 id="Spark-Streaming-consumer-Kafka-to-HDFS"><a href="#Spark-Streaming-consumer-Kafka-to-HDFS" class="headerlink" title="Spark Streaming consumer Kafka to HDFS"></a>Spark Streaming consumer Kafka to HDFS</h2><p>本篇文章主要将kafka中的message通过spark streaming根据不同的topic写到不同的hdfs文件中，并且能够记录消费message的offset，以支持故障恢复。</p>
<h3 id="offset存储方案选择"><a href="#offset存储方案选择" class="headerlink" title="offset存储方案选择"></a>offset存储方案选择</h3><ul>
<li>利用checkpoint将offset存储在hdfs<br>简单容易实现，根据需求有一定的局限，无法更好的满足需求</li>
<li>将offset存储在HDFS<br>一开始为了尽量减少依赖的组件，减少组件原因造成应用故障，使用选择将offset存储在hdfs上，但在开发中考虑到offset文件需要频繁的读写操作，可能会在性能上有所影响</li>
<li>将offset存储在zk<br>跟Kafka high-level consumer API一样将offset存储在zk上，代码逻辑图如下：<br><img src="/blogimgs/SparkStreamingconsumerKafka/spark-kafka-direct-api.png" alt="Kafka direct API with zk" title="Kafka direct API with zk"><br>由Spark driver计算下个batch的offsets，指导executor消费对应的topics和partitions。使消费Kafka消息，就像消费文件系统文件一样。</li>
</ul>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p>Spark Streaming通过Direct Approach接收数据的入口自然是KafkaUtils.createDirectStream 了。在调用该方法时，会先创建<code>KafkaCluster</code>，得到offset</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createDirectStream</span></span>[</span><br><span class="line">  <span class="type">K</span>: <span class="type">ClassTag</span>,</span><br><span class="line">  <span class="type">V</span>: <span class="type">ClassTag</span>,</span><br><span class="line">  <span class="type">KD</span> &lt;: <span class="type">Decoder</span>[<span class="type">K</span>]: <span class="type">ClassTag</span>,</span><br><span class="line">  <span class="type">VD</span> &lt;: <span class="type">Decoder</span>[<span class="type">V</span>]: <span class="type">ClassTag</span>] (</span><br><span class="line">    ssc: <span class="type">StreamingContext</span>,</span><br><span class="line">    kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>],</span><br><span class="line">    topics: <span class="type">Set</span>[<span class="type">String</span>]</span><br><span class="line">): <span class="type">InputDStream</span>[(<span class="type">K</span>, <span class="type">V</span>)] = &#123;</span><br><span class="line">  <span class="keyword">val</span> messageHandler = (mmd: <span class="type">MessageAndMetadata</span>[<span class="type">K</span>, <span class="type">V</span>]) =&gt; (mmd.key, mmd.message)</span><br><span class="line">  <span class="keyword">val</span> kc = <span class="keyword">new</span> <span class="type">KafkaCluster</span>(kafkaParams)</span><br><span class="line">  <span class="keyword">val</span> fromOffsets = getFromOffsets(kc, kafkaParams, topics)</span><br><span class="line">  <span class="keyword">new</span> <span class="type">DirectKafkaInputDStream</span>[<span class="type">K</span>, <span class="type">V</span>, <span class="type">KD</span>, <span class="type">VD</span>, (<span class="type">K</span>, <span class="type">V</span>)](</span><br><span class="line">    ssc, kafkaParams, fromOffsets, messageHandler)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p><code>KafkaCluster</code>是操作kafka的一个关键类，但由于其是private的，要想在自己的代码中使用该类得重写该类。</p>
</blockquote>
<p>创建KafkaManager类，其中主要包含三个方法，分别是根据offset创建一个DStream、得到offset、更新zk上的offset，代码如下：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.common.<span class="type">TopicAndPartition</span></span><br><span class="line"><span class="keyword">import</span> kafka.message.<span class="type">MessageAndMetadata</span></span><br><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">Decoder</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkException</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">RDD</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.<span class="type">StreamingContext</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.dstream.<span class="type">InputDStream</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.<span class="type">KafkaCluster</span>.<span class="type">LeaderOffset</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.&#123;<span class="type">HasOffsetRanges</span>, <span class="type">KafkaCluster</span>, <span class="type">KafkaUtils</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.reflect.<span class="type">ClassTag</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Created by hunhun on 2016/5/27.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KafkaManager</span>(<span class="params">val kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>]</span>) </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// KafkaCluster in Spark is overwrited by myself</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> kc = <span class="keyword">new</span> <span class="type">KafkaCluster</span>(kafkaParams)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 根据offset创建一个DStream</span></span><br><span class="line">  <span class="comment">// return key message topic</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createDirectStream</span></span>[<span class="type">K</span>: <span class="type">ClassTag</span>, <span class="type">V</span>: <span class="type">ClassTag</span>, <span class="type">KD</span> &lt;: <span class="type">Decoder</span>[<span class="type">K</span>]: <span class="type">ClassTag</span>, <span class="type">VD</span> &lt;: <span class="type">Decoder</span>[<span class="type">V</span>]: <span class="type">ClassTag</span>]</span><br><span class="line">    (ssc: <span class="type">StreamingContext</span>, kafkaParams: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>], topics: <span class="type">Set</span>[<span class="type">String</span>]): <span class="type">InputDStream</span>[(<span class="type">K</span>, <span class="type">V</span>, <span class="type">String</span>)] = &#123;</span><br><span class="line">    <span class="keyword">val</span> groupId = kafkaParams.get(<span class="string">"group.id"</span>).get</span><br><span class="line">    <span class="comment">// 在zookeeper上读取offsets前先根据实际情况更新offsets</span></span><br><span class="line">    setOrUpdateOffsets(topics, groupId)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//从zookeeper上读取offset开始消费message</span></span><br><span class="line">    <span class="keyword">val</span> messages = &#123;</span><br><span class="line">      <span class="comment">// Either 类型</span></span><br><span class="line">      <span class="keyword">val</span> partitionsE = kc.getPartitions(topics)</span><br><span class="line">      <span class="keyword">if</span> (partitionsE.isLeft)</span><br><span class="line">        <span class="comment">// s"xx $&#123;&#125;" 字符串插值</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka partition failed: <span class="subst">$&#123;partitionsE.left.get&#125;</span>"</span>)</span><br><span class="line">      <span class="keyword">val</span> partitions = partitionsE.right.get</span><br><span class="line">      <span class="keyword">val</span> consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)</span><br><span class="line">      <span class="keyword">if</span> (consumerOffsetsE.isLeft)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka consumer offsets failed: <span class="subst">$&#123;consumerOffsetsE.left.get&#125;</span>"</span>)</span><br><span class="line">      <span class="keyword">val</span> consumerOffsets = consumerOffsetsE.right.get</span><br><span class="line">      <span class="comment">// 从指定offsets处消费kafka</span></span><br><span class="line">      <span class="comment">// messageHandler = (mmd: MessageAndMetadata[String, String]) =&gt; (mmd.key(), mmd.message())</span></span><br><span class="line">      <span class="comment">// MessageAndMetadata里包含message的topic message 等等信息</span></span><br><span class="line">      <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">K</span>, <span class="type">V</span>, <span class="type">KD</span>, <span class="type">VD</span>, (<span class="type">K</span>, <span class="type">V</span>, <span class="type">String</span>)](</span><br><span class="line">        ssc, kafkaParams, consumerOffsets, (mmd: <span class="type">MessageAndMetadata</span>[<span class="type">K</span>, <span class="type">V</span>]) =&gt; ( mmd.key, mmd.message, mmd.topic))</span><br><span class="line">    &#125;</span><br><span class="line">    messages</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">setOrUpdateOffsets</span></span>(topics: <span class="type">Set</span>[<span class="type">String</span>], groupId: <span class="type">String</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    topics.foreach(topic =&gt; &#123;</span><br><span class="line">      <span class="keyword">var</span> hasConsumed = <span class="literal">true</span></span><br><span class="line">      <span class="keyword">val</span> partitionsE = kc.getPartitions(<span class="type">Set</span>(topic))</span><br><span class="line">      <span class="keyword">if</span> (partitionsE.isLeft)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get kafka partition failed: <span class="subst">$&#123;partitionsE.left.get&#125;</span>"</span>)</span><br><span class="line">      <span class="keyword">val</span> partitions = partitionsE.right.get</span><br><span class="line">      <span class="keyword">val</span> consumerOffsetsE = kc.getConsumerOffsets(groupId, partitions)</span><br><span class="line">      <span class="keyword">if</span> (consumerOffsetsE.isLeft) hasConsumed = <span class="literal">false</span></span><br><span class="line">      <span class="comment">// 某个groupid首次没有offset信息，会报错，从头开始读</span></span><br><span class="line">      <span class="keyword">if</span> (hasConsumed) &#123;<span class="comment">// 消费过</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">          * 如果streaming程序执行的时候出现kafka.common.OffsetOutOfRangeException，</span></span><br><span class="line"><span class="comment">          * 说明zk上保存的offsets已经过时了，即kafka的定时清理策略已经将包含该offsets的文件删除。</span></span><br><span class="line"><span class="comment">          * 针对这种情况，只要判断一下zk上的consumerOffsets和earliestLeaderOffsets的大小，</span></span><br><span class="line"><span class="comment">          * 如果consumerOffsets比earliestLeaderOffsets还小的话，说明consumerOffsets已过时,</span></span><br><span class="line"><span class="comment">          * 这时把consumerOffsets更新为earliestLeaderOffsets</span></span><br><span class="line"><span class="comment">          */</span></span><br><span class="line">        <span class="keyword">val</span> earliestLeaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</span><br><span class="line">        <span class="keyword">if</span> (earliestLeaderOffsetsE.isLeft)</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get earliest leader offsets failed: <span class="subst">$&#123;earliestLeaderOffsetsE.left.get&#125;</span>"</span>)</span><br><span class="line">        <span class="keyword">val</span> earliestLeaderOffsets = earliestLeaderOffsetsE.right.get</span><br><span class="line">        <span class="keyword">val</span> consumerOffsets = consumerOffsetsE.right.get</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 可能只是存在部分分区consumerOffsets过时，所以只更新过时分区的consumerOffsets为earliestLeaderOffsets</span></span><br><span class="line">        <span class="keyword">var</span> offsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">Long</span>] = <span class="type">Map</span>()</span><br><span class="line">        consumerOffsets.foreach(&#123; <span class="keyword">case</span>(tp, n) =&gt;</span><br><span class="line">          <span class="keyword">val</span> earliestLeaderOffset = earliestLeaderOffsets(tp).offset</span><br><span class="line">          <span class="keyword">if</span> (n &lt; earliestLeaderOffset) &#123;</span><br><span class="line">            println(<span class="string">"consumer group:"</span> + groupId + <span class="string">",topic:"</span> + tp.topic + <span class="string">",partition:"</span> + tp.partition +</span><br><span class="line">              <span class="string">" offsets已经过时，更新为"</span> + earliestLeaderOffset)</span><br><span class="line">            offsets += (tp -&gt; earliestLeaderOffset)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">        <span class="keyword">if</span> (!offsets.isEmpty) &#123;</span><br><span class="line">          kc.setConsumerOffsets(groupId, offsets)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;<span class="comment">// 没有消费过</span></span><br><span class="line">      <span class="keyword">val</span> reset = kafkaParams.get(<span class="string">"auto.offset.reset"</span>).map(_.toLowerCase)</span><br><span class="line">        <span class="keyword">var</span> leaderOffsets: <span class="type">Map</span>[<span class="type">TopicAndPartition</span>, <span class="type">LeaderOffset</span>] = <span class="literal">null</span></span><br><span class="line">        <span class="keyword">if</span> (reset == <span class="type">Some</span>(<span class="string">"smallest"</span>)) &#123;<span class="comment">// 从头消费</span></span><br><span class="line">          <span class="keyword">val</span> leaderOffsetsE = kc.getEarliestLeaderOffsets(partitions)</span><br><span class="line">          <span class="keyword">if</span> (leaderOffsetsE.isLeft)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get earliest leader offsets failed: <span class="subst">$&#123;leaderOffsetsE.left.get&#125;</span>"</span>)</span><br><span class="line">          leaderOffsets = leaderOffsetsE.right.get</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123; <span class="comment">// 从最新offset处消费</span></span><br><span class="line">          <span class="keyword">val</span> leaderOffsetsE = kc.getLatestLeaderOffsets(partitions)</span><br><span class="line">          <span class="keyword">if</span> (leaderOffsetsE.isLeft)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">SparkException</span>(<span class="string">s"get latest leader offsets failed: <span class="subst">$&#123;leaderOffsetsE.left.get&#125;</span>"</span>)</span><br><span class="line">          leaderOffsets = leaderOffsetsE.right.get</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">val</span> offsets = leaderOffsets.map &#123;</span><br><span class="line">          <span class="keyword">case</span> (tp, offset) =&gt; (tp, offset.offset)</span><br><span class="line">        &#125;</span><br><span class="line">        kc.setConsumerOffsets(groupId, offsets)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">updateZKOffsets</span></span>(rdd: <span class="type">RDD</span>[(<span class="type">String</span>, <span class="type">String</span>, <span class="type">String</span>)]) : <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> groupId = kafkaParams.get(<span class="string">"group.id"</span>).get</span><br><span class="line">    <span class="keyword">val</span> offsetsList = rdd.asInstanceOf[<span class="type">HasOffsetRanges</span>].offsetRanges</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (offsets &lt;- offsetsList) &#123;</span><br><span class="line">      <span class="keyword">val</span> topicAndPartition = <span class="type">TopicAndPartition</span>(offsets.topic, offsets.partition)</span><br><span class="line">      <span class="keyword">val</span> o = kc.setConsumerOffsets(groupId, <span class="type">Map</span>((topicAndPartition, offsets.untilOffset)))</span><br><span class="line">      <span class="keyword">if</span> (o.isLeft) &#123;</span><br><span class="line">        println(<span class="string">s"Error updating the offset to Kafka cluster: <span class="subst">$&#123;o.left.get&#125;</span>"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>创建主类SparkConsumerKafka</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FSDataOutputStream</span>, <span class="type">Path</span>, <span class="type">FileSystem</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> scala.collection.mutable.<span class="type">ListBuffer</span></span><br><span class="line"><span class="keyword">import</span> scala.util.<span class="type">Random</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Created by hunhun on 2016/5/23.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkConsumerKafka</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (args.length &lt; <span class="number">4</span>) &#123;</span><br><span class="line">      <span class="type">System</span>.err.println( <span class="string">s""</span><span class="string">"</span></span><br><span class="line"><span class="string">                             |Usage: DirectKafkaWordCount &lt;brokers&gt; &lt;topics&gt; &lt;groupid&gt;</span></span><br><span class="line"><span class="string">                             |  &lt;brokers&gt; is a list of one or more Kafka brokers</span></span><br><span class="line"><span class="string">                             |  &lt;topics&gt; is a list of one or more kafka topics to consume from</span></span><br><span class="line"><span class="string">                             |  &lt;groupid&gt; is a consume group</span></span><br><span class="line"><span class="string">                             |  &lt;hdfspath&gt; is a HDFS Path, like /user/admin/scalapath</span></span><br><span class="line"><span class="string">                             |</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span>.stripMargin)</span><br><span class="line">      <span class="type">System</span>.exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(brokers, topics, groupId, hdfsPath) = args</span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"SparkConsumerKafka"</span>)</span><br><span class="line">    <span class="comment">// spark.streaming.kafka.maxRatePerPartition 限速</span></span><br><span class="line">    <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">60</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create direct kafka stream with brokers and topics</span></span><br><span class="line">    <span class="keyword">val</span> topicsSet = topics.split(<span class="string">","</span>).toSet</span><br><span class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](</span><br><span class="line">      <span class="string">"metadata.broker.list"</span> -&gt; brokers,</span><br><span class="line">      <span class="string">"group.id"</span> -&gt; groupId,</span><br><span class="line">      <span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"smallest"</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> km = <span class="keyword">new</span> <span class="type">KafkaManager</span>(kafkaParams)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> messages = km.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc,</span><br><span class="line">      kafkaParams, topicsSet)</span><br><span class="line">    <span class="comment">// foreachRDD是DStream的output操作</span></span><br><span class="line">    messages.foreachRDD( rdd =&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span> (!rdd.isEmpty())&#123;</span><br><span class="line">        rdd.foreachPartition&#123; partitionOfRecords =&gt;</span><br><span class="line">          <span class="comment">// 得到HDFS的操作client</span></span><br><span class="line">          <span class="comment">// 此代码必须放在worker中创建，如果在driver中创建，则将会被序列化到worker中</span></span><br><span class="line">          <span class="comment">// 在worker中操作时会报错。</span></span><br><span class="line">          <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">Configuration</span>()</span><br><span class="line">          <span class="keyword">val</span> fs = <span class="type">FileSystem</span>.get(conf)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">var</span> messageList = <span class="keyword">new</span> <span class="type">ListBuffer</span>[<span class="type">String</span>]</span><br><span class="line">          <span class="keyword">var</span> topic = <span class="string">""</span></span><br><span class="line">          <span class="comment">// 此处代码只为得到topic</span></span><br><span class="line">          <span class="comment">// 之所以将message放入messageList中是因为partitionOfRecords变为list之后</span></span><br><span class="line">          <span class="comment">// 拿到一个record的topic之后，partitionOfRecords中的内容将消失，具体原因不知道</span></span><br><span class="line">          <span class="comment">// 代码如下：</span></span><br><span class="line">          <span class="comment">// val topic = partitionOfRecords.toList(0)._3</span></span><br><span class="line">          <span class="comment">// 然后写入hdfs时调用</span></span><br><span class="line">          <span class="comment">// partitionOfRecords.foreach(record =&gt; outputStream.write((record._2 + "\n").getBytes("UTF-8")))</span></span><br><span class="line">          <span class="comment">// 此时写入hdfs的内容为null，不知道为什么为null</span></span><br><span class="line">          <span class="comment">// 所以只好在得到topic的同时把message先存入messageList</span></span><br><span class="line">          partitionOfRecords.foreach(record =&gt; &#123;</span><br><span class="line">            messageList += record._2</span><br><span class="line">            <span class="keyword">if</span> (topic == <span class="string">""</span>)&#123;</span><br><span class="line">              topic = record._3</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">if</span> (topic != <span class="string">""</span>)&#123;</span><br><span class="line">            <span class="comment">// 拼出各个topic message的文件地址</span></span><br><span class="line">            <span class="keyword">val</span> path = <span class="keyword">new</span> <span class="type">Path</span>(hdfsPath + <span class="string">"/"</span> + topic + <span class="string">"/"</span> + <span class="type">Random</span>.nextInt(<span class="number">100</span>) + topic</span><br><span class="line">                          + <span class="type">System</span>.currentTimeMillis())</span><br><span class="line">            <span class="comment">// 创建一个HDFS outputStream流</span></span><br><span class="line">            <span class="keyword">val</span> outputStream = <span class="keyword">if</span> (fs.exists(path))&#123;</span><br><span class="line">              fs.append(path)</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">              fs.create(path)</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 将message逐条写入</span></span><br><span class="line">            messageList.foreach(message =&gt; outputStream.write((message + <span class="string">"\n"</span>).getBytes(<span class="string">"UTF-8"</span>)))</span><br><span class="line">            outputStream.close()</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 更新zk上的offset</span></span><br><span class="line">        km.updateZKOffsets(rdd)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="附加"><a href="#附加" class="headerlink" title="附加"></a>附加</h2><p>将offset写入checkpoint中</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> kafka.serializer.<span class="type">StringDecoder</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FSDataOutputStream</span>, <span class="type">Path</span>, <span class="type">FileSystem</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.<span class="type">SparkConf</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.catalyst.expressions.<span class="type">Second</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.kafka.&#123;<span class="type">HasOffsetRanges</span>, <span class="type">OffsetRange</span>, <span class="type">KafkaUtils</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.streaming.&#123;<span class="type">Seconds</span>, <span class="type">StreamingContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Created by hunhun on 2016/5/26.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">WriteToHdfsWithCheckpoint</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (args.length &lt; <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="type">System</span>.err.println(<span class="string">s""</span><span class="string">"</span></span><br><span class="line"><span class="string">                            |Usage: DirectKafkaWordCount &lt;brokers&gt; &lt;topics&gt;</span></span><br><span class="line"><span class="string">                            |  &lt;brokers&gt; is a list of one or more Kafka brokers</span></span><br><span class="line"><span class="string">                            |  &lt;topics&gt; is a list of one or more kafka topics to consume from</span></span><br><span class="line"><span class="string">                            |</span></span><br><span class="line"><span class="string">        "</span><span class="string">""</span>.stripMargin)</span><br><span class="line">      <span class="type">System</span>.exit(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(brokers, topics) = args</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create context with 2 second batch interval</span></span><br><span class="line">    <span class="keyword">val</span> sparkConf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ConsumerKafkaToHdfsWithCheckPoint"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Create direct kafka stream with brokers and topics</span></span><br><span class="line">    <span class="keyword">val</span> topicsSet = topics.split(<span class="string">","</span>).toSet</span><br><span class="line">    <span class="keyword">val</span> kafkaParams = <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>](<span class="string">"metadata.broker.list"</span> -&gt; brokers,</span><br><span class="line">      <span class="string">"auto.offset.reset"</span> -&gt; <span class="string">"smallest"</span>)</span><br><span class="line">    <span class="keyword">val</span> checkpointPath = <span class="string">"hdfs://127.0.0.1:8020/spark_checkpoint"</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">functionToCreateContext</span></span>(): <span class="type">StreamingContext</span> = &#123;</span><br><span class="line">      <span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(sparkConf, <span class="type">Seconds</span>(<span class="number">2</span>))</span><br><span class="line">      <span class="keyword">val</span> messages = <span class="type">KafkaUtils</span>.createDirectStream[<span class="type">String</span>, <span class="type">String</span>, <span class="type">StringDecoder</span>, <span class="type">StringDecoder</span>](ssc, kafkaParams, topicsSet)</span><br><span class="line">      <span class="comment">// checkpoint 在哪保存？ 这样会不会出现offset保存了但没有成功写入hdfs</span></span><br><span class="line">      <span class="comment">// checkpoint调用的位置会有影响吗？</span></span><br><span class="line">      ssc.checkpoint(checkpointPath)</span><br><span class="line"></span><br><span class="line">      messages.map(_._2).foreachRDD(rdd =&gt; &#123;</span><br><span class="line">        rdd.foreachPartition&#123; partitionOfRecords =&gt;</span><br><span class="line">          <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">Configuration</span>()</span><br><span class="line">          <span class="keyword">val</span> fs = <span class="type">FileSystem</span>.get(conf)</span><br><span class="line">          <span class="keyword">val</span> path = <span class="keyword">new</span> <span class="type">Path</span>(<span class="string">"/user/admin/scalapath/test"</span> + <span class="type">System</span>.currentTimeMillis())</span><br><span class="line">          <span class="keyword">val</span> outputStream : <span class="type">FSDataOutputStream</span> = <span class="keyword">if</span> (fs.exists(path))&#123;</span><br><span class="line">            fs.append(path)</span><br><span class="line">          &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            fs.create(path)</span><br><span class="line">          &#125;</span><br><span class="line">          partitionOfRecords.foreach(record =&gt; outputStream.write((record + <span class="string">"\n"</span>).getBytes(<span class="string">"UTF-8"</span>)))</span><br><span class="line">          outputStream.close()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;)</span><br><span class="line">      ssc</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 决定否创建新的Context</span></span><br><span class="line">    <span class="comment">// 没有checkpoint就创建一个新的StreamingContext即初次启动应用</span></span><br><span class="line">    <span class="comment">// 如果有checkpoint则checkpoint中记录的信息恢复StreamingContext</span></span><br><span class="line">    <span class="keyword">val</span> context = <span class="type">StreamingContext</span>.getOrCreate(checkpointPath, functionToCreateContext _)</span><br><span class="line"></span><br><span class="line">    context.start()</span><br><span class="line">    context.awaitTermination()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> HDFS </tag>
            
            <tag> Spark </tag>
            
            <tag> kafka </tag>
            
            <tag> Streaming </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Flume简介及初次使用]]></title>
      <url>http://bigdatadecode.club/Flume%E7%AE%80%E4%BB%8B%E5%8F%8A%E5%88%9D%E6%AC%A1%E4%BD%BF%E7%94%A8.html</url>
      <content type="html"><![CDATA[<p>最近要搭建一个日志分析平台，整体架构思路是通过flume采集日志到kafka中，从kafka之后分两条路走，一条是实时，一条是离线。实时会用spark或者storm（还没开始做），离线用hadoop+hive，将kafka中的数据消费到hdfs上，通过mr处理进hive，进行统计分析。</p>
<blockquote>
<p>采用flume的理由：<br>flume是java开发的，利于维护和二次开发<br>flume可扩展，也有较好的容错性，性能也不错<br>flume支持对现有应用无缝接入，对较老的应用程序侵入性较低</p>
</blockquote>
<p>本篇主要简单介绍下flume，因为flume是初次使用所以简单记录下。</p>
<a id="more"></a>
<h2 id="Flume版本演变"><a href="#Flume版本演变" class="headerlink" title="Flume版本演变"></a>Flume版本演变</h2><p>Flume 是 cloudera 开发的实时日志收集系统，其可以实时的将分布在不同节点、机器上的日志收集到一个存储设备中。目前Flume存在两个大版本，其一为初始发行版本目前被统称为 <em>Flume OG（original generation）</em>，属于 cloudera。其二为重构后的版本统称为<em>Flume NG（next generation）</em>。Flume NG对OG的核心组件、核心配置以及代码架构进行了重构。</p>
<h2 id="Flume-OG简介"><a href="#Flume-OG简介" class="headerlink" title="Flume OG简介"></a>Flume OG简介</h2><p>OG的架构为比较流行的主从架构，分为master和node，但角色分为3种，分别为agent、collector和master，agent和collector部署在node上，node的角色根据配置的不同又分为 logical node（逻辑节点）、physical node（物理节点）。</p>
<p>数据流是由agent收集日志数据，集中到collector，再由collector汇入存储终端，master在此过程中的作用是管理agent和collector的活动。</p>
<p>agent和collector内部组件相同，都是由source读取数据到channel，然后sink消费channel中的数据到存储终端或下一个source。</p>
<h2 id="Flume-NG简介"><a href="#Flume-NG简介" class="headerlink" title="Flume NG简介"></a>Flume NG简介</h2><p>Flume NG只有一个agent角色节点，较之OG，将collector和master节点删除，并去掉了node概念，但agent的内部组件依然是source、channel和sink。</p>
<blockquote>
<p>Flume NG主要有以下几个核心概念：</p>
<ul>
<li>Event：一个数据单元，带有一个可选的消息头</li>
<li>Flow：Event从源点到达目的节点的迁移的抽象</li>
<li>Client：操作位于源点处的Event，将其发送到Flume Agent （ExecSource是一个client，将本地文件作为flume的输入）</li>
<li>Agent：一个独立的jvm进程，包含组件Source、Channel、Sink</li>
<li>Source：用来消费传递到该组件的Event</li>
<li>Channel：中转Event的一个临时存储，保存有Source组件传递过来的Event</li>
<li>Sink：从Channel中读取，将Event传递到存储设备中或Flow Pipeline中的下一个Agent（如果有的话），然后移除Event</li>
</ul>
</blockquote>
<p>Flume采集数据的大致流程是client将event传送到flume agent，在agent中通过source将event放入channel，然后sink去channel中取数据存储到存储设备中或者flow pipeline。</p>
<h2 id="NG核心组件"><a href="#NG核心组件" class="headerlink" title="NG核心组件"></a>NG核心组件</h2><h3 id="source"><a href="#source" class="headerlink" title="source"></a>source</h3><p>source是主要作用是从外部client处接收数据并将这些数据存储在配置好的channel中。source支持的外部client包括avro，log4j，syslog 和 http post(body为json格式)。Flume还支持无缝接入现有程序，使其直接读取程序的原始日志文件，有两种方式可以实现：</p>
<ul>
<li>ExecSource: 以运行 Linux 命令的方式，持续的输出最新的数据，如 <em>tail -f 文件名</em> 指令，在这种方式下，取的文件名必须是指定的。 ExecSource 可以实现对日志的实时收集，但是存在Flume不运行或者指令执行出错时，将无法收集到日志数据，无法保证日志数据的完整性。</li>
<li>SpoolSource: 监测配置的目录下新增的文件，并将文件中的数据读取出来。需要注意两点：<em>拷贝到 spool 目录下的文件不可以再打开编辑；spool 目录下不可包含相应的子目录</em>。</li>
</ul>
<h3 id="channel"><a href="#channel" class="headerlink" title="channel"></a>channel</h3><p>channel是agent存储events的队列，source向其中加入events，sink则从其中消费events。<br>常用的channel有两个，分别是Memory Channel 和File Channel</p>
<ul>
<li>Memory Channel将events存在内存队列中（队列的大小可以在配置文件中指定）。Memory Channel主要用需要高吞吐量的，并允许存在丢失数据风险的情况下。</li>
<li>File Channel将events写入文件中，持久化所有事件。优点是容量较大且死掉时数据可恢复。缺点是速度较慢。</li>
</ul>
<h3 id="sink"><a href="#sink" class="headerlink" title="sink"></a>sink</h3><p>sink将events从channel中取出，导向下一个agent或者文件系统（可以是hdfs、kafka），可以针对不同的存储设备开发自定义的sink</p>
<h2 id="flume-kafka使用"><a href="#flume-kafka使用" class="headerlink" title="flume+kafka使用"></a>flume+kafka使用</h2><p>最近要搭建一个日志分析平台，整体架构思路是通过flume采集日志到kafka中，从kafka之后分两条路走，一条是实时，一条是离线。实时会用spark或者storm（还没开始做），离线用hadoop+hive，将kafka中的数据消费到hdfs上，通过mr处理进hive，进行统计分析。架构图如下：<br><img src="/blogimgs/Flume/日志分析系统架构图.png" alt="日志分析系统架构图" title="日志分析系统架构图"></p>
<h3 id="编译flume"><a href="#编译flume" class="headerlink" title="编译flume"></a>编译flume</h3><p>由于需要对kafka sink进行稍微改动添加一个将log内容按需拼接为json然后sink到kafka的功能，所以这里下载flume源码包，对其进行修改并编译。步骤如下：</p>
<ul>
<li>修改代码</li>
</ul>
<p>更改KafkaSink.java代码，为了扩展性，新建一个类SzwKafkaSink.java，对event实体进行修改，xxSink都继承AbstractSink，需要实现process方法，具体的处理逻辑也在此方法中。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Status <span class="title">process</span><span class="params">()</span> <span class="keyword">throws</span> EventDeliveryException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">long</span> processedEvents = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    transaction = channel.getTransaction();</span><br><span class="line">    transaction.begin();</span><br><span class="line"></span><br><span class="line">    messageList.clear();</span><br><span class="line">    <span class="keyword">for</span> (; processedEvents &lt; batchSize; processedEvents += <span class="number">1</span>) &#123;</span><br><span class="line">      event = channel.take();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (event == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// no events available in channel</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// log内容的byte数组</span></span><br><span class="line">      <span class="keyword">byte</span>[] eventBody = event.getBody();</span><br><span class="line">      Map&lt;String, String&gt; headers = event.getHeaders();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> ((eventTopic = headers.get(TOPIC_HDR)) == <span class="keyword">null</span>) &#123;</span><br><span class="line">        eventTopic = topic;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      eventKey = headers.get(KEY_HDR);</span><br><span class="line"> 	  ...</span><br><span class="line">      <span class="comment">// string to json for by szw</span></span><br><span class="line">      <span class="comment">// 添加一个方法，将string 根据需求拼接为json</span></span><br><span class="line">      eventBody = SzwKafkaSink.stringToJson(eventBody);</span><br><span class="line">      <span class="keyword">if</span> (eventBody != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// create a message and add to buffer</span></span><br><span class="line">        KeyedMessage&lt;String, <span class="keyword">byte</span>[]&gt; data = <span class="keyword">new</span> KeyedMessage&lt;String, <span class="keyword">byte</span>[]&gt;</span><br><span class="line">                (eventTopic, eventKey, eventBody);</span><br><span class="line">        messageList.add(data);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// publish batch and commit.</span></span><br><span class="line">    <span class="keyword">if</span> (processedEvents &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">long</span> startTime = System.nanoTime();</span><br><span class="line">      <span class="comment">// 调用kafka api 发送events</span></span><br><span class="line">      producer.send(messageList);</span><br><span class="line">      <span class="keyword">long</span> endTime = System.nanoTime();</span><br><span class="line">      counter.addToKafkaEventSendTimer((endTime-startTime)/(<span class="number">1000</span>*<span class="number">1000</span>));</span><br><span class="line">      counter.addToEventDrainSuccessCount(Long.valueOf(messageList.size()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    transaction.commit();</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">byte</span>[] stringToJson(<span class="keyword">byte</span>[] bytes) <span class="keyword">throws</span> UnsupportedEncodingException &#123;</span><br><span class="line">  String str = <span class="keyword">new</span> String(bytes, <span class="string">"UTF-8"</span>);</span><br><span class="line">  Map&lt;String, Object&gt; map = <span class="keyword">new</span> HashMap&lt;String, Object&gt;();</span><br><span class="line">  String[] array = &#123;&#125;;</span><br><span class="line">  <span class="keyword">int</span> index = -<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> ((index = str.indexOf(<span class="string">"[SESSIONID-"</span>)) &gt;= <span class="number">0</span>)&#123;</span><br><span class="line">    str = str.substring(index + <span class="number">1</span>);</span><br><span class="line">    array = str.split(<span class="string">"\\] \\["</span>);</span><br><span class="line">    <span class="keyword">int</span> len = array.length;</span><br><span class="line">    array[len-<span class="number">1</span>] = array[len-<span class="number">1</span>].substring(<span class="number">0</span>, array[len-<span class="number">1</span>].length()-<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;len; i++)&#123;</span><br><span class="line">      String[] kvArr = array[i].split(<span class="string">"-"</span>, <span class="number">2</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        map.put(kvArr[<span class="number">0</span>], <span class="keyword">new</span> JSONObject(kvArr[<span class="number">1</span>]));</span><br><span class="line">      &#125; <span class="keyword">catch</span> (JSONException e) &#123;</span><br><span class="line">        map.put(kvArr[<span class="number">0</span>], kvArr[<span class="number">1</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (map.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    JSONObject json = <span class="keyword">new</span> JSONObject(map);</span><br><span class="line">    <span class="keyword">return</span> json.toString().getBytes();</span><br><span class="line">  &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于将string拼接为json需要依赖json的jar包，则将所依赖的jar包添加到maven的pom文件中，否则随后的mvn过程中会发生错误。pom文件位于flume-ng-kafka-sink目录下，添加内容如下，version可以去maven网站上查找别的版本。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.json<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>json<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>20090211<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>编译flume</li>
</ul>
<p>在命令行输入<code>mvn clean install -DskipTests</code>，如果报oom的错误，则输入<code>export MAVEN_OPTS=&quot;-Xmx1024m -XX:MaxPermSize=512m&quot;</code>，然后再次执行mvn命令。</p>
<h3 id="部署flume"><a href="#部署flume" class="headerlink" title="部署flume"></a>部署flume</h3><p>解压编译好的flume，在其home目录下的conf文件夹中的<em>flume-env.sh</em>文件中设置下<code>$JAVA_HOME</code>。</p>
<p>依然在conf文件夹中新建一个conf文件，在其内设置source、channel和sink相关配置，此处是要将log文件sink到kafka中，则创建<em>flume-kafka.conf</em>文件，文件内容如下：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">agent1.sources = r1</span><br><span class="line">agent1.channels = c1</span><br><span class="line">agent1.sinks = k1</span><br><span class="line"><span class="meta">#</span><span class="bash"> For each one of the sources, the <span class="built_in">type</span> is defined</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> execSource 读取某个<span class="built_in">log</span>文本</span></span><br><span class="line">agent1.sources.r1.type = exec</span><br><span class="line">agent1.sources.r1.command=tail -f /home/hadoop/flume-test-log/flumetest.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果<span class="built_in">command</span>中有管道符 例如 tail -f /home/hadoop/flume-test-log/flumetest.log | grep xx</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 则加上下面的属性</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> agent1.sources.r1.shell = /bin/bash -c</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The channel can be defined as follows.</span></span><br><span class="line">agent1.sources.r1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Each sink<span class="string">'s type must be defined</span></span></span><br><span class="line">agent1.sinks.k1.type = org.apache.flume.sink.kafka.SzwKafkaSink</span><br><span class="line"><span class="meta">#</span><span class="bash">agent1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka topic</span></span><br><span class="line">agent1.sinks.k1.topic = test</span><br><span class="line"><span class="meta">#</span><span class="bash"> kafka 地址</span></span><br><span class="line">agent1.sinks.k1.brokerList = 127.0.0.1:9092</span><br><span class="line">agent1.sinks.k1.requiredAcks = 1</span><br><span class="line">agent1.sinks.k1.batchSize = 50</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">Specify the channel the sink should use</span></span><br><span class="line">agent1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Each channel<span class="string">'s type is defined.</span></span></span><br><span class="line">agent1.channels.c1.type = memory</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Other config values specific to each <span class="built_in">type</span> of channel(sink or <span class="built_in">source</span>)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> can be defined as well</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> In this <span class="keyword">case</span>, it specifies the capacity of the memory channel</span></span><br><span class="line">agent1.channels.c1.capacity = 1000</span><br><span class="line">agent1.channels.c1.transactionCapacity = 100</span><br></pre></td></tr></table></figure>
<h3 id="运行flume-agent"><a href="#运行flume-agent" class="headerlink" title="运行flume agent"></a>运行flume agent</h3><blockquote>
<p>运行Flume agent可以使用<code>supervise</code>，命令启动，这样当agent挂掉之后会自动重启agent。</p>
</blockquote>
<p>在运行命令之前最好现在kafka集群上创建好topic，创建命令<code>bin/kafka-topics.sh --create --zookeeper hadoop02:2181/kafka --replication-factor 1 --partitions 1 --topic szwtest</code>，否则会自动创建一个topic，<em>replication-factor</em>和<em>partitions</em>会进行默认设置，都是1。<br>命令行运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent --conf conf/ -f conf/flume-kafka.conf -n agent1 -Dflume.root.logger=DEBUG,console</span><br></pre></td></tr></table></figure>
<p>后台运行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup bin/flume-ng agent --conf conf/ -f conf/flume-kafka.conf -n agent1 &gt;out.log &amp;</span><br></pre></td></tr></table></figure>
<h2 id="Flume简单性能测试"><a href="#Flume简单性能测试" class="headerlink" title="Flume简单性能测试"></a>Flume简单性能测试</h2><ul>
<li>写个shell脚本循环往log里插入文本1百万条（大概不到3分钟插完）</li>
<li>在插入的过程中启动agent收集日志（先有log文本再启动agent，大概3分钟多点收集结束）</li>
</ul>
<blockquote>
<p>收集log使用的linux命令<code>tail -f xx.log</code>，如果先启动agent，log文件不存在，使用tail命令就无法读取内容，agent也就捕获不到标准输出，不过可以使用<code>tail --follow=name --retry xx.log</code>，这样当log不存在时就会进行重试。</p>
</blockquote>
<p>测试结果如下：<br><img src="/blogimgs/Flume/info11.png" alt="cpu/mem结果图1" title="cpu/mem结果图1"><br><img src="/blogimgs/Flume/info21.png" alt="cpu/mem结果图2" title="cpu/mem结果图2"><br><img src="/blogimgs/Flume/info31.png" alt="cpu/mem结果图3" title="cpu/mem结果图3"><br>机器配置为虚拟机8核、8G内存。</p>
<p>此次测试也就是3mins左右的时间写入1000000条log，agent进行实时收集时使用的cpu和mem情况。<br>agent的堆内存的设置是<code>export JAVA_OPTS=&quot;-Xms256m -Xmx512m&quot;</code><br>在此过程中看出cpu比较平缓，维持在5%以下，使用的堆大小维持在100M以下，但是在agent启动初期cpu和mem会有一个比较大的波动，可能是因为启动初期会有大量的log进入内存，随后随着sink的消费cpu消耗处于平缓状态，mem会有所波动但会维持在100M以下。</p>
<p>cpu和mem的信息是用jvisualvm.exe监控的，在<em>flume-env.sh</em>中加入<br><code>export JAVA_OPTS=&quot;-Dcom.sun.management.jmxremote.port=9999 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false&quot;</code>。</p>
<h2 id="远程debug调式flume-agent"><a href="#远程debug调式flume-agent" class="headerlink" title="远程debug调式flume agent"></a>远程debug调式flume agent</h2><ul>
<li>将flume源码导入ide中（我导入的是intellij idea）</li>
<li>在flume部署目录的bin下找到flume-ng文件，在<code>run_flume()</code>中添加如下代码：<br><code>FLUME_JAVA_OPTS=&quot;-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000&quot;</code></li>
<li>在ide中进行远程debug</li>
</ul>
<p>更多Flume内容查看<a href="http://flume.apache.org/FlumeUserGuide.html#flume-channel-selectors" target="_blank" rel="noopener">官网用户手册</a></p>
<hr>
<p>agent1.sources.avro-source1.command = /usr/local/bin/tail  -n +$(tail -n1 /home/storm/tmp/n) –max-unchanged-stats=600 -F  /home/storm/tmp/id.txt | awk ‘ARNGIND==1{i=$0;next}{i++; if($0~/文件已截断/)i=0; print i &gt;&gt; “/home/storm/tmp/n”;print $1”—“i}’ /home/storm/tmp/n -</p>
]]></content>
      
        <categories>
            
            <category> Flume </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> log </tag>
            
            <tag> Flume </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[再议HDFS写流程之pipeline]]></title>
      <url>http://bigdatadecode.club/%E5%86%8D%E8%AE%AEHDFS%E5%86%99%E6%B5%81%E7%A8%8B%E4%B9%8Bpipeline.html</url>
      <content type="html"><![CDATA[<p>之前有一篇是介绍HDFS写流程的，只是大致的从代码的角度解析了下，有些细节并没有深挖，这篇文章我们主要来挖下写流程中的一些细节，但是由于我水平有限，只能尽可能的挖，本篇也会不定时的进行打补丁。</p>
<p>这里重点总结下开始往pipeline中写数据到一个block结束关闭pipeline的流程。想先了解下HDFS write流程的请看<a href="http://bigdatadecode.club/HDFS write解析.html">这篇</a></p>
<p>这里先列下想要总结的知识点：</p>
<ul>
<li>lease检查发生在哪？createFile时创建lease，两个线程能否同时创建同一个文件？lease检查只在addBlock中发生？是否会判断lease的当前持有者是否继续持有</li>
<li>client或者dn何时向nn汇报Replica或者Block的状态</li>
<li>pipeline是怎么建立的，targets dn是怎么传递的</li>
<li>pipeline在setup阶段发生故障怎么办，client如何检测，如何修复</li>
<li>pipeline在stream阶段发生故障怎么办，client如何检测，如何修复</li>
<li>pipeline在close阶段发生故障怎么办，client如何检测，如何修复</li>
<li>pipeline中某个dn发生故障，是否需要replace dn，replace原则</li>
<li>pipeline recovery、block recovery和lease recovery的关系，及各个recovery发生的时间点、由谁主导？</li>
<li>Replica和Block的状态是怎么变化的，Replica的状态又是怎么影响Block的状态的。</li>
<li>pipeline中什么故障会向上游发送ack然后关闭当前dn的网络连接，是谁关闭dn的连接(<em>dn在DataXceiver.writeBlock的finally中关闭连接</em>)？dn自己还是client？</li>
</ul>
<p>之所以要把知识点列出来，是因为这些知识点不一定能一次搞清楚，避免以后忘了更新什么知识点。</p>
<a id="more"></a>
<h2 id="lease检查发生在哪"><a href="#lease检查发生在哪" class="headerlink" title="lease检查发生在哪"></a>lease检查发生在哪</h2><p>HDFS是通过lease来防止并发写，实现写锁功能的。</p>
<p>HDFS write在open FSDataOutputStream时向NN申请lease，并在得到lease之后，由client调用LeaseRenewer来续约。要想防止并发写，则需要在client在写数据时判断是否持有该文件的lease，那么这个lease的检查都发生在哪里呢？</p>
<h3 id="addFile"><a href="#addFile" class="headerlink" title="addFile"></a>addFile</h3><p>在HDFS write代码跟读中发现，在申请lease时并没有进行lease的检查(没有检查该文件的lease是否已被别的client所持有)，这样如果有两个client对同一个文件进行open FSDataOutputStream时，能否成功，会发生什么？？</p>
<p>申请lease的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> BlocksMapUpdateInfo <span class="title">startFileInternal</span><span class="params">(FSPermissionChecker pc, </span></span></span><br><span class="line"><span class="function"><span class="params">    String src, PermissionStatus permissions, String holder, </span></span></span><br><span class="line"><span class="function"><span class="params">    String clientMachine, <span class="keyword">boolean</span> create, <span class="keyword">boolean</span> overwrite, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> createParent, <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isLazyPersist, CipherSuite suite, CryptoProtocolVersion version,</span></span></span><br><span class="line"><span class="function"><span class="params">    EncryptedKeyVersion edek, <span class="keyword">boolean</span> logRetryEntry)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> FileAlreadyExistsException, AccessControlException,</span></span><br><span class="line"><span class="function">    UnresolvedLinkException, FileNotFoundException,</span></span><br><span class="line"><span class="function">    ParentNotDirectoryException, RetryStartFileException, IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    BlocksMapUpdateInfo toRemoveBlocks = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// myFile为null，也就是src不存在时，此时create为true</span></span><br><span class="line">    <span class="keyword">if</span> (myFile == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!create) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException(<span class="string">"Can't overwrite non-existent "</span> +</span><br><span class="line">            src + <span class="string">" for client "</span> + clientMachine);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// myFile不为null，也就是说src已经存在，则重写</span></span><br><span class="line">      <span class="comment">// overwrite时不应该检查下该client是否持有该文件的lease吗？</span></span><br><span class="line">      <span class="keyword">if</span> (overwrite) &#123;</span><br><span class="line">        toRemoveBlocks = <span class="keyword">new</span> BlocksMapUpdateInfo();</span><br><span class="line">        List&lt;INode&gt; toRemoveINodes = <span class="keyword">new</span> ChunkedArrayList&lt;INode&gt;();</span><br><span class="line">        <span class="keyword">long</span> ret = dir.delete(src, toRemoveBlocks, toRemoveINodes, now());</span><br><span class="line">        <span class="keyword">if</span> (ret &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">          incrDeletedFileCount(ret);</span><br><span class="line">          removePathAndBlocks(src, <span class="keyword">null</span>, toRemoveINodes, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// If lease soft limit time is expired, recover the lease</span></span><br><span class="line">        recoverLeaseInternal(myFile, src, holder, clientMachine, <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FileAlreadyExistsException(src + <span class="string">" for client "</span> +</span><br><span class="line">            clientMachine + <span class="string">" already exists"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 检查HDFS中的object(inode+block)是否达到上限</span></span><br><span class="line">    checkFsObjectLimit();</span><br><span class="line">    INodeFile newNode = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Always do an implicit mkdirs for parent directory tree.</span></span><br><span class="line">    Path parent = <span class="keyword">new</span> Path(src).getParent();</span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span> &amp;&amp; mkdirsRecursively(parent.toString(),</span><br><span class="line">            permissions, <span class="keyword">true</span>, now())) &#123;</span><br><span class="line">      <span class="comment">// addFile到namespace，这期间会判断Quota</span></span><br><span class="line">      newNode = dir.addFile(src, permissions, replication, blockSize,</span><br><span class="line">                            holder, clientMachine);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 将file添加到namespace中之后，申请lease</span></span><br><span class="line">    leaseManager.addLease(newNode.getFileUnderConstructionFeature()</span><br><span class="line">        .getClientName(), src);</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由上面的代码可知client在open一个file的输出流时，并没有进行lease检查(目前未发现)，只是判断当前file是进行create还是overwrite，然后进行namespace状态的更新，最后进行申请lease。</p>
<p>那么当clientA打开fileA文件的输出流进行写数据时，clientB也发出了请求来打开fileA文件的输出流，此时fileA已经存在，则进行overwrite，在此过程中，没有进行任何lease的检查，clientB能够将clientA已经写入fileA中的数据覆盖掉(也就是把已经写入的数据调用dir.delete删除，并且delete时也没有涉及lease检查)，<em>随后又会通过addLease得到clientB关于fileA的lease(此时clientA持有clientA关于fileA的lease)</em>。</p>
<p>lease在LeaseManager中是以持有者来区分的，clientA和clientB是不同的持有者，则在各自的lease中都保留这fileA的path。</p>
<p><strong>这种情况HDFS具体是怎么处理的？有时间找个合适的例子去测试下。。。</strong></p>
<h3 id="addBlock"><a href="#addBlock" class="headerlink" title="addBlock"></a>addBlock</h3><p>上面分析了下addFile时lease相关的操作，下面解析下addBlock时进行的lease检查。</p>
<p>block是通过pipeline写入dn的，当需要addBlock时，DataStreamer会创建一个pipeline，pipeline的创建期间进行lease检查。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSNamesystem.java</span></span><br><span class="line"><span class="function">FileState <span class="title">analyzeFileState</span><span class="params">(String src,</span></span></span><br><span class="line"><span class="function"><span class="params">                              <span class="keyword">long</span> fileId,</span></span></span><br><span class="line"><span class="function"><span class="params">                              String clientName,</span></span></span><br><span class="line"><span class="function"><span class="params">                              ExtendedBlock previous,</span></span></span><br><span class="line"><span class="function"><span class="params">                              LocatedBlock[] onRetryBlock)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException  </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// checkLease进行lease检查</span></span><br><span class="line">  <span class="keyword">final</span> INodeFile pendingFile = checkLease(src, clientName, inode, fileId);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> INodeFile <span class="title">checkLease</span><span class="params">(String src, String holder, INode inode,</span></span></span><br><span class="line"><span class="function"><span class="params">                             <span class="keyword">long</span> fileId)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> LeaseExpiredException, FileNotFoundException </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">assert</span> <span class="title">hasReadLock</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="keyword">final</span> String ident = src + <span class="string">" (inode "</span> + fileId + <span class="string">")"</span>;</span><br><span class="line">  <span class="keyword">if</span> (inode == <span class="keyword">null</span>) &#123;</span><br><span class="line">    Lease lease = leaseManager.getLease(holder);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> LeaseExpiredException(</span><br><span class="line">        <span class="string">"No lease on "</span> + ident + <span class="string">": File does not exist. "</span></span><br><span class="line">        + (lease != <span class="keyword">null</span> ? lease.toString()</span><br><span class="line">            : <span class="string">"Holder "</span> + holder + <span class="string">" does not have any open files."</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!inode.isFile()) &#123;</span><br><span class="line">    Lease lease = leaseManager.getLease(holder);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> LeaseExpiredException(</span><br><span class="line">        <span class="string">"No lease on "</span> + ident + <span class="string">": INode is not a regular file. "</span></span><br><span class="line">            + (lease != <span class="keyword">null</span> ? lease.toString()</span><br><span class="line">            : <span class="string">"Holder "</span> + holder + <span class="string">" does not have any open files."</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">final</span> INodeFile file = inode.asFile();</span><br><span class="line">  <span class="keyword">if</span> (!file.isUnderConstruction()) &#123;</span><br><span class="line">    Lease lease = leaseManager.getLease(holder);</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> LeaseExpiredException(</span><br><span class="line">        <span class="string">"No lease on "</span> + ident + <span class="string">": File is not open for writing. "</span></span><br><span class="line">        + (lease != <span class="keyword">null</span> ? lease.toString()</span><br><span class="line">            : <span class="string">"Holder "</span> + holder + <span class="string">" does not have any open files."</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// No further modification is allowed on a deleted file.</span></span><br><span class="line">  <span class="comment">// A file is considered deleted, if it is not in the inodeMap or is marked</span></span><br><span class="line">  <span class="comment">// as deleted in the snapshot feature.</span></span><br><span class="line">  <span class="keyword">if</span> (isFileDeleted(file)) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException(src);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 通过file得到该file的clientName，判断是否持有该lease</span></span><br><span class="line">  <span class="comment">// 那么上面的情况，file会有两个clientName？这肯定不会出现，但在哪进行的处理呢？？</span></span><br><span class="line">  String clientName = file.getFileUnderConstructionFeature().getClientName();</span><br><span class="line">  <span class="keyword">if</span> (holder != <span class="keyword">null</span> &amp;&amp; !clientName.equals(holder)) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> LeaseExpiredException(<span class="string">"Lease mismatch on "</span> + ident +</span><br><span class="line">        <span class="string">" owned by "</span> + clientName + <span class="string">" but is accessed by "</span> + holder);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> file;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>pipeline是怎么建立的，targets dn是怎么传递的</li>
<li>pipeline在setup阶段发生故障怎么办，client如何检测，如何修复</li>
</ul>
<h2 id="pipeline-setup-amp-error"><a href="#pipeline-setup-amp-error" class="headerlink" title="pipeline setup &amp; error"></a>pipeline setup &amp; error</h2><h3 id="pipeline-setup"><a href="#pipeline-setup" class="headerlink" title="pipeline setup"></a>pipeline setup</h3><p>HDFS写数据时是先将数据写入本地buf中，buf写满之后写入packet中，packet写满之后放入dataQueue，通知DataStreamer去消费，此时DataStreamer发现pipeline的状态是<em>PIPELINE_SETUP_CREATE</em>，则开始创建pipeline。创建pipeline时会向NN申请addBlock，NN会返回block的locations信息，然后根据locations信息创建pipeline。</p>
<p>pipeline的长度默认是3(副本因子个数)，在client端通过<code>createBlockOutputStream</code>与pipeline中的第一个dn建立连接<em>并等待dn发送回来的connect-ack</em>。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">createBlockOutputStream</span><span class="params">(DatanodeInfo[] nodes,</span></span></span><br><span class="line"><span class="function"><span class="params">    StorageType[] nodeStorageTypes, <span class="keyword">long</span> newGS, <span class="keyword">boolean</span> recoveryFlag)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">boolean</span> result = <span class="keyword">false</span>;</span><br><span class="line">    DataOutputStream out = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 与第一个dn建立http连接</span></span><br><span class="line">      s = createSocketForPipeline(nodes[<span class="number">0</span>], nodes.length, dfsClient);</span><br><span class="line">      <span class="keyword">long</span> writeTimeout = dfsClient.getDatanodeWriteTimeout(nodes.length);</span><br><span class="line">      <span class="comment">// 向下游发送请求</span></span><br><span class="line">      OutputStream unbufOut = NetUtils.getOutputStream(s, writeTimeout);</span><br><span class="line">      <span class="comment">// 接收下游返回的ack</span></span><br><span class="line">      InputStream unbufIn = NetUtils.getInputStream(s);</span><br><span class="line">      IOStreamPair saslStreams = dfsClient.saslClient.socketSend(s,</span><br><span class="line">        unbufOut, unbufIn, dfsClient, accessToken, nodes[<span class="number">0</span>]);</span><br><span class="line">      unbufOut = saslStreams.out;</span><br><span class="line">      unbufIn = saslStreams.in;</span><br><span class="line">      out = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(unbufOut,</span><br><span class="line">          HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">      </span><br><span class="line">      blockReplyStream = <span class="keyword">new</span> DataInputStream(unbufIn);</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// 向dn发送写请求，也可以理解为connect请求</span></span><br><span class="line">      <span class="comment">// 由dn上的DataXceiverServer接收，new一个DataXceiver去响应</span></span><br><span class="line">      <span class="keyword">new</span> Sender(out).writeBlock(blockCopy, nodeStorageTypes[<span class="number">0</span>], accessToken,</span><br><span class="line">          dfsClient.clientName, nodes, nodeStorageTypes, <span class="keyword">null</span>, bcs, </span><br><span class="line">          nodes.length, block.getNumBytes(), bytesSent, newGS,</span><br><span class="line">          checksum4WriteBlock, cachingStrategy.get(), isLazyPersistFile);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// receive ack for connect</span></span><br><span class="line">      <span class="comment">// 向下游发送写请求之后，等待下游返回的connect-ack</span></span><br><span class="line">      <span class="comment">// 接收到connect-ack之后才会向pipeline中send packet</span></span><br><span class="line">      BlockOpResponseProto resp = BlockOpResponseProto.parseFrom(</span><br><span class="line">          PBHelper.vintPrefixed(blockReplyStream));</span><br><span class="line">      pipelineStatus = resp.getStatus();</span><br><span class="line">      firstBadLink = resp.getFirstBadLink();</span><br><span class="line">      <span class="comment">// OOB是out of band的缩写，带外数据</span></span><br><span class="line">      <span class="comment">// Got an restart OOB ack.</span></span><br><span class="line">      <span class="comment">// If a node is already restarting, this status is not likely from</span></span><br><span class="line">      <span class="comment">// the same node. If it is from a different node, it is not</span></span><br><span class="line">      <span class="comment">// from the local datanode. Thus it is safe to treat this as a</span></span><br><span class="line">      <span class="comment">// regular node error.</span></span><br><span class="line">      <span class="keyword">if</span> (PipelineAck.isRestartOOBStatus(pipelineStatus) &amp;&amp;</span><br><span class="line">        restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        checkRestart = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"A datanode is restarting."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// pipeline setup没有成功，抛出异常在catch中处理</span></span><br><span class="line">      <span class="keyword">if</span> (pipelineStatus != SUCCESS) &#123;</span><br><span class="line">        <span class="keyword">if</span> (pipelineStatus == Status.ERROR_ACCESS_TOKEN) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> InvalidBlockTokenException(</span><br><span class="line">              <span class="string">"Got access token error for connect ack with firstBadLink as "</span></span><br><span class="line">                  + firstBadLink);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad connect ack with firstBadLink as "</span></span><br><span class="line">              + firstBadLink);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">null</span> == blockStream : <span class="string">"Previous blockStream unclosed"</span>;</span><br><span class="line">      blockStream = out;</span><br><span class="line">      result =  <span class="keyword">true</span>; <span class="comment">// success</span></span><br><span class="line">      restartingNodeIndex = -<span class="number">1</span>;</span><br><span class="line">      hasError = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Exception in createBlockOutputStream"</span>, ie);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (ie <span class="keyword">instanceof</span> InvalidEncryptionKeyException &amp;&amp; refetchEncryptionKey &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Will fetch a new encryption key and retry, "</span> </span><br><span class="line">            + <span class="string">"encryption key was invalid when connecting to "</span></span><br><span class="line">            + nodes[<span class="number">0</span>] + <span class="string">" : "</span> + ie);</span><br><span class="line">        <span class="comment">// The encryption key used is invalid.</span></span><br><span class="line">        refetchEncryptionKey--;</span><br><span class="line">        dfsClient.clearDataEncryptionKey();</span><br><span class="line">        <span class="comment">// Don't close the socket/exclude this node just yet. Try again with</span></span><br><span class="line">        <span class="comment">// a new encryption key.</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// find the datanode that matches</span></span><br><span class="line">      <span class="keyword">if</span> (firstBadLink.length() != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nodes.length; i++) &#123;</span><br><span class="line">          <span class="comment">// NB: Unconditionally using the xfer addr w/o hostname</span></span><br><span class="line">          <span class="keyword">if</span> (firstBadLink.equals(nodes[i].getXferAddr())) &#123;</span><br><span class="line">            errorIndex = i;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">assert</span> checkRestart == <span class="keyword">false</span>;</span><br><span class="line">        errorIndex = <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Check whether there is a restart worth waiting for.</span></span><br><span class="line">      <span class="keyword">if</span> (checkRestart &amp;&amp; shouldWaitForRestart(errorIndex)) &#123;</span><br><span class="line">        restartDeadline = dfsClient.getConf().datanodeRestartTimeout +</span><br><span class="line">            Time.now();</span><br><span class="line">        restartingNodeIndex = errorIndex;</span><br><span class="line">        errorIndex = -<span class="number">1</span>;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Waiting for the datanode to be restarted: "</span> +</span><br><span class="line">            nodes[restartingNodeIndex]);</span><br><span class="line">      &#125;</span><br><span class="line">      hasError = <span class="keyword">true</span>;</span><br><span class="line">      setLastException(ie);</span><br><span class="line">      result =  <span class="keyword">false</span>;  <span class="comment">// error</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">        IOUtils.closeSocket(s);</span><br><span class="line">        s = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(out);</span><br><span class="line">        out = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(blockReplyStream);</span><br><span class="line">        blockReplyStream = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在pipeline setup阶段client先向pipeline中的第一个dn发送连接请求，然后等待pipeline中dn发送回的conncet-ack，<em>由于client发送连接请求和接收dn返回的connect-ack是同步的，所以不需要像接收packet ack那样单独new一个Responder</em>。<strong>client发送连接请求之后会一直等待最后一个dn的connect-ack返回到client之后才会继续执行，去校验connect是否成功</strong>。</p>
<p>client与pipeline中的第一个dn建立连接之后，下面来看下pipeline中剩下的dn是如何建立连接的。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataXceiver.writeBlock</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeBlock</span><span class="params">(<span class="keyword">final</span> ExtendedBlock block,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType storageType, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> Token&lt;BlockTokenIdentifier&gt; blockToken,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> String clientname,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo[] targets,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType[] targetStorageTypes, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo srcDataNode,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> BlockConstructionStage stage,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">int</span> pipelineSize,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> minBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> maxBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> latestGenerationStamp,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum requestedChecksum,</span></span></span><br><span class="line"><span class="function"><span class="params">    CachingStrategy cachingStrategy,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">boolean</span> allowLazyPersist)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// reply to upstream datanode or client </span></span><br><span class="line">  <span class="keyword">final</span> DataOutputStream replyOut = <span class="keyword">new</span> DataOutputStream(</span><br><span class="line">      <span class="keyword">new</span> BufferedOutputStream(</span><br><span class="line">          getOutputStream(),</span><br><span class="line">          HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">  checkAccess(replyOut, isClient, block, blockToken,</span><br><span class="line">      Op.WRITE_BLOCK, BlockTokenSecretManager.AccessMode.WRITE);</span><br><span class="line"></span><br><span class="line">  DataOutputStream mirrorOut = <span class="keyword">null</span>;  <span class="comment">// stream to next target</span></span><br><span class="line">  DataInputStream mirrorIn = <span class="keyword">null</span>;    <span class="comment">// reply from next target</span></span><br><span class="line">  Socket mirrorSock = <span class="keyword">null</span>;           <span class="comment">// socket to next target</span></span><br><span class="line">  String mirrorNode = <span class="keyword">null</span>;           <span class="comment">// the name:port of next target</span></span><br><span class="line">  String firstBadLink = <span class="string">""</span>;           <span class="comment">// first datanode that failed in connection setup</span></span><br><span class="line">  Status mirrorInStatus = SUCCESS;</span><br><span class="line">  <span class="keyword">final</span> String storageUuid;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (isDatanode || </span><br><span class="line">        stage != BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) &#123;</span><br><span class="line">      <span class="comment">// open a block receiver</span></span><br><span class="line">      blockReceiver = <span class="keyword">new</span> BlockReceiver(block, storageType, in,</span><br><span class="line">          peer.getRemoteAddressString(),</span><br><span class="line">          peer.getLocalAddressString(),</span><br><span class="line">          stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,</span><br><span class="line">          clientname, srcDataNode, datanode, requestedChecksum,</span><br><span class="line">          cachingStrategy, allowLazyPersist);</span><br><span class="line"></span><br><span class="line">      storageUuid = blockReceiver.getStorageUuid();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      storageUuid = datanode.data.recoverClose(</span><br><span class="line">          block, latestGenerationStamp, minBytesRcvd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 与下游dn建立连接</span></span><br><span class="line">    <span class="keyword">if</span> (targets.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      InetSocketAddress mirrorTarget = <span class="keyword">null</span>;</span><br><span class="line">      <span class="comment">// Connect to backup machine</span></span><br><span class="line">      mirrorNode = targets[<span class="number">0</span>].getXferAddr(connectToDnViaHostname);</span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(<span class="string">"Connecting to datanode "</span> + mirrorNode);</span><br><span class="line">      &#125;</span><br><span class="line">      mirrorTarget = NetUtils.createSocketAddr(mirrorNode);</span><br><span class="line">      mirrorSock = datanode.newSocket();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> timeoutValue = dnConf.socketTimeout</span><br><span class="line">            + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);</span><br><span class="line">        <span class="keyword">int</span> writeTimeout = dnConf.socketWriteTimeout + </span><br><span class="line">                    (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);</span><br><span class="line">        NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);</span><br><span class="line">        mirrorSock.setSoTimeout(timeoutValue);</span><br><span class="line">        mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);</span><br><span class="line">        </span><br><span class="line">        OutputStream unbufMirrorOut = NetUtils.getOutputStream(mirrorSock,</span><br><span class="line">            writeTimeout);</span><br><span class="line">        InputStream unbufMirrorIn = NetUtils.getInputStream(mirrorSock);</span><br><span class="line">        DataEncryptionKeyFactory keyFactory =</span><br><span class="line">          datanode.getDataEncryptionKeyFactoryForBlock(block);</span><br><span class="line">        IOStreamPair saslStreams = datanode.saslClient.socketSend(mirrorSock,</span><br><span class="line">          unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[<span class="number">0</span>]);</span><br><span class="line">        unbufMirrorOut = saslStreams.out;</span><br><span class="line">        unbufMirrorIn = saslStreams.in;</span><br><span class="line">        mirrorOut = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(unbufMirrorOut,</span><br><span class="line">            HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">        mirrorIn = <span class="keyword">new</span> DataInputStream(unbufMirrorIn);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Do not propagate allowLazyPersist to downstream DataNodes.</span></span><br><span class="line">        <span class="keyword">new</span> Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[<span class="number">0</span>],</span><br><span class="line">            blockToken, clientname, targets, targetStorageTypes, srcDataNode,</span><br><span class="line">            stage, pipelineSize, minBytesRcvd, maxBytesRcvd,</span><br><span class="line">            latestGenerationStamp, requestedChecksum, cachingStrategy, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        mirrorOut.flush();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// read connect ack (only for clients, not for replication req)</span></span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          <span class="comment">// 从mirrorIn中读取下游返回的connect-ack</span></span><br><span class="line">          BlockOpResponseProto connectAck =</span><br><span class="line">            BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));</span><br><span class="line">          mirrorInStatus = connectAck.getStatus();</span><br><span class="line">          firstBadLink = connectAck.getFirstBadLink();</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled() || mirrorInStatus != SUCCESS) &#123;</span><br><span class="line">            LOG.info(<span class="string">"Datanode "</span> + targets.length +</span><br><span class="line">                     <span class="string">" got response for connect ack "</span> +</span><br><span class="line">                     <span class="string">" from downstream datanode with firstbadlink as "</span> +</span><br><span class="line">                     firstBadLink);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          BlockOpResponseProto.newBuilder()</span><br><span class="line">            .setStatus(ERROR)</span><br><span class="line">             <span class="comment">// NB: Unconditionally using the xfer addr w/o hostname</span></span><br><span class="line">            .setFirstBadLink(targets[<span class="number">0</span>].getXferAddr())</span><br><span class="line">            .build()</span><br><span class="line">            .writeDelimitedTo(replyOut);</span><br><span class="line">          replyOut.flush();</span><br><span class="line">        &#125;</span><br><span class="line">        IOUtils.closeStream(mirrorOut);</span><br><span class="line">        mirrorOut = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(mirrorIn);</span><br><span class="line">        mirrorIn = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeSocket(mirrorSock);</span><br><span class="line">        mirrorSock = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          LOG.error(datanode + <span class="string">":Exception transfering block "</span> +</span><br><span class="line">                    block + <span class="string">" to mirror "</span> + mirrorNode + <span class="string">": "</span> + e);</span><br><span class="line">          <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          LOG.info(datanode + <span class="string">":Exception transfering "</span> +</span><br><span class="line">                   block + <span class="string">" to mirror "</span> + mirrorNode +</span><br><span class="line">                   <span class="string">"- continuing without the mirror"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// send connect-ack to source for clients and not transfer-RBW/Finalized</span></span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; !isTransfer) &#123;</span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled() || mirrorInStatus != SUCCESS) &#123;</span><br><span class="line">        LOG.info(<span class="string">"Datanode "</span> + targets.length +</span><br><span class="line">                 <span class="string">" forwarding connect ack to upstream firstbadlink is "</span> +</span><br><span class="line">                 firstBadLink);</span><br><span class="line">      &#125;</span><br><span class="line">      BlockOpResponseProto.newBuilder()</span><br><span class="line">        .setStatus(mirrorInStatus)</span><br><span class="line">        .setFirstBadLink(firstBadLink)</span><br><span class="line">        .build()</span><br><span class="line">        .writeDelimitedTo(replyOut);</span><br><span class="line">      replyOut.flush();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// receive the block and mirror to the next target</span></span><br><span class="line">    <span class="keyword">if</span> (blockReceiver != <span class="keyword">null</span>) &#123;</span><br><span class="line">      String mirrorAddr = (mirrorSock == <span class="keyword">null</span>) ? <span class="keyword">null</span> : mirrorNode;</span><br><span class="line">      blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,</span><br><span class="line">          mirrorAddr, <span class="keyword">null</span>, targets, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// send close-ack for transfer-RBW/Finalized </span></span><br><span class="line">      <span class="keyword">if</span> (isTransfer) &#123;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">          LOG.trace(<span class="string">"TRANSFER: send close-ack"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        writeResponse(SUCCESS, <span class="keyword">null</span>, replyOut);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...    </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">    LOG.info(<span class="string">"opWriteBlock "</span> + block + <span class="string">" received exception "</span> + ioe);</span><br><span class="line">    <span class="keyword">throw</span> ioe;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// close all opened streams</span></span><br><span class="line">    IOUtils.closeStream(mirrorOut);</span><br><span class="line">    IOUtils.closeStream(mirrorIn);</span><br><span class="line">    IOUtils.closeStream(replyOut);</span><br><span class="line">    IOUtils.closeSocket(mirrorSock);</span><br><span class="line">    IOUtils.closeStream(blockReceiver);</span><br><span class="line">    blockReceiver = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>dn上响应上游或者client连接请求的是DataXceiver线程</em>。如果有下游dn，则DataXceiver与下游dn建立连接，发送写请求，并等待下游返回的connect-ack，接收到下游的返回的connect-ack之后将connect-ack继续返回给上游，之后开始调用<code>blockReceiver.receiveBlock</code>来接收pipeline中的packet。</p>
<p><em>当client接收到pipeline逐层返回的connect-ack之后，pipeline就创建成功了</em>。不过细心的小伙伴们可能会发现在DataXceiver中与下游dn建立连接时<em>都是从target中取出的第一个元素进行连接</em>(<code>mirrorNode = targets[0].getXferAddr(connectToDnViaHostname);</code>)，那么target中的元素是怎么减少的呢？target是通过Sender发送给下游dn的，查看Sender.writeBlock参数中target的值并没有变化，但是下游dn接收到的target却发生了变化，则target的值一定是在writeBlock中改变的，查看代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Sender.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeBlock</span><span class="params">(<span class="keyword">final</span> ExtendedBlock blk,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType storageType, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> Token&lt;BlockTokenIdentifier&gt; blockToken,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> String clientName,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo[] targets,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType[] targetStorageTypes, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo source,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> BlockConstructionStage stage,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">int</span> pipelineSize,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> minBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> maxBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> latestGenerationStamp,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum requestedChecksum,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> CachingStrategy cachingStrategy,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">boolean</span> allowLazyPersist)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  OpWriteBlockProto.Builder proto = OpWriteBlockProto.newBuilder()</span><br><span class="line">    .setHeader(header)</span><br><span class="line">    .setStorageType(PBHelper.convertStorageType(storageType))</span><br><span class="line">    <span class="comment">// PBHelper.convert 将target中的元素从索引1处开始</span></span><br><span class="line">    .addAllTargets(PBHelper.convert(targets, <span class="number">1</span>))</span><br><span class="line">    .addAllTargetStorageTypes(PBHelper.convertStorageTypes(targetStorageTypes, <span class="number">1</span>))</span><br><span class="line">    .setStage(toProto(stage))</span><br><span class="line">    .setPipelineSize(pipelineSize)</span><br><span class="line">    .setMinBytesRcvd(minBytesRcvd)</span><br><span class="line">    .setMaxBytesRcvd(maxBytesRcvd)</span><br><span class="line">    .setLatestGenerationStamp(latestGenerationStamp)</span><br><span class="line">    .setRequestedChecksum(checksumProto)</span><br><span class="line">    .setCachingStrategy(getCachingStrategy(cachingStrategy))</span><br><span class="line">    .setAllowLazyPersist(allowLazyPersist);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面看下在pipeline setup过程中出现故障怎么办？</p>
<h3 id="errors-in-pipeline-setup"><a href="#errors-in-pipeline-setup" class="headerlink" title="errors in pipeline setup"></a>errors in pipeline setup</h3><p><strong>client端</strong>可能在与dn建立socket连接时(<code>createSocketForPipeline</code>)和接收dn返回的connect-ack时(<code>BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(blockReplyStream))</code>)发生IOException error。<br>调用<code>createSocketForPipeline</code>与dn建立socket连接时，可能会抛出IOException异常；在接收dn返回的connect-ack时，根据返回的状态<code>pipelineStatus</code>是否为SUCCESS，不是SUCCESS则根据pipelineStatus的状态抛出不同的异常。这些异常在catch中捕获，处理逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  <span class="comment">// 与dn建立连接，失败抛出异常IOException</span></span><br><span class="line">  s = createSocketForPipeline(nodes[<span class="number">0</span>], nodes.length, dfsClient);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// receive ack for connect</span></span><br><span class="line">  <span class="comment">// 接收dn返回的connect-ack</span></span><br><span class="line">  BlockOpResponseProto resp = BlockOpResponseProto.parseFrom(</span><br><span class="line">      PBHelper.vintPrefixed(blockReplyStream));</span><br><span class="line">  <span class="comment">// 记录从connect的状态</span></span><br><span class="line">  pipelineStatus = resp.getStatus();</span><br><span class="line">  <span class="comment">// 记录发生故障dn的索引</span></span><br><span class="line">  firstBadLink = resp.getFirstBadLink();</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// pipelineStatus状态不为SUCCESS，抛出异常</span></span><br><span class="line">  <span class="keyword">if</span> (pipelineStatus != SUCCESS) &#123;</span><br><span class="line">    <span class="keyword">if</span> (pipelineStatus == Status.ERROR_ACCESS_TOKEN) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> InvalidBlockTokenException(</span><br><span class="line">          <span class="string">"Got access token error for connect ack with firstBadLink as "</span></span><br><span class="line">              + firstBadLink);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad connect ack with firstBadLink as "</span></span><br><span class="line">          + firstBadLink);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">  <span class="comment">// createBlockOutputStream中发生故障</span></span><br><span class="line">  <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">    DFSClient.LOG.info(<span class="string">"Exception in createBlockOutputStream"</span>, ie);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// find the datanode that matches</span></span><br><span class="line">  <span class="keyword">if</span> (firstBadLink.length() != <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nodes.length; i++) &#123;</span><br><span class="line">      <span class="comment">// NB: Unconditionally using the xfer addr w/o hostname</span></span><br><span class="line">      <span class="keyword">if</span> (firstBadLink.equals(nodes[i].getXferAddr())) &#123;</span><br><span class="line">      	<span class="comment">// errorIndex在DataStreamer中标识处理error，processDatanodeError进行处理</span></span><br><span class="line">        errorIndex = i;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  	<span class="comment">// firstBadLink.length()为0，则可能是在createBlockOutputStream时发生error</span></span><br><span class="line">    <span class="keyword">assert</span> checkRestart == <span class="keyword">false</span>;</span><br><span class="line">    errorIndex = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Check whether there is a restart worth waiting for.</span></span><br><span class="line">  <span class="keyword">if</span> (checkRestart &amp;&amp; shouldWaitForRestart(errorIndex)) &#123;</span><br><span class="line">    restartDeadline = dfsClient.getConf().datanodeRestartTimeout +</span><br><span class="line">        Time.now();</span><br><span class="line">    restartingNodeIndex = errorIndex;</span><br><span class="line">    errorIndex = -<span class="number">1</span>;</span><br><span class="line">    DFSClient.LOG.info(<span class="string">"Waiting for the datanode to be restarted: "</span> +</span><br><span class="line">        nodes[restartingNodeIndex]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// hasError在DataStreamer中标识处理error，processDatanodeError进行处理</span></span><br><span class="line">  hasError = <span class="keyword">true</span>;</span><br><span class="line">  setLastException(ie);</span><br><span class="line">  result =  <span class="keyword">false</span>;  <span class="comment">// error</span></span><br><span class="line">&#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  <span class="comment">// 发生error时，result在catch中设为false</span></span><br><span class="line">  <span class="comment">// 发生error，关闭与dn的连接</span></span><br><span class="line">  <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">    IOUtils.closeSocket(s);</span><br><span class="line">    s = <span class="keyword">null</span>;</span><br><span class="line">    IOUtils.closeStream(out);</span><br><span class="line">    out = <span class="keyword">null</span>;</span><br><span class="line">    IOUtils.closeStream(blockReplyStream);</span><br><span class="line">    blockReplyStream = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果在<code>createSocketForPipeline</code>中发生error，直接被catch捕获，<em>firstBadLink为初始值(因为没有接受dn返回的connect-ack)，errorIndex赋值为0，hasError赋值为true；</em><br>如果在接收connect-ack之后，<em>检查pipelineStatus的值为非SUCCESS，抛出异常被catch捕获，找到firstBadLink对应的dn，对errorIndex赋值，hasError赋值为true；</em></p>
<p><em>对errorIndex和hasError赋值之后，在finally中根据result的值关闭网络连接</em>。</p>
<p>errorIndex&gt;=0和hasError==true时，在DataStreamer.run中调用<em>processDatanodeError</em>对error进行处理。</p>
<p><strong>dn端</strong>的处理逻辑的入口在<em>DataXceiver.writeBlock</em>中，writeBlock会判断targets.length是否大于0，大于0则表示有下游dn，则与下游dn建立连接，建立连接时可能会发生error抛出IOException，被catch捕获，设置ack的状态为ERROR返回给上游并关闭相关网络连接。需要注意的是当前dn接收到下游dn的connect-ack时并不会判断ack中的状态，而是直接返回给上游或者client。</p>
<p>在targets.length大于0的代码段的catch中有段代码需要注意下：(<em>具体逻辑随后再屡？？？？？</em>)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">  LOG.error(datanode + <span class="string">":Exception transfering block "</span> +</span><br><span class="line">            block + <span class="string">" to mirror "</span> + mirrorNode + <span class="string">": "</span> + e);</span><br><span class="line">  <span class="comment">// catch中又抛出异常，被外层的catch捕获</span></span><br><span class="line">  <span class="keyword">throw</span> e;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="comment">// 何时选择忽略error？？？？</span></span><br><span class="line">  LOG.info(datanode + <span class="string">":Exception transfering "</span> +</span><br><span class="line">           block + <span class="string">" to mirror "</span> + mirrorNode +</span><br><span class="line">           <span class="string">"- continuing without the mirror"</span>, e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>pipeline setup中与某个dn连接发生error之后，就立即返回ERROR状态并关闭连接，通过逐层返回给client之后，又client处理，进行重新setup。</em></p>
<h3 id="pipeline-setup发生error之后的修复"><a href="#pipeline-setup发生error之后的修复" class="headerlink" title="pipeline setup发生error之后的修复"></a>pipeline setup发生error之后的修复</h3><p>errorIndex和hasError在createBlockOutputStream中被赋值，errorIndex等于0表示是client与第一个dn建立连接时发生故障，则再次进入while循环依然尝试与第一个dn建立连接。errorIndex不等0而等于pipeline中dn的索引时，则跳出while，<em>返回到<code>nextBlockOutputStream</code>中，根据createBlockOutputStream的结果和重试的次数判断是否进入while中，进行再次pipeline setup，此时会像NN重新申请block</em>。</p>
<p>这也就是之前文章中介绍的pipeline setup recovery的策略(这里只是create new block时setup error的恢复策略):<br><em>如果新建一个pipeline是为了创建一个新block，则client只是放弃这个block，重新向NN申请一个新的block。然后为这个新的block建立pipeline</em></p>
<h2 id="pipeline-streaming-amp-error"><a href="#pipeline-streaming-amp-error" class="headerlink" title="pipeline streaming &amp; error"></a>pipeline streaming &amp; error</h2><h3 id="pipeline-data-streaming"><a href="#pipeline-data-streaming" class="headerlink" title="pipeline data streaming"></a>pipeline data streaming</h3><p>pipeline setup成功之后，<strong>client端</strong>在DataStreamer.run中，通过<code>initDataStreaming</code>，设置<em>BlockConstructionStage的状态为DATA_STREAMING</em>并<em>启动一个ResponseProcessor线程接收下游dn返回的packet ack</em>。</p>
<p>ResponseProcessor线程启动之后，将packet开始向pipeline中发送，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">  one.writeTo(blockStream);</span><br><span class="line">  blockStream.flush();   </span><br><span class="line">&#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">  <span class="comment">// HDFS-3398 treat primary DN is down since client is unable to </span></span><br><span class="line">  <span class="comment">// write to primary DN. If a failed or restarting node has already</span></span><br><span class="line">  <span class="comment">// been recorded by the responder, the following call will have no </span></span><br><span class="line">  <span class="comment">// effect. Pipeline recovery can handle only one node error at a</span></span><br><span class="line">  <span class="comment">// time. If the primary node fails again during the recovery, it</span></span><br><span class="line">  <span class="comment">// will be taken out then.</span></span><br><span class="line">  tryMarkPrimaryDatanodeFailed();</span><br><span class="line">  <span class="keyword">throw</span> e;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>client端的DataStreamer发送packet到pipeline中，pipeline中的第一个dn开始接收packet，代码依然是在DataXceiver.writeBlock中，(<em>此时pipeline已经建立成功，也就是dn已经将connect-ack返回给client，则开始接收pipeline中的packet</em>)。dn通过<code>blockReceiver.receiveBlock</code>接收packet，<em>在接收packet时可能会发生error，抛出IOException，在finally中关闭连接</em>。receiveBlock的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">receiveBlock</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    DataOutputStream mirrOut, // output to next datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    DataInputStream mirrIn,   // input from next datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    DataOutputStream replyOut,  // output to previous datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    String mirrAddr, DataTransferThrottler throttlerArg,</span></span></span><br><span class="line"><span class="function"><span class="params">    DatanodeInfo[] downstreams,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isReplaceBlock)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; !isTransfer) &#123;</span><br><span class="line">      <span class="comment">// 启动一个PacketResponder守护线程</span></span><br><span class="line">      responder = <span class="keyword">new</span> Daemon(datanode.threadGroup, </span><br><span class="line">          <span class="keyword">new</span> PacketResponder(replyOut, mirrIn, downstreams));</span><br><span class="line">      responder.start(); <span class="comment">// start thread to processes responses</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 循环从socket中接收packet</span></span><br><span class="line">    <span class="keyword">while</span> (receivePacket() &gt;= <span class="number">0</span>) &#123; <span class="comment">/* Receive until the last packet */</span> &#125;</span><br><span class="line">    <span class="comment">// 该block的packet接收完毕之后，将PacketResponder线程关闭</span></span><br><span class="line">    <span class="comment">// wait for all outstanding packet responses. And then</span></span><br><span class="line">    <span class="comment">// indicate responder to gracefully shutdown.</span></span><br><span class="line">    <span class="comment">// Mark that responder has been closed for future processing</span></span><br><span class="line">    <span class="keyword">if</span> (responder != <span class="keyword">null</span>) &#123;</span><br><span class="line">      ((PacketResponder)responder.getRunnable()).close();</span><br><span class="line">      responderClosed = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">    <span class="keyword">if</span> (datanode.isRestarting()) &#123;</span><br><span class="line">      <span class="comment">// Do not throw if shutting down for restart. Otherwise, it will cause</span></span><br><span class="line">      <span class="comment">// premature termination of responder.</span></span><br><span class="line">      LOG.info(<span class="string">"Shutting down for restart ("</span> + block + <span class="string">")."</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      LOG.info(<span class="string">"Exception for "</span> + block, ioe);</span><br><span class="line">      <span class="keyword">throw</span> ioe;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">  ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在DataXceiver.writeBlock中会先根据stage创建不同状态Replica的BlockReceiver，然后调用blockReceiver.receiveBlock来接收socket中的packet。</p>
<p>client端会单独起一个ResponseProcessor线程来接收packet ack，那么dn也会新起一个PacketResponder的守护线程来接收下游的返回的ack和向上游发送ack。(<em>需要注意的是client端和dn端中用来存储packet的数据结构有所不同，client端是先将packet放入dataQueue，然后放入ackQueue，而dn端只有ackQueue，没有dataQueue，因为pipeline中dn的内存中只有一个packet，向下游发送之后将内存中的packet放入ackQueue中。</em>)</p>
<p>dn端是以packet为单位接收数据的，<code>packetReceiver.receiveNextPacket(in)</code>从socket接收packet到dn的内存中，然后放入ackQueue中，向下游发送<code>packetReceiver.mirrorPacketTo(mirrorOut)</code>，发送完之后将内存中的数据写入disk。</p>
<p>上面介绍了packet从client发送到pipeline中，并在pipeline中的传送，下面介绍下在pipeline Streaming发生error的情况</p>
<h3 id="errors-in-pipeline-streaming"><a href="#errors-in-pipeline-streaming" class="headerlink" title="errors in pipeline streaming"></a>errors in pipeline streaming</h3><p>pipeline stream中可以再细分为3个阶段，分别为1.a接收socket中的packet到内存，1.b将内存中的packet发送到下游的socket中，2将内存中的packet写入磁盘，3.a接收下游返回的ack，3.b向上游发送ack。这几个阶段都有可能发生error。</p>
<p>1.a接收socket中的packet的内存时(<code>packetReceiver.receiveNextPacket(in)</code>)会抛出异常IOException，在writeBlock中被捕获，finally执行关闭连接。</p>
<p>1.b将内存中的packet写入下游socket时(<code>packetReceiver.mirrorPacketTo(mirrorOut)</code>)会抛出异常IOException，被catch捕获，调用<code>handleMirrorOutError</code>，handleMirrorOutError代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * While writing to mirrorOut, failure to write to mirror should not</span></span><br><span class="line"><span class="comment"> * affect this datanode unless it is caused by interruption.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">handleMirrorOutError</span><span class="params">(IOException ioe)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  String bpid = block.getBlockPoolId();</span><br><span class="line">  LOG.info(datanode.getDNRegistrationForBP(bpid)</span><br><span class="line">      + <span class="string">":Exception writing "</span> + block + <span class="string">" to mirror "</span> + mirrorAddr, ioe);</span><br><span class="line">  <span class="keyword">if</span> (Thread.interrupted()) &#123; <span class="comment">// shut down if the thread is interrupted</span></span><br><span class="line">    <span class="keyword">throw</span> ioe;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123; <span class="comment">// encounter an error while writing to mirror</span></span><br><span class="line">    <span class="comment">// continue to run even if can not write to mirror</span></span><br><span class="line">    <span class="comment">// notify client of the error</span></span><br><span class="line">    <span class="comment">// and wait for the client to shut down the pipeline</span></span><br><span class="line">    mirrorError = <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>无论1.b是否发生error，始终都会将内存中的packet写入磁盘，也就是肯定会执行2。2中写入磁盘的数据主要是chunksum数据和data数据，那么这两步都可能会发生error。</p>
<p>在校验chunksum时(<code>verifyChunks(dataBuf, checksumBuf)</code>)抛出异常被捕获，可能会将packet的状态设置为<em>Status.ERROR_CHECKSUM</em>然后放入ackQueue中(<strong>在将packet向下游socket中发送之前已经将该packet放入ackQueue中，此时又放进去？会不会重？为什么？？？</strong>)，并再抛出IOException异常在writeBlock中捕获，finally执行关闭连接。</p>
<p>将data写入disk时会抛出IOException，在writeBlock中捕获，finally执行关闭连接。</p>
<p>3.a和3.b是在另一个线程中执行的，3.a接收下游的ack时可能会抛出IOException异常，被捕获并对mirrorError赋值为true。3.b向上游或者client发送ack时也可能抛出IOException异常。下面看下PacketResponder.run代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> lastPacketInBlock = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> startTime = ClientTraceLog.isInfoEnabled() ? System.nanoTime() : <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (isRunning() &amp;&amp; !lastPacketInBlock) &#123;</span><br><span class="line">    <span class="keyword">long</span> totalAckTimeNanos = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">boolean</span> isInterrupted = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Packet pkt = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">long</span> expected = -<span class="number">2</span>;</span><br><span class="line">      <span class="comment">// new 一个null的ack</span></span><br><span class="line">      PipelineAck ack = <span class="keyword">new</span> PipelineAck();</span><br><span class="line">      <span class="keyword">long</span> seqno = PipelineAck.UNKOWN_SEQNO;</span><br><span class="line">      <span class="keyword">long</span> ackRecvNanoTime = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">      	<span class="comment">// 向下游发送packet发生error或者接收下游返回的ack时发生error，</span></span><br><span class="line">      	<span class="comment">// 都有可能将mirrorError置为true，导致不进if也就是不接受下游的ack</span></span><br><span class="line">        <span class="keyword">if</span> (type != PacketResponderType.LAST_IN_PIPELINE &amp;&amp; !mirrorError) &#123;</span><br><span class="line">          <span class="comment">// read an ack from downstream datanode</span></span><br><span class="line">          ack.readFields(downstreamIn);</span><br><span class="line">          ackRecvNanoTime = System.nanoTime();</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">            LOG.debug(myString + <span class="string">" got "</span> + ack);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// Process an OOB ACK.</span></span><br><span class="line">          ...</span><br><span class="line">          seqno = ack.getSeqno();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (seqno != PipelineAck.UNKOWN_SEQNO</span><br><span class="line">            || type == PacketResponderType.LAST_IN_PIPELINE) &#123;</span><br><span class="line">          <span class="comment">// 从ackQueue中取出一个packet</span></span><br><span class="line">          pkt = waitForAckHead(seqno);</span><br><span class="line">          <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          expected = pkt.seqno;</span><br><span class="line">          <span class="keyword">if</span> (type == PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE</span><br><span class="line">              &amp;&amp; seqno != expected) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(myString + <span class="string">"seqno: expected="</span> + expected</span><br><span class="line">                + <span class="string">", received="</span> + seqno);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">if</span> (type == PacketResponderType.HAS_DOWNSTREAM_IN_PIPELINE) &#123;</span><br><span class="line">            <span class="comment">// The total ack time includes the ack times of downstream</span></span><br><span class="line">            <span class="comment">// nodes.</span></span><br><span class="line">            <span class="comment">// The value is 0 if this responder doesn't have a downstream</span></span><br><span class="line">            <span class="comment">// DN in the pipeline.</span></span><br><span class="line">            totalAckTimeNanos = ackRecvNanoTime - pkt.ackEnqueueNanoTime;</span><br><span class="line">            <span class="comment">// Report the elapsed time from ack send to ack receive minus</span></span><br><span class="line">            <span class="comment">// the downstream ack time.</span></span><br><span class="line">            <span class="keyword">long</span> ackTimeNanos = totalAckTimeNanos</span><br><span class="line">                - ack.getDownstreamAckTimeNanos();</span><br><span class="line">            <span class="keyword">if</span> (ackTimeNanos &lt; <span class="number">0</span>) &#123;</span><br><span class="line">              <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">                LOG.debug(<span class="string">"Calculated invalid ack time: "</span> + ackTimeNanos</span><br><span class="line">                    + <span class="string">"ns."</span>);</span><br><span class="line">              &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              datanode.metrics.addPacketAckRoundTripTimeNanos(ackTimeNanos);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          lastPacketInBlock = pkt.lastPacketInBlock;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ine) &#123;</span><br><span class="line">        isInterrupted = <span class="keyword">true</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">        <span class="keyword">if</span> (Thread.interrupted()) &#123;</span><br><span class="line">          isInterrupted = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// continue to run even if can not read from mirror</span></span><br><span class="line">          <span class="comment">// notify client of the error</span></span><br><span class="line">          <span class="comment">// and wait for the client to shut down the pipeline</span></span><br><span class="line">          mirrorError = <span class="keyword">true</span>;</span><br><span class="line">          LOG.info(myString, ioe);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (Thread.interrupted() || isInterrupted) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * The receiver thread cancelled this thread. We could also check</span></span><br><span class="line"><span class="comment">         * any other status updates from the receiver thread (e.g. if it is</span></span><br><span class="line"><span class="comment">         * ok to write to replyOut). It is prudent to not send any more</span></span><br><span class="line"><span class="comment">         * status back to the client because this datanode has a problem.</span></span><br><span class="line"><span class="comment">         * The upstream datanode will detect that this datanode is bad, and</span></span><br><span class="line"><span class="comment">         * rightly so.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * The receiver thread can also interrupt this thread for sending</span></span><br><span class="line"><span class="comment">         * an out-of-band response upstream.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        LOG.info(myString + <span class="string">": Thread is interrupted."</span>);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (lastPacketInBlock) &#123;</span><br><span class="line">        <span class="comment">// Finalize the block and close the block file</span></span><br><span class="line">        finalizeBlock(startTime);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 向上游发送ack，包括接收下游的ack和从自己的ack</span></span><br><span class="line">      sendAckUpstream(ack, expected, totalAckTimeNanos,</span><br><span class="line">          (pkt != <span class="keyword">null</span> ? pkt.offsetInBlock : <span class="number">0</span>), </span><br><span class="line">          (pkt != <span class="keyword">null</span> ? pkt.ackStatus : Status.SUCCESS));</span><br><span class="line">      <span class="keyword">if</span> (pkt != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// remove the packet from the ack queue</span></span><br><span class="line">        removeAckHead();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"IOException in BlockReceiver.run(): "</span>, e);</span><br><span class="line">      <span class="keyword">if</span> (running) &#123;</span><br><span class="line">        datanode.checkDiskErrorAsync();</span><br><span class="line">        LOG.info(myString, e);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (!Thread.interrupted()) &#123; <span class="comment">// failure not caused by interruption</span></span><br><span class="line">          receiverThread.interrupt();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (running) &#123;</span><br><span class="line">        LOG.info(myString, e);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        receiverThread.interrupt();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.info(myString + <span class="string">" terminating"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里还是有很多地方不清楚，记录下：</p>
<blockquote>
<p>这个过程是pipeline中重要的过程，但这里也有很多疑惑，记录下以后慢慢解决<br>data stream中发生的error的状态是怎么记录在ackQueue中，目前在代码中只发现当<code>verifyChunks</code>异常时，会将packet的状态变为ERROR_CHECKSUM放入ackQueue中，别的情况呢？？？又是怎么反馈给上游的？？？<br>向下游发送packet发生error时，mirrorError可能会被置为true，而此时PacketResponder将不接受下游的ack，那么只是将一个null的ack和Status.SUCCESS(sendAckUpstream(ack, expected, totalAckTimeNanos,(pkt != null ? pkt.offsetInBlock : 0), (pkt != null ? pkt.ackStatus : Status.SUCCESS)))发送给上游？？？？(不接受下游的ack则不能从ackQueue中取packet，但为什么要发送Status.SUCCESS)<br>当某个packet发生error，client并不是马上发现，而是等待这个packet的ack返回给client之后，client才能检测到该packet发生了error，进行处理。</p>
</blockquote>
<p>上面是dn端在pipeline stream中可能发生的error，下面介绍下client端在pipeline stream中发生的error</p>
<p>client端与pipeline stream相关的是ResponseProcessor线程和DataStreamer线程。先看下ResponseProcessor线程接收dn发来的ack，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  setName(<span class="string">"ResponseProcessor for block "</span> + block);</span><br><span class="line">  PipelineAck ack = <span class="keyword">new</span> PipelineAck();</span><br><span class="line">  <span class="keyword">while</span> (!responderClosed &amp;&amp; dfsClient.clientRunning &amp;&amp; !isLastPacketInBlock) &#123;</span><br><span class="line">    <span class="comment">// process responses from datanodes.</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// read an ack from the pipeline</span></span><br><span class="line">      <span class="keyword">long</span> begin = Time.monotonicNow();</span><br><span class="line">      ack.readFields(blockReplyStream);</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">long</span> seqno = ack.getSeqno();</span><br><span class="line">      <span class="comment">// processes response status from datanodes.</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = ack.getNumOfReplies()-<span class="number">1</span>; i &gt;=<span class="number">0</span>  &amp;&amp; dfsClient.clientRunning; i--) &#123;</span><br><span class="line">        <span class="keyword">final</span> Status reply = ack.getReply(i);</span><br><span class="line">        <span class="comment">// Restart will not be treated differently unless it is</span></span><br><span class="line">        <span class="comment">// the local node or the only one in the pipeline.</span></span><br><span class="line">        <span class="keyword">if</span> (PipelineAck.isRestartOOBStatus(reply) &amp;&amp;</span><br><span class="line">            shouldWaitForRestart(i)) &#123;</span><br><span class="line">          restartDeadline = dfsClient.getConf().datanodeRestartTimeout +</span><br><span class="line">              Time.now();</span><br><span class="line">          setRestartingNodeIndex(i);</span><br><span class="line">          String message = <span class="string">"A datanode is restarting: "</span> + targets[i];</span><br><span class="line">          DFSClient.LOG.info(message);</span><br><span class="line">         <span class="keyword">throw</span> <span class="keyword">new</span> IOException(message);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// node error</span></span><br><span class="line">        <span class="keyword">if</span> (reply != SUCCESS) &#123;</span><br><span class="line">          setErrorIndex(i); <span class="comment">// first bad datanode</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad response "</span> + reply +</span><br><span class="line">              <span class="string">" for block "</span> + block +</span><br><span class="line">              <span class="string">" from datanode "</span> + </span><br><span class="line">              targets[i]);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">assert</span> seqno != PipelineAck.UNKOWN_SEQNO : </span><br><span class="line">        <span class="string">"Ack for unknown seqno should be a failed ack: "</span> + ack;</span><br><span class="line">      <span class="keyword">if</span> (seqno == Packet.HEART_BEAT_SEQNO) &#123;  <span class="comment">// a heartbeat ack</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// a success ack for a data packet</span></span><br><span class="line">      Packet one;</span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        one = ackQueue.getFirst();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 接收到的seqno和ackQueue中的不一样，抛出异常</span></span><br><span class="line">      <span class="keyword">if</span> (one.seqno != seqno) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"ResponseProcessor: Expecting seqno "</span> +</span><br><span class="line">                              <span class="string">" for block "</span> + block +</span><br><span class="line">                              one.seqno + <span class="string">" but received "</span> + seqno);</span><br><span class="line">      &#125;</span><br><span class="line">      isLastPacketInBlock = one.lastPacketInBlock;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Fail the packet write for testing in order to force a</span></span><br><span class="line">      <span class="comment">// pipeline recovery.</span></span><br><span class="line">      <span class="keyword">if</span> (DFSClientFaultInjector.get().failPacket() &amp;&amp;</span><br><span class="line">          isLastPacketInBlock) &#123;</span><br><span class="line">        failPacket = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">              <span class="string">"Failing the last packet for testing."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">        </span><br><span class="line">      <span class="comment">// update bytesAcked</span></span><br><span class="line">      block.setNumBytes(one.getLastByteOffsetBlock());</span><br><span class="line"></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        lastAckedSeqno = seqno;</span><br><span class="line">        ackQueue.removeFirst();</span><br><span class="line">        dataQueue.notifyAll();</span><br><span class="line"></span><br><span class="line">        one.releaseBuffer(byteArrayManager);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!responderClosed) &#123;</span><br><span class="line">        <span class="keyword">if</span> (e <span class="keyword">instanceof</span> IOException) &#123;</span><br><span class="line">          setLastException((IOException)e);</span><br><span class="line">        &#125;</span><br><span class="line">        hasError = <span class="keyword">true</span>;</span><br><span class="line">        <span class="comment">// If no explicit error report was received, mark the primary</span></span><br><span class="line">        <span class="comment">// node as failed.</span></span><br><span class="line">        tryMarkPrimaryDatanodeFailed();</span><br><span class="line">        <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">          dataQueue.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">          DFSClient.LOG.warn(<span class="string">"DFSOutputStream ResponseProcessor exception "</span></span><br><span class="line">               + <span class="string">" for block "</span> + block, e);</span><br><span class="line">        &#125;</span><br><span class="line">        responderClosed = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ResponseProcessoror中接收下游的ack时，如果ack中的packet有非SUCCESS状态，则<code>setErrorIndex</code>并抛出IOException异常；如果接收到ack的seqno和从ackQueue取出的seqno不一样，则抛出IOException异常，抛出之后在catch中捕获，将hasError置为true，关闭ResponseProcessoror线程。</p>
<p>在DataStreamer.run中也可能抛出异常(在<code>one.writeTo(blockStream)</code>中抛出异常IOException)</p>
<h3 id="pipeline-stream发生error之后的修复"><a href="#pipeline-stream发生error之后的修复" class="headerlink" title="pipeline stream发生error之后的修复"></a>pipeline stream发生error之后的修复</h3><p>pipeline stream中发生error只有在client端才能检测到才进行处理。</p>
<p>如果是在ResponseProcessoror中发生的异常，分两种情况，第一种是在在下游的ack中发现packet的状态非SUCCESS，<em>则设置errorIndex为pipeline中第一个发送error的dn索引</em>并抛出IOException在catch中捕获将hasError置为true。<br>第二种情况是接收到ack的seqno和从ackQueue中取出的seqno不一样，则抛出IOException在catch中捕获将hasError置为true。</p>
<p>DataStreamer.run中one.writeTo(blockStream)抛出异常被catch捕获再次抛出IOException被外层的catch捕获将hasError置为true。</p>
<p>hasError和errorIndex的值发生变化之后，在DataStreamer.run中被发现，进行故障处理。相关代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// if the Responder encountered an error, shutdown Responder</span></span><br><span class="line"><span class="keyword">if</span> (hasError &amp;&amp; response != <span class="keyword">null</span>) &#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    response.close();</span><br><span class="line">    response.join();</span><br><span class="line">    response = <span class="keyword">null</span>;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">    DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (hasError &amp;&amp; (errorIndex &gt;= <span class="number">0</span> || restartingNodeIndex &gt;= <span class="number">0</span>)) &#123;</span><br><span class="line">  doSleep = processDatanodeError();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>processDatanodeError只有在errorIndex大于等于0或者restartingNodeIndex大于等于0时才执行，(<strong>也就是说当ResponseProcessor接收到的ack中有packet的状态是非SUCCESS时，才会执行？？？</strong>)。</p>
<p>来研究下processDatanodeError代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">processDatanodeError</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (response != <span class="keyword">null</span>) &#123;</span><br><span class="line">    DFSClient.LOG.info(<span class="string">"Error Recovery for "</span> + block +</span><br><span class="line">    <span class="string">" waiting for responder to exit. "</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 关闭连接</span></span><br><span class="line">  closeStream();</span><br><span class="line">  <span class="comment">// 将ackQueue中等待接收ack的packet重新放回dataQueue中，重新往pipeline发送</span></span><br><span class="line">  <span class="comment">// move packets from ack queue to front of the data queue</span></span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">    dataQueue.addAll(<span class="number">0</span>, ackQueue);</span><br><span class="line">    ackQueue.clear();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Record the new pipeline failure recovery.</span></span><br><span class="line">  <span class="keyword">if</span> (lastAckedSeqnoBeforeFailure != lastAckedSeqno) &#123;</span><br><span class="line">     lastAckedSeqnoBeforeFailure = lastAckedSeqno;</span><br><span class="line">     pipelineRecoveryCount = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// If we had to recover the pipeline five times in a row for the</span></span><br><span class="line">    <span class="comment">// same packet, this client likely has corrupt data or corrupting</span></span><br><span class="line">    <span class="comment">// during transmission.</span></span><br><span class="line">    <span class="keyword">if</span> (++pipelineRecoveryCount &gt; <span class="number">5</span>) &#123;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">"Error recovering pipeline for writing "</span> +</span><br><span class="line">          block + <span class="string">". Already retried 5 times for the same packet."</span>);</span><br><span class="line">      lastException.set(<span class="keyword">new</span> IOException(<span class="string">"Failing write. Tried pipeline "</span> +</span><br><span class="line">          <span class="string">"recovery 5 times without success."</span>));</span><br><span class="line">      streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// </span></span><br><span class="line">  <span class="keyword">boolean</span> doSleep = setupPipelineForAppendOrRecovery();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_CLOSE) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// If we had an error while closing the pipeline, we go through a fast-path</span></span><br><span class="line">      <span class="comment">// where the BlockReceiver does not run. Instead, the DataNode just finalizes</span></span><br><span class="line">      <span class="comment">// the block immediately during the 'connect ack' process. So, we want to pull</span></span><br><span class="line">      <span class="comment">// the end-of-block packet from the dataQueue, since we don't actually have</span></span><br><span class="line">      <span class="comment">// a true pipeline to send it over.</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that</span></span><br><span class="line">      <span class="comment">// a client waiting on close() will be aware that the flush finished.</span></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        Packet endOfBlockPacket = dataQueue.remove();  <span class="comment">// remove the end of block packet</span></span><br><span class="line">        <span class="keyword">assert</span> endOfBlockPacket.lastPacketInBlock;</span><br><span class="line">        <span class="keyword">assert</span> lastAckedSeqno == endOfBlockPacket.seqno - <span class="number">1</span>;</span><br><span class="line">        lastAckedSeqno = endOfBlockPacket.seqno;</span><br><span class="line">        dataQueue.notifyAll();</span><br><span class="line">      &#125;</span><br><span class="line">      endBlock();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      initDataStreaming();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> doSleep;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">setupPipelineForAppendOrRecovery</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// check number of datanodes</span></span><br><span class="line">  <span class="keyword">if</span> (nodes == <span class="keyword">null</span> || nodes.length == <span class="number">0</span>) &#123;</span><br><span class="line">    String msg = <span class="string">"Could not get block locations. "</span> + <span class="string">"Source file \""</span></span><br><span class="line">        + src + <span class="string">"\" - Aborting..."</span>;</span><br><span class="line">    DFSClient.LOG.warn(msg);</span><br><span class="line">    setLastException(<span class="keyword">new</span> IOException(msg));</span><br><span class="line">    streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">boolean</span> success = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">long</span> newGS = <span class="number">0L</span>;</span><br><span class="line">  <span class="keyword">while</span> (!success &amp;&amp; !streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="comment">// Sleep before reconnect if a dn is restarting.</span></span><br><span class="line">    <span class="comment">// This process will be repeated until the deadline or the datanode</span></span><br><span class="line">    <span class="comment">// starts back up.</span></span><br><span class="line">    <span class="keyword">if</span> (restartingNodeIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 4 seconds or the configured deadline period, whichever is shorter.</span></span><br><span class="line">      <span class="comment">// This is the retry interval and recovery will be retried in this</span></span><br><span class="line">      <span class="comment">// interval until timeout or success.</span></span><br><span class="line">      <span class="keyword">long</span> delay = Math.min(dfsClient.getConf().datanodeRestartTimeout,</span><br><span class="line">          <span class="number">4000L</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        Thread.sleep(delay);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">        lastException.set(<span class="keyword">new</span> IOException(<span class="string">"Interrupted while waiting for "</span> +</span><br><span class="line">            <span class="string">"datanode to restart. "</span> + nodes[restartingNodeIndex]));</span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 此时hasError的值为true</span></span><br><span class="line">    <span class="keyword">boolean</span> isRecovery = hasError;</span><br><span class="line">    <span class="comment">// remove bad datanode from list of datanodes.</span></span><br><span class="line">    <span class="comment">// If errorIndex was not set (i.e. appends), then do not remove </span></span><br><span class="line">    <span class="comment">// any datanodes</span></span><br><span class="line">    <span class="keyword">if</span> (errorIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      StringBuilder pipelineMsg = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; nodes.length; j++) &#123;</span><br><span class="line">        pipelineMsg.append(nodes[j]);</span><br><span class="line">        <span class="keyword">if</span> (j &lt; nodes.length - <span class="number">1</span>) &#123;</span><br><span class="line">          pipelineMsg.append(<span class="string">", "</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (nodes.length &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        lastException.set(<span class="keyword">new</span> IOException(<span class="string">"All datanodes "</span> + pipelineMsg</span><br><span class="line">            + <span class="string">" are bad. Aborting..."</span>));</span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">"Error Recovery for block "</span> + block +</span><br><span class="line">          <span class="string">" in pipeline "</span> + pipelineMsg + </span><br><span class="line">          <span class="string">": bad datanode "</span> + nodes[errorIndex]);</span><br><span class="line">      failed.add(nodes[errorIndex]);</span><br><span class="line"></span><br><span class="line">      DatanodeInfo[] newnodes = <span class="keyword">new</span> DatanodeInfo[nodes.length-<span class="number">1</span>];</span><br><span class="line">      arraycopy(nodes, newnodes, errorIndex);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">final</span> StorageType[] newStorageTypes = <span class="keyword">new</span> StorageType[newnodes.length];</span><br><span class="line">      arraycopy(storageTypes, newStorageTypes, errorIndex);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">final</span> String[] newStorageIDs = <span class="keyword">new</span> String[newnodes.length];</span><br><span class="line">      arraycopy(storageIDs, newStorageIDs, errorIndex);</span><br><span class="line">      <span class="comment">// 用剩下的dn组成一个新的pipeline</span></span><br><span class="line">      setPipeline(newnodes, newStorageTypes, newStorageIDs);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Just took care of a node error while waiting for a node restart</span></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// If the error came from a node further away than the restarting</span></span><br><span class="line">        <span class="comment">// node, the restart must have been complete.</span></span><br><span class="line">        <span class="keyword">if</span> (errorIndex &gt; restartingNodeIndex) &#123;</span><br><span class="line">          restartingNodeIndex = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (errorIndex &lt; restartingNodeIndex) &#123;</span><br><span class="line">          <span class="comment">// the node index has shifted.</span></span><br><span class="line">          restartingNodeIndex--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// this shouldn't happen...</span></span><br><span class="line">          <span class="keyword">assert</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        hasError = <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      lastException.set(<span class="keyword">null</span>);</span><br><span class="line">      errorIndex = -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 检查是否需要替换发生故障的dn从而组成一个新的pipeline</span></span><br><span class="line">    <span class="comment">// 由dfs.client.block.write.replace-datanode-on-failure.policy参数控制策略</span></span><br><span class="line">    <span class="comment">// Check if replace-datanode policy is satisfied.</span></span><br><span class="line">    <span class="keyword">if</span> (dfsClient.dtpReplaceDatanodeOnFailure.satisfy(blockReplication,</span><br><span class="line">        nodes, isAppend, isHflushed)) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">      	<span class="comment">// 向pipeline中新加一个dn</span></span><br><span class="line">        addDatanode2ExistingPipeline();</span><br><span class="line">      &#125; <span class="keyword">catch</span>(IOException ioe) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!dfsClient.dtpReplaceDatanodeOnFailure.isBestEffort()) &#123;</span><br><span class="line">          <span class="keyword">throw</span> ioe;</span><br><span class="line">        &#125;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"Failed to replace datanode."</span></span><br><span class="line">            + <span class="string">" Continue with the remaining datanodes since "</span></span><br><span class="line">            + DFSConfigKeys.DFS_CLIENT_WRITE_REPLACE_DATANODE_ON_FAILURE_BEST_EFFORT_KEY</span><br><span class="line">            + <span class="string">" is set to true."</span>, ioe);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// get a new generation stamp and an access token</span></span><br><span class="line">    LocatedBlock lb = dfsClient.namenode.updateBlockForPipeline(block, dfsClient.clientName);</span><br><span class="line">    newGS = lb.getBlock().getGenerationStamp();</span><br><span class="line">    accessToken = lb.getBlockToken();</span><br><span class="line">    <span class="comment">// set up the pipeline again with the remaining nodes</span></span><br><span class="line">    <span class="keyword">if</span> (failPacket) &#123; <span class="comment">// for testing</span></span><br><span class="line">      success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);</span><br><span class="line">      failPacket = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Give DNs time to send in bad reports. In real situations,</span></span><br><span class="line">        <span class="comment">// good reports should follow bad ones, if client committed</span></span><br><span class="line">        <span class="comment">// with those nodes.</span></span><br><span class="line">        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;&#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (restartingNodeIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">assert</span> hasError == <span class="keyword">true</span>;</span><br><span class="line">      <span class="comment">// check errorIndex set above</span></span><br><span class="line">      <span class="keyword">if</span> (errorIndex == restartingNodeIndex) &#123;</span><br><span class="line">        <span class="comment">// ignore, if came from the restarting node</span></span><br><span class="line">        errorIndex = -<span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// still within the deadline</span></span><br><span class="line">      <span class="keyword">if</span> (Time.now() &lt; restartDeadline) &#123;</span><br><span class="line">        <span class="keyword">continue</span>; <span class="comment">// with in the deadline</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// expired. declare the restarting node dead</span></span><br><span class="line">      restartDeadline = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">int</span> expiredNodeIndex = restartingNodeIndex;</span><br><span class="line">      restartingNodeIndex = -<span class="number">1</span>;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">"Datanode did not restart in time: "</span> +</span><br><span class="line">          nodes[expiredNodeIndex]);</span><br><span class="line">      <span class="comment">// Mark the restarting node as failed. If there is any other failed</span></span><br><span class="line">      <span class="comment">// node during the last pipeline construction attempt, it will not be</span></span><br><span class="line">      <span class="comment">// overwritten/dropped. In this case, the restarting node will get</span></span><br><span class="line">      <span class="comment">// excluded in the following attempt, if it still does not come up.</span></span><br><span class="line">      <span class="keyword">if</span> (errorIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        errorIndex = expiredNodeIndex;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// From this point on, normal pipeline recovery applies.</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="comment">// while</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (success) &#123;</span><br><span class="line">    <span class="comment">// update pipeline at the namenode</span></span><br><span class="line">    ExtendedBlock newBlock = <span class="keyword">new</span> ExtendedBlock(</span><br><span class="line">        block.getBlockPoolId(), block.getBlockId(), block.getNumBytes(), newGS);</span><br><span class="line">    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,</span><br><span class="line">        nodes, storageIDs);</span><br><span class="line">    <span class="comment">// update client side generation stamp</span></span><br><span class="line">    block = newBlock;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">// do not sleep, continue processing</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在pipeline中是否替换发生故障的dn与剩下的dn组成新的pipeline的判断条件是通过不能的replace策略决定的，默认是default策略，由<em>dfs.client.block.write.replace-datanode-on-failure.policy</em>控制，default策略如下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * DEFAULT condition:</span></span><br><span class="line"><span class="comment"> *   Let r be the replication number.</span></span><br><span class="line"><span class="comment"> *   Let n be the number of existing datanodes.</span></span><br><span class="line"><span class="comment"> *   Add a new datanode only if r &gt;= 3 and either</span></span><br><span class="line"><span class="comment"> *   (1) floor(r/2) &gt;= n; or</span></span><br><span class="line"><span class="comment"> *   (2) r &gt; n and the block is hflushed/appended.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">satisfy</span><span class="params">(<span class="keyword">final</span> <span class="keyword">short</span> replication,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo[] existings, <span class="keyword">final</span> <span class="keyword">int</span> n, <span class="keyword">final</span> <span class="keyword">boolean</span> isAppend,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">boolean</span> isHflushed)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (replication &lt; <span class="number">3</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (n &lt;= (replication/<span class="number">2</span>)) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> isAppend || isHflushed;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>是说3个dn组成的pipeline有一个dn发生故障不会替换发生故障的dn？那何时会有两个dn发生故障，在ResponseProcessor中只检测第一个发生故障的dn并设置errorIndex为该dn的索引，在哪里会检查发生多个dn故障？？？</strong></p>
<p>上面是pipeline stream相关的内容，有些还是不是太清楚，随后再根据不断的啃代码不断加深理解然后再更新吧。</p>
<h2 id="pipeline-close-amp-error"><a href="#pipeline-close-amp-error" class="headerlink" title="pipeline close &amp; error"></a>pipeline close &amp; error</h2><h3 id="pipeline-close"><a href="#pipeline-close" class="headerlink" title="pipeline close"></a>pipeline close</h3><p>client端在DataStreamer.run中首先判断当前packet是否为lastPacketInBlock，如果是则阻塞直到ackQueue中的packet返回的ack都被client收到，然后设置pipeline的状态为<em>BlockConstructionStage.PIPELINE_CLOSE</em>。</p>
<p>接着将当前packet也就是block中的最后一个packet发送到pipeline中，将此packet发送到pipeline中则等待收到该packet的ack之后调用<code>endBlock()</code>将连接关闭并将pipeline置为初始状态。</p>
<p>在dn端首先通过DataXceiver.writeBlock调用BlockReceiver.receiverPacket，在其中判断<code>lastPacketInBlock || len == 0</code>并且<strong>syncBlock(具体用来干什么？？)</strong>为true则调用<code>flushOrSync(true)</code>将data和meta写入磁盘。<br>其次在PacketResponder线程中在接收下游ack之后判断从ackQueue中取出的packet是否为lastPacketBlock，如果是则调用<code>finalizeBlock(startTime)</code>，然后向上游发送ack</p>
<h3 id="errors-in-pipeline-close"><a href="#errors-in-pipeline-close" class="headerlink" title="errors in pipeline close"></a>errors in pipeline close</h3><p>client端在close阶段可能发生error的地方是将最后一个packet发送到pipeline时可能会抛出异常然后将hasError置为true</p>
<p>dn端在close阶段发生error的地方可能是在BlockReceiver.receiverPacket中判断packet为最后一个packet并且syncBlock为true则调用flushOrSync(true)，flushOrSync(true)可能会抛出异常(<em>该IOException一路从DataXceiver.writeBlock中抛出</em>)。</p>
<h3 id="pipeline-close发生error之后的修复"><a href="#pipeline-close发生error之后的修复" class="headerlink" title="pipeline close发生error之后的修复"></a>pipeline close发生error之后的修复</h3><p>client端发送error将hasError置为true，会执行<code>processDatanodeError</code>吗？？？<br>不会执行？？但是在processDatanodeError代码中有这样一段：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">  <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_CLOSE) &#123;</span><br><span class="line">    <span class="comment">// If we had an error while closing the pipeline, we go through a fast-path</span></span><br><span class="line">    <span class="comment">// where the BlockReceiver does not run. Instead, the DataNode just finalizes</span></span><br><span class="line">    <span class="comment">// the block immediately during the 'connect ack' process. So, we want to pull</span></span><br><span class="line">    <span class="comment">// the end-of-block packet from the dataQueue, since we don't actually have</span></span><br><span class="line">    <span class="comment">// a true pipeline to send it over.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that</span></span><br><span class="line">    <span class="comment">// a client waiting on close() will be aware that the flush finished.</span></span><br><span class="line">    <span class="comment">// 如果在pipeline close阶段发生error，有一个快速的方法，该方法不用在dn上new BlockReceiver</span></span><br><span class="line">    <span class="comment">// 而是让dn在pipeline重建时就立马使block Finalized。因此只是将最后一个packet从dataQueue中取出</span></span><br><span class="line">    <span class="comment">// 没有必要往一个pipeline中发送。</span></span><br><span class="line">    <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">      Packet endOfBlockPacket = dataQueue.remove();  <span class="comment">// remove the end of block packet</span></span><br><span class="line">      <span class="keyword">assert</span> endOfBlockPacket.lastPacketInBlock;</span><br><span class="line">      <span class="keyword">assert</span> lastAckedSeqno == endOfBlockPacket.seqno - <span class="number">1</span>;</span><br><span class="line">      lastAckedSeqno = endOfBlockPacket.seqno;</span><br><span class="line">      dataQueue.notifyAll();</span><br><span class="line">    &#125;</span><br><span class="line">    endBlock();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    initDataStreaming();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>会执行？？但是errorIndex可能为-1呀。。。。</p>
<p>pipeline在close阶段是已经将之前的packet的ack返回给client，然后client才会发送最后一个packet(<em>此packet为null</em>)到pipeline中，那么在dn端的error应该和pipeline stream阶段在dn端发生的error情况类似，还没有具体搞明白？？？？。</p>
<hr>
<p>考虑客户端写文件的过程中宕机，那么在lease soft limit过期之前，其他的客户端不能写这个文件，等到lease soft limit过期后，其他客户端可以写这个文件，在写文件之前，会首先检查文件是不是没有关闭，如果没有，那么就会进入lease recovery和block recovery阶段，这个阶段的目的是使文件的最后一个block的所有副本数据达到一致，因为客户端写block的多个副本是pipeline写，pipeline中的副本数据不一致很正常。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> write </tag>
            
            <tag> fail </tag>
            
            <tag> pipeline </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS write解析]]></title>
      <url>http://bigdatadecode.club/HDFS%20write%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p>本篇主要记录下HDFS写文件的流程。其写入流程与普通文件写入流程类似，首先创建一个输出流OutputStream，然后通过这个输出流写入数据。在HDFS中数据传输的基本单元为Packet(默认64k)，每个packet又由很多个chunk组成，chunk是文件校验的基本单位，一个chunk一个chunksum，chunk是校验单位也就是写入单位，将chunk写入packet，一个packet写满之后，将packet发送到pipeline中。</p>
<p>下面从代码层次去详细解读下write流程。其写入流程图如下：<br><img src="/blogimgs/HDFS write解析/hdfs-write-flow.png" alt="write流程图" title="write流程图"></p>
<a id="more"></a>
<h2 id="创建一个输出流"><a href="#创建一个输出流" class="headerlink" title="创建一个输出流"></a>创建一个输出流</h2><p>HDFS写文件跟java写文件类似，都需要先打开一个文件流，HDFS是通过<em>FileSystem</em>对象打开文件流的，代码流程为通过<code>FileSystem.get(conf)</code>得到一个<code>FileSystem</code>对象，然后调用<code>create(Path)</code>或者<code>append(Path)</code>打开一个FSDataOutputStream流，看下create代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">create</span><span class="params">(Path f)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> create(f, <span class="keyword">true</span>); <span class="comment">// Path overwrite</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>FileSystem是一个抽象类，将具体的<code>create</code>的具体操作留给子类实现，例如DistributedFileSystem、WebHdfsFileSystem等，不同的文件系统具有不同打开文件的行为，我们以DistributedFileSystem为例，create方法实现，代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">create</span><span class="params">(<span class="keyword">final</span> Path f, <span class="keyword">final</span> FsPermission permission,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="keyword">final</span> EnumSet&lt;CreateFlag&gt; cflags, <span class="keyword">final</span> <span class="keyword">int</span> bufferSize,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="keyword">final</span> <span class="keyword">short</span> replication, <span class="keyword">final</span> <span class="keyword">long</span> blockSize, <span class="keyword">final</span> Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="keyword">final</span> ChecksumOpt checksumOpt)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  statistics.incrementWriteOps(<span class="number">1</span>);</span><br><span class="line">  Path absF = fixRelativePart(f);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> FileSystemLinkResolver&lt;FSDataOutputStream&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">doCall</span><span class="params">(<span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException, UnresolvedLinkException </span>&#123;</span><br><span class="line">      <span class="keyword">final</span> DFSOutputStream dfsos = dfs.create(getPathName(p), permission,</span><br><span class="line">              cflags, replication, blockSize, progress, bufferSize,</span><br><span class="line">              checksumOpt);</span><br><span class="line">      <span class="keyword">return</span> dfs.createWrappedOutputStream(dfsos, statistics);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FSDataOutputStream <span class="title">next</span><span class="params">(<span class="keyword">final</span> FileSystem fs, <span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> fs.create(p, permission, cflags, bufferSize,</span><br><span class="line">          replication, blockSize, progress, checksumOpt);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;.resolve(<span class="keyword">this</span>, absF);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DistributedFileSystem.create()中new一个FileSystemLinkResolver的匿名类，在resolve中调用在匿名类中重写的<code>doCall()</code>方法，如果doCall抛出UnresolvedLinkException异常，被resolve捕获调用<code>next()</code>，进行再次打开。(<em>这段代码跟open一个FSDataInputStream类似</em>)</p>
<p>在<code>doCall()</code>中调用<code>dfs.create</code>返回一个<em>DFSOutputStream</em>对象，然后再通过<code>dfs.createWrappedOutputStream</code>包装一个<em>HdfsDataOutputStream</em>对象返回给<em>FSDataOutputStream</em>，FSDataOutputStream是HdfsDataOutputStream的父类，这样就通过FileSystem.create(path)打开了一个文件流。</p>
<p>doCall中dfs是FSDataOutputStream的成员变量DFSClient，其create方法中得到一个DFSOutputStream实例，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DFSOutputStream <span class="title">create</span><span class="params">(String src, </span></span></span><br><span class="line"><span class="function"><span class="params">                           FsPermission permission,</span></span></span><br><span class="line"><span class="function"><span class="params">                           EnumSet&lt;CreateFlag&gt; flag, </span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">short</span> replication,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">long</span> blockSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">int</span> buffersize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           ChecksumOpt checksumOpt)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> create(src, permission, flag, <span class="keyword">true</span>,</span><br><span class="line">      replication, blockSize, progress, buffersize, checksumOpt, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> DFSOutputStream <span class="title">create</span><span class="params">(String src, </span></span></span><br><span class="line"><span class="function"><span class="params">                           FsPermission permission,</span></span></span><br><span class="line"><span class="function"><span class="params">                           EnumSet&lt;CreateFlag&gt; flag, </span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">boolean</span> createParent,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">short</span> replication,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">long</span> blockSize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">int</span> buffersize,</span></span></span><br><span class="line"><span class="function"><span class="params">                           ChecksumOpt checksumOpt,</span></span></span><br><span class="line"><span class="function"><span class="params">                           InetSocketAddress[] favoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  checkOpen();</span><br><span class="line">  <span class="keyword">if</span> (permission == <span class="keyword">null</span>) &#123;</span><br><span class="line">    permission = FsPermission.getFileDefault();</span><br><span class="line">  &#125;</span><br><span class="line">  FsPermission masked = permission.applyUMask(dfsClientConf.uMask);</span><br><span class="line">  <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">    LOG.debug(src + <span class="string">": masked="</span> + masked);</span><br><span class="line">  &#125;</span><br><span class="line">  String[] favoredNodeStrs = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (favoredNodes != <span class="keyword">null</span>) &#123;</span><br><span class="line">    favoredNodeStrs = <span class="keyword">new</span> String[favoredNodes.length];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; favoredNodes.length; i++) &#123;</span><br><span class="line">      favoredNodeStrs[i] = </span><br><span class="line">          favoredNodes[i].getHostName() + <span class="string">":"</span> </span><br><span class="line">                       + favoredNodes[i].getPort();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 在得到输出流的过程中，不会对lease进行检查，</span></span><br><span class="line">  <span class="comment">// 只是在创建file时，添加lease？？？</span></span><br><span class="line">  <span class="comment">// 创建file之后，根据创建的file new一个FSDataOutputStream</span></span><br><span class="line">  <span class="keyword">final</span> DFSOutputStream result = DFSOutputStream.newStreamForCreate(<span class="keyword">this</span>,</span><br><span class="line">      src, masked, flag, createParent, replication, blockSize, progress,</span><br><span class="line">      buffersize, dfsClientConf.createChecksum(checksumOpt),</span><br><span class="line">      favoredNodeStrs);</span><br><span class="line">  <span class="comment">// 得到输出流，也就得到了该file的lease，得到lease之后就应该起个线程对其进行续约</span></span><br><span class="line">  beginFileLease(result.getFileId(), result);</span><br><span class="line">  <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>文件的父目录如果不存在，dfs.create时会自动创建其父目录，在dfs.create传参时，将createParent设置为true。</p>
<p>dfs.create中得到一个DFSOutputStream的实例，DFSOutputStream实例通过静态方法newStreamForCreate得到。在HDFS写文件中是通过Lease(租约)来维护写文件凭证的，所以得到一个文件的写权限之后将其租约进行存储并定时更新。</p>
<h3 id="DFSOutputStream实例"><a href="#DFSOutputStream实例" class="headerlink" title="DFSOutputStream实例"></a>DFSOutputStream实例</h3><p>DFSOutputStream的构造方法是私有的，则实例通过静态方法newStreamForCreate得到。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> DFSOutputStream <span class="title">newStreamForCreate</span><span class="params">(DFSClient dfsClient, String src,</span></span></span><br><span class="line"><span class="function"><span class="params">    FsPermission masked, EnumSet&lt;CreateFlag&gt; flag, <span class="keyword">boolean</span> createParent,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, Progressable progress, <span class="keyword">int</span> buffersize,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum checksum, String[] favoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  HdfsFileStatus stat = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Retry the create if we get a RetryStartFileException up to a maximum</span></span><br><span class="line">  <span class="comment">// number of times</span></span><br><span class="line">  <span class="keyword">boolean</span> shouldRetry = <span class="keyword">true</span>;</span><br><span class="line">  <span class="comment">// retryCount 是 10</span></span><br><span class="line">  <span class="keyword">int</span> retryCount = CREATE_RETRY_COUNT;</span><br><span class="line">  <span class="keyword">while</span> (shouldRetry) &#123;</span><br><span class="line">    shouldRetry = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// rpc 调用</span></span><br><span class="line">      stat = dfsClient.namenode.create(src, masked, dfsClient.clientName,</span><br><span class="line">          <span class="keyword">new</span> EnumSetWritable&lt;CreateFlag&gt;(flag), createParent, replication,</span><br><span class="line">          blockSize, SUPPORTED_CRYPTO_VERSIONS);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RemoteException re) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (e <span class="keyword">instanceof</span> RetryStartFileException) &#123;</span><br><span class="line">        <span class="keyword">if</span> (retryCount &gt; <span class="number">0</span>) &#123;</span><br><span class="line">          shouldRetry = <span class="keyword">true</span>;</span><br><span class="line">          retryCount--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Too many retries because of encryption"</span> +</span><br><span class="line">              <span class="string">" zone operations"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  Preconditions.checkNotNull(stat, <span class="string">"HdfsFileStatus should not be null!"</span>);</span><br><span class="line">  <span class="keyword">final</span> DFSOutputStream out = <span class="keyword">new</span> DFSOutputStream(dfsClient, src, stat,</span><br><span class="line">      flag, progress, checksum, favoredNodes);</span><br><span class="line">  <span class="comment">// 启动DataStreamer线程</span></span><br><span class="line">  out.start();</span><br><span class="line">  <span class="keyword">return</span> out;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>newStreamForCreate先通过rpc请求namenode创建一个文件，然后通过该文件打开一个输出流。</p>
<p>rpc请求创建文件启动了重试机制，默认重试10次，通过<code>stat = dfsClient.namenode.create</code>创建，成功之后break出while循环。create远程调用的流程为NameNodeRpcServer.create -&gt; namesystem.startFile -&gt; startFileInt -&gt; startFileInternal。在startFileInternal中通过<code>newNode = dir.addFile(src, permissions, replication, blockSize, holder, clientMachine);</code>向namenode中添加一个文件，并将clientname对src的租约进行存储<code>leaseManager.addLease(newNode.getFileUnderConstructionFeature().getClientName(), src);</code>，关于租约的更多内容请看<a href="http://bigdatadecode.club/HDFS租约解析.html">HDFS中租约解析</a></p>
<p>先看下startFileInternal的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSNamesystem.java</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> BlocksMapUpdateInfo <span class="title">startFileInternal</span><span class="params">(FSPermissionChecker pc, </span></span></span><br><span class="line"><span class="function"><span class="params">    String src, PermissionStatus permissions, String holder, </span></span></span><br><span class="line"><span class="function"><span class="params">    String clientMachine, <span class="keyword">boolean</span> create, <span class="keyword">boolean</span> overwrite, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> createParent, <span class="keyword">short</span> replication, <span class="keyword">long</span> blockSize, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isLazyPersist, CipherSuite suite, CryptoProtocolVersion version,</span></span></span><br><span class="line"><span class="function"><span class="params">    EncryptedKeyVersion edek, <span class="keyword">boolean</span> logRetryEntry)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> FileAlreadyExistsException, AccessControlException,</span></span><br><span class="line"><span class="function">    UnresolvedLinkException, FileNotFoundException,</span></span><br><span class="line"><span class="function">    ParentNotDirectoryException, RetryStartFileException, IOException </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">assert</span> <span class="title">hasWriteLock</span><span class="params">()</span></span>;</span><br><span class="line">  <span class="comment">// Verify that the destination does not exist as a directory already.</span></span><br><span class="line">  <span class="keyword">final</span> INodesInPath iip = dir.getINodesInPath4Write(src);</span><br><span class="line">  <span class="keyword">final</span> INode inode = iip.getLastINode();</span><br><span class="line">  <span class="comment">// 这里判断该path是否已经以路径的形式存在</span></span><br><span class="line">  <span class="keyword">if</span> (inode != <span class="keyword">null</span> &amp;&amp; inode.isDirectory()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> FileAlreadyExistsException(src +</span><br><span class="line">        <span class="string">" already exists as a directory"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">final</span> INodeFile myFile = INodeFile.valueOf(inode, src, <span class="keyword">true</span>);</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    BlocksMapUpdateInfo toRemoveBlocks = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 该file不存在则create</span></span><br><span class="line">    <span class="keyword">if</span> (myFile == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!create) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FileNotFoundException(<span class="string">"Can't overwrite non-existent "</span> +</span><br><span class="line">            src + <span class="string">" for client "</span> + clientMachine);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 该file已经存在，则重写</span></span><br><span class="line">      <span class="keyword">if</span> (overwrite) &#123;</span><br><span class="line">        toRemoveBlocks = <span class="keyword">new</span> BlocksMapUpdateInfo();</span><br><span class="line">        List&lt;INode&gt; toRemoveINodes = <span class="keyword">new</span> ChunkedArrayList&lt;INode&gt;();</span><br><span class="line">        <span class="keyword">long</span> ret = dir.delete(src, toRemoveBlocks, toRemoveINodes, now());</span><br><span class="line">        <span class="keyword">if</span> (ret &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">          incrDeletedFileCount(ret);</span><br><span class="line">          removePathAndBlocks(src, <span class="keyword">null</span>, toRemoveINodes, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="comment">// 这是怎么执行到这的？？</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// If lease soft limit time is expired, recover the lease</span></span><br><span class="line">        recoverLeaseInternal(myFile, src, holder, clientMachine, <span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> FileAlreadyExistsException(src + <span class="string">" for client "</span> +</span><br><span class="line">            clientMachine + <span class="string">" already exists"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里会检查整个hdfs上inode的上限，一般不设置</span></span><br><span class="line">    <span class="comment">// 曾经被问过hdfs中block的上限是多少，估计问的就是这个吧</span></span><br><span class="line">    <span class="comment">// 由dfs.namenode.max.objects控制</span></span><br><span class="line">    <span class="comment">// 还有个属性控制一个file的最多block个数，默认是1024*1024</span></span><br><span class="line">    <span class="comment">// dfs.namenode.fs-limits.max-blocks-per-file控制</span></span><br><span class="line">    checkFsObjectLimit();</span><br><span class="line">    INodeFile newNode = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Always do an implicit mkdirs for parent directory tree.</span></span><br><span class="line">    Path parent = <span class="keyword">new</span> Path(src).getParent();</span><br><span class="line">    <span class="comment">// 递归的创建父目录</span></span><br><span class="line">    <span class="keyword">if</span> (parent != <span class="keyword">null</span> &amp;&amp; mkdirsRecursively(parent.toString(),</span><br><span class="line">            permissions, <span class="keyword">true</span>, now())) &#123;</span><br><span class="line">      <span class="comment">// 将file添加到namespace中</span></span><br><span class="line">      newNode = dir.addFile(src, permissions, replication, blockSize,</span><br><span class="line">                            holder, clientMachine);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (newNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unable to add "</span> + src +  <span class="string">" to namespace"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将clientName对file的lease放入LeaseManager中</span></span><br><span class="line">    leaseManager.addLease(newNode.getFileUnderConstructionFeature()</span><br><span class="line">        .getClientName(), src);</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// record file record in log, record new generation stamp</span></span><br><span class="line">    getEditLog().logOpenFile(src, newNode, overwrite, logRetryEntry);</span><br><span class="line">    <span class="keyword">if</span> (NameNode.stateChangeLog.isDebugEnabled()) &#123;</span><br><span class="line">      NameNode.stateChangeLog.debug(<span class="string">"DIR* NameSystem.startFile: added "</span> +</span><br><span class="line">          src + <span class="string">" inode "</span> + newNode.getId() + <span class="string">" "</span> + holder);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> toRemoveBlocks;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">    NameNode.stateChangeLog.warn(<span class="string">"DIR* NameSystem.startFile: "</span> + src + <span class="string">" "</span> +</span><br><span class="line">        ie.getMessage());</span><br><span class="line">    <span class="keyword">throw</span> ie;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>在得到FSDataOutputStream时，并没有对lease进行校验，那么当client1得到fileA的FSDataOutputStream之后，将其对应的租约add到LeaseManager中，此时client2也再申请fileA的FSDataOutputStream，此时会发生什么？client2也得到fileA的输出流，并将client2对应的lease也放入LeaseManager中？那么此时就有两个client持有文件fileA的租约。  是在写入bytes时进行lease 检查吗？？？疑惑中。。。</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> Lease <span class="title">addLease</span><span class="params">(String holder, String src)</span> </span>&#123;</span><br><span class="line">  Lease lease = getLease(holder);</span><br><span class="line">  <span class="keyword">if</span> (lease == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 如果当前client没有租约，则创建一个</span></span><br><span class="line">    lease = <span class="keyword">new</span> Lease(holder);</span><br><span class="line">    leases.put(holder, lease);</span><br><span class="line">    sortedLeases.add(lease);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 当前client已经持有lease，则更新时间</span></span><br><span class="line">    renewLease(lease);</span><br><span class="line">  &#125;</span><br><span class="line">  sortedLeasesByPath.put(src, lease);</span><br><span class="line">  lease.paths.add(src);</span><br><span class="line">  <span class="keyword">return</span> lease;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回到newStreamForCreate中，通过namenode创建的文件new一个输出流<code>DFSOutputStream out = new DFSOutputStream(dfsClient, src, stat, flag, progress, checksum, favoredNodes)</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">DFSOutputStream</span><span class="params">(DFSClient dfsClient, String src, HdfsFileStatus stat,</span></span></span><br><span class="line"><span class="function"><span class="params">    EnumSet&lt;CreateFlag&gt; flag, Progressable progress,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum checksum, String[] favoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>(dfsClient, src, progress, stat, checksum);</span><br><span class="line">  <span class="keyword">this</span>.shouldSyncBlock = flag.contains(CreateFlag.SYNC_BLOCK);</span><br><span class="line">  <span class="comment">// packet默认大小64k</span></span><br><span class="line">  <span class="comment">// 计算每个packet的chunk个数，和packet的大小</span></span><br><span class="line">  computePacketChunkSize(dfsClient.getConf().writePacketSize, bytesPerChecksum);</span><br><span class="line">  Span traceSpan = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (Trace.isTracing()) &#123;</span><br><span class="line">    traceSpan = Trace.startSpan(<span class="keyword">this</span>.getClass().getSimpleName()).detach();</span><br><span class="line">  &#125;</span><br><span class="line">  streamer = <span class="keyword">new</span> DataStreamer(stat, traceSpan);</span><br><span class="line">  <span class="keyword">if</span> (favoredNodes != <span class="keyword">null</span> &amp;&amp; favoredNodes.length != <span class="number">0</span>) &#123;</span><br><span class="line">    streamer.setFavoredNodes(favoredNodes);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DFSOutputStream中有个重要的线程DataStreamer，该线程主要负责向pipeline中的dn发送packet。</p>
<p>再次回到newStreamForCreate中，调用<code>out.start()</code>启动DataStreamer线程。</p>
<p>DFSOutputStream创建完毕之后，回到DFSClient.create中，执行<code>beginFileLease(result.getFileId(), result)</code>开启Lease定时Renew机制LeaseRenewer</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Get a lease and start automatic renewal */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">beginFileLease</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> inodeId, <span class="keyword">final</span> DFSOutputStream out)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  getLeaseRenewer().put(inodeId, out, <span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// LeaseRenewer 是客户端check是否更新租约</span></span><br><span class="line"><span class="comment">// A thread per namenode per user</span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">final</span> <span class="keyword">long</span> inodeId, <span class="keyword">final</span> DFSOutputStream out,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DFSClient dfsc)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (dfsc.isClientRunning()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isRunning() || isRenewerExpired()) &#123;</span><br><span class="line">      <span class="comment">//start a new deamon with a new id.</span></span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">int</span> id = ++currentId;</span><br><span class="line">      daemon = <span class="keyword">new</span> Daemon(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"Lease renewer daemon for "</span> + clientsString()</span><br><span class="line">                  + <span class="string">" with renew id "</span> + id + <span class="string">" started"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 调用LeaseRenewer.run(final int id)</span></span><br><span class="line">            <span class="comment">// 在run中调用renew对租约续约</span></span><br><span class="line">            LeaseRenewer.<span class="keyword">this</span>.run(id);</span><br><span class="line">          &#125; <span class="keyword">catch</span>(InterruptedException e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(LeaseRenewer.<span class="keyword">this</span>.getClass().getSimpleName()</span><br><span class="line">                  + <span class="string">" is interrupted."</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            <span class="keyword">synchronized</span>(LeaseRenewer.<span class="keyword">this</span>) &#123;</span><br><span class="line">              Factory.INSTANCE.remove(LeaseRenewer.<span class="keyword">this</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">              LOG.debug(<span class="string">"Lease renewer daemon for "</span> + clientsString()</span><br><span class="line">                  + <span class="string">" with renew id "</span> + id + <span class="string">" exited"</span>);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">          <span class="keyword">return</span> String.valueOf(LeaseRenewer.<span class="keyword">this</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">      daemon.start();</span><br><span class="line">    &#125;</span><br><span class="line">    dfsc.putFileBeingWritten(inodeId, out);</span><br><span class="line">    emptyTime = Long.MAX_VALUE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>回到daCall方法中，调用<code>dfs.createWrappedOutputStream(dfsos, statistics)</code>，将DFSOutputStream封装为HdfsDataOutputStream类型(FSDataOutputStream子类)，将结果return给FSDataOutputStream类型的输出流。到此FSDataOutputStream输出流创建完毕。接着该调用write方法，进行数据的写入。</p>
<h2 id="向输出流中写bytes数据流"><a href="#向输出流中写bytes数据流" class="headerlink" title="向输出流中写bytes数据流"></a>向输出流中写bytes数据流</h2><p>写入操作的API是通过FSDataOutputStream的对象out调用write(byte[])，调用流程为out.write(bytes) -&gt; FilterOutputStream.write -&gt; DataOutputStream.write -&gt; out.write(byte[], off, len) -&gt; FSOutputSummer.write(byte b[], int off, int len)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;  </span><br><span class="line">  checkClosed();</span><br><span class="line">  <span class="keyword">if</span> (off &lt; <span class="number">0</span> || len &lt; <span class="number">0</span> || off &gt; b.length - len) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> ArrayIndexOutOfBoundsException();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> n=<span class="number">0</span>;n&lt;len;n+=write1(b, off+n, len-n)) &#123;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在write中根据写入len不断的调用<code>write1</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">write1</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 写入长度大于本地buf的长度时，直接写入本地buf的长度</span></span><br><span class="line">  <span class="keyword">if</span>(count==<span class="number">0</span> &amp;&amp; len&gt;=buf.length) &#123;</span><br><span class="line">    <span class="comment">// local buffer is empty and user buffer size &gt;= local buffer size, so</span></span><br><span class="line">    <span class="comment">// simply checksum the user buffer and send it directly to the underlying</span></span><br><span class="line">    <span class="comment">// stream</span></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> length = buf.length;</span><br><span class="line">    writeChecksumChunks(b, off, length);</span><br><span class="line">    <span class="keyword">return</span> length;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 当len小于本地buf的长度时，先写入buf，当buf写满之后，flushBuffer</span></span><br><span class="line">  <span class="comment">// copy user data to local buffer</span></span><br><span class="line">  <span class="keyword">int</span> bytesToCopy = buf.length-count;</span><br><span class="line">  bytesToCopy = (len&lt;bytesToCopy) ? len : bytesToCopy;</span><br><span class="line">  System.arraycopy(b, off, buf, count, bytesToCopy);</span><br><span class="line">  count += bytesToCopy;</span><br><span class="line">  <span class="keyword">if</span> (count == buf.length) &#123;</span><br><span class="line">    <span class="comment">// local buffer is full</span></span><br><span class="line">    flushBuffer();</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="keyword">return</span> bytesToCopy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>写入数据时，是先将数据写入本地buf</em>，buf默认长度为<code>this.buf = new byte[sum.getBytesPerChecksum() * BUFFER\_NUM\_CHUNKS]; BUFFER\_NUM\_CHUNKS = 9</code>，即9个chunk的长度4608。buf写满之后对其数据生成chunksum写入packet。</p>
<p>当写入数据的len大于buf的长度时，则数据不写入buf，直接调用<code>writeChecksumChunks</code>将buf长度大小的数据生成chunksum，并写入packet中。<br>当写入数据的len小于buf的长度时，则将数据copy到buf中，等buf满时，调用<code>flushBuffer</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">flushBuffer</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  flushBuffer(<span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">flushBuffer</span><span class="params">(<span class="keyword">boolean</span> keep,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> flushPartial)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> bufLen = count;</span><br><span class="line">  <span class="keyword">int</span> partialLen = bufLen % sum.getBytesPerChecksum();</span><br><span class="line">  <span class="keyword">int</span> lenToFlush = flushPartial ? bufLen : bufLen - partialLen;</span><br><span class="line">  <span class="keyword">if</span> (lenToFlush != <span class="number">0</span>) &#123;</span><br><span class="line">    writeChecksumChunks(buf, <span class="number">0</span>, lenToFlush);</span><br><span class="line">    <span class="keyword">if</span> (!flushPartial || keep) &#123;</span><br><span class="line">      count = partialLen;</span><br><span class="line">      System.arraycopy(buf, bufLen - count, buf, <span class="number">0</span>, count);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    count = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// total bytes left minus unflushed bytes left</span></span><br><span class="line">  <span class="keyword">return</span> count - (bufLen - lenToFlush);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在flushBuffer中依然会调用<code>writeChecksumChunks</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeChecksumChunks</span><span class="params">(<span class="keyword">byte</span> b[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 计算checksum</span></span><br><span class="line">  sum.calculateChunkedSums(b, off, len, checksum, <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; len; i += sum.getBytesPerChecksum()) &#123;</span><br><span class="line">    <span class="keyword">int</span> chunkLen = Math.min(sum.getBytesPerChecksum(), len - i);</span><br><span class="line">    <span class="keyword">int</span> ckOffset = i / sum.getBytesPerChecksum() * getChecksumSize();</span><br><span class="line">    <span class="comment">// 一个chunk一个chunk的写入packet</span></span><br><span class="line">    writeChunk(b, off + i, chunkLen, checksum, ckOffset, getChecksumSize());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在writeChecksumChunks中先调用<code>calculateChunkedSums</code>计算数据的checksum，然后调用<code>writeChunk</code>将每个chunk写入packet中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DFSOutputStream.class</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">writeChunk</span><span class="params">(<span class="keyword">byte</span>[] b, <span class="keyword">int</span> offset, <span class="keyword">int</span> len,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">byte</span>[] checksum, <span class="keyword">int</span> ckoff, <span class="keyword">int</span> cklen)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 如果当前currentPacket为null，则新创建一个</span></span><br><span class="line">  <span class="keyword">if</span> (currentPacket == <span class="keyword">null</span>) &#123;</span><br><span class="line">    currentPacket = createPacket(packetSize, chunksPerPacket, </span><br><span class="line">        bytesCurBlock, currentSeqno++);</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 先写入checksum，然后写入data</span></span><br><span class="line">  currentPacket.writeChecksum(checksum, ckoff, cklen);</span><br><span class="line">  currentPacket.writeData(b, offset, len);</span><br><span class="line">  currentPacket.numChunks++;</span><br><span class="line">  bytesCurBlock += len;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If packet is full, enqueue it for transmission</span></span><br><span class="line">  <span class="comment">// currentPacket已满 或者当前写入block的长度等于block的大小</span></span><br><span class="line">  <span class="keyword">if</span> (currentPacket.numChunks == currentPacket.maxChunks ||</span><br><span class="line">      bytesCurBlock == blockSize) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// 将packet放入队列dataQueue中</span></span><br><span class="line">    waitAndQueueCurrentPacket();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If the reopened file did not end at chunk boundary and the above</span></span><br><span class="line">    <span class="comment">// write filled up its partial chunk. Tell the summer to generate full </span></span><br><span class="line">    <span class="comment">// crc chunks from now on.</span></span><br><span class="line">    <span class="keyword">if</span> (appendChunk &amp;&amp; bytesCurBlock%bytesPerChecksum == <span class="number">0</span>) &#123;</span><br><span class="line">      appendChunk = <span class="keyword">false</span>;</span><br><span class="line">      resetChecksumBufSize();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 最后一个packet时，可能会小于block的大小，需重新计算下packet的大小</span></span><br><span class="line">    <span class="keyword">if</span> (!appendChunk) &#123;</span><br><span class="line">      <span class="keyword">int</span> psize = Math.min((<span class="keyword">int</span>)(blockSize-bytesCurBlock), dfsClient.getConf().writePacketSize);</span><br><span class="line">      computePacketChunkSize(psize, bytesPerChecksum);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// if encountering a block boundary, send an empty packet to </span></span><br><span class="line">    <span class="comment">// indicate the end of block and reset bytesCurBlock.</span></span><br><span class="line">    <span class="comment">// 达到block大小之后，发生一个空的packet</span></span><br><span class="line">    <span class="keyword">if</span> (bytesCurBlock == blockSize) &#123;</span><br><span class="line">      currentPacket = createPacket(<span class="number">0</span>, <span class="number">0</span>, bytesCurBlock, currentSeqno++);</span><br><span class="line">      currentPacket.lastPacketInBlock = <span class="keyword">true</span>;</span><br><span class="line">      currentPacket.syncBlock = shouldSyncBlock;</span><br><span class="line">      waitAndQueueCurrentPacket();</span><br><span class="line">      bytesCurBlock = <span class="number">0</span>;</span><br><span class="line">      lastFlushOffset = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>writeChunk</code>先将chunk写入currentPacket中，当currentPacket写满之后调用<code>waitAndQueueCurrentPacket</code>，将packet放入dataQueue队列，等待DataStreamer线程将packet写入pipeline中，<em>整个block发送完毕之后将发送一个空的packet</em>。</p>
<p>将packet放入dataQueue的逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">waitAndQueueCurrentPacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// If queue is full, then wait till we have enough space</span></span><br><span class="line">    <span class="comment">// dfs.client.write.max-packets-in-flight 默认值80</span></span><br><span class="line">    <span class="comment">// 当dataQueue和ackQueue的大小之和大于80时，等待</span></span><br><span class="line">    <span class="keyword">while</span> (!closed &amp;&amp; dataQueue.size() + ackQueue.size()  &gt; dfsClient.getConf().writeMaxPackets) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        dataQueue.wait();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">        <span class="comment">// If we get interrupted while waiting to queue data, we still need to get rid</span></span><br><span class="line">        <span class="comment">// of the current packet. This is because we have an invariant that if</span></span><br><span class="line">        <span class="comment">// currentPacket gets full, it will get queued before the next writeChunk.</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// Rather than wait around for space in the queue, we should instead try to</span></span><br><span class="line">        <span class="comment">// return to the caller as soon as possible, even though we slightly overrun</span></span><br><span class="line">        <span class="comment">// the MAX_PACKETS length.</span></span><br><span class="line">        Thread.currentThread().interrupt();</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    checkClosed();</span><br><span class="line">    <span class="comment">// 将currentPacket放入dataQueue</span></span><br><span class="line">    queueCurrentPacket();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ClosedChannelException e) &#123;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">queueCurrentPacket</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">    <span class="keyword">if</span> (currentPacket == <span class="keyword">null</span>) <span class="keyword">return</span>;</span><br><span class="line">    dataQueue.addLast(currentPacket);</span><br><span class="line">    lastQueuedSeqno = currentPacket.seqno;</span><br><span class="line">    <span class="keyword">if</span> (DFSClient.LOG.isDebugEnabled()) &#123;</span><br><span class="line">      DFSClient.LOG.debug(<span class="string">"Queued packet "</span> + currentPacket.seqno);</span><br><span class="line">    &#125;</span><br><span class="line">    currentPacket = <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 通知DataStreamer线程消费</span></span><br><span class="line">    dataQueue.notifyAll();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="DFSOutputStream-DataStreamer发送packet"><a href="#DFSOutputStream-DataStreamer发送packet" class="headerlink" title="DFSOutputStream.DataStreamer发送packet"></a>DFSOutputStream.DataStreamer发送packet</h2><p>DFSOutputStream中有两个队列，一个dataQueue一个ackQueue，两个队列大小的和不能超过<em>dfs.client.write.max-packets-in-flight</em>的值。<br>将currentPacket放入dataQueue中，并通知DataStreamer线程来消费，DataStreamer的run方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataStreamer.run</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> lastPacket = Time.now();</span><br><span class="line">  TraceScope traceScope = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (traceSpan != <span class="keyword">null</span>) &#123;</span><br><span class="line">    traceScope = Trace.continueSpan(traceSpan);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">while</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if the Responder encountered an error, shutdown Responder</span></span><br><span class="line">    <span class="keyword">if</span> (hasError &amp;&amp; response != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        response.close();</span><br><span class="line">        response.join();</span><br><span class="line">        response = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Packet one;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// process datanode IO errors if any</span></span><br><span class="line">      <span class="keyword">boolean</span> doSleep = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (hasError &amp;&amp; (errorIndex &gt;= <span class="number">0</span> || restartingNodeIndex &gt;= <span class="number">0</span>)) &#123;</span><br><span class="line">        doSleep = processDatanodeError();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        <span class="comment">// wait for a packet to be sent.</span></span><br><span class="line">        <span class="keyword">long</span> now = Time.now();</span><br><span class="line">        <span class="comment">// dataQueue为null，并且时间未超时，则等待</span></span><br><span class="line">        <span class="keyword">while</span> ((!streamerClosed &amp;&amp; !hasError &amp;&amp; dfsClient.clientRunning </span><br><span class="line">            &amp;&amp; dataQueue.size() == <span class="number">0</span> &amp;&amp; </span><br><span class="line">            (stage != BlockConstructionStage.DATA_STREAMING || </span><br><span class="line">             stage == BlockConstructionStage.DATA_STREAMING &amp;&amp; </span><br><span class="line">             now - lastPacket &lt; dfsClient.getConf().socketTimeout/<span class="number">2</span>)) || doSleep ) &#123;</span><br><span class="line">          <span class="keyword">long</span> timeout = dfsClient.getConf().socketTimeout/<span class="number">2</span> - (now-lastPacket);</span><br><span class="line">          timeout = timeout &lt;= <span class="number">0</span> ? <span class="number">1000</span> : timeout;</span><br><span class="line">          timeout = (stage == BlockConstructionStage.DATA_STREAMING)?</span><br><span class="line">             timeout : <span class="number">1000</span>;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            dataQueue.wait(timeout);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">            DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">          &#125;</span><br><span class="line">          doSleep = <span class="keyword">false</span>;</span><br><span class="line">          now = Time.now();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// get packet to be sent.</span></span><br><span class="line">        <span class="comment">// 发送packet，dataQueue为null，则发送一个心跳</span></span><br><span class="line">        <span class="keyword">if</span> (dataQueue.isEmpty()) &#123;</span><br><span class="line">          one = createHeartbeatPacket();</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          one = dataQueue.getFirst(); <span class="comment">// regular data packet</span></span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">assert</span> one != <span class="keyword">null</span>;</span><br><span class="line">      <span class="comment">// get new block from namenode.</span></span><br><span class="line">      <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_SETUP_CREATE) &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// 建立pipeline</span></span><br><span class="line">        setPipeline(nextBlockOutputStream());</span><br><span class="line">        <span class="comment">// 启动ResponseProcessor线程，更新DataStreamer的状态为DATA_STREAMING</span></span><br><span class="line">        initDataStreaming();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_SETUP_APPEND) &#123;</span><br><span class="line">        ...</span><br><span class="line">        setupPipelineForAppendOrRecovery();</span><br><span class="line">        initDataStreaming();</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">long</span> lastByteOffsetInBlock = one.getLastByteOffsetBlock();</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// 当前packet是block的最后一个packet，等待接收之前所有packet的ack</span></span><br><span class="line">      <span class="keyword">if</span> (one.lastPacketInBlock) &#123;</span><br><span class="line">        <span class="comment">// wait for all data packets have been successfully acked</span></span><br><span class="line">        <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">          <span class="keyword">while</span> (!streamerClosed &amp;&amp; !hasError &amp;&amp; </span><br><span class="line">              ackQueue.size() != <span class="number">0</span> &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">              <span class="comment">// wait for acks to arrive from datanodes</span></span><br><span class="line">              dataQueue.wait(<span class="number">1000</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">              DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        stage = BlockConstructionStage.PIPELINE_CLOSE;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// send the packet</span></span><br><span class="line">      <span class="comment">// 将packet从dataQueue移到ackQueue，准备发送packet</span></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        <span class="comment">// move packet from dataQueue to ackQueue</span></span><br><span class="line">        <span class="keyword">if</span> (!one.isHeartbeatPacket()) &#123;</span><br><span class="line">          dataQueue.removeFirst();</span><br><span class="line">          ackQueue.addLast(one);</span><br><span class="line">          dataQueue.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// write out data to remote datanode</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 将packet写入pipeline</span></span><br><span class="line">        one.writeTo(blockStream);</span><br><span class="line">        blockStream.flush();   </span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="comment">// HDFS-3398 treat primary DN is down since client is unable to </span></span><br><span class="line">        <span class="comment">// write to primary DN. If a failed or restarting node has already</span></span><br><span class="line">        <span class="comment">// been recorded by the responder, the following call will have no </span></span><br><span class="line">        <span class="comment">// effect. Pipeline recovery can handle only one node error at a</span></span><br><span class="line">        <span class="comment">// time. If the primary node fails again during the recovery, it</span></span><br><span class="line">        <span class="comment">// will be taken out then.</span></span><br><span class="line">        tryMarkPrimaryDatanodeFailed();</span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">      &#125;</span><br><span class="line">      lastPacket = Time.now();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// update bytesSent</span></span><br><span class="line">      <span class="keyword">long</span> tmpBytesSent = one.getLastByteOffsetBlock();</span><br><span class="line">      <span class="keyword">if</span> (bytesSent &lt; tmpBytesSent) &#123;</span><br><span class="line">        bytesSent = tmpBytesSent;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Is this block full?</span></span><br><span class="line">      <span class="comment">// 将当前packet发送之后，即将当前packet放入ackQueue</span></span><br><span class="line">      <span class="comment">// 如果当前packet是最后一个，则继续等待此packet的ack，</span></span><br><span class="line">      <span class="comment">// 然后endBlock</span></span><br><span class="line">      <span class="keyword">if</span> (one.lastPacketInBlock) &#123;</span><br><span class="line">        <span class="comment">// wait for the close packet has been acked</span></span><br><span class="line">        <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">          <span class="keyword">while</span> (!streamerClosed &amp;&amp; !hasError &amp;&amp; </span><br><span class="line">              ackQueue.size() != <span class="number">0</span> &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">            dataQueue.wait(<span class="number">1000</span>);<span class="comment">// wait for acks to arrive from datanodes</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (streamerClosed || hasError || !dfsClient.clientRunning) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        endBlock();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (progress != <span class="keyword">null</span>) &#123; progress.progress(); &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// This is used by unit test to trigger race conditions.</span></span><br><span class="line">      <span class="keyword">if</span> (artificialSlowdown != <span class="number">0</span> &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">        Thread.sleep(artificialSlowdown); </span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      <span class="comment">// Log warning if there was a real error.</span></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"DataStreamer Exception"</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (e <span class="keyword">instanceof</span> IOException) &#123;</span><br><span class="line">        setLastException((IOException)e);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        setLastException(<span class="keyword">new</span> IOException(<span class="string">"DataStreamer Exception: "</span>,e));</span><br><span class="line">      &#125;</span><br><span class="line">      hasError = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">if</span> (errorIndex == -<span class="number">1</span> &amp;&amp; restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        <span class="comment">// Not a datanode issue</span></span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (traceScope != <span class="keyword">null</span>) &#123;</span><br><span class="line">    traceScope.close();</span><br><span class="line">  &#125;</span><br><span class="line">  closeInternal();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DataStreamer线程主要是从dataQueue中拿出packet发送到pipeline，通过<code>setPipeline(nextBlockOutputStream())</code>创建pipeline，<code>nextBlockOutputStream</code>打开一个DataOutputStream</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> LocatedBlock <span class="title">nextBlockOutputStream</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  LocatedBlock lb = <span class="keyword">null</span>;</span><br><span class="line">  DatanodeInfo[] nodes = <span class="keyword">null</span>;</span><br><span class="line">  StorageType[] storageTypes = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">int</span> count = dfsClient.getConf().nBlockWriteRetry;</span><br><span class="line">  <span class="keyword">boolean</span> success = <span class="keyword">false</span>;</span><br><span class="line">  ExtendedBlock oldBlock = block;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    hasError = <span class="keyword">false</span>;</span><br><span class="line">    lastException.set(<span class="keyword">null</span>);</span><br><span class="line">    errorIndex = -<span class="number">1</span>;</span><br><span class="line">    success = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">long</span> startTime = Time.now();</span><br><span class="line">    DatanodeInfo[] excluded =</span><br><span class="line">        excludedNodes.getAllPresent(excludedNodes.asMap().keySet())</span><br><span class="line">        .keySet()</span><br><span class="line">        .toArray(<span class="keyword">new</span> DatanodeInfo[<span class="number">0</span>]);</span><br><span class="line">    block = oldBlock;</span><br><span class="line">    <span class="comment">// 向namenode发送add block请求</span></span><br><span class="line">    <span class="comment">// add block 时会checkLease(在analyzeFileState中调用)</span></span><br><span class="line">    lb = locateFollowingBlock(startTime,</span><br><span class="line">        excluded.length &gt; <span class="number">0</span> ? excluded : <span class="keyword">null</span>);</span><br><span class="line">    block = lb.getBlock();</span><br><span class="line">    block.setNumBytes(<span class="number">0</span>);</span><br><span class="line">    bytesSent = <span class="number">0</span>;</span><br><span class="line">    accessToken = lb.getBlockToken();</span><br><span class="line">    nodes = lb.getLocations();</span><br><span class="line">    storageTypes = lb.getStorageTypes();</span><br><span class="line"></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Connect to first DataNode in the list.</span></span><br><span class="line">    <span class="comment">// 与nodes中的第一个datanode建立连接</span></span><br><span class="line">    <span class="comment">// 向下游发送写请求，由Sender发送</span></span><br><span class="line">    success = createBlockOutputStream(nodes, storageTypes, <span class="number">0L</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">      DFSClient.LOG.info(<span class="string">"Abandoning "</span> + block);</span><br><span class="line">      dfsClient.namenode.abandonBlock(block, fileId, src,</span><br><span class="line">          dfsClient.clientName);</span><br><span class="line">      block = <span class="keyword">null</span>;</span><br><span class="line">      DFSClient.LOG.info(<span class="string">"Excluding datanode "</span> + nodes[errorIndex]);</span><br><span class="line">      excludedNodes.put(nodes[errorIndex], nodes[errorIndex]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">while</span> (!success &amp;&amp; --count &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (!success) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unable to create new block."</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> lb;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">createBlockOutputStream</span><span class="params">(DatanodeInfo[] nodes,</span></span></span><br><span class="line"><span class="function"><span class="params">    StorageType[] nodeStorageTypes, <span class="keyword">long</span> newGS, <span class="keyword">boolean</span> recoveryFlag)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  Status pipelineStatus = SUCCESS;</span><br><span class="line">  String firstBadLink = <span class="string">""</span>;</span><br><span class="line">  <span class="keyword">boolean</span> checkRestart = <span class="keyword">false</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// persist blocks on namenode on next flush</span></span><br><span class="line">  persistBlocks.set(<span class="keyword">true</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> refetchEncryptionKey = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">boolean</span> result = <span class="keyword">false</span>;</span><br><span class="line">    DataOutputStream out = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">null</span> == s : <span class="string">"Previous socket unclosed"</span>;</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">null</span> == blockReplyStream : <span class="string">"Previous blockReplyStream unclosed"</span>;</span><br><span class="line">      <span class="comment">// 建立socket连接</span></span><br><span class="line">      s = createSocketForPipeline(nodes[<span class="number">0</span>], nodes.length, dfsClient);</span><br><span class="line">      <span class="keyword">long</span> writeTimeout = dfsClient.getDatanodeWriteTimeout(nodes.length);</span><br><span class="line">      </span><br><span class="line">      OutputStream unbufOut = NetUtils.getOutputStream(s, writeTimeout);</span><br><span class="line">      InputStream unbufIn = NetUtils.getInputStream(s);</span><br><span class="line">      IOStreamPair saslStreams = dfsClient.saslClient.socketSend(s,</span><br><span class="line">        unbufOut, unbufIn, dfsClient, accessToken, nodes[<span class="number">0</span>]);</span><br><span class="line">      unbufOut = saslStreams.out;</span><br><span class="line">      unbufIn = saslStreams.in;</span><br><span class="line">      out = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(unbufOut,</span><br><span class="line">          HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">      blockReplyStream = <span class="keyword">new</span> DataInputStream(unbufIn);</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// send the request</span></span><br><span class="line">      <span class="comment">// 向dn发送写请求，由DataXceiver接收</span></span><br><span class="line">      <span class="keyword">new</span> Sender(out).writeBlock(blockCopy, nodeStorageTypes[<span class="number">0</span>], accessToken,</span><br><span class="line">          dfsClient.clientName, nodes, nodeStorageTypes, <span class="keyword">null</span>, bcs, </span><br><span class="line">          nodes.length, block.getNumBytes(), bytesSent, newGS,</span><br><span class="line">          checksum4WriteBlock, cachingStrategy.get(), isLazyPersistFile);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// receive ack for connect</span></span><br><span class="line">      BlockOpResponseProto resp = BlockOpResponseProto.parseFrom(</span><br><span class="line">          PBHelper.vintPrefixed(blockReplyStream));</span><br><span class="line">      pipelineStatus = resp.getStatus();</span><br><span class="line">      firstBadLink = resp.getFirstBadLink();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Got an restart OOB ack.</span></span><br><span class="line">      <span class="comment">// If a node is already restarting, this status is not likely from</span></span><br><span class="line">      <span class="comment">// the same node. If it is from a different node, it is not</span></span><br><span class="line">      <span class="comment">// from the local datanode. Thus it is safe to treat this as a</span></span><br><span class="line">      <span class="comment">// regular node error.</span></span><br><span class="line">      <span class="keyword">if</span> (PipelineAck.isRestartOOBStatus(pipelineStatus) &amp;&amp;</span><br><span class="line">        restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        checkRestart = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"A datanode is restarting."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (pipelineStatus != SUCCESS) &#123;</span><br><span class="line">        <span class="keyword">if</span> (pipelineStatus == Status.ERROR_ACCESS_TOKEN) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> InvalidBlockTokenException(</span><br><span class="line">              <span class="string">"Got access token error for connect ack with firstBadLink as "</span></span><br><span class="line">                  + firstBadLink);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad connect ack with firstBadLink as "</span></span><br><span class="line">              + firstBadLink);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">null</span> == blockStream : <span class="string">"Previous blockStream unclosed"</span>;</span><br><span class="line">      blockStream = out;</span><br><span class="line">      result =  <span class="keyword">true</span>; <span class="comment">// success</span></span><br><span class="line">      restartingNodeIndex = -<span class="number">1</span>;</span><br><span class="line">      hasError = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Exception in createBlockOutputStream"</span>, ie);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (ie <span class="keyword">instanceof</span> InvalidEncryptionKeyException &amp;&amp; refetchEncryptionKey &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Will fetch a new encryption key and retry, "</span> </span><br><span class="line">            + <span class="string">"encryption key was invalid when connecting to "</span></span><br><span class="line">            + nodes[<span class="number">0</span>] + <span class="string">" : "</span> + ie);</span><br><span class="line">        <span class="comment">// The encryption key used is invalid.</span></span><br><span class="line">        refetchEncryptionKey--;</span><br><span class="line">        dfsClient.clearDataEncryptionKey();</span><br><span class="line">        <span class="comment">// Don't close the socket/exclude this node just yet. Try again with</span></span><br><span class="line">        <span class="comment">// a new encryption key.</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// find the datanode that matches</span></span><br><span class="line">      <span class="keyword">if</span> (firstBadLink.length() != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nodes.length; i++) &#123;</span><br><span class="line">          <span class="comment">// NB: Unconditionally using the xfer addr w/o hostname</span></span><br><span class="line">          <span class="keyword">if</span> (firstBadLink.equals(nodes[i].getXferAddr())) &#123;</span><br><span class="line">            errorIndex = i;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">assert</span> checkRestart == <span class="keyword">false</span>;</span><br><span class="line">        errorIndex = <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Check whether there is a restart worth waiting for.</span></span><br><span class="line">      <span class="keyword">if</span> (checkRestart &amp;&amp; shouldWaitForRestart(errorIndex)) &#123;</span><br><span class="line">        restartDeadline = dfsClient.getConf().datanodeRestartTimeout +</span><br><span class="line">            Time.now();</span><br><span class="line">        restartingNodeIndex = errorIndex;</span><br><span class="line">        errorIndex = -<span class="number">1</span>;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Waiting for the datanode to be restarted: "</span> +</span><br><span class="line">            nodes[restartingNodeIndex]);</span><br><span class="line">      &#125;</span><br><span class="line">      hasError = <span class="keyword">true</span>;</span><br><span class="line">      setLastException(ie);</span><br><span class="line">      result =  <span class="keyword">false</span>;  <span class="comment">// error</span></span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (!result) &#123;</span><br><span class="line">        IOUtils.closeSocket(s);</span><br><span class="line">        s = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(out);</span><br><span class="line">        out = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(blockReplyStream);</span><br><span class="line">        blockReplyStream = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>nextBlockOutputStream中通过<code>locateFollowingBlock</code>得到block的locateLocations，由<code>createBlockOutputStream</code>与nodes中的第一个dn建立socket连接(<em>此过程中会建立一个输出流和一个输入流，其中输出流用来向下游发送packet，输入流用来接收下游发来的ack</em>)，<em>并发送writeBlock请求</em>。最后nextBlockOutputStream返回nodes列表，由<code>setPipeline</code>设置当前block的pipeLine</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setPipeline</span><span class="params">(DatanodeInfo[] nodes, StorageType[] storageTypes,</span></span></span><br><span class="line"><span class="function"><span class="params">    String[] storageIDs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.nodes = nodes;</span><br><span class="line">  <span class="keyword">this</span>.storageTypes = storageTypes;</span><br><span class="line">  <span class="keyword">this</span>.storageIDs = storageIDs;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>建立pipeLine之后，还要启一个新的线程<code>ResponseProcessor</code>接收packet的ack，这个线程在<code>initDataStreaming</code>中启动，并更新DataStreamer线程的状态为<em>DATA_STREAMING</em></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initDataStreaming</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.setName(<span class="string">"DataStreamer for file "</span> + src +</span><br><span class="line">      <span class="string">" block "</span> + block);</span><br><span class="line">  response = <span class="keyword">new</span> ResponseProcessor(nodes);</span><br><span class="line">  response.start();</span><br><span class="line">  stage = BlockConstructionStage.DATA_STREAMING;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>准备工作结束之后，就是发送packet，调用<code>one.writeTo(blockStream)</code>，<strong>这里只是将packet写入pipeline中的第一个dn</strong>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">writeTo</span><span class="params">(DataOutputStream stm)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> dataLen = dataPos - dataStart;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> checksumLen = checksumPos - checksumStart;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> pktLen = HdfsConstants.BYTES_IN_INTEGER + dataLen + checksumLen;</span><br><span class="line"></span><br><span class="line">  PacketHeader header = <span class="keyword">new</span> PacketHeader(</span><br><span class="line">    pktLen, offsetInBlock, seqno, lastPacketInBlock, dataLen, syncBlock);</span><br><span class="line">  <span class="comment">// checksumPos不等于dataStart时，将checksum移动到data前面，</span></span><br><span class="line">  <span class="comment">// 紧挨着data，为header空出足够的空间</span></span><br><span class="line">  <span class="keyword">if</span> (checksumPos != dataStart) &#123;</span><br><span class="line">    <span class="comment">// Move the checksum to cover the gap. This can happen for the last</span></span><br><span class="line">    <span class="comment">// packet or during an hflush/hsync call.</span></span><br><span class="line">    System.arraycopy(buf, checksumStart, buf, </span><br><span class="line">                     dataStart - checksumLen , checksumLen); </span><br><span class="line">    checksumPos = dataStart;</span><br><span class="line">    checksumStart = checksumPos - checksumLen;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> headerStart = checksumStart - header.getSerializedSize();</span><br><span class="line">  <span class="keyword">assert</span> checksumStart + <span class="number">1</span> &gt;= header.getSerializedSize();</span><br><span class="line">  <span class="keyword">assert</span> checksumPos == dataStart;</span><br><span class="line">  <span class="keyword">assert</span> headerStart &gt;= <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">assert</span> headerStart + header.getSerializedSize() == checksumStart;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Copy the header data into the buffer immediately preceding the checksum</span></span><br><span class="line">  <span class="comment">// data.</span></span><br><span class="line">  <span class="comment">// 将header复制到packet的buf中，组成一个完整的packet</span></span><br><span class="line">  System.arraycopy(header.getBytes(), <span class="number">0</span>, buf, headerStart,</span><br><span class="line">      header.getSerializedSize());</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// corrupt the data for testing.</span></span><br><span class="line">  <span class="keyword">if</span> (DFSClientFaultInjector.get().corruptPacket()) &#123;</span><br><span class="line">    buf[headerStart+header.getSerializedSize() + checksumLen + dataLen-<span class="number">1</span>] ^= <span class="number">0xff</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Write the now contiguous full packet to the output stream.</span></span><br><span class="line">  <span class="comment">// 将buf写入输出流中</span></span><br><span class="line">  stm.write(buf, headerStart, header.getSerializedSize() + checksumLen + dataLen);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// undo corruption.</span></span><br><span class="line">  <span class="keyword">if</span> (DFSClientFaultInjector.get().uncorruptPacket()) &#123;</span><br><span class="line">    buf[headerStart+header.getSerializedSize() + checksumLen + dataLen-<span class="number">1</span>] ^= <span class="number">0xff</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="DataXceiver线程写入DataNode"><a href="#DataXceiver线程写入DataNode" class="headerlink" title="DataXceiver线程写入DataNode"></a>DataXceiver线程写入DataNode</h2><p>以上的流程可以看做是client端，client端将数据发送到dn上，由dn负责将packet写入本地磁盘，并向下一个dn发送。这其中涉及到DataXceiverServer线程和DataXceiver线程，DataXceiverServer相当于监听器，而DataXceiver相当于handle，由DataXceiverServer监听来自client的socket请求，根据请求创建DataXceiver线程。由DataXceiver线程进行写dn。看下DataXceiverServer.run方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Peer peer = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">while</span> (datanode.shouldRun &amp;&amp; !datanode.shutdownForUpgrade) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 接收client的socket请求</span></span><br><span class="line">      peer = peerServer.accept();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Make sure the xceiver count is not exceeded</span></span><br><span class="line">      <span class="keyword">int</span> curXceiverCount = datanode.getXceiverCount();</span><br><span class="line">      <span class="comment">// 查看当前线程是否超出上限 dfs.datanode.max.transfer.threads控制</span></span><br><span class="line">      <span class="keyword">if</span> (curXceiverCount &gt; maxXceiverCount) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Xceiver count "</span> + curXceiverCount</span><br><span class="line">            + <span class="string">" exceeds the limit of concurrent xcievers: "</span></span><br><span class="line">            + maxXceiverCount);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 新启一个DataXceiver线程</span></span><br><span class="line">      <span class="keyword">new</span> Daemon(datanode.threadGroup,</span><br><span class="line">          DataXceiver.create(peer, datanode, <span class="keyword">this</span>))</span><br><span class="line">          .start();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (SocketTimeoutException ignored)</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>具体的处理逻辑在DataXceiver线程中，查看run方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> opsProcessed = <span class="number">0</span>;</span><br><span class="line">  Op op = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="comment">// We process requests in a loop, and stay around for a short timeout.</span></span><br><span class="line">    <span class="comment">// This optimistic behaviour allows the other end to reuse connections.</span></span><br><span class="line">    <span class="comment">// Setting keepalive timeout to 0 disable this behavior.</span></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">      updateCurrentThreadName(<span class="string">"Waiting for operation #"</span> + (opsProcessed + <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// 读取操作码</span></span><br><span class="line">        op = readOp();</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedIOException ignored) &#123;</span><br><span class="line">        <span class="comment">// Time out while we wait for client rpc</span></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException err) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// 处理操作码</span></span><br><span class="line">      processOp(op);</span><br><span class="line">      ++opsProcessed;</span><br><span class="line">    &#125; <span class="keyword">while</span> ((peer != <span class="keyword">null</span>) &amp;&amp;</span><br><span class="line">        (!peer.isClosed() &amp;&amp; dnConf.socketKeepaliveTimeout &gt; <span class="number">0</span>));</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DataXceiver.run方法中主要是读取操作码(readOp)并解析操作码(processOp)，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Receiver.class</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">processOp</span><span class="params">(Op op)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">switch</span>(op) &#123;</span><br><span class="line">  <span class="keyword">case</span> READ_BLOCK:</span><br><span class="line">    opReadBlock();</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> WRITE_BLOCK:</span><br><span class="line">    opWriteBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> REPLACE_BLOCK:</span><br><span class="line">    opReplaceBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> COPY_BLOCK:</span><br><span class="line">    opCopyBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> BLOCK_CHECKSUM:</span><br><span class="line">    opBlockChecksum(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> TRANSFER_BLOCK:</span><br><span class="line">    opTransferBlock(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> REQUEST_SHORT_CIRCUIT_FDS:</span><br><span class="line">    opRequestShortCircuitFds(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> RELEASE_SHORT_CIRCUIT_FDS:</span><br><span class="line">    opReleaseShortCircuitFds(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">case</span> REQUEST_SHORT_CIRCUIT_SHM:</span><br><span class="line">    opRequestShortCircuitShm(in);</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  <span class="keyword">default</span>:</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unknown op "</span> + op + <span class="string">" in data stream"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里是写入操作，则调用<code>opWriteBlock</code>，opWriteBlock中又调用writeBlock，DataXceiver重新了writeBlock，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DataXceiver.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">writeBlock</span><span class="params">(<span class="keyword">final</span> ExtendedBlock block,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType storageType, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> Token&lt;BlockTokenIdentifier&gt; blockToken,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> String clientname,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo[] targets,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> StorageType[] targetStorageTypes, </span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> DatanodeInfo srcDataNode,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> BlockConstructionStage stage,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">int</span> pipelineSize,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> minBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> maxBytesRcvd,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> latestGenerationStamp,</span></span></span><br><span class="line"><span class="function"><span class="params">    DataChecksum requestedChecksum,</span></span></span><br><span class="line"><span class="function"><span class="params">    CachingStrategy cachingStrategy,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">boolean</span> allowLazyPersist)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  previousOpClientName = clientname;</span><br><span class="line">  updateCurrentThreadName(<span class="string">"Receiving block "</span> + block);</span><br><span class="line">  <span class="comment">// clientname不为null，则isDatanode为false，isClient为true</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> isDatanode = clientname.length() == <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> isClient = !isDatanode;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> isTransfer = stage == BlockConstructionStage.TRANSFER_RBW</span><br><span class="line">      || stage == BlockConstructionStage.TRANSFER_FINALIZED;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// We later mutate block's generation stamp and length, but we need to</span></span><br><span class="line">  <span class="comment">// forward the original version of the block to downstream mirrors, so</span></span><br><span class="line">  <span class="comment">// make a copy here.</span></span><br><span class="line">  <span class="keyword">final</span> ExtendedBlock originalBlock = <span class="keyword">new</span> ExtendedBlock(block);</span><br><span class="line">  <span class="keyword">if</span> (block.getNumBytes() == <span class="number">0</span>) &#123;</span><br><span class="line">    block.setNumBytes(dataXceiverServer.estimateBlockSize);</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// reply to upstream datanode or client</span></span><br><span class="line">  <span class="comment">// 向upstream或者client建立一个输出流，用于发送ack </span></span><br><span class="line">  <span class="keyword">final</span> DataOutputStream replyOut = <span class="keyword">new</span> DataOutputStream(</span><br><span class="line">      <span class="keyword">new</span> BufferedOutputStream(</span><br><span class="line">          getOutputStream(),</span><br><span class="line">          HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">  ...</span><br><span class="line">  DataOutputStream mirrorOut = <span class="keyword">null</span>;  <span class="comment">// stream to next target</span></span><br><span class="line">  DataInputStream mirrorIn = <span class="keyword">null</span>;    <span class="comment">// reply from next target</span></span><br><span class="line">  Socket mirrorSock = <span class="keyword">null</span>;           <span class="comment">// socket to next target</span></span><br><span class="line">  String mirrorNode = <span class="keyword">null</span>;           <span class="comment">// the name:port of next target</span></span><br><span class="line">  String firstBadLink = <span class="string">""</span>;           <span class="comment">// first datanode that failed in connection setup</span></span><br><span class="line">  Status mirrorInStatus = SUCCESS;</span><br><span class="line">  <span class="keyword">final</span> String storageUuid;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (isDatanode || </span><br><span class="line">        stage != BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) &#123;</span><br><span class="line">      <span class="comment">// open a block receiver</span></span><br><span class="line">      <span class="comment">// 实例化blockReceiver，用于接收packet</span></span><br><span class="line">      blockReceiver = <span class="keyword">new</span> BlockReceiver(block, storageType, in,</span><br><span class="line">          peer.getRemoteAddressString(),</span><br><span class="line">          peer.getLocalAddressString(),</span><br><span class="line">          stage, latestGenerationStamp, minBytesRcvd, maxBytesRcvd,</span><br><span class="line">          clientname, srcDataNode, datanode, requestedChecksum,</span><br><span class="line">          cachingStrategy, allowLazyPersist);</span><br><span class="line"></span><br><span class="line">      storageUuid = blockReceiver.getStorageUuid();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      storageUuid = datanode.data.recoverClose(</span><br><span class="line">          block, latestGenerationStamp, minBytesRcvd);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Connect to downstream machine, if appropriate</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">if</span> (targets.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      InetSocketAddress mirrorTarget = <span class="keyword">null</span>;</span><br><span class="line">      <span class="comment">// Connect to backup machine</span></span><br><span class="line">      <span class="comment">// 得到downstream的dn</span></span><br><span class="line">      mirrorNode = targets[<span class="number">0</span>].getXferAddr(connectToDnViaHostname);</span><br><span class="line">      ...</span><br><span class="line">      mirrorTarget = NetUtils.createSocketAddr(mirrorNode);</span><br><span class="line">      mirrorSock = datanode.newSocket();</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> timeoutValue = dnConf.socketTimeout</span><br><span class="line">            + (HdfsServerConstants.READ_TIMEOUT_EXTENSION * targets.length);</span><br><span class="line">        <span class="keyword">int</span> writeTimeout = dnConf.socketWriteTimeout + </span><br><span class="line">                    (HdfsServerConstants.WRITE_TIMEOUT_EXTENSION * targets.length);</span><br><span class="line">        <span class="comment">// 建立连接</span></span><br><span class="line">        NetUtils.connect(mirrorSock, mirrorTarget, timeoutValue);</span><br><span class="line">        mirrorSock.setSoTimeout(timeoutValue);</span><br><span class="line">        mirrorSock.setSendBufferSize(HdfsConstants.DEFAULT_DATA_SOCKET_SIZE);</span><br><span class="line">        </span><br><span class="line">        OutputStream unbufMirrorOut = NetUtils.getOutputStream(mirrorSock,</span><br><span class="line">            writeTimeout);</span><br><span class="line">        InputStream unbufMirrorIn = NetUtils.getInputStream(mirrorSock);</span><br><span class="line">        DataEncryptionKeyFactory keyFactory =</span><br><span class="line">          datanode.getDataEncryptionKeyFactoryForBlock(block);</span><br><span class="line">        IOStreamPair saslStreams = datanode.saslClient.socketSend(mirrorSock,</span><br><span class="line">          unbufMirrorOut, unbufMirrorIn, keyFactory, blockToken, targets[<span class="number">0</span>]);</span><br><span class="line">        unbufMirrorOut = saslStreams.out;</span><br><span class="line">        unbufMirrorIn = saslStreams.in;</span><br><span class="line">        mirrorOut = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(unbufMirrorOut,</span><br><span class="line">            HdfsConstants.SMALL_BUFFER_SIZE));</span><br><span class="line">        mirrorIn = <span class="keyword">new</span> DataInputStream(unbufMirrorIn);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Do not propagate allowLazyPersist to downstream DataNodes.</span></span><br><span class="line">        <span class="comment">// 向downstream发送写请求</span></span><br><span class="line">        <span class="keyword">new</span> Sender(mirrorOut).writeBlock(originalBlock, targetStorageTypes[<span class="number">0</span>],</span><br><span class="line">            blockToken, clientname, targets, targetStorageTypes, srcDataNode,</span><br><span class="line">            stage, pipelineSize, minBytesRcvd, maxBytesRcvd,</span><br><span class="line">            latestGenerationStamp, requestedChecksum, cachingStrategy, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        mirrorOut.flush();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// read connect ack (only for clients, not for replication req)</span></span><br><span class="line">        <span class="comment">// 得到下游的connect-ack</span></span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          BlockOpResponseProto connectAck =</span><br><span class="line">            BlockOpResponseProto.parseFrom(PBHelper.vintPrefixed(mirrorIn));</span><br><span class="line">          mirrorInStatus = connectAck.getStatus();</span><br><span class="line">          firstBadLink = connectAck.getFirstBadLink();</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled() || mirrorInStatus != SUCCESS) &#123;</span><br><span class="line">            LOG.info(<span class="string">"Datanode "</span> + targets.length +</span><br><span class="line">                     <span class="string">" got response for connect ack "</span> +</span><br><span class="line">                     <span class="string">" from downstream datanode with firstbadlink as "</span> +</span><br><span class="line">                     firstBadLink);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      <span class="comment">// 这个catch捕获的是pipeline建立时的异常</span></span><br><span class="line">      <span class="comment">// 当前dn与下游建立连接时发生的异常</span></span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          BlockOpResponseProto.newBuilder()</span><br><span class="line">            .setStatus(ERROR)</span><br><span class="line">             <span class="comment">// NB: Unconditionally using the xfer addr w/o hostname</span></span><br><span class="line">            .setFirstBadLink(targets[<span class="number">0</span>].getXferAddr())</span><br><span class="line">            .build()</span><br><span class="line">            .writeDelimitedTo(replyOut);</span><br><span class="line">          replyOut.flush();</span><br><span class="line">        &#125;</span><br><span class="line">        IOUtils.closeStream(mirrorOut);</span><br><span class="line">        mirrorOut = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeStream(mirrorIn);</span><br><span class="line">        mirrorIn = <span class="keyword">null</span>;</span><br><span class="line">        IOUtils.closeSocket(mirrorSock);</span><br><span class="line">        mirrorSock = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (isClient) &#123;</span><br><span class="line">          LOG.error(datanode + <span class="string">":Exception transfering block "</span> +</span><br><span class="line">                    block + <span class="string">" to mirror "</span> + mirrorNode + <span class="string">": "</span> + e);</span><br><span class="line">          <span class="keyword">throw</span> e;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          LOG.info(datanode + <span class="string">":Exception transfering "</span> +</span><br><span class="line">                   block + <span class="string">" to mirror "</span> + mirrorNode +</span><br><span class="line">                   <span class="string">"- continuing without the mirror"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;<span class="comment">// if结束，判断是否有下游dn，是否建立连接</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// send connect-ack to source for clients and not transfer-RBW/Finalized</span></span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; !isTransfer) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// 向upstream发送connect-ack</span></span><br><span class="line">      BlockOpResponseProto.newBuilder()</span><br><span class="line">        .setStatus(mirrorInStatus)</span><br><span class="line">        .setFirstBadLink(firstBadLink)</span><br><span class="line">        .build()</span><br><span class="line">        .writeDelimitedTo(replyOut);</span><br><span class="line">      replyOut.flush();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 向上游发送connect-ack之后准备接收block packet</span></span><br><span class="line">    <span class="comment">// receive the block and mirror to the next target</span></span><br><span class="line">    <span class="keyword">if</span> (blockReceiver != <span class="keyword">null</span>) &#123;</span><br><span class="line">      String mirrorAddr = (mirrorSock == <span class="keyword">null</span>) ? <span class="keyword">null</span> : mirrorNode;</span><br><span class="line">      <span class="comment">// 接收block</span></span><br><span class="line">      blockReceiver.receiveBlock(mirrorOut, mirrorIn, replyOut,</span><br><span class="line">          mirrorAddr, <span class="keyword">null</span>, targets, <span class="keyword">false</span>);</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update its generation stamp</span></span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; </span><br><span class="line">        stage == BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) &#123;</span><br><span class="line">      block.setGenerationStamp(latestGenerationStamp);</span><br><span class="line">      block.setNumBytes(minBytesRcvd);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// if this write is for a replication request or recovering</span></span><br><span class="line">    <span class="comment">// a failed close for client, then confirm block. For other client-writes,</span></span><br><span class="line">    <span class="comment">// the block is finalized in the PacketResponder.</span></span><br><span class="line">    <span class="keyword">if</span> (isDatanode ||</span><br><span class="line">        stage == BlockConstructionStage.PIPELINE_CLOSE_RECOVERY) &#123;</span><br><span class="line">      datanode.closeBlock(block, DataNode.EMPTY_DEL_HINT, storageUuid);</span><br><span class="line">      LOG.info(<span class="string">"Received "</span> + block + <span class="string">" src: "</span> + remoteAddress + <span class="string">" dest: "</span></span><br><span class="line">          + localAddress + <span class="string">" of size "</span> + block.getNumBytes());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">    LOG.info(<span class="string">"opWriteBlock "</span> + block + <span class="string">" received exception "</span> + ioe);</span><br><span class="line">    <span class="keyword">throw</span> ioe;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// close all opened streams</span></span><br><span class="line">    ...</span><br><span class="line">    blockReceiver = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>writeBlock中实例化blockReceiver，由blockReceiver.receiveBlock接收packet并写入downstream和本地磁盘，在接收packet之前先创建于downstream的连接，并向downstream发送写请求</em>。下面来看下receiveBlock的代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">receiveBlock</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    DataOutputStream mirrOut, // output to next datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    DataInputStream mirrIn,   // input from next datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    DataOutputStream replyOut,  // output to previous datanode</span></span></span><br><span class="line"><span class="function"><span class="params">    String mirrAddr, DataTransferThrottler throttlerArg,</span></span></span><br><span class="line"><span class="function"><span class="params">    DatanodeInfo[] downstreams,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isReplaceBlock)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">    syncOnClose = datanode.getDnConf().syncOnClose;</span><br><span class="line">    <span class="keyword">boolean</span> responderClosed = <span class="keyword">false</span>;</span><br><span class="line">    mirrorOut = mirrOut;</span><br><span class="line">    mirrorAddr = mirrAddr;</span><br><span class="line">    throttler = throttlerArg;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.replyOut = replyOut;</span><br><span class="line">    <span class="keyword">this</span>.isReplaceBlock = isReplaceBlock;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (isClient &amp;&amp; !isTransfer) &#123;</span><br><span class="line">      responder = <span class="keyword">new</span> Daemon(datanode.threadGroup, </span><br><span class="line">          <span class="keyword">new</span> PacketResponder(replyOut, mirrIn, downstreams));</span><br><span class="line">      responder.start(); <span class="comment">// start thread to processes responses</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里是个空循环</span></span><br><span class="line">    <span class="comment">// 不停的调用receivePacket接收packet，直到整个block的packet接收完</span></span><br><span class="line">    <span class="keyword">while</span> (receivePacket() &gt;= <span class="number">0</span>) &#123; <span class="comment">/* Receive until the last packet */</span> &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// wait for all outstanding packet responses. And then</span></span><br><span class="line">    <span class="comment">// indicate responder to gracefully shutdown.</span></span><br><span class="line">    <span class="comment">// Mark that responder has been closed for future processing</span></span><br><span class="line">    <span class="keyword">if</span> (responder != <span class="keyword">null</span>) &#123;</span><br><span class="line">      ((PacketResponder)responder.getRunnable()).close();</span><br><span class="line">      responderClosed = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If this write is for a replication or transfer-RBW/Finalized,</span></span><br><span class="line">    <span class="comment">// then finalize block or convert temporary to RBW.</span></span><br><span class="line">    <span class="comment">// For client-writes, the block is finalized in the PacketResponder.</span></span><br><span class="line">    <span class="keyword">if</span> (isDatanode || isTransfer) &#123;</span><br><span class="line">      <span class="comment">// close the block/crc files</span></span><br><span class="line">      close();</span><br><span class="line">      block.setNumBytes(replicaInfo.getNumBytes());</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (stage == BlockConstructionStage.TRANSFER_RBW) &#123;</span><br><span class="line">        <span class="comment">// for TRANSFER_RBW, convert temporary to RBW</span></span><br><span class="line">        datanode.data.convertTemporaryToRbw(block);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// for isDatnode or TRANSFER_FINALIZED</span></span><br><span class="line">        <span class="comment">// Finalize the block.</span></span><br><span class="line">        datanode.data.finalizeBlock(block);</span><br><span class="line">      &#125;</span><br><span class="line">      datanode.metrics.incrBlocksWritten();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>receiveBlock会启动PacketResponder线程来接收来自downstream的packet ack和向upstream发送packet ack。<em>PacketResponder中也有个ackQueue队列</em>(注意和DFSOutputStream中的dataQueue和ackQueue区分)，receivePacket将接收的packet放入ackQueue中，由PacketResponder接收ack并从ackQueue中取出packet。receivePacket代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">receivePacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// read the next packet</span></span><br><span class="line">  <span class="comment">// 从流中读取packet</span></span><br><span class="line">  packetReceiver.receiveNextPacket(in);</span><br><span class="line"></span><br><span class="line">  PacketHeader header = packetReceiver.getHeader();</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Sanity check the header</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">long</span> offsetInBlock = header.getOffsetInBlock();</span><br><span class="line">  <span class="keyword">long</span> seqno = header.getSeqno();</span><br><span class="line">  <span class="keyword">boolean</span> lastPacketInBlock = header.isLastPacketInBlock();</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> len = header.getDataLen();</span><br><span class="line">  <span class="keyword">boolean</span> syncBlock = header.getSyncBlock();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// avoid double sync'ing on close</span></span><br><span class="line">  <span class="keyword">if</span> (syncBlock &amp;&amp; lastPacketInBlock) &#123;</span><br><span class="line">    <span class="keyword">this</span>.syncOnClose = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// update received bytes</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> firstByteInBlock = offsetInBlock;</span><br><span class="line">  offsetInBlock += len;</span><br><span class="line">  <span class="keyword">if</span> (replicaInfo.getNumBytes() &lt; offsetInBlock) &#123;</span><br><span class="line">    replicaInfo.setNumBytes(offsetInBlock);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// put in queue for pending acks, unless sync was requested</span></span><br><span class="line">  <span class="comment">// 在向downstream发送packet之前，将packet放入ackQueue中</span></span><br><span class="line">  <span class="keyword">if</span> (responder != <span class="keyword">null</span> &amp;&amp; !syncBlock &amp;&amp; !shouldVerifyChecksum()) &#123;</span><br><span class="line">    ((PacketResponder) responder.getRunnable()).enqueue(seqno,</span><br><span class="line">        lastPacketInBlock, offsetInBlock, Status.SUCCESS);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//First write the packet to the mirror:</span></span><br><span class="line">  <span class="keyword">if</span> (mirrorOut != <span class="keyword">null</span> &amp;&amp; !mirrorError) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">long</span> begin = Time.monotonicNow();</span><br><span class="line">      <span class="comment">// 向downstream发送packet</span></span><br><span class="line">      packetReceiver.mirrorPacketTo(mirrorOut);</span><br><span class="line">      mirrorOut.flush();</span><br><span class="line">      <span class="keyword">long</span> duration = Time.monotonicNow() - begin;</span><br><span class="line">      <span class="keyword">if</span> (duration &gt; datanodeSlowLogThresholdMs) &#123;</span><br><span class="line">        LOG.warn(<span class="string">"Slow BlockReceiver write packet to mirror took "</span> + duration</span><br><span class="line">            + <span class="string">"ms (threshold="</span> + datanodeSlowLogThresholdMs + <span class="string">"ms)"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      handleMirrorOutError(e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将packet的data部分写入本地时的buf</span></span><br><span class="line">  ByteBuffer dataBuf = packetReceiver.getDataSlice();</span><br><span class="line">  ByteBuffer checksumBuf = packetReceiver.getChecksumSlice();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (lastPacketInBlock || len == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"Receiving an empty packet or the end of the block "</span> + block);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// sync block if requested</span></span><br><span class="line">    <span class="keyword">if</span> (syncBlock) &#123;</span><br><span class="line">      flushOrSync(<span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> checksumLen = diskChecksum.getChecksumSize(len);</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> checksumReceivedLen = checksumBuf.capacity();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (checksumReceivedLen &gt; <span class="number">0</span> &amp;&amp; checksumReceivedLen != checksumLen) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Invalid checksum length: received length is "</span></span><br><span class="line">          + checksumReceivedLen + <span class="string">" but expected length is "</span> + checksumLen);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (checksumReceivedLen &gt; <span class="number">0</span> &amp;&amp; shouldVerifyChecksum()) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 校验checksum</span></span><br><span class="line">        verifyChunks(dataBuf, checksumBuf);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">        <span class="comment">// checksum error detected locally. there is no reason to continue.</span></span><br><span class="line">        <span class="keyword">if</span> (responder != <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            ((PacketResponder) responder.getRunnable()).enqueue(seqno,</span><br><span class="line">                lastPacketInBlock, offsetInBlock,</span><br><span class="line">                Status.ERROR_CHECKSUM);</span><br><span class="line">            <span class="comment">// Wait until the responder sends back the response</span></span><br><span class="line">            <span class="comment">// and interrupt this thread.</span></span><br><span class="line">            Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (InterruptedException e) &#123; &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Terminating due to a checksum error."</span> + ioe);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (needsChecksumTranslation) &#123;</span><br><span class="line">        <span class="comment">// overwrite the checksums in the packet buffer with the</span></span><br><span class="line">        <span class="comment">// appropriate polynomial for the disk storage.</span></span><br><span class="line">        translateChunks(dataBuf, checksumBuf);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// checksum在传输过程中丢失，则重新计算</span></span><br><span class="line">    <span class="keyword">if</span> (checksumReceivedLen == <span class="number">0</span> &amp;&amp; !streams.isTransientStorage()) &#123;</span><br><span class="line">      <span class="comment">// checksum is missing, need to calculate it</span></span><br><span class="line">      checksumBuf = ByteBuffer.allocate(checksumLen);</span><br><span class="line">      diskChecksum.calculateChunkedSums(dataBuf, checksumBuf);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// by this point, the data in the buffer uses the disk checksum</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">boolean</span> shouldNotWriteChecksum = checksumReceivedLen == <span class="number">0</span></span><br><span class="line">        &amp;&amp; streams.isTransientStorage();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 得到磁盘中当前block的长度</span></span><br><span class="line">      <span class="keyword">long</span> onDiskLen = replicaInfo.getBytesOnDisk();</span><br><span class="line">      <span class="keyword">if</span> (onDiskLen&lt;offsetInBlock) &#123;</span><br><span class="line">        <span class="comment">//finally write to the disk :</span></span><br><span class="line">        <span class="comment">// 当磁盘中已写入block的长度不是chunk的整数倍，则将最后一个checksum进行重写</span></span><br><span class="line">        <span class="keyword">if</span> (onDiskLen % bytesPerChecksum != <span class="number">0</span>) &#123; </span><br><span class="line">          <span class="comment">// prepare to overwrite last checksum</span></span><br><span class="line">          adjustCrcFilePosition();</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// If this is a partial chunk, then read in pre-existing checksum</span></span><br><span class="line">        Checksum partialCrc = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">if</span> (!shouldNotWriteChecksum &amp;&amp; firstByteInBlock % bytesPerChecksum != <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">            LOG.debug(<span class="string">"receivePacket for "</span> + block </span><br><span class="line">                + <span class="string">": bytesPerChecksum="</span> + bytesPerChecksum                  </span><br><span class="line">                + <span class="string">" does not divide firstByteInBlock="</span> + firstByteInBlock);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">long</span> offsetInChecksum = BlockMetadataHeader.getHeaderSize() +</span><br><span class="line">              onDiskLen / bytesPerChecksum * checksumSize;</span><br><span class="line">          partialCrc = computePartialChunkCrc(onDiskLen, offsetInChecksum);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> startByteToDisk = (<span class="keyword">int</span>)(onDiskLen-firstByteInBlock) </span><br><span class="line">            + dataBuf.arrayOffset() + dataBuf.position();</span><br><span class="line">        <span class="comment">// data的len</span></span><br><span class="line">        <span class="keyword">int</span> numBytesToDisk = (<span class="keyword">int</span>)(offsetInBlock-onDiskLen);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Write data to disk.</span></span><br><span class="line">        <span class="keyword">long</span> begin = Time.monotonicNow();</span><br><span class="line">        <span class="comment">// 将data写入磁盘</span></span><br><span class="line">        out.write(dataBuf.array(), startByteToDisk, numBytesToDisk);</span><br><span class="line">        <span class="keyword">long</span> duration = Time.monotonicNow() - begin;</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">byte</span>[] lastCrc;</span><br><span class="line">        <span class="keyword">if</span> (shouldNotWriteChecksum) &#123;</span><br><span class="line">          lastCrc = <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (partialCrc != <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// If this is a partial chunk, then verify that this is the only</span></span><br><span class="line">          <span class="comment">// chunk in the packet. Calculate new crc for this chunk.</span></span><br><span class="line">          <span class="keyword">if</span> (len &gt; bytesPerChecksum) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unexpected packet data length for "</span></span><br><span class="line">                +  block + <span class="string">" from "</span> + inAddr + <span class="string">": a partial chunk must be "</span></span><br><span class="line">                + <span class="string">" sent in an individual packet (data length = "</span> + len</span><br><span class="line">                +  <span class="string">" &gt; bytesPerChecksum = "</span> + bytesPerChecksum + <span class="string">")"</span>);</span><br><span class="line">          &#125;</span><br><span class="line">          partialCrc.update(dataBuf.array(), startByteToDisk, numBytesToDisk);</span><br><span class="line">          <span class="keyword">byte</span>[] buf = FSOutputSummer.convertToByteStream(partialCrc, checksumSize);</span><br><span class="line">          lastCrc = copyLastChunkChecksum(buf, checksumSize, buf.length);</span><br><span class="line">          checksumOut.write(buf);</span><br><span class="line">          <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">            LOG.debug(<span class="string">"Writing out partial crc for data len "</span> + len);</span><br><span class="line">          &#125;</span><br><span class="line">          partialCrc = <span class="keyword">null</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// write checksum</span></span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> offset = checksumBuf.arrayOffset() +</span><br><span class="line">              checksumBuf.position();</span><br><span class="line">          <span class="keyword">final</span> <span class="keyword">int</span> end = offset + checksumLen;</span><br><span class="line">          lastCrc = copyLastChunkChecksum(checksumBuf.array(), checksumSize,</span><br><span class="line">              end);</span><br><span class="line">          <span class="comment">// 将checksum写入磁盘</span></span><br><span class="line">          checksumOut.write(checksumBuf.array(), offset, checksumLen);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/// flush entire packet, sync if requested</span></span><br><span class="line">        <span class="comment">// 将block data和metadata flush到磁盘</span></span><br><span class="line">        flushOrSync(syncBlock);       </span><br><span class="line">        replicaInfo.setLastChecksumAndDataLen(offsetInBlock, lastCrc);</span><br><span class="line">        datanode.metrics.incrBytesWritten(len);</span><br><span class="line">        manageWriterOsCache(offsetInBlock);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException iex) &#123;</span><br><span class="line">      datanode.checkDiskErrorAsync();</span><br><span class="line">      <span class="keyword">throw</span> iex;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> lastPacketInBlock?-<span class="number">1</span>:len;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="发送接收ACK"><a href="#发送接收ACK" class="headerlink" title="发送接收ACK"></a>发送接收ACK</h2><p><em>receivePacket从流中读出packet，在其向downstream发送时，先将packet当如ackQueue队列中，由PacketResponder线程等待接收此packet的ack，然后向downstream发送packet，最后将packet写入本地磁盘。</em></p>
<p>下面看下PacketResponder线程的run方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> lastPacketInBlock = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> startTime = ClientTraceLog.isInfoEnabled() ? System.nanoTime() : <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (isRunning() &amp;&amp; !lastPacketInBlock) &#123;</span><br><span class="line">    <span class="keyword">long</span> totalAckTimeNanos = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">boolean</span> isInterrupted = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      Packet pkt = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">long</span> expected = -<span class="number">2</span>;</span><br><span class="line">      PipelineAck ack = <span class="keyword">new</span> PipelineAck();</span><br><span class="line">      <span class="keyword">long</span> seqno = PipelineAck.UNKOWN_SEQNO;</span><br><span class="line">      <span class="keyword">long</span> ackRecvNanoTime = <span class="number">0</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (type != PacketResponderType.LAST_IN_PIPELINE &amp;&amp; !mirrorError) &#123;</span><br><span class="line">          <span class="comment">// read an ack from downstream datanode</span></span><br><span class="line">          <span class="comment">// 读取ack</span></span><br><span class="line">          ack.readFields(downstreamIn);</span><br><span class="line">          ackRecvNanoTime = System.nanoTime();</span><br><span class="line">          <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">            LOG.debug(myString + <span class="string">" got "</span> + ack);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// Process an OOB ACK.</span></span><br><span class="line">          Status oobStatus = ack.getOOBStatus();</span><br><span class="line">          <span class="keyword">if</span> (oobStatus != <span class="keyword">null</span>) &#123;</span><br><span class="line">            LOG.info(<span class="string">"Relaying an out of band ack of type "</span> + oobStatus);</span><br><span class="line">            sendAckUpstream(ack, PipelineAck.UNKOWN_SEQNO, <span class="number">0L</span>, <span class="number">0L</span>,</span><br><span class="line">                Status.SUCCESS);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 新收到的ack的seqno</span></span><br><span class="line">          seqno = ack.getSeqno();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 获得一个ack</span></span><br><span class="line">        <span class="keyword">if</span> (seqno != PipelineAck.UNKOWN_SEQNO</span><br><span class="line">            || type == PacketResponderType.LAST_IN_PIPELINE) &#123;</span><br><span class="line">          <span class="comment">// 按照发送packet的顺序接收packet ack</span></span><br><span class="line">          pkt = waitForAckHead(seqno);</span><br><span class="line">          <span class="keyword">if</span> (!isRunning()) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          expected = pkt.seqno;</span><br><span class="line">          ...</span><br><span class="line">          lastPacketInBlock = pkt.lastPacketInBlock;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ine) &#123;</span><br><span class="line">        isInterrupted = <span class="keyword">true</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">        <span class="keyword">if</span> (Thread.interrupted()) &#123;</span><br><span class="line">          isInterrupted = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// continue to run even if can not read from mirror</span></span><br><span class="line">          <span class="comment">// notify client of the error</span></span><br><span class="line">          <span class="comment">// and wait for the client to shut down the pipeline</span></span><br><span class="line">          mirrorError = <span class="keyword">true</span>;</span><br><span class="line">          LOG.info(myString, ioe);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (Thread.interrupted() || isInterrupted) &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">         * The receiver thread cancelled this thread. We could also check</span></span><br><span class="line"><span class="comment">         * any other status updates from the receiver thread (e.g. if it is</span></span><br><span class="line"><span class="comment">         * ok to write to replyOut). It is prudent to not send any more</span></span><br><span class="line"><span class="comment">         * status back to the client because this datanode has a problem.</span></span><br><span class="line"><span class="comment">         * The upstream datanode will detect that this datanode is bad, and</span></span><br><span class="line"><span class="comment">         * rightly so.</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * The receiver thread can also interrupt this thread for sending</span></span><br><span class="line"><span class="comment">         * an out-of-band response upstream.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        LOG.info(myString + <span class="string">": Thread is interrupted."</span>);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (lastPacketInBlock) &#123;</span><br><span class="line">        <span class="comment">// Finalize the block and close the block file</span></span><br><span class="line">        finalizeBlock(startTime);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 向upstream发送ack</span></span><br><span class="line">      sendAckUpstream(ack, expected, totalAckTimeNanos,</span><br><span class="line">          (pkt != <span class="keyword">null</span> ? pkt.offsetInBlock : <span class="number">0</span>), </span><br><span class="line">          (pkt != <span class="keyword">null</span> ? pkt.ackStatus : Status.SUCCESS));</span><br><span class="line">      <span class="keyword">if</span> (pkt != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// remove the packet from the ack queue</span></span><br><span class="line">        removeAckHead();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"IOException in BlockReceiver.run(): "</span>, e);</span><br><span class="line">      <span class="keyword">if</span> (running) &#123;</span><br><span class="line">        datanode.checkDiskErrorAsync();</span><br><span class="line">        LOG.info(myString, e);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">if</span> (!Thread.interrupted()) &#123; <span class="comment">// failure not caused by interruption</span></span><br><span class="line">          receiverThread.interrupt();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (running) &#123;</span><br><span class="line">        LOG.info(myString, e);</span><br><span class="line">        running = <span class="keyword">false</span>;</span><br><span class="line">        receiverThread.interrupt();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.info(myString + <span class="string">" terminating"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>PacketResponder线程主要用来接收和发送packet ack，并且是按照packet的写入顺序发送ack。</p>
<p>如果packet的type为<em>LAST_IN_PIPELINE</em>时，不进入<code>if (type != PacketResponderType.LAST_IN_PIPELINE &amp;&amp; !mirrorError)</code>语句，直接进入<code>if (seqno != PipelineAck.UNKOWN_SEQNO || type == PacketResponderType.LAST_IN_PIPELINE)</code>，从ackQueue队列中拿出第一个packet，<code>sendAckUpstream</code>向upstream发送ack，发送结束之后从ackQueue中移除packet。因为ackQueue的里packet的顺序是packet的写入顺序，则这样就保证了ack也是有序的。</p>
<p>如果packet的type为<em>HAS_DOWNSTREAM_IN_PIPELINE</em>时，进入<code>if (type != PacketResponderType.LAST_IN_PIPELINE &amp;&amp; !mirrorError)</code>，从输入流中读取ack，再进入<code>if (seqno != PipelineAck.UNKOWN_SEQNO || type == PacketResponderType.LAST_IN_PIPELINE)</code>从ackQueue中读取expect的packet，进行一些列校验之后，想upstream发送ack<code>sendAckUpstream</code>(<em>此时发送的ack包括自己和downstream的ack</em>)，发送结束之后从ackQueue中移除packet。</p>
<p><em>PacketResponder线程负责dn上packet ack的发送和接收，ResponseProcessor线程负责client端packet ack的接收</em>，看下ResponseProcessor线程的run方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  PipelineAck ack = <span class="keyword">new</span> PipelineAck();</span><br><span class="line">  <span class="keyword">while</span> (!responderClosed &amp;&amp; dfsClient.clientRunning &amp;&amp; !isLastPacketInBlock) &#123;</span><br><span class="line">    <span class="comment">// process responses from datanodes.</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// read an ack from the pipeline</span></span><br><span class="line">      <span class="keyword">long</span> begin = Time.monotonicNow();</span><br><span class="line">      <span class="comment">// 读取ack</span></span><br><span class="line">      ack.readFields(blockReplyStream);</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">long</span> seqno = ack.getSeqno();</span><br><span class="line">      <span class="comment">// processes response status from datanodes.</span></span><br><span class="line">      <span class="comment">// 从pipeline的最后一个dn开始接收ack</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = ack.getNumOfReplies()-<span class="number">1</span>; i &gt;=<span class="number">0</span>  &amp;&amp; dfsClient.clientRunning; i--) &#123;</span><br><span class="line">        <span class="keyword">final</span> Status reply = ack.getReply(i);</span><br><span class="line">        ...</span><br><span class="line">        <span class="comment">// node error</span></span><br><span class="line">        <span class="keyword">if</span> (reply != SUCCESS) &#123;</span><br><span class="line">          setErrorIndex(i); <span class="comment">// first bad datanode</span></span><br><span class="line">          <span class="comment">// throw 则跳出for循环，被catch捕获异常</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Bad response "</span> + reply +</span><br><span class="line">              <span class="string">" for block "</span> + block +</span><br><span class="line">              <span class="string">" from datanode "</span> + </span><br><span class="line">              targets[i]);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">assert</span> seqno != PipelineAck.UNKOWN_SEQNO : </span><br><span class="line">        <span class="string">"Ack for unknown seqno should be a failed ack: "</span> + ack;</span><br><span class="line">      <span class="keyword">if</span> (seqno == Packet.HEART_BEAT_SEQNO) &#123;  <span class="comment">// a heartbeat ack</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// a success ack for a data packet</span></span><br><span class="line">      Packet one;</span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        one = ackQueue.getFirst();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 从输入流中读取的ack的seqno与ackQueue中取得的seqno不一样则抛出异常</span></span><br><span class="line">      <span class="keyword">if</span> (one.seqno != seqno) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"ResponseProcessor: Expecting seqno "</span> +</span><br><span class="line">                              <span class="string">" for block "</span> + block +</span><br><span class="line">                              one.seqno + <span class="string">" but received "</span> + seqno);</span><br><span class="line">      &#125;</span><br><span class="line">      isLastPacketInBlock = one.lastPacketInBlock;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Fail the packet write for testing in order to force a</span></span><br><span class="line">      <span class="comment">// pipeline recovery.</span></span><br><span class="line">      <span class="keyword">if</span> (DFSClientFaultInjector.get().failPacket() &amp;&amp;</span><br><span class="line">          isLastPacketInBlock) &#123;</span><br><span class="line">        failPacket = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">              <span class="string">"Failing the last packet for testing."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">        </span><br><span class="line">      <span class="comment">// update bytesAcked</span></span><br><span class="line">      block.setNumBytes(one.getLastByteOffsetBlock());</span><br><span class="line">      <span class="comment">// 接收到ack后，从ackQueue中移除packet</span></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        lastAckedSeqno = seqno;</span><br><span class="line">        ackQueue.removeFirst();</span><br><span class="line">        dataQueue.notifyAll();</span><br><span class="line"></span><br><span class="line">        one.releaseBuffer(byteArrayManager);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!responderClosed) &#123;</span><br><span class="line">        <span class="keyword">if</span> (e <span class="keyword">instanceof</span> IOException) &#123;</span><br><span class="line">          setLastException((IOException)e);</span><br><span class="line">        &#125;</span><br><span class="line">        hasError = <span class="keyword">true</span>;</span><br><span class="line">        <span class="comment">// If no explicit error report was received, mark the primary</span></span><br><span class="line">        <span class="comment">// node as failed.</span></span><br><span class="line">        tryMarkPrimaryDatanodeFailed();</span><br><span class="line">        <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">          dataQueue.notifyAll();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">          DFSClient.LOG.warn(<span class="string">"DFSOutputStream ResponseProcessor exception "</span></span><br><span class="line">               + <span class="string">" for block "</span> + block, e);</span><br><span class="line">        &#125;</span><br><span class="line">        responderClosed = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ResponseProcessor线程读取ack，并从pipeline中的最后一个dn检查packet的状态，如果发现error则设置errorIndex为当前dn的索引，在catch中设置<code>hasError = true</code>；如果没有error则从ackQueue中移除packet。</p>
<h2 id="pipeline中写发送错误"><a href="#pipeline中写发送错误" class="headerlink" title="pipeline中写发送错误"></a>pipeline中写发送错误</h2><p>在写数据的过程中，如果Pipeline数据流管道中的一个DataNode节点写失败了会发生什问题、需要做哪些内部处理呢？下面从代码中寻找答案。</p>
<p>ResponseProcessor线程中从接收到的ack中发现error，则设置errorIndex为错误节点的index，hasError标识为true，在DataStreamer线程中发现属性的变化，进行错误处理，看下部分DataStreamer的run代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">while</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="comment">// if the Responder encountered an error, shutdown Responder</span></span><br><span class="line">    <span class="keyword">if</span> (hasError &amp;&amp; response != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        response.close();</span><br><span class="line">        response.join();</span><br><span class="line">        response = <span class="keyword">null</span>;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException  e) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"Caught exception "</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    Packet one;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// process datanode IO errors if any</span></span><br><span class="line">      <span class="keyword">boolean</span> doSleep = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">if</span> (hasError &amp;&amp; (errorIndex &gt;= <span class="number">0</span> || restartingNodeIndex &gt;= <span class="number">0</span>)) &#123;</span><br><span class="line">        <span class="comment">// 处理错误</span></span><br><span class="line">        doSleep = processDatanodeError();</span><br><span class="line">      &#125;</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DataStreamer线程发现error之后调用<code>processDatanodeError</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">processDatanodeError</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (response != <span class="keyword">null</span>) &#123;</span><br><span class="line">    DFSClient.LOG.info(<span class="string">"Error Recovery for "</span> + block +</span><br><span class="line">    <span class="string">" waiting for responder to exit. "</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 关闭pipeline流</span></span><br><span class="line">  closeStream();</span><br><span class="line">  <span class="comment">// 将ackQueue中的packet移到dataQueue</span></span><br><span class="line">  <span class="comment">// move packets from ack queue to front of the data queue</span></span><br><span class="line">  <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">    dataQueue.addAll(<span class="number">0</span>, ackQueue);</span><br><span class="line">    ackQueue.clear();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Record the new pipeline failure recovery.</span></span><br><span class="line">  <span class="comment">// 创建新的pipeline可以进行重试</span></span><br><span class="line">  <span class="keyword">if</span> (lastAckedSeqnoBeforeFailure != lastAckedSeqno) &#123;</span><br><span class="line">     lastAckedSeqnoBeforeFailure = lastAckedSeqno;</span><br><span class="line">     pipelineRecoveryCount = <span class="number">1</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// If we had to recover the pipeline five times in a row for the</span></span><br><span class="line">    <span class="comment">// same packet, this client likely has corrupt data or corrupting</span></span><br><span class="line">    <span class="comment">// during transmission.</span></span><br><span class="line">    <span class="keyword">if</span> (++pipelineRecoveryCount &gt; <span class="number">5</span>) &#123;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">"Error recovering pipeline for writing "</span> +</span><br><span class="line">          block + <span class="string">". Already retried 5 times for the same packet."</span>);</span><br><span class="line">      lastException.set(<span class="keyword">new</span> IOException(<span class="string">"Failing write. Tried pipeline "</span> +</span><br><span class="line">          <span class="string">"recovery 5 times without success."</span>));</span><br><span class="line">      streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 重建pipeline</span></span><br><span class="line">  <span class="keyword">boolean</span> doSleep = setupPipelineForAppendOrRecovery();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (!streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="keyword">if</span> (stage == BlockConstructionStage.PIPELINE_CLOSE) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// If we had an error while closing the pipeline, we go through a fast-path</span></span><br><span class="line">      <span class="comment">// where the BlockReceiver does not run. Instead, the DataNode just finalizes</span></span><br><span class="line">      <span class="comment">// the block immediately during the 'connect ack' process. So, we want to pull</span></span><br><span class="line">      <span class="comment">// the end-of-block packet from the dataQueue, since we don't actually have</span></span><br><span class="line">      <span class="comment">// a true pipeline to send it over.</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// We also need to set lastAckedSeqno to the end-of-block Packet's seqno, so that</span></span><br><span class="line">      <span class="comment">// a client waiting on close() will be aware that the flush finished.</span></span><br><span class="line">      <span class="keyword">synchronized</span> (dataQueue) &#123;</span><br><span class="line">        Packet endOfBlockPacket = dataQueue.remove();  <span class="comment">// remove the end of block packet</span></span><br><span class="line">        <span class="keyword">assert</span> endOfBlockPacket.lastPacketInBlock;</span><br><span class="line">        <span class="keyword">assert</span> lastAckedSeqno == endOfBlockPacket.seqno - <span class="number">1</span>;</span><br><span class="line">        lastAckedSeqno = endOfBlockPacket.seqno;</span><br><span class="line">        dataQueue.notifyAll();</span><br><span class="line">      &#125;</span><br><span class="line">      endBlock();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 启动ResponseProcess线程</span></span><br><span class="line">      initDataStreaming();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> doSleep;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>processDatanodeError方法中主要逻辑是<code>setupPipelineForAppendOrRecovery</code>，创建新的pipeline</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">setupPipelineForAppendOrRecovery</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// check number of datanodes</span></span><br><span class="line">  ...  </span><br><span class="line">  <span class="keyword">boolean</span> success = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">long</span> newGS = <span class="number">0L</span>;</span><br><span class="line">  <span class="keyword">while</span> (!success &amp;&amp; !streamerClosed &amp;&amp; dfsClient.clientRunning) &#123;</span><br><span class="line">    <span class="comment">// Sleep before reconnect if a dn is restarting.</span></span><br><span class="line">    <span class="comment">// This process will be repeated until the deadline or the datanode</span></span><br><span class="line">    <span class="comment">// starts back up.</span></span><br><span class="line">    <span class="keyword">if</span> (restartingNodeIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 4 seconds or the configured deadline period, whichever is shorter.</span></span><br><span class="line">      <span class="comment">// This is the retry interval and recovery will be retried in this</span></span><br><span class="line">      <span class="comment">// interval until timeout or success.</span></span><br><span class="line">      <span class="keyword">long</span> delay = Math.min(dfsClient.getConf().datanodeRestartTimeout,</span><br><span class="line">          <span class="number">4000L</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        Thread.sleep(delay);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">        lastException.set(<span class="keyword">new</span> IOException(<span class="string">"Interrupted while waiting for "</span> +</span><br><span class="line">            <span class="string">"datanode to restart. "</span> + nodes[restartingNodeIndex]));</span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">boolean</span> isRecovery = hasError;</span><br><span class="line">    <span class="comment">// remove bad datanode from list of datanodes.</span></span><br><span class="line">    <span class="comment">// If errorIndex was not set (i.e. appends), then do not remove </span></span><br><span class="line">    <span class="comment">// any datanodes</span></span><br><span class="line">    <span class="comment">// </span></span><br><span class="line">    <span class="keyword">if</span> (errorIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="keyword">if</span> (nodes.length &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">        lastException.set(<span class="keyword">new</span> IOException(<span class="string">"All datanodes "</span> + pipelineMsg</span><br><span class="line">            + <span class="string">" are bad. Aborting..."</span>));</span><br><span class="line">        streamerClosed = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 将错误的dn加入failed列表中</span></span><br><span class="line">      failed.add(nodes[errorIndex]);</span><br><span class="line">      DatanodeInfo[] newnodes = <span class="keyword">new</span> DatanodeInfo[nodes.length-<span class="number">1</span>];</span><br><span class="line">      <span class="comment">// 将正常的dn复制到新的数组newnodes里</span></span><br><span class="line">      arraycopy(nodes, newnodes, errorIndex);</span><br><span class="line">      <span class="keyword">final</span> StorageType[] newStorageTypes = <span class="keyword">new</span> StorageType[newnodes.length];</span><br><span class="line">      arraycopy(storageTypes, newStorageTypes, errorIndex);</span><br><span class="line">      <span class="keyword">final</span> String[] newStorageIDs = <span class="keyword">new</span> String[newnodes.length];</span><br><span class="line">      arraycopy(storageIDs, newStorageIDs, errorIndex);</span><br><span class="line">      <span class="comment">// 使用newnodes设置pipeline</span></span><br><span class="line">      setPipeline(newnodes, newStorageTypes, newStorageIDs);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Just took care of a node error while waiting for a node restart</span></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// If the error came from a node further away than the restarting</span></span><br><span class="line">        <span class="comment">// node, the restart must have been complete.</span></span><br><span class="line">        <span class="keyword">if</span> (errorIndex &gt; restartingNodeIndex) &#123;</span><br><span class="line">          restartingNodeIndex = -<span class="number">1</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (errorIndex &lt; restartingNodeIndex) &#123;</span><br><span class="line">          <span class="comment">// the node index has shifted.</span></span><br><span class="line">          restartingNodeIndex--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// this shouldn't happen...</span></span><br><span class="line">          <span class="keyword">assert</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (restartingNodeIndex == -<span class="number">1</span>) &#123;</span><br><span class="line">        hasError = <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      lastException.set(<span class="keyword">null</span>);</span><br><span class="line">      errorIndex = -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Check if replace-datanode policy is satisfied.</span></span><br><span class="line">    <span class="keyword">if</span> (dfsClient.dtpReplaceDatanodeOnFailure.satisfy(blockReplication,</span><br><span class="line">        nodes, isAppend, isHflushed)) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 补全pipeline的节点数量</span></span><br><span class="line">        addDatanode2ExistingPipeline();</span><br><span class="line">      &#125; <span class="keyword">catch</span>(IOException ioe) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get a new generation stamp and an access token</span></span><br><span class="line">    <span class="comment">// 生成一个新的stamp</span></span><br><span class="line">    LocatedBlock lb = dfsClient.namenode.updateBlockForPipeline(block, dfsClient.clientName);</span><br><span class="line">    newGS = lb.getBlock().getGenerationStamp();</span><br><span class="line">    accessToken = lb.getBlockToken();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// set up the pipeline again with the remaining nodes</span></span><br><span class="line">    <span class="keyword">if</span> (failPacket) &#123; <span class="comment">// for testing</span></span><br><span class="line">      success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);</span><br><span class="line">      failPacket = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Give DNs time to send in bad reports. In real situations,</span></span><br><span class="line">        <span class="comment">// good reports should follow bad ones, if client committed</span></span><br><span class="line">        <span class="comment">// with those nodes.</span></span><br><span class="line">        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;&#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 与pipeline中的第一个dn建立连接</span></span><br><span class="line">      success = createBlockOutputStream(nodes, storageTypes, newGS, isRecovery);</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">  &#125; <span class="comment">// while</span></span><br><span class="line">  <span class="comment">// 更新block的stamp</span></span><br><span class="line">  <span class="keyword">if</span> (success) &#123;</span><br><span class="line">    <span class="comment">// update pipeline at the namenode</span></span><br><span class="line">    ExtendedBlock newBlock = <span class="keyword">new</span> ExtendedBlock(</span><br><span class="line">        block.getBlockPoolId(), block.getBlockId(), block.getNumBytes(), newGS);</span><br><span class="line">    dfsClient.namenode.updatePipeline(dfsClient.clientName, block, newBlock,</span><br><span class="line">        nodes, storageIDs);</span><br><span class="line">    <span class="comment">// update client side generation stamp</span></span><br><span class="line">    block = newBlock;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">// do not sleep, continue processing</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>setupPipelineForAppendOrRecovery从原pipeline中取出正常的dn，将错误dn排除，然后调用<code>addDatanode2ExistingPipeline</code>，加入一个新的dn与原来正常的两个dn组成一个新的pipeline(<em>在这个过程中会transfer之前传输成功的数据</em>)，并生成新的stamp和token，调用<code>createBlockOutputStream</code>与pipeline建立socket连接。使用stamp更新block标识，这样namenode可以删除以前发生错误的block。</p>
<p>下面主要看写<code>addDatanode2ExistingPipeline</code>代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addDatanode2ExistingPipeline</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">/*</span></span><br><span class="line"><span class="comment">   * Is data transfer necessary?  We have the following cases.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * Case 1: Failure in Pipeline Setup</span></span><br><span class="line"><span class="comment">   * - Append</span></span><br><span class="line"><span class="comment">   *    + Transfer the stored replica, which may be a RBW or a finalized.</span></span><br><span class="line"><span class="comment">   * - Create</span></span><br><span class="line"><span class="comment">   *    + If no data, then no transfer is required.</span></span><br><span class="line"><span class="comment">   *    + If there are data written, transfer RBW. This case may happens </span></span><br><span class="line"><span class="comment">   *      when there are streaming failure earlier in this pipeline.</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * Case 2: Failure in Streaming</span></span><br><span class="line"><span class="comment">   * - Append/Create:</span></span><br><span class="line"><span class="comment">   *    + transfer RBW</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * Case 3: Failure in Close</span></span><br><span class="line"><span class="comment">   * - Append/Create:</span></span><br><span class="line"><span class="comment">   *    + no transfer, let NameNode replicates the block.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">//get a new datanode</span></span><br><span class="line">  <span class="keyword">final</span> DatanodeInfo[] original = nodes;</span><br><span class="line">  <span class="comment">// 从namenode得到一个新的dn</span></span><br><span class="line">  <span class="keyword">final</span> LocatedBlock lb = dfsClient.namenode.getAdditionalDatanode(</span><br><span class="line">      src, fileId, block, nodes, storageIDs,</span><br><span class="line">      failed.toArray(<span class="keyword">new</span> DatanodeInfo[failed.size()]),</span><br><span class="line">      <span class="number">1</span>, dfsClient.clientName);</span><br><span class="line">  <span class="comment">// 更新pipeline    </span></span><br><span class="line">  setPipeline(lb);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//find the new datanode</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> d = findNewDatanode(original);</span><br><span class="line">  <span class="comment">//transfer replica</span></span><br><span class="line">  <span class="keyword">final</span> DatanodeInfo src = d == <span class="number">0</span>? nodes[<span class="number">1</span>]: nodes[d - <span class="number">1</span>];</span><br><span class="line">  <span class="comment">// transfer的目标节点，也就是新添加的节点</span></span><br><span class="line">  <span class="keyword">final</span> DatanodeInfo[] targets = &#123;nodes[d]&#125;;</span><br><span class="line">  <span class="keyword">final</span> StorageType[] targetStorageTypes = &#123;storageTypes[d]&#125;;</span><br><span class="line">  <span class="comment">// tarnsfer</span></span><br><span class="line">  transfer(src, targets, targetStorageTypes, lb.getBlockToken());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>hdfs write的流程为：</p>
<ul>
<li>通过FileSystem.create创建一个FSDataOutputStream输出流，在此过程中client通过rpc向namenode添加一个文件记录，得到该文件的租约，启动一个DataStreamer线程(DataStreamer线程中维护dataQueue和ackQueue队列)，并持续更新租约</li>
<li>FSDataOutputStream输出流建好之后，就可以调用FSDataOutputStream.write方法进行数据的写入。在写入过程中先将数据写入client本地的buf中，此buf默认是9个chunk的大小，当本地buf写满之后(<em>如果要写入的数据长度大于本地buf的长度，则直接将buf长度的数据写入currentPacket中</em>)，计算这些数据的checksum，并写入currentPacket中，currentPacket写满之后放入dataQueue中排队并通知DataStreamer线程去dataQueue中消费数据。(<strong>数据先写入本地buf，然后写入packet，等packet满之后才向namenode申请blockId</strong>)</li>
<li>DataStreamer线程从dataQueue中取出packet，如果DataStreamer的stage为<em>PIPELINE_SETUP_CREATE</em>时，表示当前block的pipeline还没有建立，向namenode申请blockId和block的locations，将申请到的locations组成一个pipeline，与第一个dn建立socket连接，由Sender发送写请求。新启动ResponseProcessor线程接收dn返回的packet ack，并更新DataStreamer的stage，由<em>PIPELINE_SETUP_CREATE</em>变为<em>DATA_STREAMING</em></li>
<li>将要发送的packet从dataQueue中移到ackQueue中，然后向pipeline中发送packet</li>
</ul>
<p>以上的流程都发生在client端，下面的流程发生在dn端</p>
<ul>
<li>dn在client创建pipeline时，通过DataXceiverServer接收到client的socket请求，创建一个DataXceiver线程，由DataXceiver线程处理来自client的写请求。</li>
<li>DataXceiver线程会实例化一个BlockReceiver对象，并判断是否有downstream，如果有则创建一个downstream的socket，发送写请求。</li>
<li>与downstream建立连接之后，在blockReceiver.receiveBlock循环调用receivePacket接收packet，向downstream发送packet之前将packet放入ackQueue(当前ackQueue是PacketResponder线程维护的)中，然后将data和checksum写入磁盘</li>
<li>在blockReceiver.receiveBlock中还会启动一个PacketResponder线程，此线程负责接收downstream发送的packet ack，校验成功之后从ackQueue中移除，向upstream发送自己的ack和downstream的ack。</li>
<li>最终所有的ack都汇集到ResponseProcessor线程中，如果ack没有error则从ackQueue中移除；如果有error，先将ackQueue中的packet移到dataQueue中，然后将发生error的dn从pipeline中删除，从namenode中重新申请dn与原有的没有发生error的dn组成新的pipeline，在<code>addDatanode2ExistingPipeline</code>中判断是否要transfer已经发送的packet，<em>将已经发送成功的packet从之前正常的dn上transfer到新增加的dn上，并更新block是stamp</em>，这样发生故障的DataNode节点上的block数据会在节点恢复正常后被删除。</li>
</ul>
<h2 id="疑问"><a href="#疑问" class="headerlink" title="疑问"></a>疑问</h2><p>在DataNode节点的流水复制过程中，如果一个DataNode节点发生错误，如接收到的packet出错了，那么该DataNode的BlockReceiver自动结束该线程，也不会向发送端发送确认帧，发送端就会迟迟收不到接收端的确认帧，这样的话，接受端就任务它以后的所有DataNode节点在接受该Block的packet是发生了错误，并把这个情况发送给发送端的发送端。</p>
<p>如果Pipeline中的多个节点在写数据是发生失败，那么只要写成功的block的数量达到dfs.replication.min(默认为1)，那么就任务是写成功的，然后NameNode后通过一步的方式将block复制到其他节点，最后事数据副本达到dfs.replication参数配置的个数。 </p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> write </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Append/Hflush/Read设计文档]]></title>
      <url>http://bigdatadecode.club/%5B%E8%AF%91%5DAppend%20Hflush%20Read%E8%AE%BE%E8%AE%A1%E6%96%87%E6%A1%A3.html</url>
      <content type="html"><![CDATA[<p>本篇是一篇译文，主要是翻译下Append/Hflush/Read Design。hdfs的write一直看不太懂，想翻译下此设计文档，希望能有更深入的理解。</p>
<a id="more"></a>
<h2 id="Replica-Block-状态"><a href="#Replica-Block-状态" class="headerlink" title="Replica/Block 状态"></a>Replica/Block 状态</h2><p>Block在NameNode和DataNode中有不同的称呼，<em>在NameNode中为block，在DataNode中为Replica</em>。通常说的block的副本数是3，指的就是dn中Replica为3。</p>
<h3 id="Replica状态"><a href="#Replica状态" class="headerlink" title="Replica状态"></a>Replica状态</h3><p><strong>Finalized</strong>:<br>   <em>finalized Replica已经完成了写入操作</em>。不会再有新的数据写入，除非此Replica被再次打开或者被追加。<br>   finalized Replica的数据和meta数据是匹配的。<br>   <em>当前block id的所有Replica有相同的数据大小</em>。<br>   但是finalized Replica的GS(generation stamp)不是一直不变的，GS可能因为一次错误的recovery而导致其发生变化。<br><strong>RBW(Replica Being Written)</strong>:<br>   <em>创建Replica或者追加Replica时，Replica的状态为RBW</em>。<br>   数据写入RBW状态的Replica。其<em>RBW Replica总是一个未关闭文件的最后一个block的Replica</em>。<br>   同一个block id的RBW状态的Replica的长度不固定。<br>   RBW状态的Replica在磁盘中的数据与meta数据不匹配，<em>也就是说还有一部分数据在内存中没有flush到磁盘</em>。<br>   RBW状态的Replica中的所有数据对readers并<strong>不都是不可见的</strong>，<em>只有接受到queue ack的packet才是可见的</em>。<br>   <em>如果发生故障，RBW状态的Replica中的数据是需要保护的</em>。<br><strong>RWR(Replica Waiting to be Recovered)</strong>:<br>   <em>DataNode挂掉或者重启时，所有RBW状态的Replica变为RWR状态</em>。<br>   RWR状态的Replica不会在pipeline中存在，因此RWR Replica也不能写入数据。<br>   RWR状态下的replica将会变成过期，或者<em>当client死了之后，RWR将出现在租约恢复的过程中(将RBW状态的Replica转为RWR)</em>。<br><strong>RUR(Replica Under Recovery)</strong>:<br>   租约恢复会触发Replica恢复(or Block Recovery)，此时，任何一个非TEMPORARY状态的replica都有可能转换为RUR状态。<br>   <strong>租约恢复会触发Block恢复，此时Replica的状态转为RUR，那么RWR是在哪租约恢复中哪里出现？？</strong><br><strong>TEMPORARY</strong>:<br>   在block复制(由replication monitor或者balancer引起的block复制操作)中会出现temporary状态的replica。<br>   此状态下的replica与RBW状态类似，只是该状态下的数据是不可见的。<br>   如果block复制失败，TEMPORARY状态下的replica会被删除。</p>
<p>在DataNode磁盘中(也就是存放block的dn磁盘中)，每个data目录都有三个子目录，分别为current、tmp和rbw。其中current中存放finalized replicas，tmp目录存放temporary replicas，rbw目录存放rbw、rwr和rur replicas。</p>
<p>当replica是由于replica复制或者balance而创建的，则将此replica放入temp目录。一旦一个replica完成，也就是finalized，则将其移动到current目录中。当DataNode重启时，tmp目录下的replicas被删除，rbw目录下的replicas被做为rwr状态进行加载(<strong>rbw目录下存放着rbw、rwr、rur，rur也转换为rwr？？？转换为rwr之后怎么办呢？？</strong>)，在current目录下的replicas被做为finalized状态进行加载。</p>
<p>在DataNode升级过程中，在current和rbw目录下的所有replicas将被保存在一个快照中。</p>
<h3 id="Block状态"><a href="#Block状态" class="headerlink" title="Block状态"></a>Block状态</h3><p>Block在NameNode中的状态为：<br><strong>UnderConstruction</strong>:<br>   新建一个block或者打开已存在的block来追加，此时block为UnderConstruction状态。<br>   UnderConstruction状态的block可以写入数据。通常是一个未关闭文件的最后一个block。<br>   由于此状态下的block可以写入数据，则UnderConstruction block的长度和GS是不固定的。<br>   UnderConstruction block中的数据并不是完全可见的。<br>   UnderConstruction block会记录write pipeline的位置，如果client挂了，也会记录rwr replicas的位置。(A block underconstruction keep strack of its write pipeline(i.e.,locations of valid rbw replicas) and the locations of its rwr replicas if the client dies)<br>   <em>对应Replica的状态为RBW</em><br><strong>UnderRecovery</strong>:<br>   当一个文件的租约超期之后，如果此文件的最后一个block是UnderConstruction状态，当block恢复开始时，UnderConstruction变为UnderRecovery状态。<br>   <em>对应Replica的状态为RUR</em><br><strong>Commited</strong>:<br>   <em>Committed block的长度和GS是不变的</em>，除非该block被再次打开来追加。但是<strong>DataNode还没有上报这样的Replica，导致NameNode中找不到与之匹配的finalized replica</strong>，此时block被称为Committed状态。<br>   为了响应读请求，Committed block依然要保留rbw replicas的地址。也要记录finalized replicas的GS和长度。<br>   当client要求nn给未关闭的文件增加一个block或者关闭此文件时，一个UnderConstruction block变为Committed。<br>   如果一个文件的最后一个block或者倒数第二个block是COMMITTED状态，则该文件不能被关闭，client必须进行重试。<br>   Add Block and close will be extended to include the last block’s GS and length.<br><strong>Complete</strong>:<br>   Complete block的长度和GS是不变的，并且NameNode已经发现当前block的finalized replica能够和GS/len匹配。<br>   Complete block只保存finalized replicas的位置。<br>   只有当一个文件的所有block都是Complete时，才能关闭。<br>   <em>对应Replica的状态为Finalized</em></p>
<p>和Replica的状态不同，block的状态不会在固化到磁盘。当NameNode重启时，未关闭文件的最后一个block的状态为UnderConstruction进行加载，剩下的block都为Complete状态。</p>
<p>更多的细节包括Replica和Block状态的转换图都将在后面的章节中介绍。</p>
<p><strong>疑惑Replica与Block的状态是怎么交互的？？？？？</strong></p>
<h2 id="Write-Hflush"><a href="#Write-Hflush" class="headerlink" title="Write/Hflush"></a>Write/Hflush</h2><h3 id="write-pipeline"><a href="#write-pipeline" class="headerlink" title="write pipeline"></a>write pipeline</h3><p>HDFS文件是由多个block组成。block是通过write pipeline将数据写入的。Bytes数据以packet为单位被推送到pipeline中。如果不发生error，block的构成会经过3个阶段。如图所示。<br><img src="/blogimgs/appendDesign/writePipeline.png" alt="write pipeline" title="write pipeline"><br>此pipeline包含3个DataNode(DN0、DN1和DN2)和一个由5个packet组成的block。<br>图中的粗线表示packet，虚线表示ack messages，细线表示控制信息(setup/close)。<br>t0-t1是pipeline的setup阶段。t1-t2是data streaming阶段(t1发送第一个packet，t2是接收最后一个packet的ack)，<em>在数据传输中需要注意的是packet3之所以要等到接收到packet2的ack之后才发送是因为packet2调用了hflush</em>。t2-t3是pipeline的close阶段。</p>
<p>下面详细介绍下着3个阶段：</p>
<blockquote>
<p>setup：</p>
</blockquote>
<p>client沿着pipeline的下游dn发送了一个Write_Block请求。当最后一个dn接收到这个请求，会沿着pipeline的上游dn发送一个ack给client。此时，<em>pipeline中dn的网络连接就被建立，并且每个dn都创建或者打开一个Replica</em>，等待写入数据。</p>
<blockquote>
<p>data streaming</p>
</blockquote>
<p>数据首先被缓存在client端的buf中，当buf写满之后写入packet中。一个packet写满之后，被发送到pipeline中。下一个packet在接收到之前packet的ack之前就可以发送到pipeline中。未完成packet(未发送和未接收到ack的packet统称未完成的packet，原文是outstanding packets)的个数是由client控制的，代码中是80(是dataQueue和ackQueue中packet的和)，超过了限制则阻塞。<br>如果代码中明确调用<code>hflush</code>，会将当前packet发送到pipeline中(<strong>是把packet发送到dataQueue等待DataStreamer来取还是直接发送到pipeline中？？</strong>)，无论此packet是否已经写满。<em>Hflush是一个同步操作，在接收到此packet的ack之前，不能写入任何数据</em>。</p>
<blockquote>
<p>close(finalize a block and shutdown pipeline)</p>
</blockquote>
<p>当client收到所有packet的ack之后，发送一个关闭请求。<br>这样保证了如果在data streaming失败了，恢复操作没有必要去处理一些情况，如一些Replicas已经Finalized和一些Replica并没有完整的数据。(This ensures that if data streaming fails, the recovery does not need to handle the case that some replicas have been finalized and some do not have all the data)</p>
<h3 id="packet在某个DN中是流程"><a href="#packet在某个DN中是流程" class="headerlink" title="packet在某个DN中是流程"></a>packet在某个DN中是流程</h3><p><img src="/blogimgs/appendDesign/packetPipeline.png" alt="packet in pipeline" title="packet in pipeline"><br>对于每个packet，pipeline中的dn会做3件事：</p>
<ol>
<li>Stream data<br>a. 从上游的dn或者client接收数据<br>b. 如果下游有dn则向下游发送数据</li>
<li>将data或者crc写入block文件或者mate文件</li>
<li>Stream ack<br>a. 如果下游有dn则接收下游dn发送的ack<br>b. 向上游dn或者client发送ack</li>
</ol>
<blockquote>
<p>需要注意的是上面的数字并不代表这三件事的执行顺序。</p>
</blockquote>
<p>Stream ack(3)会在Steam data(1)之后执行，但是理论上write data to disk(2)可以发生在1.a之后的任何时间里。<em>代码中在执行1.b之后并且接收到下个packet之前去执行write data to disk(2)</em></p>
<p><em>pipeline中的DataNode有两个线程</em>。data线程负责data stream和disk writing。对于每个packet，data线程按照顺序执行1.a、1.b和2。<em>packet被flush到磁盘之后，可以从内存中移除</em>。ack线程负责ack streaming。对于每个packet，ack线程按照执行3.a和3.b。<em>由于data线程和ack线程是同时执行的，因此无法保证(2)和(3)的执行顺序</em>。packet的ack可能会在写入磁盘之前发送。</p>
<p>算法在写性能、数据持久性和算法的简单性做了个权衡。<br>1、尽快的将数据写入磁盘而不是等待接收到ack之后，能够提升数据的持久性，防止数据丢失。<br>2、并发的执行data线程和ack线程<br>3、<strong>在pipeline的内存中最多只存在一个packet</strong>，使buffer管理很简单。<br>(<strong>pipeline是怎么保证内存最多只有一个packet的？？？写入磁盘的packet就从内存删除？？？</strong>)</p>
<h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><ul>
<li>client从RBW Replica中读数据时，DataNode不会将接收到的所有数据都对client可见。</li>
<li>RBW Replica维护着两个计数器：<br> 1、BA: 接收到下游ack的bytes数。这些数据对client是可见的。也被称为Replica的可见长度。<br> 2、BR: block已经接收到的bytes数，包括写入磁盘的和在dn内存中的数据。</li>
<li>假设开始在pipeline中的所有DataNode中RBW Replica的两个计数器(BA, BR)=(a, a)。则当client将一个大小为b bytes的packet发送到pipeline中，在client接收到packet的ack之前没有别的packet发送到pipeline中。<br> 1、某个DN执行完<em>1.a</em>之后，(BA, BR)变为(a, a+b)<br> 2、某个DN执行完<em>3.a</em>之后，(BA, BR)变为(a+b, a+b)<br> 3、当client成功接收packet的ack之后，pipeline中所有dns的RBW Replica的计数器变为(BA, BR)变为(a+b, a+b)</li>
<li>pipeline中有N个DataNode(DN0、DN1、…DNn)，DN0是pipeline中的第一个，离client最近，则有下面的特性：<br> 在任何给定的时间t，<br> <img src="/blogimgs/appendDesign/BABR.png" alt=""><br> 这个特性保证了一旦数据变为可见的，则pipeline中所有的dn都有此数据。(<em>只要接收到ack的packet就是可见的？一旦数据是可见的，保证所有的dn都有此数据，但不保证该数据在所有的dn上都是可见的？？是这样理解吗？？还是说只有client接收到ack之后数据才是可见的？？我感觉是前者。随后验证</em>)</li>
<li>假设BSc表示client在时间点t发送到pipeline中的数据长度，BAc是client接收到ack的数据长度。则上面的公式变为如下：<br> <img src="/blogimgs/appendDesign/BCBABR.png" alt=""></li>
</ul>
<h2 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h2><p>读一个未关闭的文件时，存在的挑战是如果最后一个block是UnderConstruction，那么如果保证一致性。解决思路是保证在DNi上读到的数据也能在DNj上读取，尽管BAi&gt;BAj。</p>
<blockquote>
<p>第一种解决方案：</p>
</blockquote>
<ul>
<li>当client读一个UnderConstruction block时，先向DN发送一个请求得到这个Replica的BA</li>
<li>如果要读的长度超过了UnderConstruction block的BA，那么抛出一个EOFException异常</li>
<li>只有当read请求的<em>起始偏移地址小于最后一个block的可见长度时</em>(是起始位置小于可见长度，即off小于BA。<strong>那么只要off大于BA，即使len小于BR，也不会发送给DN？？</strong>)，才会发送给DN。当DN收到一个read请求，读取的长度小于BR，则返回此区间的数据。</li>
<li>假设read请求是一个三元组(blck, off, len)，其中blck包含blockId和GS，off是读取的起始位置，len要读取数据的长度</li>
<li>如果DN有个Replica的GS等于blck的GS或者比blck的GS新，则可以响应当前read请求。</li>
<li><em>假设client从DNj上得到了block的length，则off和len的和必须小于等于BAj</em>。</li>
<li>假设read请求发送给了DNi(<em>能发送个DNi，则off一定小于BAi</em>)，DNi上的一个Replica的状态是(BAi, BRi)，则<br> 1、如果off+len&lt;=BAi，DNi能从off处发送len长度的bytes给client<br> 2、如果off+len&gt;BAi，并且off+len&lt;=BAj(<em>由上一条假设得知</em>)，BAj&gt;=BAi，则DNi在pipeline中一定是DNj的上游，也就是离client的距离比DNj要近。则BRi&gt;=BRj&gt;=BAj。BRi&gt;BAj,所以BRi&gt;off+len。也就是说DNi有client想要读取的数据，则DNi发送数据给client<br> 3、off+len一定不能比BRi大，如果发送了这种情况，DN记录下error并拒绝这次请求。</li>
<li>如果正在响应read请求的DNi挂掉了，client能在该block的其它Replica所在的DN中任意切换。</li>
<li>这个解决方案比较简单，<em>但是需要重新打开一个文件去取数据，因为最后一个block的可见长度是在client read之前从DN上得到的</em>(也就是说client要先跟从一个DN上得到可见数据的长度，然后再去打开一个文件去读数)，而且client读取的数据的长度不能超过最后一个block的长度。</li>
</ul>
<blockquote>
<p>概括下这种方案的读取流程：<br>读操作分为两次请求：<br>第一次向block的Replica所在的某一个DN(该DN记为DNi)发送一个请求，<em>得到block的可见长度BAi，如果off+len大于BAi，则抛出EOFException</em>；<br>第二次请求是向Replica所在的某个DN发送读请求，<em>发送时要判断off是否小于该DN的BA，只有小于BA才向该DN发送读请求</em>。(发送给DN，DN是否响应，其判断标准为DN有个<em>Replica的GS等于blck的GS或者比blck的GS新，则可以响应当前read请求</em>)</p>
</blockquote>
<blockquote>
<p>第二种解决方案</p>
</blockquote>
<ul>
<li>此种方案是让client控制一致性，DN只负责发送数据。</li>
<li>假设read请求是一个三元组(blck, off, len)，其中blck包含blockId和GS，off是读取的起始位置，len要读取数据的长度</li>
<li>如果DN有个Replica的GS等于blck的GS或者比blck的GS新，则可以响应当前read请求。</li>
<li>假设DNi中某个Replica的状态是(BAi, BRi)，则DNi能发送的数据为[off, min(off+len, BRi)]，并将BAi一起发送给client</li>
<li>client接收这些数据，并去查找当前Replica最大的BA</li>
<li>如果DNi读失败，client能去任何一台包含此Replica的DN上读取</li>
<li>如何保证一致性的呢？<br> 假设有一个由N个DN组成的pipeline，DN0是pipeline中的第一个。<br> 假设client在时间t能够提供给application的长度是BRc，则<br> <img src="/blogimgs/appendDesign/2BRC.png" alt=""><br> 因此无论从那个DN上读取数据，DN都能够满足。</li>
<li>此方法需要改变下读协议，由于client端要控制读的一致性则会变的较复杂。但是此方法不用请求再次打开一个文件去读数据。</li>
</ul>
<p><em>代码中应该用的是第一种，有时间验证下</em></p>
<h2 id="Append"><a href="#Append" class="headerlink" title="Append"></a>Append</h2><h3 id="Append-API"><a href="#Append-API" class="headerlink" title="Append API"></a>Append API</h3><ol>
<li>client向NN发送一个append请求</li>
<li>NN首先确认此文件已被关闭，然后检查这个文件的最后一个block，<br>如果<em>此block没有写满并且没有Replica，则append操作失败</em>。否则将block改为UnderConstruction状态。<br>如果最后一个block写满了，则NN分配一个新的block作为最后一个block。<br>如果最后一个block没有写满，NN改变这个block的状态为UnderConstruction，并用该block的Finalized Replicas来初始化pipeline(If the last block is not full, NN changes this block to be an underconstruction block, <em>with its finalized replicas as its initial pipeline</em>)<br>返回blockId、GS、length和locations。如果最后一个block未满，也需要返回一个新的GS。</li>
<li>如果最后一个block不满，则为append建立一个pipeline。否则为create建立一个pipeline。</li>
<li>如果最后一个block最后一个chunk没有达到chunk边界，则读取最后一部分的crc chunk，读取它是为了重写计算chunksum</li>
<li>剩下的和正常写的流程一样</li>
</ol>
<h3 id="持久化-Durability"><a href="#持久化-Durability" class="headerlink" title="持久化(Durability)"></a>持久化(Durability)</h3><ul>
<li>NN保证包含append之前数据的Complete block的副本数满足该文件的副本数。</li>
<li>包含append之前数据的UnderConstruction block的持久化在此版本中没设计</li>
</ul>
<h2 id="故障处理"><a href="#故障处理" class="headerlink" title="故障处理"></a>故障处理</h2><h3 id="pipeline-Recovery"><a href="#pipeline-Recovery" class="headerlink" title="pipeline Recovery"></a>pipeline Recovery</h3><p>当一个block是UnderConstruction状态时，可能在stage1、stage2和stage3发生错误。stage1是指pipeline setup，stage2是指data streaming，stage3是指pipeline close。<em>pipeline recovery处理pipeline中的DNs发生的error</em>。</p>
<h4 id="stage1发生故障"><a href="#stage1发生故障" class="headerlink" title="stage1发生故障"></a>stage1发生故障</h4><p>在pipeline setup时，某个DN发生了故障，这个DN发送一个故障的ack到上游DN之后，关闭block文件和所有的tcp/ip连接。一旦client检测到这个故障，client会根据建立pipeline的目的而进行不同的操作：</p>
<ul>
<li>如果新建一个pipeline是为了创建一个新block，则client只是放弃这个block，重新向NN申请一个新的block。然后为这个新的block建立pipeline</li>
<li>如果新建一个pipeline是为了append一个block，则client会用<em>剩下的DNs(不添加新的DN到pipeline中？？)</em>重建一个pipeline并更新block的GS。</li>
</ul>
<p>访问token错误在pipeline setup中是一个特殊的故障。如果由于access token过期而导致pipeline setup失败时，client会继续用之前的DNs重建pipeline。</p>
<h4 id="stage2发生故障"><a href="#stage2发生故障" class="headerlink" title="stage2发生故障"></a>stage2发生故障</h4><ul>
<li>DN的故障可能发生在1.a、1.b、2、3.a和3.b中的任何一个阶段。无论何阶段，当故障发生时，发生故障的DN会退出pipeline(关闭所有的tcp/ip连接，如果故障不是发生在3.a和3.b则将内存中的数据写入磁盘，关闭磁盘上的文件)。</li>
<li>当client检测到故障时，停止发送数据到pipeline</li>
<li>client利用剩下的DNs重构一个pipeline，该block的所有Replica都会产生一个新的GS</li>
<li>client从BAc处重新发送数据，此时GS已经更新。这里有个可以优化的地方就是client从min(BRi, i是pipeline中DN的索引)处重新发送数据。</li>
<li>当DN接收到一个packet时，如果当前DN上已经存在，则data stream直接将其packet发送到下游而不再次写入磁盘。</li>
</ul>
<p>此recovery策略有个很好的特性：只要在old pipeline中数据是可见的，则在重新建立的pipeline中依然是可见的，即使在old pipeline中存放最大长度BA的DN挂掉了。这是因为在pipeline recovery中不会减少任何DN的BA和BR。</p>
<h4 id="stage3发生故障"><a href="#stage3发生故障" class="headerlink" title="stage3发生故障"></a>stage3发生故障</h4><p>client检测到故障，会利用剩下的DNs重建一个pipeline。每个DN会更新block的GS和将未finalized的replica变为finalized。发送一个ack之后关闭所有的网络连接。</p>
<h3 id="DataNode-Restart"><a href="#DataNode-Restart" class="headerlink" title="DataNode Restart"></a>DataNode Restart</h3><ul>
<li>DataNode重启时，会将data目录下rbw子目录下的所有replica的状态变为RWR状态加载到内存，这些Replica的长度是有crc记录的最大值。</li>
<li>RWR Replica是不可见的，也不会出现在pipeline recovery中，也是不可写的(只有在pipeline中的replica才是可写的)。</li>
<li>RWR Replica的client如果存在，则该Replica可能会过时而被NN删掉，如果client不存在，则通过lease recovery将状态变为finalized。</li>
</ul>
<h3 id="NameNode-Restart"><a href="#NameNode-Restart" class="headerlink" title="NameNode Restart"></a>NameNode Restart</h3><ul>
<li>NameNode上不会将block的状态固化到磁盘。因此当NN重启时，需要重新存储block的状态。对于未关闭文件的最后一个block不管该block之前是什么状态都变为UnderConstruction状态，其它的block都是Complete状态。</li>
<li>要求每个DN注册并发送block report。block report中包括除了TEMPORARY状态的所有状态的Replica(finalized、rbw、rwr、rur、)。</li>
<li>当NameNode接收到<em>最少一个副本的Complete状态的block和UnderConstruction状态的block的个数</em>达到之前设置的阈值时，才退出safemode模式。(NameNode does exit safemode unless the number of complete and under construction blocks that have received at least one replica reaches the pre-defined threshold)</li>
</ul>
<h3 id="Lease-Recovery"><a href="#Lease-Recovery" class="headerlink" title="Lease Recovery"></a>Lease Recovery</h3><p>当问及的租约超期之后，NN要为客户端关闭这个文件。这里有两个问题：(1)并行控制，要是在pipeline setup、data steam、pipeline close或者pipeline recovery阶段中，并且client依然存活的时候进行lease recovery会怎样？如果存在多个并行的lease recovery怎么办？(2)一致性保证，当最后一个block是UnderConstruction状态时，其block的所有Replica需要保持一致的状态，也就是说所有的Replica在磁盘上应该记录相同的长度和一样的GS。</p>
<ol>
<li>NN续约时(<em>NN renews lease, 是不是翻译成NN恢复租约时，更加合适</em>)，<em>改变这个文件的租约所有者为dfs</em>并将操作记录在editlog。因此如果client依然活着，任何一个与写相关的请求如生成一个新的GS、增加一个新的block或者关闭这个文件，将被拒绝。之所以被拒绝是因为client此时已经不再拥有此文件的lease。这就阻止了client并发的改变一个未关闭的文件。</li>
<li>NN检查这个文件的最后一个block状态。其它的block应该是Complete状态。下表展示了所有可能的组合和相应组合所采取了动作：</li>
</ol>
<p><img src="/blogimgs/appendDesign/1.png" alt=""></p>
<h3 id="Block-Recovery"><a href="#Block-Recovery" class="headerlink" title="Block Recovery"></a>Block Recovery</h3><ol>
<li>NN选择从Replica所在的DNs中选择一个primary DataNode(PD)作为NN的代理来执行block recovery。如果block没有Replicas则放弃block recovery。</li>
<li>NN得到一个新GS。GS用来标识这个block在recovery成功之后的版本。Block recovery改变最后一个block的状态，如果它是UnderConstruction，则改为UnderRecovery状态(<em>not RUR</em>)。UnderRecovery block由唯一的recovery id标识和新的GS。<em>PD和NN的任何一次通信，都需要匹配recovery id。这就是怎样并发处理block recovery的</em>。<strong>最基础的规则就是最近要提交的recovery的优先级高于之前提交的</strong>。</li>
<li>随后NN要求PD recovery block。NN发送给PD新的GS、block id和所有Replica的locations(包括finalized replica、RBW replica和RWB replica)。</li>
<li>PD执行block recovery：<br>a. PD要求Replica存在的每一个DN去执行replica recovery。<br>   i. PD将recovery id、block id和GS发送给每个DN<br>   ii. DN检查各自Replica的状态：<pre><code>  1、 检查是否存在：如果DN没有这个replica，或者这个replica的GS比请求中的GS要老，更或者是比recovery id要新，则抛出ReplicaNotExistsException
  2、检查是否停止写入：如果一个replica正在写入和一个正在写入的线程，则中断写线程，等待写线程退出。如果写线程正在接受packet时被中断，则停止写线程并放弃这个写入一半的packet。在线程退出之前，确认磁盘上记录的长度与BR相同，然后关闭block文件和crc文件。*这样控制了client write和block recovery在DNs上的并发*。Block recovery抢占client write，导致pipeline失败。随后的pipeline recovery会失败，因为dfs client从NN得到一个UnderRecovery状态block的GS。
  3、停止之前的block recovery：当某个Replica已经是RUR状态时，如果此Replica的recovery id大于等于刚收到此Replica的recovery id，则抛出 RecoveryInProgressException。如果刚收到的GS大，则表示RUR replica的recovery id设置为刚收到的recovery id。
  4、状态改变：将Replica的状态变为RUR。设置recovery id为一个新的recovery id和原来状态的一个引用(Set its recovery id to be the new recovery id and a reference to its old state.)。任何一次PD和它的通信都需要匹配recovery id。*Note3和4在DNs的block recovery并发的问题*。最后一个recovery总是优先于之前的recovery，并且没有两个recovery会有所交叉。
  5、检查crc：对block文件进行一次crc检查。如果Replica的状态是finalized或者RBW时，crc不匹配则抛出CorruptedReplicaException 。然而如果Replica的状态是RWR时，对block文件进行裁剪，将不匹配的部分减掉，保留上次匹配的长度。
</code></pre>   iii. 如果没有任何异常抛出，每个DN将Replica的状态(Replica id、GS、on-disk len、pre-recovery state)返回给PD。<br>b. 从DN收到响应之后，PD来决定block的长度。<br>   i. 如果有一个DN抛出RecoveryInProgressException，则PD放弃block recovery。<br>   ii. 如果所有的DN抛出一个exception(<em>所有的DN抛出的exception必须相同还是？？？</em>)，则放弃block recovery。<br>   iii. 如果NN接收到的所有最大Replica的长度为0，则NN删除这个block<br>   iv. 否则，检查长度非0的Replica返回的状态。下表是两个Replica的可能组合情况:</li>
</ol>
<p><img src="/blogimgs/appendDesign/2.png" alt=""></p>
<p>   c. Recovery Replica的长度设置参考b.iv<br>      i. PD要求每个DN去恢复Replica，由PD发送block id、GS和长度<br>      ii. 如果DN中不存在RUR状态的Replica或者Recovery id和新的GS不匹配，则失败<br>      iii. 否则DN改变这个Replica的GS为新的GS。随后在内存中更新此Replica的长度为新的长度，裁剪这个block file(磁盘中的文件)的长度并改变crc file(may casuse truncation and/or modification of last 4 crcbytes)。如果该Replica不是Finalized状态则变为Finalized状态。此时Replica Recovery成功<br>   d. PD检查c的结果。<br>   如果没有DN成功，则block recovery失败。<br>   如果一些成功一些失败，PD从NN处得到一个新的GS，让成功的DN重复block recovery。<br>   如果所有的DN都成功了，PD将新的GS和长度告知NN。<br>   NN finalizes the block，并且如果这个文件的所有block都是Complete状态，则关闭文件。在超过了尝试关闭文件的次数之后，NN强制关闭文件</p>
<p>pipeline流中至少有一个DN是正常的并且写入流没有被中断，则lease recovery就能够保证在恢复之后对client可见的数据不会丢失。这是因为：</p>
<ol>
<li>在case1、2和3中有一个Replica是Finalized状态。则client在block构建过程中的stage1和或者stage3肯定已经挂了。这个算法不会移除任何数据。</li>
<li>在case4和5中，所有recovery的Replica都有RBW状态(<em>all replicas to be recovered are in rbw state</em>)。client肯定在block构建过程中的stage2时已经死去。假设recovery之前的pipeline有n个DN(DN0、DN1..DNn)，DNi在4.a.ii返回的长度一定等于BRi。假设在pipeline中DN的一个子集DNs(<em>Assume that a subset of the DataNodes S in the pipeline participates the length agreement</em>)，则长度为<em>min(BRi, i为DNs中的索引)&gt;=BRn-1&gt;=BAn-1&gt;=…&gt;=BA0</em>。这就保证了lease recovery不会移除已经对client可见的数据。</li>
<li>在case6中，这个算法没有任何保证，因为在recovery之前的pipeline中的所有DN都已经重启了。</li>
</ol>
<h2 id="Pipeline-Set-Up"><a href="#Pipeline-Set-Up" class="headerlink" title="Pipeline Set Up"></a>Pipeline Set Up</h2><h3 id="pipeline-setup的原因"><a href="#pipeline-setup的原因" class="headerlink" title="pipeline setup的原因"></a>pipeline setup的原因</h3><ol>
<li>Create: 当一个新的block被创建时，pipeline需要在数据传输到DN之前被创建</li>
<li>Append: 当一个文件需要追加时，并且最后一个block没有写满。由最后一个block的所有Replica所在的DN组成的pipeline需要在传输数据到DN之前被建立。</li>
<li>Append Recovery: 当第2种情况失败时，包含剩下DN的pipeline需要被创建。</li>
<li>Data Streaming Recovery: 如果Data Streaming失败，剩下DN组成的pipeline需要在Data Streaming resumes之前被建立。</li>
<li>Close Recovery: 如果pipeline关闭失败，剩下的DN组成的pipeline为了finalize block而需要被建立。</li>
</ol>
<h3 id="pipeline-setup-步骤"><a href="#pipeline-setup-步骤" class="headerlink" title="pipeline setup 步骤"></a>pipeline setup 步骤</h3><p>1、case2、3、4和5都是在已经存在的block上创建pipeline，因此block的GS需要随着pipeline的创建而更新。dfs client向NN请求一个新的GS。</p>
<p>2、dfs client向pipeline中的DN发送一个写block的请求，请求所带的参数有老版本GS的block id、block长度(Replica的长度一定大于等于此长度)、最大的Replica长度、flags、新的GS等。如下表所示：</p>
<p><img src="/blogimgs/appendDesign/3.png" alt=""></p>
<p>3、下表记录了DN在接收到pipeline setup请求之后的行为。需要注意的是，<em>RWR Replica不参与pipeline recovery</em>。通过对RWR Replica进行一些特殊的处理从而放宽这个限制。但是由于这种情况很少见，我们暂时选择什么也不做。</p>
<p><img src="/blogimgs/appendDesign/4.png" alt=""></p>
<p>4、在case2、3和4中，当pipeline setup成功之后，dfs client将new GS、min length和新pipeline中的DN通知给NN。NN随后更新UnderConstruction block的GS、len和locations。</p>
<p>5、当pipeline创建失败时，如果pipeline中还有DN存活，则返回到第一步并且设置flags为recovery。如果pipeline中没有DN存活，表示此次pipeline失败。<br>如果user application在hflush或者write中blocked，则unblocked并抛出EmptyPipelineException。否则在下次write/hflush/close会得到EmptyPipelineException。</p>
<h2 id="向NN报告Replica-Block状态、元数据信息"><a href="#向NN报告Replica-Block状态、元数据信息" class="headerlink" title="向NN报告Replica/Block状态、元数据信息"></a>向NN报告Replica/Block状态、元数据信息</h2><h3 id="client-reports"><a href="#client-reports" class="headerlink" title="client reports"></a>client reports</h3><p>client通知NN更改UnderConstruction block的元数据信息或者状态。</p>
<p>在pipeline set up章节介绍的<em>case2(append)、case3(append recovery)和case4(data streaming recovery)中，一个新的pipeline建立之后，client向NN汇报block的GS和pipeline中的DN</em>。NN随后更新UnderConstruction block的GS、length和locations。</p>
<p><em>需要注意的是，假如pipeline是因为create block而建立的，则client不向NN汇报这个新的block和locations。相反当client通过addBlock/append申请一个新的block时，NN先将这个新block和locations放入blocksMap，然后将block和locations返回给client</em>。这种设计有瑕疵。如果一个读请求去读最后一个block，<em>而这个时间点正好发生在这个block在NN端放入blocksMap后，这个block的一个Replica在DN上创建之前</em>，则这个读请求可能会得到”block dose not exit”的错。由于这种情况很少，我们有意的这样设计已换取性能。当新建block时，pipeline setup 之后，client没有必要向NN发送一个通知。</p>
<p><em>当client请求addBlock或者close文件时，NN会finalize最后一个block的GS和length。如果最后一个block已经存在一个与其GS/len相同的Replica，则将最后一个block的状态可能会变为Complete。否则将最后一个block的状态变为Committed</em>。另外，如果最后一个block的Replica个数小于副本因子，则NN复制这个block使其达满足副本因子。</p>
<h3 id="DataNode-Reports"><a href="#DataNode-Reports" class="headerlink" title="DataNode Reports"></a>DataNode Reports</h3><p>DN周期性的向NN汇报Replica的元数据信息或者状态的改变。当RBW Replica变为Finalized时向NN发送一个blockReceived信息。</p>
<h3 id="Block-Reports"><a href="#Block-Reports" class="headerlink" title="Block Reports"></a>Block Reports</h3><ul>
<li><em>block汇报的内容包括两种，一种是针对Finalized Replica，另一种是针对RBW Replica</em>。Finalized Replica时汇报的内容包括Finalized的Replica和之前状态是Finalized而现在是RUR状态的Replica。RBW Replica时汇报的内容包括RBW Replica、RWR Replicas和之前状态不是Finalized而现在的状态是RUR的Replica。<em>RBW Replica的长度是已经接收到的长度(BR)</em>。RWR的长度是一个负数。</li>
<li>Replica汇报的状态是一个四元组(DataNode, blck_id, blck_GS, blck_len, isRbw)</li>
<li>NN收到block report之后，和内存中的状态进行对比，对比的结果如下：(在内存中保存着4个list)<br> 1、如果blck_id无效则放入deleteList中，例如blocksMap中不存在blck_id的Entry或者不属于任何一个文件<br> 2、如果NN没有这个Replica(DataNode, blck_id)但是block report中有，则加入addStoredBlockList<br> 3、如果NN有这个Replica(DataNode, blck_id)但是block report中没有，则加入rmStoredBlockList<br> 4、如果Replica在NN中的状态是RBW，而block report中是Finalized，则加入updateStateList。(<strong>RBW应该是DN的状态，怎么会在NN中记录呢？？</strong>)<br>避免client report和DataNode report竞争条件，则RBW Replica只加入deleteList或者addStoredBlockList。</li>
<li>添加一个新的Replica<br> 1、Block在NN中的状态是Complete<br> 当汇报的Replica的状态是Finalized时，如果它的GS和length和NN记录的值不一样，则将它加入blocksMap但要标记为corrupt。否则add the replica(<strong>??????</strong>)。<br> 当汇报的Replica的状态是RBW时，如果这个文件已经关闭，如果Replica的GS/length和NN中记录的值不一样或者这个block已经达到了副本因子的个数，则命令它的DataNode将其Replica删除。否则do nothing。<br> 2、Block在NN中的状态是Committed<br> 这个处理的流程和上面的情况类似，除非汇报的Replica的状态是Finalized并且和NN中记录的GS和length相同，则NN将这个block的状态改为Complete。<br> 3、Block在NN中的状态是UnderConstruction或者UnderRecovery<br> 如果汇报的Replica的状态是Finalized并且此Replica的GS与NN中记录的GS相同或者比NN中记录的值新，则add the replica。同时标记这个replica为Finalized和保持对它的长度和GS的跟踪。<br> 如果汇报的Replica的状态是RBW并且此Replica是有效的(GS不老，length不短)，add the replica。如果Replica是RBW，则标记为RBW，否则标记为RWR。<br> 否则忽略它(Otherwise ignore it)。</li>
<li>更新Replica的状态<br>当block report的内容是Replica从RBW变为Finalized状态时，<br>如果这个block是UnderConstruction状态，NN标记NN存储这个Replica为Finalized并且记录这个Finalized Replica的GS和length(NN marks the NN stored replica as finalized and keeps track of the finalized replica’s GS and length)。<br>如果这个block是Committed状态，如果这个Finalized Replica的GS和length和block的GS和length相匹配，则NN改变这个block的状态为Complete。<br>否则从NN上移除该Replica。</li>
</ul>
<h3 id="blockReceived"><a href="#blockReceived" class="headerlink" title="blockReceived"></a>blockReceived</h3><p>DataNode向NN发送blockReceived通知NN一个Replica已经完成。<br>当NN接收到blockReceived通知后，<br>如果(DataNode, blck_id)在NN中不存在，则add a new replica。<br>如果replica记录的状态是RBW，则更新replica的状态。<br>如果block是无效的，则要求DataNode删除这个replica。</p>
<h2 id="Replica-Block-State-Transition"><a href="#Replica-Block-State-Transition" class="headerlink" title="Replica/Block State Transition"></a>Replica/Block State Transition</h2><h3 id="Replica-State-Transition"><a href="#Replica-State-Transition" class="headerlink" title="Replica State Transition"></a>Replica State Transition</h3><p>下图总结了Replica在DataNode上所有可能的状态转移。<br><img src="/blogimgs/appendDesign/ReplicaTransition.png" alt="Replica State Transition" title="Replica State Transition"></p>
<ul>
<li>新的Replica被创建<br> 如果新的Replica是被client创建，则Replica的状态是RBW。<br> 如果是由于NN发送的一个复制(复制副本或者balance)的指令，则Replica的状态是Temporary。</li>
<li>当DN重启时，RBW Replica改变状态为RWR。</li>
<li>当lease到期而引起的Replica recovery时，Replica的状态变为RUR</li>
<li>当client关闭文件、Replica recovery成功或者复制成功时，Replica的状态是Finalized。</li>
<li>recovery发生错误，总是会更新Replica的GS</li>
</ul>
<h3 id="Block-State-Transition"><a href="#Block-State-Transition" class="headerlink" title="Block State Transition"></a>Block State Transition</h3><p>下图总结了Block在NN上所有可能的状态转移。<br><img src="/blogimgs/appendDesign/BlockTransition.png" alt="Block State Transition" title="Block State Transition"></p>
<ul>
<li>Block被创建<br> 如果client调用addBlock给一个文件添加一个新的block时，创建Block<br> 如果client调用append并且文件的最后一个block已经写满，则创建Block<br>新创建的Block的状态是UnderConstruction   </li>
<li>如果最后一个block没有写满，则append会将最后一个block由Complete状态变为UnderConstruction。</li>
<li>当addBlock或者close时，<br> 最后一个Block的状态可能是Complete(Block的GS和len已经有Replica与之相匹配)也可能是Committed(不匹配则为Committed)。<br> addBlock会一直等到直到倒数第二个Block变为Complete。<br> 直到最后两个block变为Complete时，文件才会关闭</li>
<li>当lease到期时，lease recovery将UnderConstruction状态的block变为UnderRecovery<br> block recovery会将UnderRecovery变为：<br> 1、如果Replica的长度为0则移除。<br> 2、如果recovery成功并且没有与GS和len相匹配的Finalized Replica存在，则变为Committed。<br> 3、如果recovery成功并且有与GS和len相匹配的Finalized Replica存在，则变为Complete。<br> <strong>lease recovery会强制将Committed block变为Complete</strong>。</li>
<li>Block的状态不会存储在磁盘。当NN重启时，未关闭文件的最后一个block变为UnderConstruction，<em>其余的block为Complete(倒数第二个block是Committed也会强制变为Complete)</em>。<br> 如果这个block是文件的最后一个block，当NN重启时，最后一个block可能会从Complete或者Committed状态变为UnderConstruction。如果client依然存在，client会再次将此block finalize。否则当lease超期时，block recovery会再次finalize。</li>
<li>一旦一个block变成Complete或者Committed，该block的所有Replicas应该有相同的GS和长度。<em>当一个block是UnderConstruction，它可能有多个版本的block混合存在集群中</em>。</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> Append </tag>
            
            <tag> Hflush </tag>
            
            <tag> Read </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java NIO]]></title>
      <url>http://bigdatadecode.club/Java%20NIO.html</url>
      <content type="html"><![CDATA[<h2 id="Java-NIO"><a href="#Java-NIO" class="headerlink" title="Java NIO"></a>Java NIO</h2><p>在整理NIO文档前先介绍下5个I/O模型。在将I/O模型之前还得介绍几个概念：</p>
<p><img src="/blogimgs/javanio-1.jpg" alt="I/O操作流程" title="I/O操作流程"></p>
<ul>
<li>内核空间和用户空间</li>
</ul>
<blockquote>
<p>数据从磁盘移动到用户进程的内存区域时，要涉及到内核空间和用户空间。<br>用户空间就是常规进程（如JVM）所在区域，<em>用户空间</em>是<code>非特权区域</code>，如<code>不能直接访问硬件设备</code>。<em>内核空间</em>是<code>操作系统所在区域</code>，那肯定是有特权啦，如能与设备控制器通讯，控制用户区域的进程运行状态。进程执行I/O操作时，它执行一个系统调用把控制权交由内核。</p>
</blockquote>
<ul>
<li>缓冲区操作</li>
</ul>
<blockquote>
<p>缓冲区操作是所有I/O的基础，进程执行I/O操作，归结起来就是向操作系统发出请求，让它要么把缓冲区里的数据排干（写），要么把缓冲区填满（读）</p>
</blockquote>
<a id="more"></a>
<h3 id="5种I-O模型"><a href="#5种I-O模型" class="headerlink" title="5种I/O模型"></a>5种I/O模型</h3><p><em>IO请求分为两个阶段</em>：1、等待数据就绪。2、从内核缓冲区拷贝数据到进程缓冲区<br>按照请求是否阻塞分为：同步IO和异步IO。<br>Unix存在5种IO模型：<br>（1）阻塞IO:最常用的模型，缺省情况文件操作都是阻塞的。<br><img src="/blogimgs/javanio-blocking-2.png" alt="阻塞I/O" title="阻塞I/O"><br>（2）非阻塞IO:用户需要不断主动询问kernel数据是否准备好了，准备好之后<em>通知</em>用户将数据从内核空间copy到用户空间(<em>用户得到通知之后，<strong>亲自去</strong>内核空间中将数据复制到用户空间</em>)。<br>这里的非阻塞是指<em>等待数据准备好的这段时间不会阻塞</em>，需要说明的是等待就绪的阻塞是不使用CPU的，是在<em>空等</em>；<em>而真正的读写操作的阻塞是使用CPU的，真正在”干活”，而且这个过程非常快，属于memory copy</em>，带宽通常在1GB/s级别以上，可以理解为基本不耗时。。<br><img src="/blogimgs/javanio-nonblocking-3.png" alt="非阻塞I/O" title="非阻塞I/O"><br>（3）IO复用:也叫作event driven IO<br><img src="/blogimgs/javanio-multiplexing-4.png" alt="I/O复用" title="I/O复用"><br>（4）信号驱动IO:内核通知我们何时可以开始一个I/O操作<br>（5）异步IO:内核通知我们I/O操作何时<strong>已经完成</strong><br><img src="/blogimgs/javanio-asynchronous-5.png" alt="异步I/O" title="异步I/O"></p>
<h3 id="疑问–Java-NIO对应哪种I-O模型？"><a href="#疑问–Java-NIO对应哪种I-O模型？" class="headerlink" title="疑问–Java NIO对应哪种I/O模型？"></a>疑问–Java NIO对应哪种I/O模型？</h3><blockquote>
<p>wiki上说”Non-blocking I/O (usually called NIO, and sometimes called “New I/O”)”，而又有很多blog说NIO就是IO复用，经常说NIO的<code>select</code>是IO复用，在I/O模型中非阻塞IO和IO复用是两种不同的模型，<strong>这个是怎么回事？？？</strong>Java NIO与Non-blocking I/O、I/O复用的关系是什么？？？？<em>是一种同步非阻塞的I/O模型，也是I/O多路复用的基础</em>。</p>
</blockquote>
<h3 id="NIO的优势"><a href="#NIO的优势" class="headerlink" title="NIO的优势"></a>NIO的优势</h3><p>NIO较于传统IO的优势在于NIO是基于<em>块</em>的，而且有<em>通道</em>（Channel）和<em>缓冲区</em>（buffer）的概念，更加接近操作系统执行IO的方式。</p>
<p>优势如下：</p>
<ul>
<li>事件驱动模型(Reactor设计模式–Reactor是并发编程中的一种基于事件驱动的设计模式。)</li>
<li>避免多线程(Reactor模式中<em>单线程轮询</em>来进行事件分发)</li>
<li>非阻塞I/O，I/O读写不再阻塞，而是返回0</li>
<li>基于block的传输，通常比基于流的传输更高效</li>
<li>更高级的IO函数，zero-copy</li>
<li>IO多路复用大大提高了Java网络应用的可伸缩性和实用性</li>
</ul>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><ul>
<li>缓冲区</li>
</ul>
<p>在缓冲区中，最重要的属性有下面三个，它们一起合作完成对缓冲区内部状态的变化跟踪：<br>position：指定了下一个将要被写入或者读取的元素索引，它的值由get()/put()方法自动更新，在新创建一个Buffer对象时，position被初始化为0。<br>limit：<strong>指定当前buffer中读取数据时的末尾index</strong> 例如当前buffer的capacity是10，但只写入内容只占到4，则此时读取buffer时，limit为4，读取的内容到limit为止，也可以说limit记录了当前buffer已用的容量。也就是说指定当前buffer有多少数据需要取出(在从缓冲区写入通道时)，或者有多少空间可以放入数据(在从通道读入缓冲区时)。<br>capacity：指定了可以存储在缓冲区中的最大数据容量，实际上，它指定了底层数组的大小，或者至少是指定了准许我们使用的底层数组的容量。</p>
<blockquote>
<p>读取buffer中的数据时，调用<code>flip()</code>,此方法将会完成两件事情：<br>1、把limit设置为当前的position值<br>2、把position设置为0</p>
</blockquote>
<p>以上三个属性值之间相对大小的关系：0 &lt;= position &lt;= limit &lt;= capacity。如果我们创建一个新的容量大小为10的ByteBuffer对象，在初始化的时候（调用<code>clear()</code>方法将buffer重置为初始化），position设置为0，limit和 capacity被设置为10，在以后使用ByteBuffer对象过程中，capacity的值不会再发生变化，而其它两个个将会随着使用而变化。</p>
<ul>
<li>通道</li>
</ul>
<p>通道主要用来传输数据，与缓冲区进行交互，与Selector关联起来使用的，实际上是通过SelectableChannel中的<code>register()</code>方法进行注册的<strong>（如果在阻塞模式下注册一个通道，系统会抛出IllegalBlockingModeException异常。 ）</strong>。<code>register()</code>方法返回一个<code>SelectionKey</code>，<code>SelectionKey</code>是Channel和Selector之间的关联对象，该对象可以通过<code>channel()</code>和<code>selector()</code>方法得到该SelectionKey关联的channel和selector。SelectionKey维护着两个Set集合，一个是感兴趣的事件集合<code>interestOps()</code>，另一个是准备好了的，可以进行IO操作的集合<code>readyOps()</code>。SelectionKey类中定义了4种可选择操作：read、write、 connect和accept，每个具体通道有不同的有效的可选择操作集 合，比如ServerSocketChannel的有效操作集合是accept，而SocketChannel的有效操作集合是read、write和 connect。 </p>
<ul>
<li>选择器</li>
</ul>
<p>选择器可谓NIO中的重头戏，I/O复用的核心，其中维护着两个键的集合：<em>已注册的键的集合</em><code>keys()</code>和<em>已选择的键的集合</em><code>selectedKeys()</code>，已选择的键的集合是已注册的键的集合的子集。除此之外，其实选择器内部还维护着一个已取消的键的集合，这个集合包含了cancel()方法被调用过的键。 </p>
<p>当Selector和特定的SelectableChannel关联好后就开始工作了，工作时只需要调用<code>select()</code>方法。<code>select()</code> 是<em>阻塞</em>调用线程，直到有某个Channel的某个感兴趣的Op准备好了。<code>select()</code>只返回本次执行<code>select()</code>时从<em>未准备好到准备好状态的channel数（在执行<code>select()</code>之前已经准备好的channel不进行计数）</em>，如果不为0，将调用<code>selectedKeys()</code>方法得到一个已选择的键的集合set。</p>
<h3 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h3><p>下面是一个服务器端代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> port = <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ServerSocketChannel没有bind()方法，</span></span><br><span class="line"><span class="comment">//因此需要取出对等的Socket对象并使用它来绑定到某一端口以开始监听连接。</span></span><br><span class="line">ServerSocketChannel serverChannel = ServerSocketChannel.open( );</span><br><span class="line">ServerSocket serverSocket = serverChannel.socket( );</span><br><span class="line">serverSocket.bind (<span class="keyword">new</span> InetSocketAddress (port));</span><br><span class="line"></span><br><span class="line"><span class="comment">//通常Selector是由静态工厂方法open()实例化的</span></span><br><span class="line">Selector selector = Selector.open( );</span><br><span class="line"></span><br><span class="line"><span class="comment">//如果在阻塞模式下注册一个通道，系统会抛出IllegalBlockingModeException异常。 </span></span><br><span class="line">serverChannel.configureBlocking (<span class="keyword">false</span>);</span><br><span class="line">serverChannel.register (selector, SelectionKey.OP_ACCEPT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Dispatch Loop</span></span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">//select() 阻塞调用线程，直到有某个Channel的某个感兴趣的Op准备好了</span></span><br><span class="line"><span class="comment">//返回本次执行select时从未准备好到准备好状态的channel数，</span></span><br><span class="line"><span class="comment">//不为0，则调用selector.selectedKeys()</span></span><br><span class="line">    <span class="keyword">int</span> n = selector.select( );</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">continue</span>; <span class="comment">// nothing to do</span></span><br><span class="line">    &#125;</span><br><span class="line">    Iterator it = selector.selectedKeys().iterator( );</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext( )) &#123;</span><br><span class="line">    	<span class="comment">//得到SelectionKey</span></span><br><span class="line">        SelectionKey key = (SelectionKey) it.next( );</span><br><span class="line">        <span class="keyword">if</span> (key.isAcceptable( )) &#123;</span><br><span class="line">        	<span class="comment">//通过SelectionKey的channel()得到该感兴趣事件的channel</span></span><br><span class="line">            ServerSocketChannel server = </span><br><span class="line">            			(ServerSocketChannel) key.channel( );</span><br><span class="line">            <span class="comment">//在非阻塞模式下，当没有传入连接在等待时，</span></span><br><span class="line">            <span class="comment">//其accept()方法会立即返回null。</span></span><br><span class="line">            SocketChannel channel = server.accept( );</span><br><span class="line">            <span class="keyword">if</span> (channel == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">//handle code, could happen</span></span><br><span class="line">            &#125;</span><br><span class="line">            channel.configureBlocking (<span class="keyword">false</span>);</span><br><span class="line">            channel.register (selector, SelectionKey.OP_READ);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (key.isReadable( )) &#123;</span><br><span class="line">            readDataFromSocket (key);  </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//这行代码是必要的,将该key放入cancel集合中，在下次select()时删除</span></span><br><span class="line">        it.remove( );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><p><a href="https://yq.aliyun.com/articles/2371" target="_blank" rel="noopener">https://yq.aliyun.com/articles/2371</a><br><a href="http://www.molotang.com/articles/906.html" target="_blank" rel="noopener">http://www.molotang.com/articles/906.html</a><br><a href="http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf" target="_blank" rel="noopener">http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf</a></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> NIO </tag>
            
            <tag> IO </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS恢复过程1]]></title>
      <url>http://bigdatadecode.club/%5B%E8%AF%91%5DHDFS%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B1.html</url>
      <content type="html"><![CDATA[<p>运行或者移动生产环境中的Hadoop时，对很好的掌握HDFS的恢复过程是非常重要的。<br>HDFS中一个重要的设计需求就是要保证在生产部署中持续正确的操作。<em>尤其复杂的是在网络和节点故障的情况下保证写入HDFS的正确性，租约恢复、block恢复和pipeline恢复保证了写的正确性。</em>理解这些恢复操作何时何地被调用，以及做了什么，能帮助用户或者开发者理解HDFS集群的原理。</p>
<p>在这篇博客中，你会对那些恢复流程有个更深入的理解。首先简单介绍下HDFS write pipeline和恢复流程，对block/replica的状态和generation stamps的概念进行解释，然后逐步介绍租约恢复和block恢复。</p>
<p>这系列文章被分为两篇：第一篇介绍租约恢复和block恢复的细节，第二篇主要介绍pipeline恢复。想了解更多的内容，请参考设计文档：<a href="https://issues.apache.org/jira/secure/attachment/12445209/appendDesign3.pdf" target="_blank" rel="noopener">Append, Hflush, and Read for implementation details</a></p>
<a id="more"></a>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>HDFS中，文件被分为块存储。HDFS中的文件可以被多client同时读，但只能被一个client写入。block的多副本存储在不同的dn上保证了HDFS的容错需求。其中副本的个数被称为副本因子。当一个新文件的block被创建，或者打开一个已经存在的文件(因为写或者追加)，HDFS写操作会创建一个由dns组成的pipeline来接收并存储副本(副本因子决定了在pipeline中dns的个数)。下图是block写入pipeline的流程：<br><img src="/blogimgs/HDFS恢复过程/block2pipeline.png" alt="block写入pipeline" title="block写入pipeline"><br>client读文件时从存放文件block的dns中选择一个dn，并请求从dn上进行数据传输。</p>
<p>下面两个应用场景突显了容错的重要性：</p>
<ul>
<li>HBase的Region Server(RS)写时会先写入WAL，WAL是一个HDFS文件，能够防止数据丢失。如果一个RS宕机，一个新的RS会启动并通过读取WAL文件去重构先前RS的状态。如果在RS宕机的时候，写入pipeline没有完成，在pipeline中的dns上的数据可能并没有同步。为了重构RS正确的状态，HDFS必须保证从WAL中读取数据的正确性。</li>
<li>Flume客户端需要实时的将数据写入HDFS中，甚至在pipeline中存在一些dn失败或者停止响应的情况下，也必须保证能够持续的写。</li>
</ul>
<h2 id="租约恢复、block恢复和pipeline恢复发生在以下的情况下："><a href="#租约恢复、block恢复和pipeline恢复发生在以下的情况下：" class="headerlink" title="租约恢复、block恢复和pipeline恢复发生在以下的情况下："></a>租约恢复、block恢复和pipeline恢复发生在以下的情况下：</h2><ul>
<li>在client可以往HDFS上写文件之前，必须从nn上得到一个租约(Lease)，这个租约也就相当于一个写锁。租约保证了只有一个client写的语义。如果当前client想要维持写操作，租约必须在预定义的时间周期内更新租约。如果一个租约没有被更新或者持有该租约的client死了，则租约会过期。当租约过期之后，HDFS会关闭租约对应的文件并且会释放代表这个client的租约，然后其它clients就能够写这个文件了。<em>这个过程被称为租约回收</em>。</li>
<li>当租约恢复发生的时候，如果一个文件正在写入的最后一个block没有传播到在pipeline中的所有dn，写入到不同dn上的数据可能不同。在租约恢复导致这个文件被关闭之前，有必要保证最后一个block的所有replicas相同，<em>这个过程被称为block恢复</em>。<em>block恢复只有在租约恢复时被触发</em>，并且租约恢复只会触发一个文件的最后一个block(<em>如果该block不是COMPLETE状态</em>)进行block恢复。</li>
<li>在写pipeline操作中，有些dn可能会失败。如果发生失败，底层的写操作不能被简单粗暴的失败。HDFS会尝试恢复这些error，允许client能够继续写入pipeline中。从pipeline中恢复error的流程被称为pipeline恢复。</li>
</ul>
<p>下面的章节将对这些过程进行更加深入的介绍。</p>
<h2 id="Blocks、Replicas和他们的状态"><a href="#Blocks、Replicas和他们的状态" class="headerlink" title="Blocks、Replicas和他们的状态"></a>Blocks、Replicas和他们的状态</h2><p>为了区分Namenode中的blocks和DataNode中的blocks，将NameNode中的blocks称为blocks，将DataNode中的blocks称为replicas。</p>
<p>DataNode中的replica有如下状态(定义在org.apache.hadoop.hdfs.server.common.HdfsServerConstants.java中)：</p>
<ul>
<li>FINALIZED: 当replica是这个状态时，该replica的写入操作已经完成，数据的大小不会发生变化，除非对该replica进行append操作。有一样generation stamp(GS)的block的所有replica是相同的。finalized replica的GS可能会在block恢复中递增。</li>
<li>RBW(Replica Being Written): 不管是新建一个文件还是重新打开一个文件进行追加，此时任何一个正在被写入的replica都RBW状态。RBW状态的replica总是文件的最后一个block。数据依然正在写入该replica，replica并没有finalized。<em>RBW replica中的数据(不一定是所有的数据)是可读的</em>。如果有任何故障发生，RBW状态的replica会尝试保存数据。</li>
<li>RWR(Replica Waiting to be Recovered): 如果dn宕机或者重启了，其上的所有RBW状态的replicas将会将状态转换为RWR。RWR状态下的replica将会变成过期的，然后被丢弃；或者参与租约恢复中。</li>
<li>RUR(Replica Under Recovery): 在租约恢复的过程中，任何一个非TEMPORARY状态的replica都有可能转换为RUR状态。</li>
<li>TEMPORARY: 在block复制(由replication monitor或者balancer引起的block复制操作)中会出现temporary状态的replica。此状态下的replica与RBW状态类似，只是该状态下的数据是不可见的。如果block复制失败，TEMPORARY状态下的replica会被删除。</li>
</ul>
<p>block在NameNode中的状态(定义在org.apache.hadoop.hdfs.server.common.HdfsServerConstants.java)如下：</p>
<ul>
<li>UNDER_CONSTRUCTION: block正在写入时处于此状态。在UNDER_CONSTRUCTION下的block是被打开文件的最后一个block，该block的长度和generation stamp都是可变的，并且<em>它的数据(不一定是所有的数据)是可见的</em>。nn保持写pipeline的跟踪(有效RBW replicas的位置)，和对RWR replicas的定位</li>
<li>UNDER_RECOVERY: 如果一个文件的租约超期时，该文件的最后一个block是UNDER_CONSTRUCTION，在block恢复开始时，该block会变为UNDER_RECOVERY。</li>
<li>COMMITTED: COMMITTED意味着一个block的数据和generation stamp不会发生变化(除非再次打开进行追加)，并且比上报FINALIZED状态、有着相同GS/length的replicas的最小副本数少(<em>具体不太明白，可能翻译的有问题，附上原文–and there are fewer than the minimal-replication number of DataNodes that have reported FINALIZED replicas of same GS/length</em>)。为了提供读服务，COMMITTED状态的block必须保持对RBW replicas位置的跟踪和FINALIZED replicas的GS、length的跟踪。当client请求nn增加一个block或者关闭文件时，处于UNDER_CONSTRUCTION状态的block将变为COMMITTED状态。如果一个文件的最后一个block或者倒数第二个block是COMMITTED状态，则该文件不能被关闭，client必须进行重试。</li>
<li>COMPLETE: 当发现了有着相同GS/length的FINALIZED状态下的replicas满足最小副本数，则该block由COMMITTED转为COMPLETE状态。只有当所有的block都变成COMPLETE时，该文件才能被关闭。即使一个block不满足最小副本数，也可能被强制变为COMPLETE，例如当先前的block还没有到COMPLETE状态，client请求一个新block，此时会将先前的block强制变为COMPLETE状态。</li>
</ul>
<p>DataNodes将replica的状态持久化到磁盘，但是NameNode并不会讲block的状态持久化到磁盘。当NameNode重启时，nn会将先前打开文件的最后一个block的状态变为UNDER_CONSTRUCTION，将其余block的状态变为COMPLETE。</p>
<p>replica和block的状态转换图如下：<br><img src="/blogimgs/HDFS恢复过程/replica-state.png" alt="replica-state" title="replica-state"><br><img src="/blogimgs/HDFS恢复过程/block-state.png" alt="block-state" title="block-state"></p>
<h2 id="Generation-Stamp"><a href="#Generation-Stamp" class="headerlink" title="Generation Stamp"></a>Generation Stamp</h2><p>对于每一个block来说，GS是一个单调递增的8-byte数字，由NameNode进行维护。block和replica的GS处于下面的目的被引入：</p>
<ul>
<li>检测一个block的陈旧的replica: 也就是说，这个replica的GS小于这个block的GS。这是可能发生的，例如一个追加操作，不知什么原因跳过了此replica，没有更新此replica，使该replica的GS依然是为追加之前的GS，而其余replica的GS现在已经是追加之后的GS。</li>
<li>当一个DataNode死了一段时间，然后又重新加入了集群，此时在此DataNode上检测过时的replica。</li>
</ul>
<p>当下面的情况发生时，一个新的GS会产生：</p>
<ul>
<li>创建一个新文件</li>
<li>client对一个已经存在的文件进行append或者truncate</li>
<li>client在向dns上写数据时发生错误，会请求一个新的GS</li>
<li>NameNode对一个文件发起租约恢复操作</li>
</ul>
<h2 id="Lease-Recovery-and-Block-Recovery"><a href="#Lease-Recovery-and-Block-Recovery" class="headerlink" title="Lease Recovery and Block Recovery"></a>Lease Recovery and Block Recovery</h2><h3 id="Lease-Manager"><a href="#Lease-Manager" class="headerlink" title="Lease Manager"></a>Lease Manager</h3><p>租约在NameNode上被lease Manager进行管理。NameNode跟踪每个client打开的写文件。client没有必要为它打开的每个写文件进行单独更新租约，而是定期的向NameNode发送一个请求对所有的文件进行租约更新。</p>
<p>每个NameNode管理一个单独的HDFS namespace，每个HDFS namespace会有一个单独的lease manager来管理与该namespace相关的所有client租约。Federated HDFS集群可能有多个namespace，每个namespaces都有其自己的lease manger。</p>
<p>lease manager维护这两个超时时间(目前这两个超时时间是不可配置的)，一个是softLimit(1m)，另一个是hardLimit(1h)。lease manager管理的所有租约都遵守相同的softLimit和hardLimit。在softLimit过期之前，持有某文件租约的client独占该文件的写权限。如果softLimit超期并且client并没有更新租约或者关闭了文件，另一个client能强制接管这个租约。如果hardLimit超期并且client没有更新租约，HDFS假设此client已经退出，将自动关闭代表client的文件，从而恢复租约。</p>
<p>事实上client持有的某个文件租约并不会阻止其它client对此文件进行读，一个文件能同时有多个client进行读，但只能有一个client进行写。</p>
<p>lease manager内部支持的操作：</p>
<ul>
<li>为一个client增加一个租约和路径(如果这个client已经有了一个租约，则增加这个路径到这个租约。否则，创建一个新的租约，并添加路径到租约里面)</li>
<li>移除client的租约和路径(如果这是租约的最后一个路径，则移除这个租约)</li>
<li>检查soft/hard limit是否过期，</li>
<li>和对给定的client进行renew租约。</li>
</ul>
<p>lease manager有一个monitor线程，此线程周期性(每2s)的检查所有租约是否hardLimit超期，如果超期，则对租约中的所有文件触发租约恢复。</p>
<p>HDFS client通过org.apache.hadoop.hdfs.LeaseRenewer.LeaseRenewer类renews它自己的租约。LeaseRenewer对每个NameNode上的每个user运行一个线程去周期性的检查，当间隔超过租约检查的一半，则更新LeaseRenewer对应的所有client的租约。</p>
<p>(注意: 一个HDFS client只会关联一个NameNode; 请看它的构造器 org.apache.hadoop.hdfs.DFSClient)。 如果同一个应用想要访问联邦集群的不同NS的不同的文件，需要为每一个NameNode创建client。</p>
<h3 id="Lease-Recovery-Process"><a href="#Lease-Recovery-Process" class="headerlink" title="Lease Recovery Process"></a>Lease Recovery Process</h3><p>租约的恢复过程被NameNode触发用来对给定的client进行恢复租约。在通过监控线程检查到达hardLimit的有效期，或者softLimit过期时，其他客户端尝试接管租约的情况下NameNode会触发Lease Recovery。Lease Recovery会检查相同client打开的每个写文件，如果这个文件的最后一个block不是COMPLETE状态则执行block recovery，并且关闭这个文件。<em>Block Recovery只有在Lease Recovery时会被触发</em>。</p>
<p>下面是给定文件f的Lease Recovery算法。当client死了，该算法适用于该client打开的每个写文件。</p>
<p>1、得到包含f最后一个block的dns<br>2、从dns中分配一个dn作为primary dn p<br>3、p从NameNode中得到一个新的GS<br>4、p从每个dn上得到block的信息<br>5、p就是这个block的最小长度<br>6、p更新dns，拥有合法的GS，即新的GS和最小的block长度。<br>7、p确认NameNode更新的结果.<br>8、NameNode更新BlockInfo<br>9、NameNode移除f的租约(其他写的操作现在可以维护这个文件f的租约，进行写入操作)<br>10、NameNode提交这些改变到edit log.<br>第三步到第七步是算法的block recovery部分。如果一个文件需要block recovery，NameNode从拥有该文件最后一个block的replica的DataNodes中挑选一个primary DataNode，使其DataNode协调其余DataNodes进行block recovery。结束之后，这个DataNode想NameNode报告，NameNode更新这个block的内部状态，移除这个租约，最后想edit log提交改变。</p>
<p>有时管理员在hardLimit未超时之前，需要强制对某个文件进行Lease Recovery，此时可以使用一个CLI<br><code>hdfs debug recoverLease [-path &lt;path&gt;] [-retries &lt;num-retries&gt;]</code></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><em>租约恢复，块恢复，和pipeline恢复对HDFS容错至关重要</em>。他们一起保证了HDFS写的持久性和一致性，即使是在网络或者节点异常的情况下。</p>
<p>在下一篇中将介绍pipeline recovery。</p>
<p><a href="http://blog.cloudera.com/blog/2015/02/understanding-hdfs-recovery-processes-part-1/" target="_blank" rel="noopener">原文地址</a></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> Lease Recovery </tag>
            
            <tag> Block Recovery </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS read解析(一)之Open文件流]]></title>
      <url>http://bigdatadecode.club/HDFS%20read%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p>本篇主要记录下HDFS读取文件的流程，流程图如下：<br><img src="/blogimgs/HDFS read解析/read流程图.png" alt="read流程图" title="read流程图"></p>
<p>如上图所示，</p>
<ol>
<li>HDFS Client通过FileSystem.get()方法实例化一个FileSystem对象</li>
<li>调用FileSystem.open打开一个文件的数据流FSDataInputStream，<em>open</em>中会用rpc方法<code>getBlockLocations</code>得到block的locations信息，默认会先得到<em>prefetchSize</em>(<code>conf.getLong(DFS_CLIENT_READ_PREFETCH_SIZE_KEY, 10 * defaultBlockSize)</code>)大小文件的信息。</li>
<li>HDFS Client通过FSDataInputStream流读取离客户端最近的dn上的block，在第2步中得到的block location信息已经将block的副本按照离客户端的网络拓扑距离进行了排序，此过程是在nn端完成的。</li>
<li>读取完当前block的数据后，关闭与当前的DataNode连接，并为读取下一个block寻找最佳的DataNode；</li>
<li>当读完列表的block后，且文件读取还没有结束，客户端会继续向Namenode获取下一批的block列表。</li>
<li><em>读取完一个block都会进行checksum验证，如果读取datanode时出现错误，客户端会通知Namenode，然后再从下一个拥有该block拷贝的datanode继续读</em>； </li>
</ol>
<a id="more"></a>
<h2 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h2><ul>
<li>inode<br>文件数据都储存在”块”中，那么很显然，我们还必须找到一个地方储存文件的元信息，比如文件的创建者、文件的创建日期、文件的大小等等。这种储存文件元信息的区域就叫做inode，中文译名为”索引节点”。每一个文件都有对应的inode，里面包含了与该文件有关的一些信息。<br>在HDFS中inode也就是一个文件在内存中的一个抽象，保存了该文件的一些元数据信息。<br>INODE在代码中是一个最底层的抽象类</li>
<li>INodeFile<br>文件节点类，继承自INode，表示一个文件，其中有个重要的属性<code>private BlockInfo[] blocks</code>，blocks中存储的是该文件的block信息BlockInfo，其中每个block(BlockInfo)是一个具有3个元素的数组(triplets)，也就是三个指针域，大小为3<em>replicas，其中replicas是Block副本数量。triplets包含的信息：<br>triplets[3</em>i]：Block所在的DataNode A；(<em>DatanodeStorageInfo对象</em>)<br>triplets[3<em>i+1]：该DataNode A上前一个Block；(<em>指向前一个block的BlockInfo对象引用</em>)<br>triplets[3</em>i+2]：该DataNode A上后一个Block；(<em>指向后一个block的BlockInfo对象引用</em>)<br>其中i表示的是Block的第i个副本，i取值[0,replicas)。</li>
<li>INodeDirectory<br>文件目录类，也是继承自INode.他的孩子中是文件集也可能是目录</li>
<li>INodeDirectoryWithQuota<br>有配额限制的目录，这是为了适应HDFS中的配额策略。</li>
<li>INodeFileUnderConstruction<br>处于构建状态的文件类，可以从INodeFile中转化而来。</li>
<li><em>FSNamesystem中相关的属性</em></li>
</ul>
<h2 id="HDFS-Read之打开文件流"><a href="#HDFS-Read之打开文件流" class="headerlink" title="HDFS Read之打开文件流"></a>HDFS Read之打开文件流</h2><p>HDFS读取文件内容跟java读取文件内容类似，都需要先打开一个文件流，HDFS是通过<em>FileSystem</em>对象打开文件流的，代码流程为通过<code>FileSystem.get(conf)</code>得到一个<code>FileSystem</code>对象，然后调用<code>open(Path)</code>打开一个FSDataInputStream流，看下open代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> FSDataInputStream <span class="title">open</span><span class="params">(Path f)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">	<span class="comment">// io.file.buffer.size  The size of buffer for use in sequence files.</span></span><br><span class="line">  <span class="keyword">return</span> open(f, getConf().getInt(<span class="string">"io.file.buffer.size"</span>, <span class="number">4096</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>FileSystem是一个抽象类，将具体的<code>open</code>操作留给子类实现，例如DistributedFileSystem、WebHdfsFileSystem等，不同的文件系统具有不同打开文件的行为，我们以DistributedFileSystem为例，open方法实现，代码如下所示：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// buffersize 决定buffersize大小的数据在read/write时被缓存</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> FSDataInputStream <span class="title">open</span><span class="params">(Path f, <span class="keyword">final</span> <span class="keyword">int</span> bufferSize)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  statistics.incrementReadOps(<span class="number">1</span>);</span><br><span class="line">  Path absF = fixRelativePart(f);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> FileSystemLinkResolver&lt;FSDataInputStream&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FSDataInputStream <span class="title">doCall</span><span class="params">(<span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException, UnresolvedLinkException </span>&#123;</span><br><span class="line">      <span class="keyword">final</span> DFSInputStream dfsis =</span><br><span class="line">        dfs.open(getPathName(p), bufferSize, verifyChecksum);</span><br><span class="line">      <span class="keyword">return</span> dfs.createWrappedInputStream(dfsis);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> FSDataInputStream <span class="title">next</span><span class="params">(<span class="keyword">final</span> FileSystem fs, <span class="keyword">final</span> Path p)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">      <span class="keyword">return</span> fs.open(p, bufferSize);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;.resolve(<span class="keyword">this</span>, absF);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// FileSystemLinkResolver.resolve</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">resolve</span><span class="params">(<span class="keyword">final</span> FileSystem filesys, <span class="keyword">final</span> Path path)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">  T in = <span class="keyword">null</span>;</span><br><span class="line">  Path p = path;</span><br><span class="line">  <span class="comment">// Assumes path belongs to this FileSystem.</span></span><br><span class="line">  <span class="comment">// Callers validate this by passing paths through FileSystem#checkPath</span></span><br><span class="line">  FileSystem fs = filesys;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">boolean</span> isLink = <span class="keyword">true</span>; isLink;) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      in = doCall(p);</span><br><span class="line">      isLink = <span class="keyword">false</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (UnresolvedLinkException e) &#123;</span><br><span class="line">      ...</span><br><span class="line">      <span class="comment">// Have to call next if it's a new FS</span></span><br><span class="line">      <span class="keyword">if</span> (!fs.equals(filesys)) &#123;</span><br><span class="line">        <span class="keyword">return</span> next(fs, p);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Else, we keep resolving with this filesystem</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Successful call, path was fully resolved</span></span><br><span class="line">  <span class="keyword">return</span> in;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DistributedFileSystem.open()中new一个FileSystemLinkResolver的匿名类，在resolve中调用在匿名类中重写的<code>doCall()</code>方法，如果doCall抛出UnresolvedLinkException异常，被resolve捕获调用<code>next()</code>，进行再次打开。</p>
<p>在<code>doCall()</code>中调用<code>dfs.open(getPathName(p), bufferSize, verifyChecksum)</code>返回一个<em>DFSInputStream</em>对象，然后再通过<code>dfs.createWrappedInputStream(dfsis)</code>包装一个<em>HdfsDataInputStream</em>对象返回给<em>FSDataInputStream</em>，FSDataInputStream是HdfsDataInputStream的父类，这样就通过FileSystem.open(path)打开了一个文件流。</p>
<p>doCall中dfs是FSDataInputStream的成员变量DFSClient，其open方法中new出一个DFSInputStream实例，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> DFSInputStream <span class="title">open</span><span class="params">(String src, <span class="keyword">int</span> buffersize, <span class="keyword">boolean</span> verifyChecksum)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, UnresolvedLinkException </span>&#123;</span><br><span class="line">  checkOpen();</span><br><span class="line">  <span class="comment">//    Get block info from namenode</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> DFSInputStream(<span class="keyword">this</span>, src, buffersize, verifyChecksum);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// DFSInputStream 构造方法</span></span><br><span class="line">DFSInputStream(DFSClient dfsClient, String src, <span class="keyword">int</span> buffersize, <span class="keyword">boolean</span> verifyChecksum</span><br><span class="line">               ) <span class="keyword">throws</span> IOException, UnresolvedLinkException &#123;</span><br><span class="line">  <span class="keyword">this</span>.dfsClient = dfsClient;</span><br><span class="line">  <span class="keyword">this</span>.verifyChecksum = verifyChecksum;</span><br><span class="line">  <span class="keyword">this</span>.buffersize = buffersize;</span><br><span class="line">  <span class="keyword">this</span>.src = src;</span><br><span class="line">  <span class="comment">// Client的缓存策略，CachingStrategy(readDropBehind, readahead);</span></span><br><span class="line">  <span class="comment">// Boolean readDropBehind = (conf.get(DFS_CLIENT_CACHE_DROP_BEHIND_READS) == null) ?</span></span><br><span class="line">  <span class="comment">//     null : conf.getBoolean(DFS_CLIENT_CACHE_DROP_BEHIND_READS, false);</span></span><br><span class="line">  <span class="comment">// Long readahead = (conf.get(DFS_CLIENT_CACHE_READAHEAD) == null) ?</span></span><br><span class="line">  <span class="comment">//     null : conf.getLong(DFS_CLIENT_CACHE_READAHEAD, 0);  </span></span><br><span class="line">  <span class="keyword">this</span>.cachingStrategy =</span><br><span class="line">      dfsClient.getDefaultReadCachingStrategy();</span><br><span class="line">  openInfo();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">openInfo</span><span class="params">()</span> <span class="keyword">throws</span> IOException, UnresolvedLinkException </span>&#123;</span><br><span class="line">  <span class="comment">// fetchLocatedBlocksAndGetLastBlockLength有两个功能，</span></span><br><span class="line">  <span class="comment">// 一个是对locatedBlocks赋值</span></span><br><span class="line">  <span class="comment">// 另一个是返回最后一个未构造完成的block的长度</span></span><br><span class="line">  lastBlockBeingWrittenLength = fetchLocatedBlocksAndGetLastBlockLength();</span><br><span class="line">  <span class="keyword">int</span> retriesForLastBlockLength = dfsClient.getConf().retryTimesForGetLastBlockLength;</span><br><span class="line">  <span class="comment">// 如果获取失败，则进行重试，默认是3次</span></span><br><span class="line">  <span class="comment">// dfs.client.retry.times.get-last-block-length 设置重试次数</span></span><br><span class="line">  <span class="comment">// 当集群重启时，dn可能没来及汇报block，此时可能存在部分block的location无法从nn上读出</span></span><br><span class="line">  <span class="keyword">while</span> (retriesForLastBlockLength &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Getting last block length as -1 is a special case. When cluster</span></span><br><span class="line">    <span class="comment">// restarts, DNs may not report immediately. At this time partial block</span></span><br><span class="line">    <span class="comment">// locations will not be available with NN for getting the length. Lets</span></span><br><span class="line">    <span class="comment">// retry for 3 times to get the length.</span></span><br><span class="line">    <span class="keyword">if</span> (lastBlockBeingWrittenLength == -<span class="number">1</span>) &#123;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">"Last block locations not available. "</span></span><br><span class="line">          + <span class="string">"Datanodes might not have reported blocks completely."</span></span><br><span class="line">          + <span class="string">" Will retry for "</span> + retriesForLastBlockLength + <span class="string">" times"</span>);</span><br><span class="line">      <span class="comment">// 等待dfs.client.retry.interval-ms.get-last-block-length ms之后重试 </span></span><br><span class="line">      <span class="comment">// 默认是4000ms</span></span><br><span class="line">      waitFor(dfsClient.getConf().retryIntervalForGetLastBlockLength);</span><br><span class="line">      lastBlockBeingWrittenLength = fetchLocatedBlocksAndGetLastBlockLength();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    retriesForLastBlockLength--;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (retriesForLastBlockLength == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Could not obtain the last block locations."</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>openInfo里只调用了一个方法fetchLocatedBlocksAndGetLastBlockLength，openInfo主要是保证能够正确获取<em>写入的起始地址lastBlockBeingWrittenLength</em>，因为<em>当集群重启时，dn可能没来及汇报block，此时可能存在部分block的location无法从nn上读出</em>，所以当lastBlockBeingWrittenLength赋值失败时，等待4000ms然后进行重试，默认重试次数为3次，由<em>dfs.client.retry.times.get-last-block-length</em>控制。主要逻辑在方法fetchLocatedBlocksAndGetLastBlockLength中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">fetchLocatedBlocksAndGetLastBlockLength</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">   <span class="comment">// DFSClient 通过rpc调用FSNamespace.getLocatedBlocks得到部分block的locations</span></span><br><span class="line">  <span class="keyword">final</span> LocatedBlocks newInfo = dfsClient.getLocatedBlocks(src, <span class="number">0</span>);</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (locatedBlocks != <span class="keyword">null</span>) &#123;</span><br><span class="line">    Iterator&lt;LocatedBlock&gt; oldIter = locatedBlocks.getLocatedBlocks().iterator();</span><br><span class="line">    Iterator&lt;LocatedBlock&gt; newIter = newInfo.getLocatedBlocks().iterator();</span><br><span class="line">    <span class="keyword">while</span> (oldIter.hasNext() &amp;&amp; newIter.hasNext()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (! oldIter.next().getBlock().equals(newIter.next().getBlock())) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Blocklist for "</span> + src + <span class="string">" has changed!"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  locatedBlocks = newInfo;</span><br><span class="line">  <span class="keyword">long</span> lastBlockBeingWrittenLength = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 判断此src是否有正在构建的block，有则返回当前的长度，没有则返回0，-1表示失败</span></span><br><span class="line">  <span class="keyword">if</span> (!locatedBlocks.isLastBlockComplete()) &#123;</span><br><span class="line">    <span class="keyword">final</span> LocatedBlock last = locatedBlocks.getLastLocatedBlock();</span><br><span class="line">    <span class="keyword">if</span> (last != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (last.getLocations().length == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (last.getBlockSize() == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="comment">// if the length is zero, then no data has been written to</span></span><br><span class="line">          <span class="comment">// datanode. So no need to wait for the locations.</span></span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">long</span> len = readBlockLength(last);</span><br><span class="line">      last.getBlock().setNumBytes(len);</span><br><span class="line">      lastBlockBeingWrittenLength = len; </span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  fileEncryptionInfo = locatedBlocks.getFileEncryptionInfo();</span><br><span class="line"></span><br><span class="line">  currentNode = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">return</span> lastBlockBeingWrittenLength;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>fetchLocatedBlocksAndGetLastBlockLength主要是通过DFSClient.getLocatedBlocks得到src的LocatedBlocks。</p>
<p>LocatedBlocks包含blocks locations信息和src文件长度。LocatedBlocks中重要的属性有：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 存储文件的长度</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> fileLength;</span><br><span class="line"><span class="comment">// 存储文件中block与dn的信息和溢写block的元数据</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> List&lt;LocatedBlock&gt; blocks; <span class="comment">// array of blocks with prioritized locations</span></span><br><span class="line"><span class="comment">// 表示src是否有正在创建的block</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">boolean</span> underConstruction;</span><br><span class="line"><span class="comment">// src的最后一个block</span></span><br><span class="line"><span class="keyword">private</span> LocatedBlock lastLocatedBlock = <span class="keyword">null</span>;</span><br><span class="line"><span class="comment">// 标识最后一个block是否完成</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> isLastBlockComplete = <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="keyword">private</span> FileEncryptionInfo fileEncryptionInfo = <span class="keyword">null</span>;</span><br></pre></td></tr></table></figure>
<p>LocatedBlocks中有个<em>LocatedBlock</em>的list，LocatedBlock中存储的是block与其副本所在dn的信息和block的元数据信息，比较重要的属性有：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// file 的某个block</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ExtendedBlock b;</span><br><span class="line"><span class="comment">// block中第一个字节在file中的偏移量</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> offset;  </span><br><span class="line"><span class="comment">// block的副本所在dn数组</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> DatanodeInfo[] locs;</span><br><span class="line"><span class="comment">// 每个副本所在的磁盘id</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String[] storageIDs;</span><br><span class="line"><span class="comment">// 每个副本所在磁盘的类型</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> StorageType[] storageTypes;</span><br><span class="line"><span class="comment">// corrupt flag is true if all of the replicas of a block are corrupt.</span></span><br><span class="line"><span class="comment">// else false. If block has few corrupt replicas, they are filtered and </span></span><br><span class="line"><span class="comment">// their locations are not part of this object</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> corrupt;</span><br><span class="line"><span class="keyword">private</span> Token&lt;BlockTokenIdentifier&gt; blockToken = <span class="keyword">new</span> Token&lt;BlockTokenIdentifier&gt;();</span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * List of cached datanode locations</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span> DatanodeInfo[] cachedLocs;</span><br></pre></td></tr></table></figure>
<p>DFSClient.getLocatedBlocks是通过RPC得到结果的，调用顺序为<br><em>dfsClient.getLocatedBlocks(src, 0) -&gt; getLocatedBlocks(src, start, dfsClientConf.prefetchSize) -&gt; callGetBlockLocations(namenode, src, start, length) -&gt; namenode.getBlockLocations(src, start, length) -&gt; NameNodeRpcServer.getBlockLocations(src, start, length) -&gt; namesystem.getBlockLocations(getClientMachine(), src, offset, length)</em></p>
<p>在此过程中涉及到一个变量<em>prefetchSize</em>，由属性<em>dfs.client.read.prefetch.size</em>控制，默认值是<code>10 * defaultBlockSize</code>，<strong>表示在打开一个文件流时默认情况下将10个block的信息放入内存中，对读的一种优化</strong>。</p>
<p>下面看下FSNamesystem.getBlockLocations的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">LocatedBlocks <span class="title">getBlockLocations</span><span class="params">(String clientMachine, String src,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">long</span> offset, <span class="keyword">long</span> length)</span> <span class="keyword">throws</span> AccessControlException,</span></span><br><span class="line"><span class="function">    FileNotFoundException, UnresolvedLinkException, IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 得到某段长度区间的block信息</span></span><br><span class="line">  LocatedBlocks blocks = getBlockLocations(src, offset, length, <span class="keyword">true</span>, <span class="keyword">true</span>, <span class="keyword">true</span>);</span><br><span class="line">  <span class="comment">// 对block的副本所在的dn按照到client的网络拓扑距离进行排序</span></span><br><span class="line">  <span class="keyword">if</span> (blocks != <span class="keyword">null</span>) &#123;</span><br><span class="line">    blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,</span><br><span class="line">        blocks.getLocatedBlocks());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// lastBlock is not part of getLocatedBlocks(), might need to sort it too</span></span><br><span class="line">    LocatedBlock lastBlock = blocks.getLastLocatedBlock();</span><br><span class="line">    <span class="keyword">if</span> (lastBlock != <span class="keyword">null</span>) &#123;</span><br><span class="line">      ArrayList&lt;LocatedBlock&gt; lastBlockList =</span><br><span class="line">          Lists.newArrayListWithCapacity(<span class="number">1</span>);</span><br><span class="line">      lastBlockList.add(lastBlock);</span><br><span class="line">      blockManager.getDatanodeManager().sortLocatedBlocks(clientMachine,</span><br><span class="line">          lastBlockList);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将按照网络拓扑排好序的block返回给client端</span></span><br><span class="line">  <span class="keyword">return</span> blocks;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getBlockLocations又调用getBlockLocationsInt()</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> LocatedBlocks <span class="title">getBlockLocationsInt</span><span class="params">(String src, <span class="keyword">long</span> offset,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">long</span> length, <span class="keyword">boolean</span> doAccessTime, <span class="keyword">boolean</span> needBlockToken,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> checkSafeMode)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> FileNotFoundException, UnresolvedLinkException, IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 检验offset length是否合法，不合法抛出异常</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> LocatedBlocks ret = getBlockLocationsUpdateTimes(src,</span><br><span class="line">      offset, length, doAccessTime, needBlockToken);  </span><br><span class="line">  logAuditEvent(<span class="keyword">true</span>, <span class="string">"open"</span>, src);</span><br><span class="line">  <span class="keyword">if</span> (checkSafeMode &amp;&amp; isInSafeMode()) &#123;</span><br><span class="line">    <span class="keyword">for</span> (LocatedBlock b : ret.getLocatedBlocks()) &#123;</span><br><span class="line">      <span class="comment">// if safemode &amp; no block locations yet then throw safemodeException</span></span><br><span class="line">      <span class="keyword">if</span> ((b.getLocations() == <span class="keyword">null</span>) || (b.getLocations().length == <span class="number">0</span>)) &#123;</span><br><span class="line">        SafeModeException se = <span class="keyword">new</span> SafeModeException(</span><br><span class="line">            <span class="string">"Zero blocklocations for "</span> + src, safeMode);</span><br><span class="line">        <span class="keyword">if</span> (haEnabled &amp;&amp; haContext != <span class="keyword">null</span> &amp;&amp; </span><br><span class="line">            haContext.getState().getServiceState() == HAServiceState.ACTIVE) &#123;</span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RetriableException(se);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">throw</span> se;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getBlockLocationsInt主要是用来检查SafeMode模式下，当block的locations信息为null时，抛出safemodeException。getBlockLocationsInt中调用getBlockLocationsUpdateTimes得到LocatedBlocks，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> LocatedBlocks <span class="title">getBlockLocationsUpdateTimes</span><span class="params">(<span class="keyword">final</span> String srcArg,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">long</span> offset, <span class="keyword">long</span> length, <span class="keyword">boolean</span> doAccessTime, <span class="keyword">boolean</span> needBlockToken)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> FileNotFoundException,</span></span><br><span class="line"><span class="function">    UnresolvedLinkException, IOException </span>&#123;</span><br><span class="line">  String src = srcArg;</span><br><span class="line">  FSPermissionChecker pc = getPermissionChecker();</span><br><span class="line">  <span class="comment">// 此处的pathComponents在普通src(/user/hadoop/xx)中为null</span></span><br><span class="line">  <span class="keyword">byte</span>[][] pathComponents = FSDirectory.getPathComponentsForReservedPath(src);</span><br><span class="line">  <span class="comment">// 是否需要更新访问时间，如果超过了访问精度则进行访问时间的更新，</span></span><br><span class="line">  <span class="comment">// 更新时需要拿到writeLock</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> attempt = <span class="number">0</span>; attempt &lt; <span class="number">2</span>; attempt++) &#123;</span><br><span class="line">    <span class="keyword">boolean</span> isReadOp = (attempt == <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (isReadOp) &#123; <span class="comment">// first attempt is with readlock</span></span><br><span class="line">      checkOperation(OperationCategory.READ);</span><br><span class="line">      <span class="comment">// 可重入锁</span></span><br><span class="line">      readLock();</span><br><span class="line">    &#125;  <span class="keyword">else</span> &#123; <span class="comment">// second attempt is with  write lock</span></span><br><span class="line">      checkOperation(OperationCategory.WRITE);</span><br><span class="line">      writeLock(); <span class="comment">// writelock is needed to set accesstime</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      src = resolvePath(src, pathComponents);</span><br><span class="line">      <span class="keyword">if</span> (isReadOp) &#123;</span><br><span class="line">        checkOperation(OperationCategory.READ);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        checkOperation(OperationCategory.WRITE);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (isPermissionEnabled) &#123;</span><br><span class="line">        checkPathAccess(pc, src, FsAction.READ);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// if the namenode is in safemode, then do not update access time</span></span><br><span class="line">      <span class="keyword">if</span> (isInSafeMode()) &#123;</span><br><span class="line">        doAccessTime = <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 将src path解析为INodes infomation</span></span><br><span class="line">      <span class="keyword">final</span> INodesInPath iip = dir.getINodesInPath(src, <span class="keyword">true</span>);</span><br><span class="line">      <span class="keyword">final</span> INode[] inodes = iip.getINodes();</span><br><span class="line">      <span class="comment">// 将path中的文件名INode转化为INodeFile</span></span><br><span class="line">      <span class="keyword">final</span> INodeFile inode = INodeFile.valueOf(</span><br><span class="line">          inodes[inodes.length - <span class="number">1</span>], src);</span><br><span class="line">      <span class="keyword">if</span> (isPermissionEnabled) &#123;</span><br><span class="line">        checkUnreadableBySuperuser(pc, inode, iip.getPathSnapshotId());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!iip.isSnapshot() <span class="comment">//snapshots are readonly, so don't update atime.</span></span><br><span class="line">          &amp;&amp; doAccessTime &amp;&amp; isAccessTimeSupported()) &#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> now = now();</span><br><span class="line">        <span class="comment">// 当前的访问时间与上次访问时间超过了访问时间精度</span></span><br><span class="line">        <span class="comment">// 进行访问时间的更新</span></span><br><span class="line">        <span class="keyword">if</span> (now &gt; inode.getAccessTime() + getAccessTimePrecision()) &#123;</span><br><span class="line">          <span class="comment">// if we have to set access time but we only have the readlock, then</span></span><br><span class="line">          <span class="comment">// restart this entire operation with the writeLock.</span></span><br><span class="line">          <span class="keyword">if</span> (isReadOp) &#123;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">boolean</span> changed = dir.setTimes(inode, -<span class="number">1</span>, now, <span class="keyword">false</span>,</span><br><span class="line">                  iip.getLatestSnapshotId());</span><br><span class="line">          <span class="keyword">if</span> (changed) &#123;</span><br><span class="line">            getEditLog().logTimes(src, -<span class="number">1</span>, now);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 当前src path不是快照则计算文件的长度时不包括最后一个正在构建的block</span></span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">long</span> fileSize = iip.isSnapshot() ?</span><br><span class="line">          inode.computeFileSize(iip.getPathSnapshotId())</span><br><span class="line">          : inode.computeFileSizeNotIncludingLastUcBlock();</span><br><span class="line">      <span class="keyword">boolean</span> isUc = inode.isUnderConstruction();</span><br><span class="line">      <span class="keyword">if</span> (iip.isSnapshot()) &#123;</span><br><span class="line">        <span class="comment">// if src indicates a snapshot file, we need to make sure the returned</span></span><br><span class="line">        <span class="comment">// blocks do not exceed the size of the snapshot file.</span></span><br><span class="line">        length = Math.min(length, fileSize - offset);</span><br><span class="line">        isUc = <span class="keyword">false</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">final</span> FileEncryptionInfo feInfo =</span><br><span class="line">        FSDirectory.isReservedRawName(srcArg) ?</span><br><span class="line">        <span class="keyword">null</span> : dir.getFileEncryptionInfo(inode, iip.getPathSnapshotId(),</span><br><span class="line">            iip);</span><br><span class="line">      <span class="comment">// INodeFile的blocks通过blockManager创建LocatedBlocks</span></span><br><span class="line">      <span class="keyword">final</span> LocatedBlocks blocks =</span><br><span class="line">        blockManager.createLocatedBlocks(inode.getBlocks(), fileSize,</span><br><span class="line">          isUc, offset, length, needBlockToken, iip.isSnapshot(), feInfo);</span><br><span class="line">      <span class="comment">// Set caching information for the located blocks.</span></span><br><span class="line">      <span class="keyword">for</span> (LocatedBlock lb: blocks.getLocatedBlocks()) &#123;</span><br><span class="line">        cacheManager.setCachedLocations(lb);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> blocks;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (isReadOp) &#123;</span><br><span class="line">        readUnlock();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        writeUnlock();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>; <span class="comment">// can never reach here</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getBlockLocationsUpdateTimes中有个for循环，初次进入循环attempt为0，得到readLock，如果支持访问时间的设置，则当前的访问时间与上次的访问时间差超过了HDFS设置的访问时间精度(<em>dfs.namenode.accesstime.precision</em>)，则进行访问时间的更新，时间的更新需要得到writeLock，如果当前是readLock则continue，进行第二次循环拿到writeLock进行更新。（<strong>可以根据file的访问时间判断数据的冷热</strong>）</p>
<p>通过(FSDirectory)dir.getINodesInPath得到src的INode信息，然后将INode转化为INodeFile(INodeFile对应一个文件)。然后通过blockManager.createLocatedBlocks将INodeFile中的Block转化为LocatedBlocks</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> LocatedBlocks <span class="title">createLocatedBlocks</span><span class="params">(<span class="keyword">final</span> BlockInfo[] blocks,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> fileSizeExcludeBlocksUnderConstruction,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">boolean</span> isFileUnderConstruction, <span class="keyword">final</span> <span class="keyword">long</span> offset,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> length, <span class="keyword">final</span> <span class="keyword">boolean</span> needBlockToken,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">boolean</span> inSnapshot, FileEncryptionInfo feInfo)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> namesystem.hasReadLock();</span><br><span class="line">  <span class="keyword">if</span> (blocks == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (blocks.length == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> LocatedBlocks(<span class="number">0</span>, isFileUnderConstruction,</span><br><span class="line">        Collections.&lt;LocatedBlock&gt;emptyList(), <span class="keyword">null</span>, <span class="keyword">false</span>, feInfo);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"blocks = "</span> + java.util.Arrays.asList(blocks));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">final</span> AccessMode mode = needBlockToken? AccessMode.READ: <span class="keyword">null</span>;</span><br><span class="line">    <span class="comment">// 从blocks中将offset到length之间的block创建为LocateBlock</span></span><br><span class="line">    <span class="comment">// 这里是LocateBlock不是LocateBlocks，注意区分，LocateBlocks里有个LocateBlock的list</span></span><br><span class="line">    <span class="keyword">final</span> List&lt;LocatedBlock&gt; locatedblocks = createLocatedBlockList(</span><br><span class="line">        blocks, offset, length, Integer.MAX_VALUE, mode);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> LocatedBlock lastlb;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">boolean</span> isComplete;</span><br><span class="line">    <span class="keyword">if</span> (!inSnapshot) &#123;</span><br><span class="line">      <span class="keyword">final</span> BlockInfo last = blocks[blocks.length - <span class="number">1</span>];</span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">long</span> lastPos = last.isComplete()?</span><br><span class="line">          fileSizeExcludeBlocksUnderConstruction - last.getNumBytes()</span><br><span class="line">          : fileSizeExcludeBlocksUnderConstruction;</span><br><span class="line">      <span class="comment">// 将文件的最后一个block创建为LocateBlock</span></span><br><span class="line">      <span class="comment">// 这里是LocateBlock不是LocateBlocks，注意区分，LocateBlocks里有个LocateBlock的list</span></span><br><span class="line">      lastlb = createLocatedBlock(last, lastPos, mode);</span><br><span class="line">      isComplete = last.isComplete();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      lastlb = createLocatedBlock(blocks,</span><br><span class="line">          fileSizeExcludeBlocksUnderConstruction, mode);</span><br><span class="line">      isComplete = <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 实例化LocateBlocks对象</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> LocatedBlocks(</span><br><span class="line">        fileSizeExcludeBlocksUnderConstruction, isFileUnderConstruction,</span><br><span class="line">        locatedblocks, lastlb, isComplete, feInfo);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>createLocatedBlocks中有<code>createLocatedBlockList</code>和<code>createLocatedBlock</code>两个方法，看名字就可以猜到这两个方法一个返回已LocatedBlock List，一个只返回一个LocatedBlock。其源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> List&lt;LocatedBlock&gt; <span class="title">createLocatedBlockList</span><span class="params">(<span class="keyword">final</span> BlockInfo[] blocks,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">long</span> offset, <span class="keyword">final</span> <span class="keyword">long</span> length, <span class="keyword">final</span> <span class="keyword">int</span> nrBlocksToReturn,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> AccessMode mode)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> curBlk = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">long</span> curPos = <span class="number">0</span>, blkSize = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> nrBlocks = (blocks[<span class="number">0</span>].getNumBytes() == <span class="number">0</span>) ? <span class="number">0</span> : blocks.length;</span><br><span class="line">  <span class="comment">// 找到offset所在的block</span></span><br><span class="line">  <span class="keyword">for</span> (curBlk = <span class="number">0</span>; curBlk &lt; nrBlocks; curBlk++) &#123;</span><br><span class="line">    blkSize = blocks[curBlk].getNumBytes();</span><br><span class="line">    <span class="keyword">assert</span> blkSize &gt; <span class="number">0</span> : <span class="string">"Block of size 0"</span>;</span><br><span class="line">    <span class="keyword">if</span> (curPos + blkSize &gt; offset) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    curPos += blkSize;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (nrBlocks &gt; <span class="number">0</span> &amp;&amp; curBlk == nrBlocks)   <span class="comment">// offset &gt;= end of file</span></span><br><span class="line">    <span class="keyword">return</span> Collections.&lt;LocatedBlock&gt;emptyList();</span><br><span class="line">  <span class="comment">// 此处的length默认是128*10，由属性dfs.client.read.prefetch.size控制</span></span><br><span class="line">  <span class="keyword">long</span> endOff = offset + length;</span><br><span class="line">  List&lt;LocatedBlock&gt; results = <span class="keyword">new</span> ArrayList&lt;LocatedBlock&gt;(blocks.length);</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">  	<span class="comment">// 调用createLocatedBlock create LocatedBlock</span></span><br><span class="line">    results.add(createLocatedBlock(blocks[curBlk], curPos, mode));</span><br><span class="line">    curPos += blocks[curBlk].getNumBytes();</span><br><span class="line">    curBlk++;</span><br><span class="line">  &#125; <span class="keyword">while</span> (curPos &lt; endOff </span><br><span class="line">        &amp;&amp; curBlk &lt; blocks.length</span><br><span class="line">        &amp;&amp; results.size() &lt; nrBlocksToReturn);</span><br><span class="line">  <span class="keyword">return</span> results;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>createLocatedBlockList内部也是调用createLocatedBlock得到LocatedBlock然后放入list中，createLocatedBlock源码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> LocatedBlock <span class="title">createLocatedBlock</span><span class="params">(<span class="keyword">final</span> BlockInfo blk, <span class="keyword">final</span> <span class="keyword">long</span> pos,</span></span></span><br><span class="line"><span class="function"><span class="params">  <span class="keyword">final</span> BlockTokenSecretManager.AccessMode mode)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> LocatedBlock lb = createLocatedBlock(blk, pos);</span><br><span class="line">  <span class="keyword">if</span> (mode != <span class="keyword">null</span>) &#123;</span><br><span class="line">    setBlockToken(lb, mode);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> lb;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> LocatedBlock <span class="title">createLocatedBlock</span><span class="params">(<span class="keyword">final</span> BlockInfo blk, <span class="keyword">final</span> <span class="keyword">long</span> pos</span></span></span><br><span class="line"><span class="function"><span class="params">    )</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">   <span class="comment">// blk 正在构建</span></span><br><span class="line">  <span class="keyword">if</span> (blk <span class="keyword">instanceof</span> BlockInfoUnderConstruction) &#123;</span><br><span class="line">    <span class="keyword">if</span> (blk.isComplete()) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">          <span class="string">"blk instanceof BlockInfoUnderConstruction &amp;&amp; blk.isComplete()"</span></span><br><span class="line">          + <span class="string">", blk="</span> + blk);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">final</span> BlockInfoUnderConstruction uc = (BlockInfoUnderConstruction)blk;</span><br><span class="line">    <span class="keyword">final</span> DatanodeStorageInfo[] storages = uc.getExpectedStorageLocations();</span><br><span class="line">    <span class="keyword">final</span> ExtendedBlock eb = <span class="keyword">new</span> ExtendedBlock(namesystem.getBlockPoolId(), blk);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> LocatedBlock(eb, storages, pos, <span class="keyword">false</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// get block locations</span></span><br><span class="line">  <span class="comment">// 计算src中Block的副本中无法读取该Block的Datanode节点数</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numCorruptNodes = countNodes(blk).corruptReplicas();</span><br><span class="line">  <span class="comment">// 计算FSNamesystem在内存中维护的Block=&gt;Datanode映射的列表中，无法读取该Block的Datanode节点数</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numCorruptReplicas = corruptReplicas.numCorruptReplicas(blk);</span><br><span class="line">  <span class="keyword">if</span> (numCorruptNodes != numCorruptReplicas) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Inconsistent number of corrupt replicas for "</span></span><br><span class="line">        + blk + <span class="string">" blockMap has "</span> + numCorruptNodes</span><br><span class="line">        + <span class="string">" but corrupt replicas map has "</span> + numCorruptReplicas);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 计算src中Block存储的Datanode节点数 </span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numNodes = blocksMap.numNodes(blk);</span><br><span class="line">  <span class="comment">// 如果损坏的数和副本数一样，则标识此block为corrupt</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">boolean</span> isCorrupt = numCorruptNodes == numNodes;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numMachines = isCorrupt ? numNodes: numNodes - numCorruptNodes;</span><br><span class="line">  <span class="keyword">final</span> DatanodeStorageInfo[] machines = <span class="keyword">new</span> DatanodeStorageInfo[numMachines];</span><br><span class="line">  <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (numMachines &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">for</span>(DatanodeStorageInfo storage : blocksMap.getStorages(blk)) &#123;</span><br><span class="line">      <span class="keyword">final</span> DatanodeDescriptor d = storage.getDatanodeDescriptor();</span><br><span class="line">      <span class="keyword">final</span> <span class="keyword">boolean</span> replicaCorrupt = corruptReplicas.isReplicaCorrupt(blk, d);</span><br><span class="line">      <span class="comment">// 如果某个block的副本corrupt，则不将此副本放入machines中</span></span><br><span class="line">      <span class="comment">// 只有在block是corrupt时，才将损坏的副本放入machines</span></span><br><span class="line">      <span class="keyword">if</span> (isCorrupt || (!replicaCorrupt))</span><br><span class="line">        machines[j++] = storage;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">assert</span> j == machines.length :</span><br><span class="line">    <span class="string">"isCorrupt: "</span> + isCorrupt + </span><br><span class="line">    <span class="string">" numMachines: "</span> + numMachines +</span><br><span class="line">    <span class="string">" numNodes: "</span> + numNodes +</span><br><span class="line">    <span class="string">" numCorrupt: "</span> + numCorruptNodes +</span><br><span class="line">    <span class="string">" numCorruptRepls: "</span> + numCorruptReplicas;</span><br><span class="line">  <span class="keyword">final</span> ExtendedBlock eb = <span class="keyword">new</span> ExtendedBlock(namesystem.getBlockPoolId(), blk);</span><br><span class="line">  <span class="comment">// 实例化一个LocatedBlock，isCorrupt标识block是否corrupt</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> LocatedBlock(eb, machines, pos, isCorrupt);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述方法是在BlockManager类中，类中有两个属性blocksMap和corruptReplicas，简单介绍下这两个属性的作用：<br><code>blocksMap</code>是<code>BlocksMap</code>的实例，其代表了Block→{INode、datanodes}的映射。具体代表了每一个Block在哪一个DataNode上存储，其内部有个BlockInfo对象。<br><code>CorruptReplicasMap corruptReplicas = new CorruptReplicasMap()</code>，corruptReplicas是CorruptReplicasMap的一个实例。<strong>corruptReplicas保存了文件系统中所有的损坏block</strong>。注意，只有一个block的所有备份存储都损坏才认为该block是损坏的。其保存的形式如下，一个block和所有保存该block的datanode，Block→TreeSet<datanodedescriptor></datanodedescriptor></p>
<p>得到LocatedBlocks之后，回到FSNamesystem.getBlockLocations中对block的locations根据client的网络拓扑距离进行排序，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sortLocatedBlocks</span><span class="params">(<span class="keyword">final</span> String targethost,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> List&lt;LocatedBlock&gt; locatedblocks)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//sort the blocks</span></span><br><span class="line">  <span class="comment">// As it is possible for the separation of node manager and datanode, </span></span><br><span class="line">  <span class="comment">// here we should get node but not datanode only .</span></span><br><span class="line">  Node client = getDatanodeByHost(targethost);</span><br><span class="line">  <span class="keyword">if</span> (client == <span class="keyword">null</span>) &#123;</span><br><span class="line">    List&lt;String&gt; hosts = <span class="keyword">new</span> ArrayList&lt;String&gt; (<span class="number">1</span>);</span><br><span class="line">    hosts.add(targethost);</span><br><span class="line">    String rName = dnsToSwitchMapping.resolve(hosts).get(<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (rName != <span class="keyword">null</span>)</span><br><span class="line">      client = <span class="keyword">new</span> NodeBase(rName + NodeBase.PATH_SEPARATOR_STR + targethost);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  Comparator&lt;DatanodeInfo&gt; comparator = avoidStaleDataNodesForRead ?</span><br><span class="line">      <span class="keyword">new</span> DFSUtil.DecomStaleComparator(staleInterval) : </span><br><span class="line">      DFSUtil.DECOM_COMPARATOR;</span><br><span class="line">      </span><br><span class="line">  <span class="keyword">for</span> (LocatedBlock b : locatedblocks) &#123;</span><br><span class="line">    DatanodeInfo[] di = b.getLocations();</span><br><span class="line">    <span class="comment">// 将下线的或者过时的dn放到最后</span></span><br><span class="line">    Arrays.sort(di, comparator);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> lastActiveIndex = di.length - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (lastActiveIndex &gt; <span class="number">0</span> &amp;&amp; isInactive(di[lastActiveIndex])) &#123;</span><br><span class="line">        --lastActiveIndex;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> activeLen = lastActiveIndex + <span class="number">1</span>;      </span><br><span class="line">    networktopology.sortByDistance(client, b.getLocations(), activeLen);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对block的locations进行排序分为两步，首先对locations中的状态进行排序，将下线的或者过时的dn排在最后。<br>Block所在的Datanode列表中，如果其中某个Datanode在指定的时间内没有向Namenode发送heartbeat（默认由常量DFSConfigKeys.DFS_NAMENODE_STALE_DATANODE_INTERVAL_DEFAULT定义，默认值为30s），则该Datanode的状态即为STALE，具有该状态的Datanode对应的Block排在后面</p>
<p>然后按照网络拓扑进行排序，方法为sortByDistance：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sortByDistance</span><span class="params">(Node reader, Node[] nodes, <span class="keyword">int</span> activeLen)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/** Sort weights for the nodes array */</span></span><br><span class="line">  <span class="keyword">int</span>[] weights = <span class="keyword">new</span> <span class="keyword">int</span>[activeLen];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;activeLen; i++) &#123;</span><br><span class="line">  	<span class="comment">// 0 is local, 1 is same rack, 2 is off rack</span></span><br><span class="line">    weights[i] = getWeight(reader, nodes[i]);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Add weight/node pairs to a TreeMap to sort</span></span><br><span class="line">  <span class="comment">// TreeMap 按照key进行排序</span></span><br><span class="line">  TreeMap&lt;Integer, List&lt;Node&gt;&gt; tree = <span class="keyword">new</span> TreeMap&lt;Integer, List&lt;Node&gt;&gt;();</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;activeLen; i++) &#123;</span><br><span class="line">    <span class="keyword">int</span> weight = weights[i];</span><br><span class="line">    Node node = nodes[i];</span><br><span class="line">    List&lt;Node&gt; list = tree.get(weight);</span><br><span class="line">    <span class="keyword">if</span> (list == <span class="keyword">null</span>) &#123;</span><br><span class="line">      list = Lists.newArrayListWithExpectedSize(<span class="number">1</span>);</span><br><span class="line">      tree.put(weight, list);</span><br><span class="line">    &#125;</span><br><span class="line">    list.add(node);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> idx = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (List&lt;Node&gt; list: tree.values()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (list != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// 对TreeMap中value进行shuffle，以免产生热点</span></span><br><span class="line">      <span class="comment">// 默认情况下list里只有一个node，当副本数增多，</span></span><br><span class="line">      <span class="comment">// 可能在同一rack上有两个副本，则此时list中就有两个node</span></span><br><span class="line">      Collections.shuffle(list, r);</span><br><span class="line">      <span class="keyword">for</span> (Node n: list) &#123;</span><br><span class="line">        nodes[idx] = n;</span><br><span class="line">        idx++;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  Preconditions.checkState(idx == activeLen,</span><br><span class="line">      <span class="string">"Sorted the wrong number of nodes!"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后将排好序的LocatedBlocks返回给客户端，则open file的过程结束。下面就是<a href="http://bigdatadecode.club/HDFS read解析2之从文件流中read.html">read file阶段</a>。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> read </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS HA相关的几个问题和示例场景]]></title>
      <url>http://bigdatadecode.club/HDFS%20HA%E7%9B%B8%E5%85%B3%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%E5%92%8C%E7%A4%BA%E4%BE%8B%E5%9C%BA%E6%99%AF.html</url>
      <content type="html"><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ol>
<li><p>何时会触发主备选举<br>当active nn的HealthMonitor检测到active状态为_SERVICE_UNHEALTHY_和_SERVICE_NOT_RESPONDING_时，active的ActiveStandbyElector会quitElection，<strong>quitElection就是关闭zk连接（zk关闭连接之后，相应的watcher也失去作用）</strong>，ZKFailoverController会主动删除当前在Zookeeper上建立的临时节点/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock，此时active的zk已经关闭连接，watcher已无法监听到<em>DeleteNode</em>事件，standby上的watcher则可以监听到<em>DeleteNode</em>事件，会马上再次进入到创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock节点的流程，如果创建成功，这个本来处于Standby状态的NameNode 就选举为主NameNode并随后开始切换为Active状态。</p>
</li>
<li><p>active所在的主机宕机(<em>ActiveNN断电，网络异常，负载过高或者机器出现异常无法连接</em>)，standby能否切换成功，怎么配置<br>active宕机，active上的zkfc也退出，导致与zk的连接关闭，临时节点ActiveStandbyElectorLock被删除，但ActiveBreadCrumb没有删除，standby上的ActiveStandbyElector检测到节点ActiveStandbyElectorLock被删除，进行抢锁，去创建节点ActiveStandbyElectorLock，创建成功之后，进行状态切换，调用becomeActive，<em>因为ActiveBreadCrumb没有被删除</em>，为了防止脑裂会调用fenceOldActive去fence，如果fence成功则进行状态的写入，状态切换成功。<em>由此可见fence的成决定了切换是否成功</em>，fence方法有两个，一个是sshfence，另一个是shell。当active宕机，则ssh不通，sshfence会fence失败，<strong>也就是说如果只配置了sshfence方法，则无法切换成功</strong>。<strong>当active宕机，想切换成功需要配置shell方法，shell方法可以说是来弥补active宕机的</strong>。<em>所以在配置fence method的时候最好配置两个方法</em>。</p>
</li>
<li><p>active发生异常，active上的zkfc会不会进行fence<br>zkfc进行fence的时候是在拿到createLock之后，nn进行状态转换时才进行fence。active发生异常，其上的zkfc不会进行fence，因为healthmonitor检测到异常之后，会让其退出选举，也就是关闭zk连接，zk连接关闭之后，注册的watcher也消失，也就无法监听到节点被删除，也就不会去抢锁，更不会去fence。</p>
</li>
<li><p>SSHFence是从standby ssh到active进行fence，那ShellFence是怎么搞的？<br><strong>在哪执行，谁调用的，怎么进行kill掉active</strong><br>shell fence是怎么到原active机器上执行的？<br>shell fence 不会到原active上执行activekill掉，shell可以是一个空命令使其单纯的正常退出，然后standby会进行状态转换。但是我疑惑的是shell只是将standby进行的状态转换，但原active呢？原active检测到异常，退出选举关闭了zk连接，只有HM在不断的检测nn的状态，当检测到healthy之后，重新建立zk连接，然后watcher捕获到连接事件，<em>调用monitorActiveStatus进行状态的检查进行变换，此时原active变为standby</em>；<em>但是假如原active一直是不健康的呢？那么原active是怎么进行状态转换的</em>？</p>
</li>
<li><p>fence method需要怎么配置，如果需要配置两个方法，那为什么不只配置shell menthod</p>
</li>
<li><p>一般导致NameNode切换的原因<br>nn不健康（没有磁盘空间），rpc没有响应（callqueue占满），<br>随着集群规模的变大和任务量变多，NameNode的压力会越来越大，一些默认参数已经不能满足集群的日常需求，除此之外，<em>异常的Job在短时间内创建和删除大量文件</em>，<strong>引起NN节点频繁更新内存的数据结构从而导致RPC的处理时间变长，CallQueue里面的RpcCall堆积，甚至严重的情况下打满CallQueue，导致NameNode响应变慢，甚至无响应</strong>，ZKFC的HealthMonitor监控自己的NN异常时，则会断开与ZooKeeper的链接，从而释放锁，另外一个NN上的ZKFC进行抢锁进行Standby到Active状态的切换。这是一般引起的切换的流程。</p>
</li>
<li><p>active发生异常，并且active和standby无法正常ssh，fence methods设置的为ssh 和 shell，此时能否切换成功<br>HealthMonitor检查到active不正常，放弃选举，断开zk连接，临时节点被删除，standby进行选举，创建临时节点成功，准备becomeActive，此时发现ActiveBreadCrumb上存储的信息和当前节点不一致，进行fence，FailoverController没有gracefully fence成功，进行NodeFence.fence，首先选用ssh，发现ssh不通，再选择shell，shell返回正常值(<em>shell中没有任何逻辑直接返回正常值</em>)，standby转换状态为active成功，<strong>此时原active节点的状态是什么？是不是两个节点都是active，出现脑裂？</strong>，不会出现脑裂，zfkc会在进行状态检查时将原active变成standby</p>
</li>
</ol>
<a id="more"></a>
<h2 id="示例场景"><a href="#示例场景" class="headerlink" title="示例场景"></a>示例场景</h2><ul>
<li><p>ActiveNN产生JVM crash<br>一旦这种情况发生，HealthMonitor在调用monitorHealth()将失效。然后HM将向ZKFC调用enterState(SERVICE_NOT_RESPONDING)，本地ZKFC将退出Election，另外一个ZKFC获取active lock，执行fencing，变成active。</p>
</li>
<li><p>ActiveNN JVM freeze<br>如果JVM freeze了但是没有crash掉，这与上面情况一样，monitorHealth会由于timeout而引发上述过程。FUTURE-WORK：使用JVMTI来判断NN是否在进行gc，如此可以使用另一个timeout来为gc进行failover。</p>
</li>
<li><p>ActiveNN machine crash<br><strong>当整个机器crash了，ASE(ActiveStandbyElector)在zk的session将会过期，另一个ZKFC将会获取这个事件，引发failover。</strong></p>
</li>
<li><p>Active ZKFC crash<br>尽管ZKFC设计简单，但是仍然有可能会crash掉，在这个情况下，failover将会被错误的触发。另一个NN的ZKFC将会对ActiveNN调用transitionToStandby让它放弃active lock，然后进行aggressive fencing。<strong>尽管会成功，但是会导致进行了一次没有必要的failover</strong>。</p>
</li>
<li><p>Zookeeper crash<br>当zk集群crash了，那么所有的ZKFC将收到DISCONNECTED事件。然后ZKFC在本地NN调用enterNeutralMode，除此之外不做任何改变。系统除了不能执行failover之外，与其他情况无异。<br>当zk恢复了，clients立马能够重连。而zk能够将之前的session信息重新被各个client进行获取（在启动的一个timeou时间内）。所以所有的nodes将会重新获取session，不需要进行无必要的failover。<br>FutureWork：breadcrumb znode在这个情况下可以优先的给予到ActiveNN，在ZK挂掉之前。</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> HA </tag>
            
            <tag> ZKFC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS恢复过程2]]></title>
      <url>http://bigdatadecode.club/%5B%E8%AF%91%5DHDFS%E6%81%A2%E5%A4%8D%E8%BF%87%E7%A8%8B2.html</url>
      <content type="html"><![CDATA[<p>本篇主要接着<a href="http://bigdatadecode.club/[译]HDFS恢复过程1.html">上篇</a>介绍Pipeline Recovery。</p>
<h2 id="写Pipeline"><a href="#写Pipeline" class="headerlink" title="写Pipeline"></a>写Pipeline</h2><p>当HDFS client执行一个写操作时，数据是以序列化的block形式写进去的。其中block又被分为很多packets，将packets发送到由一些dn组成的pipeline中，如下图所示：<br><img src="/blogimgs/HDFS恢复过程/packet-in-pipeline.png" alt="pipeline流程" title="pipeline流程"></p>
<a id="more"></a>
<p>pipeline分为三个阶段：</p>
<ol>
<li>Pipeline setup<br>client向pipeline发送一个Write_Block请求，pipeline中的最后一个DataNode往回发送一个ack。client收到ack之后，pipeline就处于setup状态，准备写入数据。</li>
<li>Data streaming<br>数据通过packets发送到pipeline中。client端缓存数据到buffer中，buffer满之后写入packet，等packet满之后，发送packet到pipeline中。如果client调用<code>hflush()</code>，<em>即使当前packet没有被写满，也会发送到pipeline中，并且下一个packet在收到当前packet的ack之前不会发送到pipeline中</em>(<strong>上图中的packet2就是调用hflush</strong>)。</li>
<li>Close(改变replica的状态为finalize并且关闭pipeline)<br>client等待收到所有packet的ack之后，才会发送一个关闭请求。pipeline中的dn改变相应replica的状态为FINALIZED，并向nn报告。当nn收到replica的FINALIZED状态的个数满足最小副本数时，nn改变block的状态为COMPLETE。</li>
</ol>
<h2 id="Pipeline-Recovery"><a href="#Pipeline-Recovery" class="headerlink" title="Pipeline Recovery"></a>Pipeline Recovery</h2><p>无论在pipeline三个阶段中的哪个阶段，只要当pipeline中的dn发生error时，Pipeline Recovery就会被启动。</p>
<h2 id="Recovery-from-Pipeline-Setup-Failure"><a href="#Recovery-from-Pipeline-Setup-Failure" class="headerlink" title="Recovery from Pipeline Setup Failure"></a>Recovery from Pipeline Setup Failure</h2><p>1、当pipeline用来新增加一个block时，client放弃这个block，并向nn请求一个新的block和一组新的dn组重新组成一个pipeline。<br>2、当pipeline用来追加一个block时，client使用剩余的dn重建pipeline并且增加block的generation stamp。</p>
<h2 id="Recovery-from-Data-Streaming-Failure"><a href="#Recovery-from-Data-Streaming-Failure" class="headerlink" title="Recovery from Data Streaming Failure"></a>Recovery from Data Streaming Failure</h2><p>1、当pipeline中的dn发现error(checksum异常或者写到磁盘发生异常)，发生error的dn关闭TCP/IP连接，移出pipeline。如果数据没有损坏，将缓存中的数据写入相应的block和checksum文件中(If the data is deemed not corrupted, it also writes buffered data to the relevant block and checksum (METADATA) files.)。<br>2、当client发现异常，client停止向pipeline中发送数据，使用剩余正常的dn重建一个新的pipeline。此时，block的所有replica都有一个新的GS。<br>3、client带着新的GS发送数据packet。有些dn如果已经接受到这些数据，则忽略这些packet并向pipel的下游发送这些packet。</p>
<h2 id="Recovery-from-Close-Failure"><a href="#Recovery-from-Close-Failure" class="headerlink" title="Recovery from Close Failure"></a>Recovery from Close Failure</h2><p>当pipeline处于close状态时，client发现故障，则利用剩余正常的dn重建pipeline。每个dn递增block的GS，如果replica不是finalized状态就将其改为finalized。</p>
<p>当pipeline中的一个dn发生故障，则将其故障节点从pipeline中移除。在pipeline recovery阶段，client可能需要利用剩余正常的节点重建pipeline。(在重建pipeline中，是否需要新的dn替代发生故障的dn，这个决策依赖DataNode替换策略，在下面的章节中介绍)复制监控线程将会检查block的复本，使其满足配置的副本因子。</p>
<h2 id="DataNode-Replacement-Policy-upon-Failure"><a href="#DataNode-Replacement-Policy-upon-Failure" class="headerlink" title="DataNode Replacement Policy upon Failure"></a>DataNode Replacement Policy upon Failure</h2><p>在pipeline recovery中，决定是否增加dn替换发生故障的dn的策略有4种。如下：</p>
<ul>
<li>DISABLE: 禁止进行dn替换，并在服务器端抛出一个异常。类似于client端的NEVER。</li>
<li>NEVER: 当pipeline失败时不替换dn。(一般不这样搞)</li>
<li>DEFAULT: 基于以下规则替换dn:<br> 将配置的副本因子数设为r<br> 将pipeline中存活的dn数设为n<br> 如果r&gt;=3并且满足下面任意一个条件才替换发生故障的dn<br> floor(r/2) &gt;= n; or (当hflush/append被调用并且r &gt; n)</li>
<li>ALWAYS: Always是只要存在dn发生故障就会有新的dn进行替换。如果不能替换则失败。</li>
</ul>
<p>如果想禁止这些策略，可以设置下面这个配置(默认值是true):<br><code>dfs.client.block.write.replace-datanode-on-failure.enable</code><br>假如上面的配置是true，则默认的替换策略是DEFAULT。由下面的属性控制:<br><code>dfs.client.block.write.replace-datanode-on-failure.policy</code><br>当使用DEFAULT或者ALWAYS时，如果pipeline中只有一个dn<strong>替换</strong>成功了，pipeline recovery将不会成功，并且client将不能在执行写操作。这个问题通过设置下面的属性进行解决:<br><code>dfs.client.block.write.replace-datanode-on-failure.best-effort</code><br>此属性默认是false。如果是默认值，client会一直尝试替换发生故障的dn直到满足特定的策略。如果设置为true，即使特定的策略不满足(在pipeline中只有一个dn成功，比要求的数量要少)，client依然可以继续写。</p>
<p><a href="http://blog.cloudera.com/blog/2015/03/understanding-hdfs-recovery-processes-part-2/" target="_blank" rel="noopener">原文地址</a></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> Pipeline Recovery </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS read解析2之从文件流中read]]></title>
      <url>http://bigdatadecode.club/HDFS%20read%E8%A7%A3%E6%9E%902%E4%B9%8B%E4%BB%8E%E6%96%87%E4%BB%B6%E6%B5%81%E4%B8%ADread.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/HDFS read解析.html">上篇</a>主要记录了HDFS read打开一个文件流的流程，该篇记录下从打开的文件流里read数据的流程。</p>
<a id="more"></a>
<h2 id="HDFS-Read之从文件流中read"><a href="#HDFS-Read之从文件流中read" class="headerlink" title="HDFS Read之从文件流中read"></a>HDFS Read之从文件流中read</h2><p>读取文件流中的数据通过文件流FSDataInputStream对象的read方法进行读取，最终调用了DFSInputStream的read方法(可以写个hdfs read file demo 进行debug下就会发现)</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">final</span> <span class="keyword">byte</span> buf[], <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// ReaderStrategy 将不同的BlockReader进行了封装</span></span><br><span class="line">  <span class="comment">// 真正读数据的是BlockReader对象</span></span><br><span class="line">  ReaderStrategy byteArrayReader = <span class="keyword">new</span> ByteArrayStrategy(buf);</span><br><span class="line">  <span class="keyword">return</span> readWithStrategy(byteArrayReader, off, len);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">readWithStrategy</span><span class="params">(ReaderStrategy strategy, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  Map&lt;ExtendedBlock,Set&lt;DatanodeInfo&gt;&gt; corruptedBlockMap </span><br><span class="line">    = <span class="keyword">new</span> HashMap&lt;ExtendedBlock, Set&lt;DatanodeInfo&gt;&gt;();</span><br><span class="line">  failures = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span> (pos &lt; getFileLength()) &#123;</span><br><span class="line">    <span class="keyword">int</span> retries = <span class="number">2</span>;</span><br><span class="line">    <span class="keyword">while</span> (retries &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// currentNode can be left as null if previous read had a checksum</span></span><br><span class="line">        <span class="comment">// error on the same block. See HDFS-3067</span></span><br><span class="line">        <span class="comment">// pos 和 blockEnd 会在blockSeekTo -&gt; getBlockAt 中赋值</span></span><br><span class="line">        <span class="keyword">if</span> (pos &gt; blockEnd || currentNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// 当前position所在的block</span></span><br><span class="line">          currentNode = blockSeekTo(pos);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> realLen = (<span class="keyword">int</span>) Math.min(len, (blockEnd - pos + <span class="number">1L</span>));</span><br><span class="line">        <span class="keyword">if</span> (locatedBlocks.isLastBlockComplete()) &#123;</span><br><span class="line">          realLen = (<span class="keyword">int</span>) Math.min(realLen, locatedBlocks.getFileLength());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 读取buffer</span></span><br><span class="line">        <span class="keyword">int</span> result = readBuffer(strategy, off, realLen, corruptedBlockMap);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (result &gt;= <span class="number">0</span>) &#123;</span><br><span class="line">          pos += result;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// got a EOS from reader though we expect more data on it.</span></span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Unexpected EOS from the reader"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (dfsClient.stats != <span class="keyword">null</span>) &#123;</span><br><span class="line">          dfsClient.stats.incrementBytesRead(result);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">        <span class="comment">// 如果检测到ChecksumException 则只抛出异常，再次进行循环</span></span><br><span class="line">      &#125; <span class="keyword">catch</span> (ChecksumException ce) &#123;</span><br><span class="line">        <span class="keyword">throw</span> ce;    </span><br><span class="line">        <span class="comment">// 如果捕获到IO异常，则retries次数减1，进入下一次循环        </span></span><br><span class="line">      &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (retries == <span class="number">1</span>) &#123;</span><br><span class="line">          DFSClient.LOG.warn(<span class="string">"DFS Read"</span>, e);</span><br><span class="line">        &#125;</span><br><span class="line">        blockEnd = -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (currentNode != <span class="keyword">null</span>) &#123; addToDeadNodes(currentNode); &#125;</span><br><span class="line">        <span class="keyword">if</span> (--retries == <span class="number">0</span>) &#123;</span><br><span class="line">          <span class="keyword">throw</span> e;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="comment">// Check if need to report block replicas corruption either read</span></span><br><span class="line">        <span class="comment">// was successful or ChecksumException occured.</span></span><br><span class="line">        reportCheckSumFailure(corruptedBlockMap, </span><br><span class="line">            currentLocatedBlock.getLocations().length);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>readWithStrategy会重试2次进行读取，<em>如果捕获到<code>ChecksumException</code>则直接进行重试(本次尝试不计数)</em>，当捕获到<code>IOException</code>异常时会进行重试(尝试次数减1)，重新选择dn进行读取，并把有io异常的dn放入deadNodes map中。<strong>一个block一个deadNodes？？？</strong></p>
<p><strong>deadNodes是DFSInputStream的属性，则应该是一个DFSInputStream一个deadNodes，但是在读取一个block结束之后，deadNodes会不会被clear掉？？读取失败之后会clear deadNodes</strong></p>
<p>readWithStrategy中主要有两个方法，分别是<code>blockSeekTo</code>和<code>readBuffer</code>，blockSeekTo是找到当前pos的block，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> DatanodeInfo <span class="title">blockSeekTo</span><span class="params">(<span class="keyword">long</span> target)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Connect to best DataNode for desired Block, with potential offset</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  DatanodeInfo chosenNode = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">int</span> refetchToken = <span class="number">1</span>; <span class="comment">// only need to get a new access token once</span></span><br><span class="line">  <span class="keyword">int</span> refetchEncryptionKey = <span class="number">1</span>; <span class="comment">// only need to get a new encryption key once</span></span><br><span class="line">  <span class="keyword">boolean</span> connectFailedOnce = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Compute desired block</span></span><br><span class="line">    <span class="comment">//得到target所在的dn locations信息</span></span><br><span class="line">    LocatedBlock targetBlock = getBlockAt(target, <span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">assert</span> (target==pos) : <span class="string">"Wrong postion "</span> + pos + <span class="string">" expect "</span> + target;</span><br><span class="line">    <span class="keyword">long</span> offsetIntoBlock = target - targetBlock.getStartOffset();</span><br><span class="line">    <span class="comment">// 从dn set中选出一个dn</span></span><br><span class="line">    DNAddrPair retval = chooseDataNode(targetBlock, <span class="keyword">null</span>);</span><br><span class="line">    chosenNode = retval.info;</span><br><span class="line">    InetSocketAddress targetAddr = retval.addr;</span><br><span class="line">    StorageType storageType = retval.storageType;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      ExtendedBlock blk = targetBlock.getBlock();</span><br><span class="line">      Token&lt;BlockTokenIdentifier&gt; accessToken = targetBlock.getBlockToken();</span><br><span class="line">      <span class="comment">// 使用 Builder模式 创建一个 blockReader</span></span><br><span class="line">      blockReader = <span class="keyword">new</span> BlockReaderFactory(dfsClient.getConf()).</span><br><span class="line">          setInetSocketAddress(targetAddr).</span><br><span class="line">          setRemotePeerFactory(dfsClient).</span><br><span class="line">          setDatanodeInfo(chosenNode).</span><br><span class="line">          setStorageType(storageType).</span><br><span class="line">          setFileName(src).</span><br><span class="line">          setBlock(blk).</span><br><span class="line">          setBlockToken(accessToken).</span><br><span class="line">          setStartOffset(offsetIntoBlock).</span><br><span class="line">          setVerifyChecksum(verifyChecksum).</span><br><span class="line">          setClientName(dfsClient.clientName).</span><br><span class="line">          setLength(blk.getNumBytes() - offsetIntoBlock).</span><br><span class="line">          setCachingStrategy(cachingStrategy).</span><br><span class="line">          setAllowShortCircuitLocalReads(!shortCircuitForbidden()).</span><br><span class="line">          setClientCacheContext(dfsClient.getClientContext()).</span><br><span class="line">          setUserGroupInformation(dfsClient.ugi).</span><br><span class="line">          setConfiguration(dfsClient.getConfiguration()).</span><br><span class="line">          build();</span><br><span class="line">      <span class="keyword">if</span>(connectFailedOnce) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Successfully connected to "</span> + targetAddr +</span><br><span class="line">                           <span class="string">" for "</span> + blk);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> chosenNode;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ex) &#123;</span><br><span class="line">      <span class="keyword">if</span> (ex <span class="keyword">instanceof</span> InvalidEncryptionKeyException &amp;&amp; refetchEncryptionKey &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"Will fetch a new encryption key and retry, "</span> </span><br><span class="line">            + <span class="string">"encryption key was invalid when connecting to "</span> + targetAddr</span><br><span class="line">            + <span class="string">" : "</span> + ex);</span><br><span class="line">        <span class="comment">// The encryption key used is invalid.</span></span><br><span class="line">        refetchEncryptionKey--;</span><br><span class="line">        dfsClient.clearDataEncryptionKey();</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (refetchToken &gt; <span class="number">0</span> &amp;&amp; tokenRefetchNeeded(ex, targetAddr)) &#123;</span><br><span class="line">        refetchToken--;</span><br><span class="line">        <span class="comment">// Fetch a block from namenode and cache it ????</span></span><br><span class="line">        fetchBlockAt(target);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        connectFailedOnce = <span class="keyword">true</span>;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"Failed to connect to "</span> + targetAddr + <span class="string">" for block"</span></span><br><span class="line">          + <span class="string">", add to deadNodes and continue. "</span> + ex, ex);</span><br><span class="line">        <span class="comment">// Put chosen node into dead list, continue</span></span><br><span class="line">        addToDeadNodes(chosenNode);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>blockSeekTo主要包含两个方法和一个BlockReader的实例化对象，一个方法是<code>getBlockAt</code>，其作用是得到当前offset所在的block的dn locations信息，另一个方法是<code>chooseDataNode</code>，其作用是从<code>getBlockAt</code>得到的dn locations list中得到一个dn。getBlockAt的实现逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> LocatedBlock <span class="title">getBlockAt</span><span class="params">(<span class="keyword">long</span> offset,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> updatePosition)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> (locatedBlocks != <span class="keyword">null</span>) : <span class="string">"locatedBlocks is null"</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> LocatedBlock blk;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//check offset</span></span><br><span class="line">  <span class="keyword">if</span> (offset &lt; <span class="number">0</span> || offset &gt;= getFileLength()) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"offset &lt; 0 || offset &gt;= getFileLength(), offset="</span></span><br><span class="line">        + offset</span><br><span class="line">        + <span class="string">", updatePosition="</span> + updatePosition</span><br><span class="line">        + <span class="string">", locatedBlocks="</span> + locatedBlocks);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (offset &gt;= locatedBlocks.getFileLength()) &#123;</span><br><span class="line">    <span class="comment">// offset to the portion of the last block,</span></span><br><span class="line">    <span class="comment">// which is not known to the name-node yet;</span></span><br><span class="line">    <span class="comment">// getting the last block </span></span><br><span class="line">    blk = locatedBlocks.getLastLocatedBlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// search cached blocks first</span></span><br><span class="line">    <span class="comment">// 使用二分查找从缓存的block中查找当前offset所在的block</span></span><br><span class="line">    <span class="keyword">int</span> targetBlockIdx = locatedBlocks.findBlock(offset);</span><br><span class="line">    <span class="comment">// 在缓存中没有找到</span></span><br><span class="line">    <span class="keyword">if</span> (targetBlockIdx &lt; <span class="number">0</span>) &#123; <span class="comment">// block is not cached</span></span><br><span class="line">      targetBlockIdx = LocatedBlocks.getInsertIndex(targetBlockIdx);</span><br><span class="line">      <span class="comment">// fetch more blocks</span></span><br><span class="line">      <span class="comment">// 再次抓取blocks，从当前offset处开始抓取</span></span><br><span class="line">      <span class="keyword">final</span> LocatedBlocks newBlocks = dfsClient.getLocatedBlocks(src, offset);</span><br><span class="line">      <span class="keyword">assert</span> (newBlocks != <span class="keyword">null</span>) : <span class="string">"Could not find target position "</span> + offset;</span><br><span class="line">      <span class="comment">// 将new block插入到缓存的targetBlockIdx位置中</span></span><br><span class="line">      locatedBlocks.insertRange(targetBlockIdx, newBlocks.getLocatedBlocks());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 得到offset所在的block  targetBlockIdx是block在缓存中的索引</span></span><br><span class="line">    blk = locatedBlocks.get(targetBlockIdx);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// update current position</span></span><br><span class="line">  <span class="comment">// 更新read的起始地址pos和结束地址blockEnd</span></span><br><span class="line">  <span class="keyword">if</span> (updatePosition) &#123;</span><br><span class="line">    pos = offset;</span><br><span class="line">    blockEnd = blk.getStartOffset() + blk.getBlockSize() - <span class="number">1</span>;</span><br><span class="line">    currentLocatedBlock = blk;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> blk;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getBlockAt主要是得到offset所在的block，其检索方法是先在缓存(这个缓存大小是由<em>dfs.client.read.prefetch.size</em>决定的)中进行二分查找，找到就返回其索引，如果没有找到则再次调用rpc进行重新抓取block，<strong>此次抓取的block的是从offset所在block开始抓取的</strong>。下面看下<code>findBlock</code>的代码：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public int findBlock(long offset) &#123;</span><br><span class="line">  <span class="comment">// create fake block of size 0 as a key</span></span><br><span class="line">  <span class="comment">// 创建一个LocatedBlock对象，便于和LocatedBlocks中的block进行比较</span></span><br><span class="line">  <span class="type">LocatedBlock</span> key = <span class="keyword">new</span> <span class="type">LocatedBlock</span>(</span><br><span class="line">      <span class="keyword">new</span> <span class="type">ExtendedBlock</span>(), <span class="keyword">new</span> <span class="type">DatanodeInfo</span>[<span class="number">0</span>], <span class="number">0</span>L, <span class="literal">false</span>);</span><br><span class="line">  key.setStartOffset(offset);</span><br><span class="line">  key.getBlock().setNumBytes(<span class="number">1</span>);</span><br><span class="line">  <span class="comment">// 重写comparator</span></span><br><span class="line">  <span class="type">Comparator</span>&lt;<span class="type">LocatedBlock</span>&gt; comp = </span><br><span class="line">    <span class="keyword">new</span> <span class="type">Comparator</span>&lt;<span class="type">LocatedBlock</span>&gt;() &#123;</span><br><span class="line">      <span class="comment">// Returns 0 iff a is inside b or b is inside a</span></span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      public int compare(<span class="type">LocatedBlock</span> a, <span class="type">LocatedBlock</span> b) &#123;</span><br><span class="line">        long aBeg = a.getStartOffset();</span><br><span class="line">        long bBeg = b.getStartOffset();</span><br><span class="line">        long aEnd = aBeg + a.getBlockSize();</span><br><span class="line">        long bEnd = bBeg + b.getBlockSize();</span><br><span class="line">        <span class="keyword">if</span>(aBeg &lt;= bBeg &amp;&amp; bEnd &lt;= aEnd </span><br><span class="line">            || bBeg &lt;= aBeg &amp;&amp; aEnd &lt;= bEnd)</span><br><span class="line">          <span class="keyword">return</span> <span class="number">0</span>; <span class="comment">// one of the blocks is inside the other</span></span><br><span class="line">        <span class="keyword">if</span>(aBeg &lt; bBeg)</span><br><span class="line">          <span class="keyword">return</span> <span class="number">-1</span>; <span class="comment">// a's left bound is to the left of the b's</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="comment">// 调用Collections的二分查找</span></span><br><span class="line">  <span class="keyword">return</span> <span class="type">Collections</span>.binarySearch(blocks, key, comp);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>findBlock主要是利用Collections的二分查找进行查找offset所在的block，进行比较时先创建一个LocatedBlock对象，然后重写Comparator进行对象的比较。如果没有找到则调用<code>dfsClient.getLocatedBlocks</code>，从当前offset所在的block为起点进行再次抓取固定长度的block，并将newBlocks插入缓存中的blocks中。</p>
<p>抓取block是通过rpc调用dfsClient.getLocatedBlocks从FSNamesystem中获得blocks列表，然后通过<code>locatedBlocks.insertRange</code>插入到缓存中，locatedBlocks.insertRange代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insertRange</span><span class="params">(<span class="keyword">int</span> blockIdx, List&lt;LocatedBlock&gt; newBlocks)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 返回在缓存中查找失败返回的low处的索引</span></span><br><span class="line">  <span class="keyword">int</span> oldIdx = blockIdx;</span><br><span class="line">  <span class="keyword">int</span> insStart = <span class="number">0</span>, insEnd = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 如果缓存blocks的最后一个元素依然小于目标block的offset时(也就是low=len+1)</span></span><br><span class="line">  <span class="comment">// 则不进入for循环</span></span><br><span class="line">  <span class="comment">// 找到目标block在newBlocks中的索引</span></span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">int</span> newIdx = <span class="number">0</span>; newIdx &lt; newBlocks.size() &amp;&amp; oldIdx &lt; blocks.size(); </span><br><span class="line">                                                      newIdx++) &#123;</span><br><span class="line">    <span class="keyword">long</span> newOff = newBlocks.get(newIdx).getStartOffset();</span><br><span class="line">    <span class="keyword">long</span> oldOff = blocks.get(oldIdx).getStartOffset();</span><br><span class="line">    <span class="comment">// 当newBlocks</span></span><br><span class="line">    <span class="keyword">if</span>(newOff &lt; oldOff) &#123;</span><br><span class="line">      insEnd++;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span>(newOff == oldOff) &#123;</span><br><span class="line">      <span class="comment">// replace old cached block by the new one</span></span><br><span class="line">      blocks.set(oldIdx, newBlocks.get(newIdx));</span><br><span class="line">      <span class="keyword">if</span>(insStart &lt; insEnd) &#123; <span class="comment">// insert new blocks</span></span><br><span class="line">        blocks.addAll(oldIdx, newBlocks.subList(insStart, insEnd));</span><br><span class="line">        oldIdx += insEnd - insStart;</span><br><span class="line">      &#125;</span><br><span class="line">      insStart = insEnd = newIdx+<span class="number">1</span>;</span><br><span class="line">      oldIdx++;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;  <span class="comment">// newOff &gt; oldOff</span></span><br><span class="line">      <span class="keyword">assert</span> <span class="keyword">false</span> : <span class="string">"List of LocatedBlock must be sorted by startOffset"</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  insEnd = newBlocks.size();</span><br><span class="line">  <span class="comment">// 将大于目标block的blocks插入缓存中</span></span><br><span class="line">  <span class="keyword">if</span>(insStart &lt; insEnd) &#123; <span class="comment">// insert new blocks</span></span><br><span class="line">    blocks.addAll(oldIdx, newBlocks.subList(insStart, insEnd));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>insertRange将<em>newBlocks</em>中的block根据其在<em>blocks</em>中的顺序<em>分区间插入blocks中</em>。区间由insStart和insEnd控制，for循环中调整insEnd和insStart的值，分批次插入到blocks中。</p>
<p>此时就可以得到目标block的locations信息，通过<code>chooseDataNode</code>选择一个dn，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> DNAddrPair <span class="title">chooseDataNode</span><span class="params">(LocatedBlock block,</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;DatanodeInfo&gt; ignoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> getBestNodeDNAddrPair(block, ignoredNodes);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">      <span class="comment">// 捕获到getBestNodeDNAddrPair中chosenNode为null的异常之后</span></span><br><span class="line">      <span class="comment">// 清空deadNodes，重新获取该block的信息</span></span><br><span class="line">      <span class="comment">// 尝试3次，抛出异常</span></span><br><span class="line">      String errMsg = getBestNodeDNAddrPairErrorString(block.getLocations(),</span><br><span class="line">        deadNodes, ignoredNodes);</span><br><span class="line">      String blockInfo = block.getBlock() + <span class="string">" file="</span> + src;</span><br><span class="line">      <span class="comment">// dfs.client.max.block.acquire.failures 默认是3</span></span><br><span class="line">      <span class="comment">// 获取该block信息3次，注意与获取3次dn的区别</span></span><br><span class="line">      <span class="keyword">if</span> (failures &gt;= dfsClient.getMaxBlockAcquireFailures()) &#123;</span><br><span class="line">        String description = <span class="string">"Could not obtain block: "</span> + blockInfo;</span><br><span class="line">        DFSClient.LOG.warn(description + errMsg</span><br><span class="line">            + <span class="string">". Throwing a BlockMissingException"</span>);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> BlockMissingException(src, description,</span><br><span class="line">            block.getStartOffset());</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      DatanodeInfo[] nodes = block.getLocations();</span><br><span class="line">      <span class="keyword">if</span> (nodes == <span class="keyword">null</span> || nodes.length == <span class="number">0</span>) &#123;</span><br><span class="line">        DFSClient.LOG.info(<span class="string">"No node available for "</span> + blockInfo);</span><br><span class="line">      &#125;</span><br><span class="line">      DFSClient.LOG.info(<span class="string">"Could not obtain "</span> + block.getBlock()</span><br><span class="line">          + <span class="string">" from any node: "</span> + ie + errMsg</span><br><span class="line">          + <span class="string">". Will get new block locations from namenode and retry..."</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Introducing a random factor to the wait time before another retry.</span></span><br><span class="line">        <span class="comment">// The wait time is dependent on # of failures and a random factor.</span></span><br><span class="line">        <span class="comment">// At the first time of getting a BlockMissingException, the wait time</span></span><br><span class="line">        <span class="comment">// is a random number between 0..3000 ms. If the first retry</span></span><br><span class="line">        <span class="comment">// still fails, we will wait 3000 ms grace period before the 2nd retry.</span></span><br><span class="line">        <span class="comment">// Also at the second retry, the waiting window is expanded to 6000 ms</span></span><br><span class="line">        <span class="comment">// alleviating the request rate from the server. Similarly the 3rd retry</span></span><br><span class="line">        <span class="comment">// will wait 6000ms grace period before retry and the waiting window is</span></span><br><span class="line">        <span class="comment">// expanded to 9000ms. </span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> timeWindow = dfsClient.getConf().timeWindow;</span><br><span class="line">        <span class="keyword">double</span> waitTime = timeWindow * failures +       <span class="comment">// grace period for the last round of attempt</span></span><br><span class="line">          timeWindow * (failures + <span class="number">1</span>) * DFSUtil.getRandom().nextDouble(); <span class="comment">// expanding time window for each failure</span></span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"DFS chooseDataNode: got # "</span> + (failures + <span class="number">1</span>) + <span class="string">" IOException, will wait for "</span> + waitTime + <span class="string">" msec."</span>);</span><br><span class="line">        Thread.sleep((<span class="keyword">long</span>)waitTime);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (InterruptedException iex) &#123;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 从block的所有dn中没有找到合适的dn，则将deadNodes清空，重新获取该block的信息</span></span><br><span class="line">      <span class="comment">// 一个block一个deadNodes</span></span><br><span class="line">      deadNodes.clear(); <span class="comment">//2nd option is to remove only nodes[blockId]</span></span><br><span class="line">      openInfo();</span><br><span class="line">      block = getBlockAt(block.getStartOffset(), <span class="keyword">false</span>);</span><br><span class="line">      failures++;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> DNAddrPair <span class="title">getBestNodeDNAddrPair</span><span class="params">(LocatedBlock block,</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;DatanodeInfo&gt; ignoredNodes)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  DatanodeInfo[] nodes = block.getLocations();</span><br><span class="line">  StorageType[] storageTypes = block.getStorageTypes();</span><br><span class="line">  DatanodeInfo chosenNode = <span class="keyword">null</span>;</span><br><span class="line">  StorageType storageType = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">if</span> (nodes != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// 遍历选出非deadNode节点</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nodes.length; i++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!deadNodes.containsKey(nodes[i])</span><br><span class="line">          &amp;&amp; (ignoredNodes == <span class="keyword">null</span> || !ignoredNodes.contains(nodes[i]))) &#123;</span><br><span class="line">        chosenNode = nodes[i];</span><br><span class="line">        <span class="comment">// Storage types are ordered to correspond with nodes, so use the same</span></span><br><span class="line">        <span class="comment">// index to get storage type.</span></span><br><span class="line">        <span class="keyword">if</span> (storageTypes != <span class="keyword">null</span> &amp;&amp; i &lt; storageTypes.length) &#123;</span><br><span class="line">          storageType = storageTypes[i];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 循环了一圈依然没有找到合适的dn</span></span><br><span class="line">  <span class="keyword">if</span> (chosenNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"No live nodes contain block "</span> + block.getBlock() +</span><br><span class="line">        <span class="string">" after checking nodes = "</span> + Arrays.toString(nodes) +</span><br><span class="line">        <span class="string">", ignoredNodes = "</span> + ignoredNodes);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">final</span> String dnAddr =</span><br><span class="line">      chosenNode.getXferAddr(dfsClient.getConf().connectToDnViaHostname);</span><br><span class="line">  <span class="keyword">if</span> (DFSClient.LOG.isDebugEnabled()) &#123;</span><br><span class="line">    DFSClient.LOG.debug(<span class="string">"Connecting to datanode "</span> + dnAddr);</span><br><span class="line">  &#125;</span><br><span class="line">  InetSocketAddress targetAddr = NetUtils.createSocketAddr(dnAddr);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> DNAddrPair(chosenNode, targetAddr, storageType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>chooseDataNode调用<code>getBestNodeDNAddrPair</code>在<em>block的locations中选择一个dn</em>，如果没有找到则抛出一个<em>IOException异常</em>，在chooseDataNode中捕获，在catch中校验重试次数是否超过<code>dfs.client.max.block.acquire.failures</code>，没有则清空deadNodes再次去获取该block的locations。依然失败则抛出异常。</p>
<p>chooseDataNode结束返回到blockSeekTo中，由BlockReaderFactory创建BlockReader对象，这里创建的BlockReader对象会根据<em>short circuit local read</em>还是<em>远程读</em>创建不同的BlockReader。BlockReaderFactory使用了Builder设计模式，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> BlockReader <span class="title">build</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  BlockReader reader = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  Preconditions.checkNotNull(configuration);</span><br><span class="line">  <span class="comment">// 检查是否开启了short circuit local read</span></span><br><span class="line">  <span class="comment">// short circuit local read 使用的就是 Unix Domain Socket技术，</span></span><br><span class="line">  <span class="comment">// 那为什么还要将conf.domainSocketDataTraffic作为一个备选方案</span></span><br><span class="line">  <span class="keyword">if</span> (conf.shortCircuitLocalReads &amp;&amp; allowShortCircuitLocalReads) &#123;</span><br><span class="line">    <span class="keyword">if</span> (clientContext.getUseLegacyBlockReaderLocal()) &#123;</span><br><span class="line">      reader = getLegacyBlockReaderLocal();</span><br><span class="line">      <span class="keyword">if</span> (reader != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">          LOG.trace(<span class="keyword">this</span> + <span class="string">": returning new legacy block reader local."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> reader;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      reader = getBlockReaderLocal();</span><br><span class="line">      <span class="keyword">if</span> (reader != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">          LOG.trace(<span class="keyword">this</span> + <span class="string">": returning new block reader local."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> reader;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 通过UNIX domain socket 得到一个remote block reader</span></span><br><span class="line">  <span class="comment">// 与short circuit local read 的区别？？？？</span></span><br><span class="line">  <span class="keyword">if</span> (conf.domainSocketDataTraffic) &#123;</span><br><span class="line">    reader = getRemoteBlockReaderFromDomain();</span><br><span class="line">    <span class="keyword">if</span> (reader != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">        LOG.trace(<span class="keyword">this</span> + <span class="string">": returning new remote block reader using "</span> +</span><br><span class="line">            <span class="string">"UNIX domain socket on "</span> + pathInfo.getPath());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> reader;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  Preconditions.checkState(!DFSInputStream.tcpReadsDisabledForTesting,</span><br><span class="line">      <span class="string">"TCP reads were disabled for testing, but we failed to "</span> +</span><br><span class="line">      <span class="string">"do a non-TCP read."</span>);</span><br><span class="line">  <span class="comment">// 返回远程BlockReader</span></span><br><span class="line">  <span class="keyword">return</span> getRemoteBlockReaderFromTcp();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>得到BlockReader之后代码回到<code>readWithStrategy</code>中，然后进行<code>readBuffer</code>操作，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// corruptedBlockMap在readWithStrategy中被实例化</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">readBuffer</span><span class="params">(ReaderStrategy reader, <span class="keyword">int</span> off, <span class="keyword">int</span> len,</span></span></span><br><span class="line"><span class="function"><span class="params">    Map&lt;ExtendedBlock, Set&lt;DatanodeInfo&gt;&gt; corruptedBlockMap)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  IOException ioe;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/* we retry current node only once. So this is set to true only here.</span></span><br><span class="line"><span class="comment">   * Intention is to handle one common case of an error that is not a</span></span><br><span class="line"><span class="comment">   * failure on datanode or client : when DataNode closes the connection</span></span><br><span class="line"><span class="comment">   * since client is idle. If there are other cases of "non-errors" then</span></span><br><span class="line"><span class="comment">   * then a datanode might be retried by setting this to true again.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">boolean</span> retryCurrentNode = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">// retry as many times as seekToNewSource allows.</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> reader.doRead(blockReader, off, len, readStatistics);</span><br><span class="line">    &#125; <span class="keyword">catch</span> ( ChecksumException ce ) &#123;</span><br><span class="line">      DFSClient.LOG.warn(<span class="string">"Found Checksum error for "</span></span><br><span class="line">          + getCurrentBlock() + <span class="string">" from "</span> + currentNode</span><br><span class="line">          + <span class="string">" at "</span> + ce.getPos());        </span><br><span class="line">      ioe = ce;</span><br><span class="line">      retryCurrentNode = <span class="keyword">false</span>;</span><br><span class="line">      <span class="comment">// we want to remember which block replicas we have tried</span></span><br><span class="line">      addIntoCorruptedBlockMap(getCurrentBlock(), currentNode,</span><br><span class="line">          corruptedBlockMap);</span><br><span class="line">    &#125; <span class="keyword">catch</span> ( IOException e ) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!retryCurrentNode) &#123;</span><br><span class="line">        DFSClient.LOG.warn(<span class="string">"Exception while reading from "</span></span><br><span class="line">            + getCurrentBlock() + <span class="string">" of "</span> + src + <span class="string">" from "</span></span><br><span class="line">            + currentNode, e);</span><br><span class="line">      &#125;</span><br><span class="line">      ioe = e;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">boolean</span> sourceFound = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (retryCurrentNode) &#123;</span><br><span class="line">      <span class="comment">/* possibly retry the same node so that transient errors don't</span></span><br><span class="line"><span class="comment">       * result in application level failures (e.g. Datanode could have</span></span><br><span class="line"><span class="comment">       * closed the connection because the client is idle for too long).</span></span><br><span class="line"><span class="comment">       */</span> </span><br><span class="line">      sourceFound = seekToBlockSource(pos);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      addToDeadNodes(currentNode);</span><br><span class="line">      sourceFound = seekToNewSource(pos);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (!sourceFound) &#123;</span><br><span class="line">      <span class="keyword">throw</span> ioe;</span><br><span class="line">    &#125;</span><br><span class="line">    retryCurrentNode = <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>readBuffer是通过调用ByteArrayStrategy重写的doRead方法来read的，而<code>ByteArrayStrategy.doRead</code>又是调用<code>BlockReader.read</code>来进行真正的读操作。</p>
<p>doRead时readBuffer会捕获到ChecksumException和IOException异常，</p>
<ul>
<li>如果检测到<em>ChecksumException</em>异常，retryCurrentNode 变为fasle，将当前节点加入deadNodes，然后进行seekToNewSource</li>
<li>如果检测到<em>IOException</em>异常，并且retryCurrentNode为true，则进行seekToBlockSource<pre><code>如果retryCurrentNode为false，将当前节点加入deadNodes，然后进行seekToNewSource
</code></pre></li>
</ul>
<p>retryCurrentNode标识当前节点read失败之后是否进行重试，如果是ChecksumException失败，则不进行重试，如果是IOException失败，则进行重试，并且只重试一次。<em>因为可能存在由于client长时间没有任何动作，则dn关闭了连接导致IOException，此时进行重试</em>。<strong>此处进行重试并不是马上对该节点进行重试，只是不该节点标为dead，可以在随后的choseNode时可以被再次选择</strong>。</p>
<p>由seekToNewSource来选择再次read的节点，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">seekToNewSource</span><span class="params">(<span class="keyword">long</span> targetPos)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> markedDead = deadNodes.containsKey(currentNode);</span><br><span class="line">  addToDeadNodes(currentNode);</span><br><span class="line">  DatanodeInfo oldNode = currentNode;</span><br><span class="line">  DatanodeInfo newNode = blockSeekTo(targetPos);</span><br><span class="line">  <span class="keyword">if</span> (!markedDead) &#123;</span><br><span class="line">    <span class="comment">/* remove it from deadNodes. blockSeekTo could have cleared </span></span><br><span class="line"><span class="comment">     * deadNodes and added currentNode again. Thats ok. */</span></span><br><span class="line">    deadNodes.remove(oldNode);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!oldNode.getDatanodeUuid().equals(newNode.getDatanodeUuid())) &#123;</span><br><span class="line">    currentNode = newNode;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>真正的read操作是<code>BlockReader.read</code>，BlockReader是在blockSeekTo中实例化的，此处是<em>远程read</em>，其实现是<code>RemoteBlockReader2.read</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// RemoteBlockReader2.read</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">byte</span>[] buf, <span class="keyword">int</span> off, <span class="keyword">int</span> len)</span> </span></span><br><span class="line"><span class="function">                             <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">  UUID randomId = <span class="keyword">null</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (curDataSlice == <span class="keyword">null</span> || curDataSlice.remaining() == <span class="number">0</span> &amp;&amp; bytesNeededToFinish &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    readNextPacket();</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (curDataSlice.remaining() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// we're at EOF now</span></span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 如果buf的len小于curDataSlice的长度，剩下的内容怎么读</span></span><br><span class="line">  <span class="keyword">int</span> nRead = Math.min(curDataSlice.remaining(), len);</span><br><span class="line">  <span class="comment">// 从curDataSlice中读取数据到buf中</span></span><br><span class="line">  curDataSlice.get(buf, off, nRead);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> nRead;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">readNextPacket</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">//Read packet headers.</span></span><br><span class="line">  packetReceiver.receiveNextPacket(in);</span><br><span class="line"></span><br><span class="line">  PacketHeader curHeader = packetReceiver.getHeader();</span><br><span class="line">  curDataSlice = packetReceiver.getDataSlice();</span><br><span class="line">  <span class="keyword">assert</span> curDataSlice.capacity() == curHeader.getDataLen();</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">if</span> (curHeader.getDataLen() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// bytesPerChecksum 多少字节一个checkcum</span></span><br><span class="line">    <span class="comment">// curHeader.getDataLen得到数据data的长度，然后得出需要多少个chunks</span></span><br><span class="line">    <span class="keyword">int</span> chunks = <span class="number">1</span> + (curHeader.getDataLen() - <span class="number">1</span>) / bytesPerChecksum;</span><br><span class="line">    <span class="comment">// 得出checksum的长度</span></span><br><span class="line">    <span class="keyword">int</span> checksumsLen = chunks * checksumSize;</span><br><span class="line">    ...</span><br><span class="line">    lastSeqNo = curHeader.getSeqno();</span><br><span class="line">    <span class="keyword">if</span> (verifyChecksum &amp;&amp; curDataSlice.remaining() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// N.B.: the checksum error offset reported here is actually</span></span><br><span class="line">      <span class="comment">// relative to the start of the block, not the start of the file.</span></span><br><span class="line">      <span class="comment">// This is slightly misleading, but preserves the behavior from</span></span><br><span class="line">      <span class="comment">// the older BlockReader.</span></span><br><span class="line">      <span class="comment">// 利用checksum检查数据是否正确</span></span><br><span class="line">      checksum.verifyChunkedSums(curDataSlice,</span><br><span class="line">          packetReceiver.getChecksumSlice(),</span><br><span class="line">          filename, curHeader.getOffsetInBlock());</span><br><span class="line">    &#125;</span><br><span class="line">    bytesNeededToFinish -= curHeader.getDataLen();</span><br><span class="line">  &#125;    </span><br><span class="line">  </span><br><span class="line">  <span class="comment">// First packet will include some data prior to the first byte</span></span><br><span class="line">  <span class="comment">// the user requested. Skip it.</span></span><br><span class="line">  <span class="keyword">if</span> (curHeader.getOffsetInBlock() &lt; startOffset) &#123;</span><br><span class="line">    <span class="keyword">int</span> newPos = (<span class="keyword">int</span>) (startOffset - curHeader.getOffsetInBlock());</span><br><span class="line">    curDataSlice.position(newPos);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If we've now satisfied the whole client read, read one last packet</span></span><br><span class="line">  <span class="comment">// header, which should be empty</span></span><br><span class="line">  <span class="comment">// bytesNeededToFinish是表示还需要读多少字节，</span></span><br><span class="line">  <span class="comment">// 这个是在哪赋值的？怎么知道还有多少字节要读</span></span><br><span class="line">  <span class="keyword">if</span> (bytesNeededToFinish &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// 读取结束</span></span><br><span class="line">    readTrailingEmptyPacket();</span><br><span class="line">    <span class="keyword">if</span> (verifyChecksum) &#123;</span><br><span class="line">      sendReadResult(Status.CHECKSUM_OK);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      sendReadResult(Status.SUCCESS);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>read时packet是基本的传输单位，每个packet(默认每个packet为64K)由若干个chunk组成，每个chunk对应一个chunksum。</p>
<p>curDataSlice中存储这需要读取data的信息，初次读取packet时，curDataSlice为null，进行packet读取<code>readNextPacket</code>，对curDataSlice进行赋值（<em>也就是先把内容读取到packet中，此时curDataSlice就相当于一个packet</em>），并对packet中的数据调用<code>checksum.verifyChunkedSums</code>进行checksum检验。</p>
<p>最后由<code>curDataSlice.get(buf, off, nRead)</code>从curDataSlice读取一定长度的byte放入buf中。</p>
<p>则一次调用read流程结束，一次read只是从packet中读取一些byte，再次调用read会继续从curDataSlice中get一定长度的byte，直到<code>curDataSlice.remaining() == 0 &amp;&amp; bytesNeededToFinish &gt; 0</code>时，也就是当前packet内容读取完毕，然后再次调用readNextPacket进行读取block。</p>
<p>简单说下packet的数据结构</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Each packet looks like:</span></span><br><span class="line"><span class="comment">//   PLEN    HLEN      HEADER     CHECKSUMS  DATA</span></span><br><span class="line"><span class="comment">//   32-bit  16-bit   &lt;protobuf&gt;  &lt;variable length&gt;</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// PLEN:      Payload length</span></span><br><span class="line"><span class="comment">//            = length(PLEN) + length(CHECKSUMS) + length(DATA)</span></span><br><span class="line"><span class="comment">//            This length includes its own encoded length in</span></span><br><span class="line"><span class="comment">//            the sum for historical reasons.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// HLEN:      Header length</span></span><br><span class="line"><span class="comment">//            = length(HEADER)</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// HEADER:    the actual packet header fields, encoded in protobuf</span></span><br><span class="line"><span class="comment">// CHECKSUMS: the crcs for the data chunk. May be missing if</span></span><br><span class="line"><span class="comment">//            checksums were not requested</span></span><br><span class="line"><span class="comment">// DATA       the actual block data</span></span><br></pre></td></tr></table></figure>
<p>HDFS一个文件由多个block构成。HDFS在进行block读写的时候是以packet(默认每个packet为64K)为单位进行的。每一个packet由若干个chunk（默认512Byte）组成。Chunk是进行数据校验的基本单位，对每一个chunk生成一个校验和(默认4Byte)并将校验和进行存储。在读取一个block的时候，数据传输的基本单位是packet，每个packet由若干个chunk组成。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h3 id="getRemoteBlockReaderFromTcp代码跟读"><a href="#getRemoteBlockReaderFromTcp代码跟读" class="headerlink" title="getRemoteBlockReaderFromTcp代码跟读"></a>getRemoteBlockReaderFromTcp代码跟读</h3><p>getRemoteBlockReaderFromTcp得到一个远程BlockReader</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> BlockReader <span class="title">getRemoteBlockReaderFromTcp</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  BlockReader blockReader = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    BlockReaderPeer curPeer = <span class="keyword">null</span>;</span><br><span class="line">    Peer peer = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//Get the next TCP-based peer-- either from the cache or by creating it.</span></span><br><span class="line">      curPeer = nextTcpPeer();</span><br><span class="line">      <span class="keyword">if</span> (curPeer == <span class="keyword">null</span>) <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">if</span> (curPeer.fromCache) remainingCacheTries--;</span><br><span class="line">      peer = curPeer.peer;</span><br><span class="line">      <span class="comment">// 通过peer得到某个block的blockReader</span></span><br><span class="line">      blockReader = getRemoteBlockReader(peer);</span><br><span class="line">      <span class="keyword">return</span> blockReader;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (blockReader == <span class="keyword">null</span>) &#123;</span><br><span class="line">        IOUtils.cleanup(LOG, peer);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> BlockReader <span class="title">getRemoteBlockReader</span><span class="params">(Peer peer)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (conf.useLegacyBlockReader) &#123;</span><br><span class="line">    <span class="keyword">return</span> RemoteBlockReader.newBlockReader(fileName,</span><br><span class="line">        block, token, startOffset, length, conf.ioBufferSize,</span><br><span class="line">        verifyChecksum, clientName, peer, datanode,</span><br><span class="line">        clientContext.getPeerCache(), cachingStrategy);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> RemoteBlockReader2.newBlockReader(</span><br><span class="line">        fileName, block, token, startOffset, length,</span><br><span class="line">        verifyChecksum, clientName, peer, datanode,</span><br><span class="line">        clientContext.getPeerCache(), cachingStrategy);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// RemoteBlockReader2</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> BlockReader <span class="title">newBlockReader</span><span class="params">(String file,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   ExtendedBlock block,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   Token&lt;BlockTokenIdentifier&gt; blockToken,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   <span class="keyword">long</span> startOffset, <span class="keyword">long</span> len,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   <span class="keyword">boolean</span> verifyChecksum,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   String clientName,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   Peer peer, DatanodeID datanodeID,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   PeerCache peerCache,</span></span></span><br><span class="line"><span class="function"><span class="params">                                   CachingStrategy cachingStrategy)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// in and out will be closed when sock is closed (by the caller)</span></span><br><span class="line">  <span class="comment">// 使用Socket建立写入流，</span></span><br><span class="line">  <span class="keyword">final</span> DataOutputStream out = <span class="keyword">new</span> DataOutputStream(<span class="keyword">new</span> BufferedOutputStream(</span><br><span class="line">        peer.getOutputStream()));</span><br><span class="line">  <span class="comment">// 向DataNode发送读指令</span></span><br><span class="line">  <span class="comment">// 此处的readBlock与DataXceiver中的readBlock的区别是啥？这是一个rpc调用？？</span></span><br><span class="line">  <span class="comment">// Sender是client端，DataXceiver是Server端？？？</span></span><br><span class="line">  <span class="keyword">new</span> Sender(out).readBlock(block, blockToken, clientName, startOffset, len,</span><br><span class="line">      verifyChecksum, cachingStrategy);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Get bytes in block</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  DataInputStream in = <span class="keyword">new</span> DataInputStream(peer.getInputStream());</span><br><span class="line"></span><br><span class="line">  BlockOpResponseProto status = BlockOpResponseProto.parseFrom(</span><br><span class="line">      PBHelper.vintPrefixed(in));</span><br><span class="line">  checkSuccess(status, peer, block, file);</span><br><span class="line">  ReadOpChecksumInfoProto checksumInfo =</span><br><span class="line">    status.getReadOpChecksumInfo();</span><br><span class="line">  DataChecksum checksum = DataTransferProtoUtil.fromProto(</span><br><span class="line">      checksumInfo.getChecksum());</span><br><span class="line">  <span class="comment">//Warning when we get CHECKSUM_NULL?</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Read the first chunk offset.</span></span><br><span class="line">  <span class="keyword">long</span> firstChunkOffset = checksumInfo.getChunkOffset();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ( firstChunkOffset &lt; <span class="number">0</span> || firstChunkOffset &gt; startOffset ||</span><br><span class="line">      firstChunkOffset &lt;= (startOffset - checksum.getBytesPerChecksum())) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"BlockReader: error in first chunk offset ("</span> +</span><br><span class="line">                          firstChunkOffset + <span class="string">") startOffset is "</span> +</span><br><span class="line">                          startOffset + <span class="string">" for file "</span> + file);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> RemoteBlockReader2(file, block.getBlockPoolId(), block.getBlockId(),</span><br><span class="line">      checksum, verifyChecksum, startOffset, firstChunkOffset, len, peer,</span><br><span class="line">      datanodeID, peerCache);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="随机读"><a href="#随机读" class="headerlink" title="随机读"></a>随机读</h3><p>HDFS读文件包含两种，一种是最经常使用的顺序读，另一种是随机读。像MR任务，一般都会涉及到随机读。MR在提交作业时，已经确定了每个map和reduce要读取的文件，文件的偏移量，读取的长度，则只读取相应的split就行。</p>
<p>随机读的代码入口函数依然在<code>FSDataInputStream</code>中：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSDataInputStream.read</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">byte</span>[] buffer, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> ((PositionedReadable)in).read(position, buffer, offset, length);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//DFSInputStream.read</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">read</span><span class="params">(<span class="keyword">long</span> position, <span class="keyword">byte</span>[] buffer, <span class="keyword">int</span> offset, <span class="keyword">int</span> length)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// sanity checks</span></span><br><span class="line">  dfsClient.checkOpen();</span><br><span class="line">  <span class="keyword">if</span> (closed) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"Stream closed"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  failures = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">long</span> filelen = getFileLength();</span><br><span class="line">  <span class="keyword">if</span> ((position &lt; <span class="number">0</span>) || (position &gt;= filelen)) &#123;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">int</span> realLen = length;</span><br><span class="line">  <span class="keyword">if</span> ((position + length) &gt; filelen) &#123;</span><br><span class="line">    realLen = (<span class="keyword">int</span>)(filelen - position);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// determine the block and byte range within the block</span></span><br><span class="line">  <span class="comment">// corresponding to position and realLen</span></span><br><span class="line">  List&lt;LocatedBlock&gt; blockRange = getBlockRange(position, realLen);</span><br><span class="line">  <span class="keyword">int</span> remaining = realLen;</span><br><span class="line">  Map&lt;ExtendedBlock,Set&lt;DatanodeInfo&gt;&gt; corruptedBlockMap </span><br><span class="line">    = <span class="keyword">new</span> HashMap&lt;ExtendedBlock, Set&lt;DatanodeInfo&gt;&gt;();</span><br><span class="line">  <span class="keyword">for</span> (LocatedBlock blk : blockRange) &#123;</span><br><span class="line">    <span class="keyword">long</span> targetStart = position - blk.getStartOffset();</span><br><span class="line">    <span class="keyword">long</span> bytesToRead = Math.min(remaining, blk.getBlockSize() - targetStart);</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (dfsClient.isHedgedReadsEnabled()) &#123;</span><br><span class="line">        hedgedFetchBlockByteRange(blk, targetStart, targetStart + bytesToRead</span><br><span class="line">            - <span class="number">1</span>, buffer, offset, corruptedBlockMap);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        fetchBlockByteRange(blk, targetStart, targetStart + bytesToRead - <span class="number">1</span>,</span><br><span class="line">            buffer, offset, corruptedBlockMap);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="comment">// Check and report if any block replicas are corrupted.</span></span><br><span class="line">      <span class="comment">// BlockMissingException may be caught if all block replicas are</span></span><br><span class="line">      <span class="comment">// corrupted.</span></span><br><span class="line">      reportCheckSumFailure(corruptedBlockMap, blk.getLocations().length);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    remaining -= bytesToRead;</span><br><span class="line">    position += bytesToRead;</span><br><span class="line">    offset += bytesToRead;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">assert</span> remaining == <span class="number">0</span> : <span class="string">"Wrong number of bytes read."</span>;</span><br><span class="line">  <span class="keyword">if</span> (dfsClient.stats != <span class="keyword">null</span>) &#123;</span><br><span class="line">    dfsClient.stats.incrementBytesRead(realLen);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> realLen;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>这两篇文章主要介绍了hdfs读文件的流程，整个流程为：<br>1) 得到一个文件系统的实例，通过getFileSystem得到<br>2) open一个文件输入流，open时根据指定的path调用rpc打开一个FSDataInputStream，在初始化输入流时，会将一部分block的locations信息读入内存进行缓存，默认是10个block。将输入流的实例返回给client。<em>内存中缓存的block已经是按照各个dn到client的距离进行排序之后的结果</em><br>3) 输入流实例化之后，调用read方法读取数据。(读分为顺序读和随机读)</p>
<ol>
<li>read时可以选择几种ReaderStrategy，本篇选择的是ByteArrayStrategy。</li>
<li>根据off和len进行读。通过off找到对应的block A(二分查找)，如果block A在之前的缓存中，则直接返回block A。如果block A不在之前的缓存中，则再次请求从nn请求一部分block，将新请求的blocks根据其中block在原缓存中的位置插入到缓存中，之后得到该off对应的block A。</li>
<li>通过block A选择离client最近的dn，<em>如果得到dn时发生IOException错误(当从locations中没有选择到合适的dn时，抛出IOException)</em>，则等待一段时间之后，进行重试，默认是重试3次。</li>
<li>得到dn之后，通过BlockRead进行读取数据，BlockRead根据是否short circuit local 和 remote实例化不同的BlockRead。</li>
<li><em>read数据时发生的错误为checksumException和IOException</em>，如果是ChecksumException则将dn放入deadNodes中，换个dn进行重读，如果是IOException则直接重读(<em>可能是连接断开了</em>)，不将dn放入deadNodes中。</li>
<li>本篇介绍的是RemoteBlockReader，读文件时是以packet为单位的，读取一个packet放入内存，对其中的chunk进行checksum校验。从内存中读取len的长度，如果读完则继续读取下一个packet。<em>读取完毕之后发送一个空packet。</em><strong>是block的最后一个packet还是？？</strong></li>
<li>读文件时还需要dn端的一些操作，主要类是DataXceiver，这个类随后再分析。</li>
</ol>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><ul>
<li>何种情况下block会丢失</li>
<li>读取速度慢，某个node读取失败</li>
<li>怎么判断需要创建远程BlockReader还是本地BlockReader(是否还有本地读的概念，都是通过remote吗？)<br>仅由此来判断是否开启本地读还是远程读？  setRemotePeerFactory<br>allowShortCircuitLocalReads 当 当前文件正在构建中则为false</li>
<li>read某个block的dn时，出错，怎么办<br>看在哪出错？是在get block dn时还是在得到dn进行read时出错，<br><em>如果在get block的dn时出错</em>，重复3次依然出错，则抛出异常。<br><em>如果在得到dn之后，read时出错</em>，此时又分两种情况，如果是checksum错，换个dn重读，如果是IOException，则直接重试。</li>
<li>发送，数据是怎么发送的？？？   读的过程中有send嘛？</li>
<li>读取某个dn的block时失败，将此dn加入哪？或者dn死掉，。。<br>  加入deadNodes</li>
<li>这个deadNodes是谁维护的？只是本次读？<br>读一个block，一个deadNodes</li>
<li>In HDFS, why corrupted block(s) happens?<br> dfs.datanode.scan.period.hours</li>
<li>Sender(out).readBlock与DataXceiver中的readBlock的区别是啥？这是一个rpc调用？？<br>// Sender是client端，DataXceiver是Server端？？？</li>
</ul>
<h2 id="相关配置属性"><a href="#相关配置属性" class="headerlink" title="相关配置属性"></a>相关配置属性</h2><ul>
<li><p>io.file.buffer.size(4096)<br> The size of buffer for use in sequence files. The size of this buffer should probably be a multiple of hardware page size (4096 on Intel x86), and it determines how much data is buffered during read and write operations.</p>
</li>
<li><p>dfs.client.read.prefetch.size</p>
</li>
</ul>
<p>prefetchSize = conf.getLong(DFS_CLIENT_READ_PREFETCH_SIZE_KEY,<br>          10 * defaultBlockSize);</p>
<ul>
<li><p>dfs.client.<em>cache.drop</em>.behind.reads (vs dfs.datanode.<em>drop.cache</em>.behind.reads)</p>
<p> Just like dfs.datanode.drop.cache.behind.reads, this setting causes the page cache to be dropped behind HDFS reads, potentially freeing up more memory for other uses. Unlike dfs.datanode.drop.cache.behind.reads, this is a client-side setting rather than a setting for the entire datanode. If present, this setting will override the DataNode default. If the native libraries are not available to the DataNode, this configuration has no effect.</p>
<p> In some workloads, the data read from HDFS is known to be significantly large enough that it is unlikely to be useful to cache it in the operating system buffer cache. In this case, the DataNode may be configured to automatically purge all data from the buffer cache after it is delivered to the client. This behavior is automatically disabled for workloads which read only short sections of a block (e.g HBase random-IO workloads). This may improve performance for some workloads by freeing buffer cache space usage for more cacheable data. If the Hadoop native libraries are not available, this configuration has no effect.</p>
</li>
</ul>
<ul>
<li><p>dfs.client.cache.drop.behind.writes</p>
</li>
<li><p>dfs.client.cache.readahead (vs dfs.datanode.readahead.bytes)</p>
<p> When using remote reads, this setting causes the datanode to read ahead in the block file using posix_fadvise, potentially decreasing I/O wait times. Unlike dfs.datanode.readahead.bytes, this is a client-side setting rather than a setting for the entire datanode. If present, this setting will override the DataNode default. When using local reads, this setting determines how much readahead we do in BlockReaderLocal. If the native libraries are not available to the DataNode, this configuration has no effect.</p>
</li>
</ul>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> read </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[NameNode内存解析及大小评估]]></title>
      <url>http://bigdatadecode.club/NameNode%E5%86%85%E5%AD%98%E8%A7%A3%E6%9E%90%E5%8F%8A%E5%A4%A7%E5%B0%8F%E8%AF%84%E4%BC%B0.html</url>
      <content type="html"><![CDATA[<p>HDFS由NameNode和DataNode组成，其中NameNode作为Master节点，负责维护整个集群的状态，为了提高响应速度其大部分数据都常驻内存，则NameNode内存的使用尤为重要，一旦NameNode出现故障，整个Hadoop集群就将处于不可服务的状态。</p>
<p>在解析NameNode内存之前先来回顾下HDFS整体架构。</p>
<a id="more"></a>
<h2 id="HDFS架构"><a href="#HDFS架构" class="headerlink" title="HDFS架构"></a>HDFS架构</h2><p><img src="/blogimgs/NameNode内存评估/HDFS-A.gif" alt="HDFS架构" title="HDFS架构"><br>从上图中可以看出HDFS可以分为两层，分别为NameSpace和Block Storage Service，其中Block Storage Service包含Block Management和Storage两部分。</p>
<p>NameSpace和Block Management在NameNode中，Storage在DataNode中。</p>
<p>NameSpace主要存储集群的目录结构和文件所对应的block映射(file-&gt;blocks的映射)，是HDFS文件系统实际执行的核心，提供各种增删改查文件操作接口。</p>
<p>Block Management</p>
<ul>
<li>通过注册和周期性的心跳提供dn集群成员</li>
<li>处理dn的block report，存储在BlocksMap中</li>
<li>提供block相关的操作，如create、delete、modif和get block location</li>
<li>管理replica的放置策略，不足副本因子的replica进行复制，超过副本因子的replica进行删除</li>
</ul>
<p>Storage<br>由DataNode提供，用于将replica存放在本地文件系统中并提供读写权限。</p>
<p>由上得知NameNode中主要由NameSpace和Block Management组成，其中NameSpace和BlocksMap是占内存的大户。</p>
<h2 id="NameNode内存概述"><a href="#NameNode内存概述" class="headerlink" title="NameNode内存概述"></a>NameNode内存概述</h2><p>NameNode的内存中除了上面提到的NameSpace和BlocksMap之外，还有维护整个集群拓扑结构的NetworkTopology、管理整个集群写租约的LeaseManager、管理集中式缓存的CacheManager和SnapshotManager。NameNode的内存结构如下图：<br><img src="/blogimgs/NameNode内存评估/namenodemem.png" alt="NameNode内存结构" title="NameNode内存结构"><br>Namespace：维护整个文件系统的目录树结构，及目录树上的状态变化；<br>BlocksManager：维护整个文件系统中与数据块相关的信息，及数据块的状态变化；<br>NetworkTopology：维护机架拓扑及DataNode信息，机架感知的基础；<br>LeaseManager：读写的互斥同步就是靠Lease实现，支持HDFS的Write-Once-Read-Many的核心数据结构；<br>CacheManager：<em>Hadoop 2.3.0引入的集中式缓存新特性</em>，支持集中式缓存的管理，实现memory-locality提升读性能；<br>SnapshotManager：<em>Hadoop 2.1.0引入的Snapshot新特性</em>，用于数据备份、回滚，以防止因用户误操作导致集群出现数据问题；<br>DelegationTokenSecretManager：管理HDFS的安全访问；<br>其他：临时数据信息、统计信息metrics等等。</p>
<p>NameNode常驻内存主要被Namespace和BlockManager使用，二者使用占比分别接近50%。其他部分内存开销较小且相对固定，与Namespace和BlockManager相比基本可以忽略。</p>
<h2 id="NameNode内存解析"><a href="#NameNode内存解析" class="headerlink" title="NameNode内存解析"></a>NameNode内存解析</h2><h3 id="NameSpace"><a href="#NameSpace" class="headerlink" title="NameSpace"></a>NameSpace</h3><p>与单机文件系统相似，HDFS对文件系统的目录结构也是按照树状结构维护，Namespace保存了目录树及每个目录/文件节点的属性。<em>除在内存常驻外，这部分数据会定期flush到持久化设备上，生成一个新的FsImage文件，方便NameNode发生重启时，从FsImage及时恢复整个Namespace</em>。</p>
<p>在整个Namespace目录树中存在两种不同类型的<em>INode</em>数据结构：INodeDirectory和INodeFile。其中<em>INodeDirectory标识的是目录树中的目录</em>，<em>INodeFile标识的是目录树中的文件</em>。由于二者均继承自INode，所以具备大部分相同的公共信息INodeWithAdditionalFields，除常用基础属性外，其中还提供了扩展属性features，如Quota，Snapshot等均通过Feature增加，如果以后出现新属性也可通过Feature方便扩展。不同的是，INodeFile特有的标识<em>副本数和数据块大小组合的header</em>（2.6.1之后又新增了标识存储策略ID的信息）及该文件包含的有序Blocks数组；INodeDirectory则特有子节点的列表children。这里需要特别说明children是默认大小为5的ArrayList，按照子节点name有序存储，虽然在插入时会损失一部分写性能，但是可以方便后续快速二分查找提高读性能，对一般存储系统，读操作比写操作占比要高。</p>
<h3 id="BlockManager"><a href="#BlockManager" class="headerlink" title="BlockManager"></a>BlockManager</h3><p>BlocksMap在NameNode的内存空间中占据很大的比例，由BlockManager统一管理。相比NameSpace，BlockManager管理的这部分数据要复杂的多。<em>Namespace与BlockManager之间通过前面提到的INodeFile有序Blocks数组关联到一起</em>。下图是BlockManager管理的内存结构。<br><img src="/blogimgs/NameNode内存评估/blockmanager.png" alt="BlockManager" title="BlockManager"></p>
<p>INodeFile是一个实体file在NameNode内存中的一个对象，包含一个存放block信息的BlockInfo数组，数组的大小为文件block的个数。如上图BlockInfo[A~K]所示。</p>
<p>BlockInfo继承自Block，维护的是Block的元数据，除基本信息外还包括一个<em>inode引用(<code>private BlockCollection bc</code>)</em>，表示该block所属的文件；以及一个记录replica到底存放在那些dn上的三元组数组<code>Object[] triplets</code>，大小为3*replicas，其中replicas是Block副本数量。triplets包含的信息：</p>
<p>triplets[3<em>i]：Block所在的DataNode A；(<em>DatanodeStorageInfo对象</em>)<br>triplets[3</em>i+1]：该DataNode A上前一个Block；(<em>指向前一个block的BlockInfo对象引用</em>)<br>triplets[3*i+2]：该DataNode A上后一个Block；(<em>指向后一个block的BlockInfo对象引用</em>)</p>
<p>其中i表示的是Block的第i个副本，i取值[0,replicas)。</p>
<p>从前面描述中通过BlockInfo可以得到以下几块重要信息：</p>
<ul>
<li>文件包含了哪些Block(由BlockInfo对该文件的引用可以得到该文件所有的block信息)</li>
<li>这些Block分别被实际存储在哪些DataNode上(通过BlockInfo的triplets数组可以得到该block的replica存储位置)</li>
<li>DataNode上所有Block前后链表关系(通过BlockInfo的triplets数组中pre)</li>
</ul>
<p>如果从信息完整度来看，以上数据足够支持所有关于HDFS文件系统的正常操作，但还存在一个使用场景较多的问题：<em>不能通过blockid快速定位Block</em>，所以引入了BlocksMap。</p>
<p>BlocksMap底层通过LightWeightGSet实现(关于LightWeightGSet的详细介绍可参考<a href="http://bigdatadecode.club/HDFS中LightWeightGSet与HashMap结构解析.html">这篇blog</a>)，本质是一个链式解决冲突的哈希表。为了避免rehash过程带来的性能开销，初始化时，索引空间直接给到了整个JVM可用内存的2%，并且不再变化。集群启动过程，<em>DataNode会进行BR(BlockReport)，根据BR的每一个Block计算其HashCode，之后将对应的BlockInfo插入到相应位置逐渐构建起来巨大的BlocksMap</em>。前面在INodeFile里也提到的BlockInfo集合，如果我们将BlocksMap里的BlockInfo与所有INodeFile里的BlockInfo分别收集起来，可以发现两个集合完全相同，事实上BlocksMap里所有的BlockInfo就是INodeFile中对应BlockInfo的引用；通过Block查找对应BlockInfo时，也是先对Block计算HashCode，根据结果快速定位到对应的BlockInfo信息。</p>
<p>前面提到部分都属于静态数据部分，NameNode内存中所有数据都要随读写情况发生变化，BlockManager当然也需要管理这部分动态数据。主要是当Block发生变化不符合预期时需要及时调整Blocks的分布。这里涉及几个核心的数据结构：</p>
<ul>
<li>excessReplicateMap：若某个Block实际存储的副本数多于预设副本数，这时候需要删除多余副本，这里多余副本会被置于excessReplicateMap中。<em>excessReplicateMap是从DataNode的StorageID到Block集合的映射集</em>。 </li>
<li>neededReplications：若某个Block实际存储的副本数少于预设副本数，这时候需要补充缺少副本，这里哪些Block缺少多少个副本都统一存在neededReplications里，<em>本质上neededReplications是一个优先级队列</em>，缺少副本数越多的Block之后越会被优先处理。</li>
<li>invalidateBlocks：若某个Block即将被删除，会被置于invalidateBlocks中。invalidateBlocks是从DataNode的StorageID到Block集合的映射集。如某个文件被客户端执行了删除操作，该文件所属的所有Block会先被置于invalidateBlocks中。 </li>
<li>corruptReplicas：有些场景Block由于时间戳/长度不匹配等等造成Block不可用，会被暂存在corruptReplicas中，之后再做处理。</li>
</ul>
<blockquote>
<p>关于这几个数据结构在维持副本平衡中的更多内容，可以移步到<a href="http://bigdatadecode.club/HDFS维持副本平衡的流程.html">这篇blog</a></p>
</blockquote>
<p>前面几个涉及到Block分布情况动态变化的核心数据结构，<em>这里的数据实际上是过渡性质的</em>，BlocksManager内部的ReplicationMonitor线程(关于ReplicationMonitor的内容可以查看<a href="http://bigdatadecode.club/HDFS ReplicationMonitor副本监控线程解析.html">blog</a>会持续从其中取出数据并通过逻辑处理后分发给具体的<em>DatanodeDescriptor对应数据结构</em>，当对应DataNode的心跳过来之后，NameNode会遍历DatanodeDescriptor里暂存的数据，将其转换成对应指令返回给DataNode，DataNode收到任务并执行完成后再反馈回NameNode，之后DatanodeDescriptor里对应信息被清除。如BlockB预设副本数为3，由于某种原因实际副本变成4(如之前下线的DataNode D重新上线，其中B正好有BlockB的一个副本数据)，BlockManager能及时发现副本变化，并将多余的DataNode D上BlockB副本放置到excessReplicateMap中，ReplicationMonitor线程定期检查时发现excessReplicateMap中数据后将其移到DataNode D对应DatanodeDescriptor中invalidateBlocks里，当DataNode D下次心跳过来后，随心跳返回删除Block B的指令，DataNode D收到指令实际删除其上的Block B数据并反馈回NameNode，此后BlockManager将DataNode D上的Block B从内存中清除，至此Block B的副本符合预期，整个流程如下所示。<br><img src="/blogimgs/NameNode内存评估/blockreplica.png" alt="删除多余副本流程图" title="删除多余副本流程图"></p>
<h3 id="NetworkTopology"><a href="#NetworkTopology" class="headerlink" title="NetworkTopology"></a>NetworkTopology</h3><p>前面多次提到Block与DataNode之间的关联关系，事实上NameNode确实还需要管理所有DataNode，不仅如此，由于数据写入前需要确定数据块写入位置，NameNode还维护着整个机架拓扑NetworkTopology。下图所示内存中机架拓扑图。<br><img src="/blogimgs/NameNode内存评估/networktopology.png" alt="NetworkTopology内存结构" title="NetworkTopology内存结构"></p>
<p>从图中可以看出这里包含两个部分：<em>机架拓扑结构NetworkTopology和DataNode节点信息</em>。其中树状的机架拓扑是根据机架感知(一般都是外部脚本计算得到)在集群启动完成后建立起来，整个机架的拓扑结构在NameNode的生命周期内一般不会发生变化；另一部分是比较关键的DataNode信息，BlockManager已经提到每一个DataNode上的Blocks集合都会形成一个双向链表，更准确的应该是DataNode的每一个存储单元DatanodeStorageInfo上的所有Blocks集合会形成一个双向链表，这个链表的入口就是机架拓扑结构叶子节点即DataNode管理的DatanodeStorageInfo。此外由于上层应用对数据的增删查随时发生变化，随之DatanodeStorageInfo上的Blocks也会动态变化，所以NetworkTopology上的DataNode对象还会管理这些动态变化的数据结构，如replicateBlocks/recoverBlocks/invalidateBlocks，这些数据结构正好和BlockManager管理的动态数据结构对应，实现了数据的动态变化由BlockManager传达到DataNode内存对象最后通过指令下达到物理DataNode实际执行的流动过程。</p>
<p>这里存在一个问题，为什么DatanodeStorageInfo下所有Block之间会以双向链表组织，而不是其他数据结构？如果结合实际场景就不难发现，对每一个DatanodeStorageInfo下Block的操作集中在快速增加/删除(Block动态增减变化)及顺序遍历(BlockReport期间)，所以双向链表是非常合适的数据结构。</p>
<h3 id="LeaseManager"><a href="#LeaseManager" class="headerlink" title="LeaseManager"></a>LeaseManager</h3><p>这里只简单介绍下Lease机制，更多内容请查看blog<a href="http://bigdatadecode.club/HDFS租约解析.html">HDFS租约解析</a></p>
<p>Lease机制是重要的分布式协议，广泛应用于各种实际的分布式系统中。HDFS支持Write-Once-Read-Many，对文件写操作的互斥同步靠Lease实现。Lease实际上是时间约束锁，其主要特点是排他性。客户端写文件时需要先申请一个Lease，一旦有客户端持有了某个文件的Lease，其他客户端就不可能再申请到该文件的Lease，这就保证了同一时刻对一个文件的写操作只能发生在一个客户端。NameNode的LeaseManager是Lease机制的核心，维护了文件与Lease、客户端与Lease的对应关系，这类信息会随写数据的变化实时发生对应改变。<br><img src="/blogimgs/NameNode内存评估/leasemanager.png" alt="LeaseManager内存结构" title="LeaseManager内存结构"></p>
<p>从上图中可以看出LeaseManager内存结构中主要包括以下三个核心数据结构：</p>
<ul>
<li>sortedLeases：Lease集合，按照时间先后进行排序，便于检查Lease是否超时(hardLimit)；</li>
<li>leases：客户端到Lease的映射关系；(一对一，一个clent对应一个lease)</li>
<li>sortedLeasesByPath：文件路径到Lease的映射关系；(多对一，多个path对应一个lease)</li>
</ul>
<p>其中每一个写数据的客户端会对应一个Lease，每个Lease里包含至少一个标识文件路径的Path。Lease本身已经维护了其持有者(客户端)及该Lease正在操作的文件路径集合，之所以增加了leases和sortedLeasesByPath为提高通过Lease持有者或文件路径快速索引到Lease的性能。</p>
<p>由于Lease本身的时间约束特性，当Lease发生超时后需要强制回收，内存中与该Lease相关的内容要被及时清除。超时检查及超时后的处理逻辑由LeaseManager.Monitor统一执行。LeaseManager中维护了两个与Lease相关的超时时间：软超时(softLimit)和硬超时(hardLimit)，使用场景稍有不同。</p>
<p>正常情况下，<em>客户端向集群写文件前需要向NameNode的LeaseManager申请Lease；写文件过程中定期更新Lease时间，以防Lease过期，周期与softLimit相关</em>；写完数据后申请释放Lease。整个过程可能发生两类问题：<br>1、写文件过程中客户端没有及时更新Lease时间；<br>2、写完文件后没有成功释放Lease。<br>两个问题分别对应为softLimit和hardLimit。两种场景都会触发LeaseManager对Lease超时强制回收。如果客户端写文件过程中没有及时更新Lease超过softLimit时间后，另一客户端尝试对同一文件进行写操作时触发Lease软超时强制回收；如果客户端写文件完成但是没有成功释放Lease，则会由LeaseManager的后台线程LeaseManager.Monitor检查是否硬超时后统一触发超时回收。不管是softLimit还是hardLimit超时触发的强制Lease回收，处理逻辑都一样：FSNamesystem.internalReleaseLease，逻辑本身比较复杂，这里不再展开(详细内容可以查看<a href="http://bigdatadecode.club/HDFS租约解析.html">blog</a>)，简单的说先对Lease过期前最后一次写入的Block进行检查和修复，之后释放超时持有的Lease，保证后面其他客户端的写入能够正常申请到该文件的Lease。</p>
<p>NameNode内存数据结构非常丰富，这里对几个重要的数据结构进行了简单的描述，除了前面罗列之外，其实还有如SnapShotManager/CacheManager等，由于其内存占用有限且有一些特性还尚未稳定，这里不再展开</p>
<h2 id="NameNode内存大小评估"><a href="#NameNode内存大小评估" class="headerlink" title="NameNode内存大小评估"></a>NameNode内存大小评估</h2><p>NameNode的内存主要由NameSpace和BlocksMap占用，其中NameSpace存储的主要是INodeFile和INodeDirectory对象，BlocksMap存储的主要是BlockInfo对象。则估算NameNode占用的内存大小也就是估算集群中INodeFile、INodeDirectory和BlockInfo这些对象占用的heap空间。</p>
<blockquote>
<p>Java中常见数据结构占用的内存大小<br>下面先列举下java中常见数据结构占用的内存大小(64bit的jvm)<br>int = 4 bytes<br>long = 8 bytes<br>Reference size(引用) = 8 bytes<br>Object header size(对象头) = 16 bytes<br>Array header size(数组头) = 24 bytes<br>ArrayList header size(list头) = 24(数组头) + 4(属性size的大小) = 28 bytes<br>TreeMap.Entry = 64 bytes. (Entry的属性中有5个引用)<br>HashMap.Entry = 48 bytes. (Entry的属性有3个引用)<br>String header = 64 bytes.</p>
</blockquote>
<p>则对INodeFile、INodeDirectory和BlockInfo对象进行大小评估还有一点疑惑，看了几篇资料还是有点不清晰，这里就不展开了，有兴趣的可以看文章末尾的资料，随后搞清楚了会进行更新。</p>
<p>但参考了很多资料如<em>Hadoop权威指南</em>、<em>HADOOP-1687</em>等，INodeFile、INodeDirectory和BlockInfo对象大小在150~200bytes之间，可以使用150bytes对其内存进行评估，</p>
<p>例子：<br>NameNode文件和block信息如下：<br>94115032 files and directories, 91722740 blocks = 185837772 total filesystem object(s).</p>
<p>memSum = 185837772 * 150 bytes = 27875665800bytes = 25.9612368g &lt; 26g</p>
<p>使用jmap命令查看此时NameNode的内存<br>命令<code>jmap -histo:live pid &gt; mem</code>，输出内存大小为24619484976(22.9286821g，大约23g)</p>
<blockquote>
<p>小插曲<br>使用命令<code>jmap -heap pid</code>查看nn所占的内存时，发现nn占的内存比估算的26g要大很多，随后使用<code>histo</code>命令之后才发现和估算的差不多，原因可能是使用<code>heap</code>查看的nn占用的内存，其中可能包括一些无用的对象(在等待gc)，而使用<code>histo</code>查看的是nn中存活的对象，能够更好的展示评估的结果。</p>
</blockquote>
<p><em>如果是2亿的FileSystem object则内存空间大约为30g(200M * 150 = 30000M，约等30G)</em></p>
<p>本篇文章大部分内容是从网上整理所得，只有少部分是原创，所涉及的资料在参考一节。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://issues.apache.org/jira/browse/HADOOP-1687" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/HADOOP-1687</a><br><a href="http://hexiaoqiao.github.io/blog/2016/07/06/namenode-memory-overview" target="_blank" rel="noopener">http://hexiaoqiao.github.io/blog/2016/07/06/namenode-memory-overview</a><br><a href="http://hexiaoqiao.github.io/blog/2016/07/21/namenode-memory-detail/" target="_blank" rel="noopener">http://hexiaoqiao.github.io/blog/2016/07/21/namenode-memory-detail/</a></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> Memory </tag>
            
            <tag> Size </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之Fair Scheduler part2]]></title>
      <url>http://bigdatadecode.club/YARN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BFair%20Scheduler%20part2.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/YARN源码分析之Fair Scheduler part1.html">上篇</a>介绍了Fair Scheduler中FairShare和SteadyFairShare的计算方法，本篇主要介绍其抢占相关的知识。</p>
<p>抢占在YARN中经常发生，但其在什么时候发生，抢占谁的资源，又将抢占后的资源分配给谁，这篇文章就尝试着去解释这些问题。</p>
<p>本篇主要将在Fair Scheduler调度中发生的抢占。先介绍几个相关配置。</p>
<a id="more"></a>
<h2 id="与抢占相关的配置"><a href="#与抢占相关的配置" class="headerlink" title="与抢占相关的配置"></a>与抢占相关的配置</h2><h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><blockquote>
<p>yarn.scheduler.fair.preemption</p>
</blockquote>
<p>Fair调度时是否开启抢占功能。默认为false</p>
<blockquote>
<p>yarn.scheduler.fair.preemption.cluster-utilization-threshold    </p>
</blockquote>
<p>集群中使用的资源超过此阈值时，才发生抢占。默认是0.8f</p>
<p>还有几个配置貌似没有开放设置，</p>
<ul>
<li><p><code>yarn.scheduler.fair.waitTimeBeforeKill</code>，默认是15000ms。等待时间超过此值时，将抢占队列中的containerkill掉。</p>
</li>
<li><p><code>yarn.scheduler.fair.preemptionInterval</code>，默认是5000ms，两次抢占检查的时间间隔</p>
</li>
</ul>
<h3 id="fair-scheduler-xml"><a href="#fair-scheduler-xml" class="headerlink" title="fair-scheduler.xml"></a>fair-scheduler.xml</h3><p>在fair-scheduler.xml中可以单独对某个队列设置抢占时间和阈值，也可以设置一个全局的抢占时间和阈值。<br>对队列单独设置是在queue中设置，参数如下：</p>
<blockquote>
<p>fairSharePreemptionTimeout</p>
</blockquote>
<p>队列所分配的资源小于<code>fairShare*fairSharePreemptionThreshold</code>的时间超过了这个阈值，此队列将从别的队列中抢占资源。如果不设置，此队列该属性的值将继承父队列的设置。</p>
<blockquote>
<p>fairSharePreemptionThreshold</p>
</blockquote>
<p>the fair share preemption threshold for the queue.<br>如果队列等待了fairSharePreemptionTimeout时间，队列中的资源依然少于<code>fairSharePreemptionThreshold*fairShare</code>，则从别的队列中抢占。如果不设置，此队列该属性的值将继承父队列的设置。</p>
<p>全局抢占属性设置的参数如下：</p>
<blockquote>
<p>defaultFairSharePreemptionTimeout</p>
</blockquote>
<p>设置root队列发生fairShare抢占的时间阈值，被fairSharePreemptionTimeout重写</p>
<blockquote>
<p>defaultMinSharePreemptionTimeout </p>
</blockquote>
<p>设置root队列发生minShare抢占的时间阈值，被minSharePreemptionTimeout重写</p>
<blockquote>
<p>defaultFairSharePreemptionThreshold</p>
</blockquote>
<p>设置root队列发生fairShare抢占资源的阈值，被fairSharePreemptionThreshold重写。也就是说某个队列的资源低于fairSharePreemptionThreshold阈值的时间超过FairSharePreemptionTimeout时，则发生抢占。</p>
<h2 id="测试代码"><a href="#测试代码" class="headerlink" title="测试代码"></a>测试代码</h2><p>先看代码吧，代码有点长，按照程序流程一个方法一个方法解析吧，最后再把整个代码贴上备用。</p>
<p>yarn在启动时需要加载配置文件，也就是configuration，那么我们的第一步也就是初始化发fair Scheduler发生抢占的环境。相关的环境配置是在<code>createConfiguration</code>中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Configuration <span class="title">createConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Configuration conf = <span class="keyword">super</span>.createConfiguration();</span><br><span class="line">  conf.setClass(YarnConfiguration.RM_SCHEDULER, FairScheduler.class,</span><br><span class="line">      ResourceScheduler.class);</span><br><span class="line">  <span class="comment">// 开启抢占开关  yarn.scheduler.fair.preemption</span></span><br><span class="line">  conf.setBoolean(FairSchedulerConfiguration.PREEMPTION, <span class="keyword">true</span>);</span><br><span class="line">  <span class="comment">// fair配置所在路径</span></span><br><span class="line">  conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);</span><br><span class="line">  <span class="keyword">return</span> conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>fair调度中默认抢占功能是关闭的，要想让fair调度使用抢占功能需要更改配置<code>yarn.scheduler.fair.preemption</code>，除此之外还有一个参数来控制<code>yarn.scheduler.fair.preemption.cluster-utilization-threshold</code>，<em>该参数控制着集群的资源使用率达到多少之后可以发生抢占行为</em>。该参数在<code>createConfiguration</code>中没有设置，而是在随后的<code>startResourceManager</code>方法中设置的。下面就来看下<code>startResourceManager</code>方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startResourceManager</span><span class="params">(<span class="keyword">float</span> utilizationThreshold)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// yarn.scheduler.fair.preemption.cluster-utilization-threshold</span></span><br><span class="line">  <span class="comment">// 设置集群资源发生抢占的阈值</span></span><br><span class="line">  conf.setFloat(FairSchedulerConfiguration.PREEMPTION_THRESHOLD,</span><br><span class="line">      utilizationThreshold);</span><br><span class="line">  <span class="comment">// 虚拟RM，只是为了方便测试</span></span><br><span class="line">  resourceManager = <span class="keyword">new</span> MockRM(conf);</span><br><span class="line">  resourceManager.start();</span><br><span class="line"></span><br><span class="line">  scheduler = (FairScheduler)resourceManager.getResourceScheduler();</span><br><span class="line"></span><br><span class="line">  scheduler.setClock(clock);</span><br><span class="line">  scheduler.updateInterval = <span class="number">60</span> * <span class="number">1000</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>startResourceManager传进去个参数，该参数赋值给<code>yarn.scheduler.fair.preemption.cluster-utilization-threshold</code>用来控制集群发生抢占的时机。</p>
<p>fair调度则需要启动一个RM用来进行资源管理，这里new一个<code>MockRM</code>，MockRM是一个虚拟的RM，只是为了方便测试，Hadoop中有很多类似的类，极大的方便了代码的测试。</p>
<p>启动RM之后就是想RM注册NM，即为集群添加资源，然后app申请资源，请看代码<code>registerNodeAndSubmitApp</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> ApplicationAttemptId <span class="title">registerNodeAndSubmitApp</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> memory, <span class="keyword">int</span> vcores, <span class="keyword">int</span> appContainers, <span class="keyword">int</span> appMemory)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// new出一个名为node1的nm，资源为memory vcores</span></span><br><span class="line">  RMNode node1 = MockNodes.newNodeInfo(</span><br><span class="line">      <span class="number">1</span>, Resources.createResource(memory, vcores), <span class="number">1</span>, <span class="string">"node1"</span>);</span><br><span class="line">  NodeAddedSchedulerEvent nodeEvent1 = <span class="keyword">new</span> NodeAddedSchedulerEvent(node1);</span><br><span class="line">  scheduler.handle(nodeEvent1);</span><br><span class="line">  System.out.println(<span class="string">"resources in the cluster : "</span> + scheduler.rootMetrics.getAvailableMB());</span><br><span class="line">  <span class="comment">// 提交一个app，所需资源为 appContainers * appMemory</span></span><br><span class="line">  ApplicationAttemptId app1 = createSchedulingRequest(appMemory, <span class="string">"queueA"</span>, <span class="string">"user1"</span>, appContainers);</span><br><span class="line">  scheduler.update();</span><br><span class="line">  <span class="comment">// Sufficient node check-ins to fully schedule containers</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; appContainers; i++) &#123;</span><br><span class="line">    NodeUpdateSchedulerEvent nodeUpdate1 = <span class="keyword">new</span> NodeUpdateSchedulerEvent(node1);</span><br><span class="line">    scheduler.handle(nodeUpdate1);</span><br><span class="line">  &#125;</span><br><span class="line">  FSLeafQueue queue = scheduler.getQueueManager().getLeafQueue(</span><br><span class="line">          <span class="string">"queueA"</span>, <span class="keyword">false</span>);</span><br><span class="line">  <span class="comment">// 打印queueA队列相关的参数，计算方式可以参考上一篇blog</span></span><br><span class="line">  System.out.println( <span class="string">"queueA : "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">          <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">          <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">          <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">          <span class="string">", running : "</span> + queue.getResourceUsage() +</span><br><span class="line">          <span class="string">", preempt : "</span> + queue.preemptContainer());</span><br><span class="line">  System.out.println(<span class="string">"rest resources of cluster : "</span> +</span><br><span class="line">          (memory - appContainers * appMemory) + <span class="string">" , "</span> +</span><br><span class="line">      scheduler.rootMetrics.getAvailableMB());</span><br><span class="line">  <span class="keyword">return</span> app1;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面看下主代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testPreemptionWithFreeResources</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  PrintWriter out = <span class="keyword">new</span> PrintWriter(<span class="keyword">new</span> FileWriter(ALLOC_FILE));</span><br><span class="line">  <span class="comment">// 将fair-scheduler.xml配置写入文件</span></span><br><span class="line">  out.println(<span class="string">"&lt;?xml version=\"1.0\"?&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;allocations&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;queue name=\"default\"&gt;"</span>);</span><br><span class="line">  <span class="comment">// maxResources 为0，则default得到fixed队列，</span></span><br><span class="line">  <span class="comment">// 不列入计算SteadyFairShare和FairShare的集合中</span></span><br><span class="line">  out.println(<span class="string">"&lt;maxResources&gt;0mb,0vcores&lt;/maxResources&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;queue name=\"queueA\"&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;weight&gt;1&lt;/weight&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;minResources&gt;1024mb,0vcores&lt;/minResources&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;queue name=\"queueB\"&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;weight&gt;1&lt;/weight&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;minResources&gt;1024mb,0vcores&lt;/minResources&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;defaultMinSharePreemptionTimeout&gt;5&lt;/defaultMinSharePreemptionTimeout&gt;"</span>);</span><br><span class="line">  <span class="comment">// if fairSharePreemptionTimeout and defaultFairSharePreemptionTimeout both exist,</span></span><br><span class="line">  <span class="comment">// we take the default one</span></span><br><span class="line">  out.println(<span class="string">"&lt;fairSharePreemptionTimeout&gt;10&lt;/fairSharePreemptionTimeout&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;/allocations&gt;"</span>);</span><br><span class="line">  out.close();</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 参数0f表示集群资源的使用量超过此值时发生抢占</span></span><br><span class="line">  startResourceManager(<span class="number">0f</span>);</span><br><span class="line">  <span class="comment">// Create node with 4GB memory and 4 vcores</span></span><br><span class="line">  <span class="comment">// app1申请4个container，每个container占1024MB，则占满集群资源</span></span><br><span class="line">  ApplicationAttemptId app1 = registerNodeAndSubmitApp(<span class="number">4</span> * <span class="number">1024</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// app2 提交到queueB，抢占开发已打开并且集群资源占用比例超过0则可以发生抢占</span></span><br><span class="line">  ApplicationAttemptId app2 = createSchedulingRequest(<span class="number">1024</span>, <span class="string">"queueB"</span>, <span class="string">"user1"</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">  scheduler.update();</span><br><span class="line">  <span class="comment">// 停顿6秒，使其超过defaultMinSharePreemptionTimeout，queueB没有满足minShare则抢占</span></span><br><span class="line">  clock.tick(<span class="number">6</span>);</span><br><span class="line">  <span class="comment">// 抢占前queueA的状态</span></span><br><span class="line">  FSLeafQueue queue = scheduler.getQueueManager().getLeafQueue(</span><br><span class="line">          <span class="string">"queueA"</span>, <span class="keyword">false</span>);</span><br><span class="line">  System.out.println( <span class="string">"queueA : "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">          <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">          <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">          <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">          <span class="string">", running : "</span> + queue.getResourceUsage() +</span><br><span class="line">          <span class="string">", preempt : "</span> + queue.preemptContainer());</span><br><span class="line">  <span class="comment">// 检查是否抢占</span></span><br><span class="line">  <span class="comment">// 此次只是将要抢占的container放入warnedContainers list中</span></span><br><span class="line">  scheduler.preemptTasksIfNecessary();</span><br><span class="line">  <span class="comment">// 打印要抢占多少资源</span></span><br><span class="line">  System.out.println(<span class="string">"preemptResources() should have been called "</span> + <span class="number">1024</span> + <span class="string">" , "</span> +</span><br><span class="line">          scheduler.getSchedulerApp(app1).getPreemptionContainers().iterator().next().getContainer().getResource());</span><br><span class="line">  System.out.println(<span class="string">"===================================================================="</span>);</span><br><span class="line">  <span class="comment">// 停顿超过15s，将container杀掉，释放资源</span></span><br><span class="line">  clock.tick(<span class="number">18</span>);</span><br><span class="line">  <span class="comment">// 将container杀掉，释放资源</span></span><br><span class="line">  scheduler.preemptTasksIfNecessary();</span><br><span class="line">  System.out.println(<span class="string">"preemptResources() should have been called "</span> + <span class="number">1024</span> + <span class="string">" , "</span> +</span><br><span class="line">          scheduler.getSchedulerApp(app1).getPreemptionContainers());</span><br><span class="line">  System.out.println( <span class="string">"queueA : "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">          <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">          <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">          <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">          <span class="string">", running : "</span> + queue.getResourceUsage() +</span><br><span class="line">          <span class="string">", preempt : "</span> + queue.preemptContainer());</span><br><span class="line"></span><br><span class="line">  resourceManager.stop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整个测试抢占的流程就结束了。大致思路是，<em>startResourceManager时设置集群可以发生抢占的时机(例子设置的阈值是0)，然后向集群注册了一个4g的node1，又想集群queueA提交了app1(4个container，一个container占1024MB)，app1占满整个集群资源，此时app2(1个container，1024MB)提交给queueB，模拟等待6s(defaultMinSharePreemptionTimeout是5s，queueB此时不满足minShare，需要抢占)，调用preemptTasksIfNecessary查看是否要抢占(查看是否要抢占在真实环境中其实是一个线程不断的在check)，最后再等待18s(yarn.scheduler.fair.waitTimeBeforeKill设置的是15s，超过此值才会将containerkill掉释放资源)，然后查看queueA队列被抢占前后状态的变化。</em></p>
<p>上面代码运行结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">resources <span class="keyword">in</span> the cluster : 4096</span><br><span class="line">queueA : 4096, weight : 1.0, steadyShare : &lt;memory:2048, vCores:0&gt;, demand : &lt;memory:4096, vCores:4&gt;, running : &lt;memory:4096, vCores:4&gt;, preempt : null</span><br><span class="line">rest resources of cluster : 0</span><br><span class="line">queueA : 2048, weight : 1.0, steadyShare : &lt;memory:2048, vCores:0&gt;, demand : &lt;memory:4096, vCores:4&gt;, running : &lt;memory:4096, vCores:4&gt;, preempt : container_0_0001_01_000004</span><br><span class="line">preemptResources() should have been called 1024 , &lt;memory:1024, vCores:1&gt;</span><br><span class="line">====================================================================</span><br><span class="line">preemptResources() should have been called 1024 , []</span><br><span class="line">queueA : 2048, weight : 1.0, steadyShare : &lt;memory:2048, vCores:0&gt;, demand : &lt;memory:4096, vCores:4&gt;, running : &lt;memory:3072, vCores:3&gt;, preempt : container_0_0001_01_000003</span><br></pre></td></tr></table></figure>
<p>从运行结果中可以看出初期集群被queueA中的app1全占，然后queueB中的app2提交，而queueB的资源在5s之后仍然低于minShare(1024)，则发生抢占，从queueA中抢占1024满足minShare，等待时间超过15s之后，依然没有资源被释放则kill掉container_0_0001_01_000004，queueA中running的资源变为3072，说明抢占成功。</p>
<h2 id="抢占进阶"><a href="#抢占进阶" class="headerlink" title="抢占进阶"></a>抢占进阶</h2><p>上一节说到了queueB从queueA抢占1024MB，那么假如集群中有多个队列，那么应该怎样选择从哪个队列抢占，又应该抢占多少呢？带着这个问题再去看下代码。</p>
<p>与抢占相关的代码是<code>scheduler.preemptTasksIfNecessary()</code>，那么就先看下这个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">preemptTasksIfNecessary</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 校验当前集群是否能发生抢占</span></span><br><span class="line">  <span class="keyword">if</span> (!shouldAttemptPreemption()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">long</span> curTime = getClock().getTime();</span><br><span class="line">  <span class="comment">// 时间间隔是否超过 yarn.scheduler.fair.preemptionInterval</span></span><br><span class="line">  <span class="keyword">if</span> (curTime - lastPreemptCheckTime &lt; preemptionInterval) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  lastPreemptCheckTime = curTime;</span><br><span class="line"></span><br><span class="line">  Resource resToPreempt = Resources.clone(Resources.none());</span><br><span class="line">  <span class="keyword">for</span> (FSLeafQueue sched : queueMgr.getLeafQueues()) &#123;</span><br><span class="line">  	<span class="comment">// 遍历所有队列，计算哪些队列需要抢占资源，抢占多少</span></span><br><span class="line">    Resources.addTo(resToPreempt, resToPreempt(sched, curTime));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (Resources.greaterThan(RESOURCE_CALCULATOR, clusterResource, resToPreempt,</span><br><span class="line">      Resources.none())) &#123;</span><br><span class="line">    <span class="comment">// 选择从哪个队列中抢</span></span><br><span class="line">    preemptResources(resToPreempt);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>preemptTasksIfNecessary用来检查哪些队列需要进行tasks的抢占，计算共有多少个task需要被抢占，并从中选择。</p>
<p>判断队列是否要进行抢占的条件是<em>当队列的资源低于minShare的时间超过minSharePreemptionTimeout或者低于fairShare的时间超过fairSharePreemptionTimeout时就认为该队列需要去抢占别的队列的资源</em>。</p>
<p>在检查队列是否需要抢占时，得先校验下大环境是否允许抢占发生，这个是在<code>shouldAttemptPreemption</code>中校验的，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldAttemptPreemption</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// yarn.scheduler.fair.preemption 为true时，</span></span><br><span class="line">  <span class="comment">// 再判断是否超过 yarn.scheduler.fair.preemption.cluster-utilization-threshold</span></span><br><span class="line">  <span class="comment">// 超过才可以发生抢占</span></span><br><span class="line">  <span class="keyword">if</span> (preemptionEnabled) &#123;</span><br><span class="line">    <span class="keyword">return</span> (preemptionUtilizationThreshold &lt; Math.max(</span><br><span class="line">        (<span class="keyword">float</span>) rootMetrics.getAllocatedMB() / clusterResource.getMemory(),</span><br><span class="line">        (<span class="keyword">float</span>) rootMetrics.getAllocatedVirtualCores() /</span><br><span class="line">            clusterResource.getVirtualCores()));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>只有在集群允许发生抢占的前提下才有可能发生抢占，而判断<em>集群是否允许发生抢占的条件是yarn.scheduler.fair.preemption为true，并且集群资源的使用率超过了yarn.scheduler.fair.preemption.cluster-utilization-threshold</em></p>
<p>当集群允许发生抢占时，遍历所有的队列，找出需要抢占的队列并计算出需要抢占多少资源。这部分代码逻辑在<code>resToPreempt</code>中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Resource <span class="title">resToPreempt</span><span class="params">(FSLeafQueue sched, <span class="keyword">long</span> curTime)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> minShareTimeout = sched.getMinSharePreemptionTimeout();</span><br><span class="line">  <span class="keyword">long</span> fairShareTimeout = sched.getFairSharePreemptionTimeout();</span><br><span class="line">  Resource resDueToMinShare = Resources.none();</span><br><span class="line">  Resource resDueToFairShare = Resources.none();</span><br><span class="line">  <span class="comment">// 是否超过了minSharePreemptionTimeout</span></span><br><span class="line">  <span class="keyword">if</span> (curTime - sched.getLastTimeAtMinShare() &gt; minShareTimeout) &#123;</span><br><span class="line">    Resource target = Resources.min(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">        sched.getMinShare(), sched.getDemand());</span><br><span class="line">    resDueToMinShare = Resources.max(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">        Resources.none(), Resources.subtract(target, sched.getResourceUsage()));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 是否超过了fairSharePreemptionTimeout</span></span><br><span class="line">  <span class="keyword">if</span> (curTime - sched.getLastTimeAtFairShareThreshold() &gt; fairShareTimeout) &#123;</span><br><span class="line">    Resource target = Resources.min(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">        sched.getFairShare(), sched.getDemand());</span><br><span class="line">    resDueToFairShare = Resources.max(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">        Resources.none(), Resources.subtract(target, sched.getResourceUsage()));</span><br><span class="line">  &#125;</span><br><span class="line">  Resource resToPreempt = Resources.max(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">      resDueToMinShare, resDueToFairShare);</span><br><span class="line">  <span class="keyword">if</span> (Resources.greaterThan(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">      resToPreempt, Resources.none())) &#123;</span><br><span class="line">    String message = <span class="string">"Should preempt "</span> + resToPreempt + <span class="string">" res for queue "</span></span><br><span class="line">        + sched.getName() + <span class="string">": resDueToMinShare = "</span> + resDueToMinShare</span><br><span class="line">        + <span class="string">", resDueToFairShare = "</span> + resDueToFairShare;</span><br><span class="line">    LOG.info(message);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> resToPreempt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>resToPreempt计算当前队列需要抢占多少资源，计算规则为：<br>假设队列所需的资源大于minShare和fairShare</p>
<ul>
<li>如果此队列的资源低于minShare的时间超过minSharePreemptionTimeout，则应该抢占minShare和正在使用资源的差值。</li>
<li>如果此队列的资源低于fairShare的时间超过fairSharePreemptionTimeout，则应该抢占fairShare和正在使用资源的差值。</li>
<li>如果上述两个条件都满足，则抢占两者较大的数。</li>
</ul>
<p>resToPreempt决定了该队列是否应该去抢占，应该抢多少，那么从哪抢占是在哪决定的？答案是<code>preemptResources</code>，看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">preemptResources</span><span class="params">(Resource toPreempt)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> start = getClock().getTime();</span><br><span class="line">  <span class="keyword">if</span> (Resources.equals(toPreempt, Resources.none())) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Scan down the list of containers we've already warned and kill them</span></span><br><span class="line">  <span class="comment">// if we need to.  Remove any containers from the list that we don't need</span></span><br><span class="line">  <span class="comment">// or that are no longer running.</span></span><br><span class="line">  Iterator&lt;RMContainer&gt; warnedIter = warnedContainers.iterator();</span><br><span class="line">  <span class="keyword">while</span> (warnedIter.hasNext()) &#123;</span><br><span class="line">    RMContainer container = warnedIter.next();</span><br><span class="line">    <span class="keyword">if</span> ((container.getState() == RMContainerState.RUNNING ||</span><br><span class="line">            container.getState() == RMContainerState.ALLOCATED) &amp;&amp;</span><br><span class="line">        Resources.greaterThan(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">            toPreempt, Resources.none())) &#123;</span><br><span class="line">      warnOrKillContainer(container);</span><br><span class="line">      Resources.subtractFrom(toPreempt, container.getContainer().getResource());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      warnedIter.remove();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// Reset preemptedResource for each app</span></span><br><span class="line">    <span class="keyword">for</span> (FSLeafQueue queue : getQueueManager().getLeafQueues()) &#123;</span><br><span class="line">      <span class="keyword">for</span> (FSAppAttempt app : queue.getRunnableAppSchedulables()) &#123;</span><br><span class="line">        app.resetPreemptedResources();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (Resources.greaterThan(RESOURCE_CALCULATOR, clusterResource,</span><br><span class="line">        toPreempt, Resources.none())) &#123;</span><br><span class="line">      <span class="comment">// preemptContainer 决定从哪个队列中抢资源</span></span><br><span class="line">      RMContainer container =</span><br><span class="line">          getQueueManager().getRootQueue().preemptContainer();</span><br><span class="line">      <span class="keyword">if</span> (container == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        warnOrKillContainer(container);</span><br><span class="line">        warnedContainers.add(container);</span><br><span class="line">        Resources.subtractFrom(</span><br><span class="line">            toPreempt, container.getContainer().getResource());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="comment">// Clear preemptedResources for each app</span></span><br><span class="line">    <span class="keyword">for</span> (FSLeafQueue queue : getQueueManager().getLeafQueues()) &#123;</span><br><span class="line">      <span class="keyword">for</span> (FSAppAttempt app : queue.getRunnableAppSchedulables()) &#123;</span><br><span class="line">        app.clearPreemptedResources();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">long</span> duration = getClock().getTime() - start;</span><br><span class="line">  fsOpDurations.addPreemptCallDuration(duration);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>资源的抢占是通过挑选队列，然后在队列中选app，最后在此app上选一个container上，队列的选取是从root队列开始，然后一层一层的选取，直到一个候选Application。</p>
<p>抢占策略根据不同的调度策略而不同：<br>(1) fair/drf  选择超过fairShare最多的队列<br>(2) fifo 选择最近提交的app的队列<br>在app中选择container是根据container的优先级，抢占优先级最低的container，container的优先级是由数字标识的，数字越大优先级越低。</p>
<p>这个挑选流程的入口函数是<code>getQueueManager().getRootQueue().preemptContainer()</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSParentQueue.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RMContainer <span class="title">preemptContainer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  RMContainer toBePreempted = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Find the childQueue which is most over fair share</span></span><br><span class="line">  FSQueue candidateQueue = <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// 根据调度策略选择比较器</span></span><br><span class="line">  Comparator&lt;Schedulable&gt; comparator = policy.getComparator();</span><br><span class="line">  <span class="comment">// 找到超过fairShaer最多的队列</span></span><br><span class="line">  <span class="keyword">for</span> (FSQueue queue : childQueues) &#123;</span><br><span class="line">    <span class="keyword">if</span> (candidateQueue == <span class="keyword">null</span> ||</span><br><span class="line">        comparator.compare(queue, candidateQueue) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      candidateQueue = queue;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Let the selected queue choose which of its container to preempt</span></span><br><span class="line">  <span class="keyword">if</span> (candidateQueue != <span class="keyword">null</span>) &#123;</span><br><span class="line">  	<span class="comment">// 如果候选队列依然是父队列，则继续调用FSParentQueue.preemptContainer，形成递归</span></span><br><span class="line">  	<span class="comment">// 如果候选队列是叶子队列，则从队列中找到合适的app进行抢占</span></span><br><span class="line">    toBePreempted = candidateQueue.preemptContainer();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> toBePreempted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>FSParentQueue.preemptContainer从root队列选择超过fairShare最多的一个队列作为候选队列，如果此候选队列依然是父队列则继续调用FSParentQueue.preemptContainer形成递归，如果是叶子队列则调用FSLeafQueue.preemptContainer，从队列中选择一个app。</strong></p>
<p>选择队列和app时涉及到一个比较器，这个比较器根据不同的策略实现不一样，这里主要介绍下<code>FairShareComparator</code>，FairShareComparator是FairSharePolicy.java的内部类，实现了Comparator接口，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FairShareComparator</span> <span class="keyword">implements</span> <span class="title">Comparator</span>&lt;<span class="title">Schedulable</span>&gt;,</span></span><br><span class="line"><span class="class">    <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">5564969375856699313L</span>;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Resource ONE = Resources.createResource(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Schedulable s1, Schedulable s2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> minShareRatio1, minShareRatio2;</span><br><span class="line">    <span class="keyword">double</span> useToWeightRatio1, useToWeightRatio2;</span><br><span class="line">    Resource minShare1 = Resources.min(RESOURCE_CALCULATOR, <span class="keyword">null</span>,</span><br><span class="line">        s1.getMinShare(), s1.getDemand());</span><br><span class="line">    Resource minShare2 = Resources.min(RESOURCE_CALCULATOR, <span class="keyword">null</span>,</span><br><span class="line">        s2.getMinShare(), s2.getDemand());</span><br><span class="line">    <span class="keyword">boolean</span> s1Needy = Resources.lessThan(RESOURCE_CALCULATOR, <span class="keyword">null</span>,</span><br><span class="line">        s1.getResourceUsage(), minShare1);</span><br><span class="line">    <span class="keyword">boolean</span> s2Needy = Resources.lessThan(RESOURCE_CALCULATOR, <span class="keyword">null</span>,</span><br><span class="line">        s2.getResourceUsage(), minShare2);</span><br><span class="line">    minShareRatio1 = (<span class="keyword">double</span>) s1.getResourceUsage().getMemory()</span><br><span class="line">        / Resources.max(RESOURCE_CALCULATOR, <span class="keyword">null</span>, minShare1, ONE).getMemory();</span><br><span class="line">    minShareRatio2 = (<span class="keyword">double</span>) s2.getResourceUsage().getMemory()</span><br><span class="line">        / Resources.max(RESOURCE_CALCULATOR, <span class="keyword">null</span>, minShare2, ONE).getMemory();</span><br><span class="line">    useToWeightRatio1 = s1.getResourceUsage().getMemory() /</span><br><span class="line">        s1.getWeights().getWeight(ResourceType.MEMORY);</span><br><span class="line">    useToWeightRatio2 = s2.getResourceUsage().getMemory() /</span><br><span class="line">        s2.getWeights().getWeight(ResourceType.MEMORY);</span><br><span class="line">    <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (s1Needy &amp;&amp; !s2Needy)</span><br><span class="line">      res = -<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (s2Needy &amp;&amp; !s1Needy)</span><br><span class="line">      res = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (s1Needy &amp;&amp; s2Needy)</span><br><span class="line">      res = (<span class="keyword">int</span>) Math.signum(minShareRatio1 - minShareRatio2);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">      <span class="comment">// Neither schedulable is needy</span></span><br><span class="line">      res = (<span class="keyword">int</span>) Math.signum(useToWeightRatio1 - useToWeightRatio2);</span><br><span class="line">    <span class="keyword">if</span> (res == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// Apps are tied in fairness ratio. Break the tie by submit time and job</span></span><br><span class="line">      <span class="comment">// name to get a deterministic ordering, which is useful for unit tests.</span></span><br><span class="line">      res = (<span class="keyword">int</span>) Math.signum(s1.getStartTime() - s2.getStartTime());</span><br><span class="line">      <span class="keyword">if</span> (res == <span class="number">0</span>)</span><br><span class="line">        res = s1.getName().compareTo(s2.getName());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> res;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该比较器传入两个队列A、B，如果A大于B，则返回1，小于返回-1，等于则返回0。</p>
<p><strong>队列比较时分两种情况，</strong>一种是所用资源低于minShare，另一种情况是高于minShare。<br>(1) 低于minShare时，</p>
<ul>
<li>两个队列都低于minShare时，则比较<em>两个队列挂起的任务数与总任务数的比例</em>，比例值越低则越应该先得到资源。则比较器认为比例大的队列较大。</li>
<li>只有一个队列低于minShare时，则超过minShare的那个队列较大，因为低于minShare的队列得到资源的优先级高于已经超过minShare队列的优先级。</li>
</ul>
<p>(2) 高于minShare时，</p>
<ul>
<li>高于minShare则计算队列所使用的资源与weight的比例，比例大的队列大。</li>
</ul>
<p>接下来看下<code>FSLeafQueue.preemptContainer</code>，看下app是怎么从队列中选中的，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// FSLeafQueue.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> RMContainer <span class="title">preemptContainer</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  RMContainer toBePreempted = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If this queue is not over its fair share, reject</span></span><br><span class="line">  <span class="keyword">if</span> (!preemptContainerPreCheck()) &#123;</span><br><span class="line">    <span class="keyword">return</span> toBePreempted;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">    LOG.debug(<span class="string">"Queue "</span> + getName() + <span class="string">" is going to preempt a container "</span> +</span><br><span class="line">        <span class="string">"from its applications."</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Choose the app that is most over fair share</span></span><br><span class="line">  <span class="comment">// 此处的比较器依然是上面介绍的比较器</span></span><br><span class="line">  Comparator&lt;Schedulable&gt; comparator = policy.getComparator();</span><br><span class="line">  FSAppAttempt candidateSched = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">for</span> (FSAppAttempt sched : runnableApps) &#123;</span><br><span class="line">    <span class="keyword">if</span> (candidateSched == <span class="keyword">null</span> ||</span><br><span class="line">        comparator.compare(sched, candidateSched) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      candidateSched = sched;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Preempt from the selected app</span></span><br><span class="line">  <span class="keyword">if</span> (candidateSched != <span class="keyword">null</span>) &#123;</span><br><span class="line">  	<span class="comment">// 从app中选择一个container，container的选取是按照优先级</span></span><br><span class="line">  	<span class="comment">// 优先级一样则比较containerId</span></span><br><span class="line">    toBePreempted = candidateSched.preemptContainer();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> toBePreempted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过上面的步骤将container从app中选出之后，调用<code>warnOrKillContainer</code>，判断是将container放入<code>preemptionMap</code>(这里记录了可以被抢占的container和放入的时间)还是直接kill掉(当超过yarn.scheduler.fair.waitTimeBeforeKill时，则kill掉container释放资源)。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">warnOrKillContainer</span><span class="params">(RMContainer container)</span> </span>&#123;</span><br><span class="line">  ApplicationAttemptId appAttemptId = container.getApplicationAttemptId();</span><br><span class="line">  FSAppAttempt app = getSchedulerApp(appAttemptId);</span><br><span class="line">  FSLeafQueue queue = app.getQueue();</span><br><span class="line">  LOG.info(<span class="string">"Preempting container (prio="</span> + container.getContainer().getPriority() +</span><br><span class="line">      <span class="string">"res="</span> + container.getContainer().getResource() +</span><br><span class="line">      <span class="string">") from queue "</span> + queue.getName());</span><br><span class="line">  </span><br><span class="line">  Long time = app.getContainerPreemptionTime(container);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (time != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// if we asked for preemption more than maxWaitTimeBeforeKill ms ago,</span></span><br><span class="line">    <span class="comment">// proceed with kill</span></span><br><span class="line">    <span class="keyword">if</span> (time + waitTimeBeforeKill &lt; getClock().getTime()) &#123;</span><br><span class="line">      ContainerStatus status =</span><br><span class="line">        SchedulerUtils.createPreemptedContainerStatus(</span><br><span class="line">          container.getContainerId(), SchedulerUtils.PREEMPTED_CONTAINER);</span><br><span class="line"></span><br><span class="line">      recoverResourceRequestForContainer(container);</span><br><span class="line">      <span class="comment">// <span class="doctag">TODO:</span> Not sure if this ever actually adds this to the list of cleanup</span></span><br><span class="line">      <span class="comment">// containers on the RMNode (see SchedulerNode.releaseContainer()).</span></span><br><span class="line">      completedContainer(container, status, RMContainerEventType.KILL);</span><br><span class="line">      LOG.info(<span class="string">"Killing container"</span> + container +</span><br><span class="line">          <span class="string">" (after waiting for premption for "</span> +</span><br><span class="line">          (getClock().getTime() - time) + <span class="string">"ms)"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// track the request in the FSAppAttempt itself</span></span><br><span class="line">    <span class="comment">// 每个app都记录自己可以被抢占的container</span></span><br><span class="line">    app.addPreemption(container, getClock().getTime());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当warnOrKillContainer将container杀掉之后，队列就可以抢到资源了，整个抢占过程也就结束了。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在fair环境下抢占时，先看大环境是否可以发生抢占，</p>
<blockquote>
<p>判断是否发生抢占的条件是<br>yarn.scheduler.fair.preemption为true，并且集群资源的使用率超过了yarn.scheduler.fair.preemption.cluster-utilization-threshold</p>
</blockquote>
<blockquote>
<p>可以发生抢占时，则要判断需要抢占多少资源。抢占多少资源则是将所有的队列都遍历一遍，对每个队列需要抢占的资源进行汇总。在<em>FairScheduler.resToPreempt</em>方法中。<br>每个队列要抢占多少资源的计算规则为：<br>假设队列所需的资源大于minShare和fairShare</p>
<ul>
<li>如果此队列的资源低于minShare的时间超过minSharePreemptionTimeout，则应该抢占minShare和正在使用资源的差值。</li>
<li>如果此队列的资源低于fairShare的时间超过fairSharePreemptionTimeout，则应该抢占fairShare和正在使用资源的差值。</li>
<li>如果上述两个条件都满足，则抢占两者较大的数。</li>
</ul>
</blockquote>
<blockquote>
<p>计算出需要抢占的资源总数之后就是找出抢哪些container。找哪些container的流程是从root队列一层一层的查找可以抢占的队列，然后从队列中找到Application，最后找到可以抢占的container。这个流程的入口函数是<code>FairScheduler.preemptResources</code>。<br>preemptResources先遍历<em>warnedContainers</em>(是个list)中的container，如果toPreempt依然有剩余，则循环的从root队列向下一层一层的查找可以抢占的container，并将此container放入list warnedContainers中。<br>抢占策略根据不同的调度策略而不同：<br>(1) fair/drf  选择超过fairShare最多的队列<br>(2) fifo 选择最近提交的app的队列<br>在app中选择container是根据container的优先级，抢占优先级最低的container，container的优先级是由数字标识的，数字越大优先级越低。</p>
</blockquote>
<h2 id="Tips"><a href="#Tips" class="headerlink" title="Tips"></a>Tips</h2><ul>
<li>FairSharePreemptionTimeout的值应该大于0.0小于1.0，因为设置为0.0则表示关闭了fairShare抢占功能。</li>
<li>抢占是将queueA的container杀掉进行重新分配给queueX队列，不能将queueA中app1的container杀掉然后再分配给queueA中的app2</li>
<li>SchedulingPolicy<br><a href="http://bigdatadecode.club/YARN源码分析之Fair Scheduler part1.html">上篇</a>中介绍了SchedulingPolicy中计算fairShare的逻辑，本篇中介绍了队列排序比较的逻辑，这也就把SchedulingPolicy的功能介绍完了。<br>包括两个功能：<br>(1)计算fairshare的逻辑<br>(2)队列排序比较的逻辑（在分配资源，以及在抢占资源时候会进行排序），分配给最需要资源的，以及抢占掉最不需要资源的</li>
</ul>
<h2 id="附件-完整代码"><a href="#附件-完整代码" class="headerlink" title="附件-完整代码"></a>附件-完整代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestFairSchedulerPreemptionSzw</span> <span class="keyword">extends</span> <span class="title">FairSchedulerTestBase</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> String ALLOC_FILE = <span class="keyword">new</span> File(<span class="string">"F:\\test-queues"</span>).getAbsolutePath();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> MockClock clock;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> Configuration <span class="title">createConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">super</span>.createConfiguration();</span><br><span class="line">    conf.setClass(YarnConfiguration.RM_SCHEDULER, FairScheduler.class,</span><br><span class="line">        ResourceScheduler.class);</span><br><span class="line">    <span class="comment">// 开启抢占开关  yarn.scheduler.fair.preemption</span></span><br><span class="line">    conf.setBoolean(FairSchedulerConfiguration.PREEMPTION, <span class="keyword">true</span>);</span><br><span class="line">    <span class="comment">// fair配置所在路径</span></span><br><span class="line">    conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);</span><br><span class="line">    <span class="keyword">return</span> conf;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Before</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    conf = createConfiguration();</span><br><span class="line">    clock = <span class="keyword">new</span> MockClock();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@After</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">teardown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (resourceManager != <span class="keyword">null</span>) &#123;</span><br><span class="line">      resourceManager.stop();</span><br><span class="line">      resourceManager = <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    conf = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">startResourceManager</span><span class="params">(<span class="keyword">float</span> utilizationThreshold)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// yarn.scheduler.fair.preemption.cluster-utilization-threshold</span></span><br><span class="line">    <span class="comment">// 设置集群资源发生抢占的阈值</span></span><br><span class="line">    conf.setFloat(FairSchedulerConfiguration.PREEMPTION_THRESHOLD,</span><br><span class="line">        utilizationThreshold);</span><br><span class="line">    <span class="comment">// 虚拟RM，只是为了方便测试</span></span><br><span class="line">    resourceManager = <span class="keyword">new</span> MockRM(conf);</span><br><span class="line">    resourceManager.start();</span><br><span class="line"></span><br><span class="line">    scheduler = (FairScheduler)resourceManager.getResourceScheduler();</span><br><span class="line"></span><br><span class="line">    scheduler.setClock(clock);</span><br><span class="line">    scheduler.updateInterval = <span class="number">60</span> * <span class="number">1000</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> ApplicationAttemptId <span class="title">registerNodeAndSubmitApp</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">      <span class="keyword">int</span> memory, <span class="keyword">int</span> vcores, <span class="keyword">int</span> appContainers, <span class="keyword">int</span> appMemory)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// new出一个名为node1的nm，资源为memory vcores</span></span><br><span class="line">    RMNode node1 = MockNodes.newNodeInfo(</span><br><span class="line">        <span class="number">1</span>, Resources.createResource(memory, vcores), <span class="number">1</span>, <span class="string">"node1"</span>);</span><br><span class="line">    NodeAddedSchedulerEvent nodeEvent1 = <span class="keyword">new</span> NodeAddedSchedulerEvent(node1);</span><br><span class="line">    scheduler.handle(nodeEvent1);</span><br><span class="line"></span><br><span class="line">    System.out.println(<span class="string">"resources in the cluster : "</span> + scheduler.rootMetrics.getAvailableMB());</span><br><span class="line">    <span class="comment">// 提交一个app，所需资源为 appContainers * appMemory</span></span><br><span class="line">    ApplicationAttemptId app1 = createSchedulingRequest(appMemory, <span class="string">"queueA"</span>, <span class="string">"user1"</span>, appContainers);</span><br><span class="line">    scheduler.update();</span><br><span class="line">    <span class="comment">// Sufficient node check-ins to fully schedule containers</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; appContainers; i++) &#123;</span><br><span class="line">      NodeUpdateSchedulerEvent nodeUpdate1 = <span class="keyword">new</span> NodeUpdateSchedulerEvent(node1);</span><br><span class="line">      scheduler.handle(nodeUpdate1);</span><br><span class="line">    &#125;</span><br><span class="line">    FSLeafQueue queue = scheduler.getQueueManager().getLeafQueue(</span><br><span class="line">            <span class="string">"queueA"</span>, <span class="keyword">false</span>);</span><br><span class="line">    System.out.println( <span class="string">"queueA : "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">            <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">            <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">            <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">            <span class="string">", running : "</span> + queue.getResourceUsage() +</span><br><span class="line">            <span class="string">", preempt : "</span> + queue.preemptContainer());</span><br><span class="line">    System.out.println(<span class="string">"rest resources of cluster : "</span> +</span><br><span class="line">            (memory - appContainers * appMemory) + <span class="string">" , "</span> +</span><br><span class="line">        scheduler.rootMetrics.getAvailableMB());</span><br><span class="line">    <span class="keyword">return</span> app1;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Test</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testPreemptionWithFreeResources</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    PrintWriter out = <span class="keyword">new</span> PrintWriter(<span class="keyword">new</span> FileWriter(ALLOC_FILE));</span><br><span class="line">    out.println(<span class="string">"&lt;?xml version=\"1.0\"?&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;allocations&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;queue name=\"default\"&gt;"</span>);</span><br><span class="line">    <span class="comment">// maxResources 为0，则default得到fixed队列，</span></span><br><span class="line">    <span class="comment">// 不列入计算SteadyFairShare和FairShare的集合中</span></span><br><span class="line">    out.println(<span class="string">"&lt;maxResources&gt;0mb,0vcores&lt;/maxResources&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;queue name=\"queueA\"&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;weight&gt;1&lt;/weight&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;minResources&gt;1024mb,0vcores&lt;/minResources&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;queue name=\"queueB\"&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;weight&gt;1&lt;/weight&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;minResources&gt;1024mb,0vcores&lt;/minResources&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;defaultMinSharePreemptionTimeout&gt;5&lt;/defaultMinSharePreemptionTimeout&gt;"</span>);</span><br><span class="line">    <span class="comment">// if fairSharePreemptionTimeout and defaultFairSharePreemptionTimeout both exist,</span></span><br><span class="line">    <span class="comment">// we take the default one</span></span><br><span class="line">    out.println(<span class="string">"&lt;fairSharePreemptionTimeout&gt;10&lt;/fairSharePreemptionTimeout&gt;"</span>);</span><br><span class="line">    out.println(<span class="string">"&lt;/allocations&gt;"</span>);</span><br><span class="line">    out.close();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 参数0f表示集群资源的使用量超过此值时发生抢占</span></span><br><span class="line">    startResourceManager(<span class="number">0f</span>);</span><br><span class="line">    <span class="comment">// Create node with 4GB memory and 4 vcores</span></span><br><span class="line">    <span class="comment">// 2 个container 1024mb</span></span><br><span class="line">    ApplicationAttemptId app1 = registerNodeAndSubmitApp(<span class="number">4</span> * <span class="number">1024</span>, <span class="number">4</span>, <span class="number">4</span>, <span class="number">1024</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Verify submitting another request triggers preemption</span></span><br><span class="line">    ApplicationAttemptId app2 = createSchedulingRequest(<span class="number">1024</span>, <span class="string">"queueB"</span>, <span class="string">"user1"</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">    scheduler.update();</span><br><span class="line">    <span class="comment">// 停顿6秒，使其超过defaultMinSharePreemptionTimeout，queueB没有满足minShare则抢占</span></span><br><span class="line">    clock.tick(<span class="number">6</span>);</span><br><span class="line"></span><br><span class="line">    FSLeafQueue queue = scheduler.getQueueManager().getLeafQueue(</span><br><span class="line">            <span class="string">"queueA"</span>, <span class="keyword">false</span>);</span><br><span class="line">    System.out.println( <span class="string">"queueA : "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">            <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">            <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">            <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">            <span class="string">", running : "</span> + queue.getResourceUsage() +</span><br><span class="line">            <span class="string">", preempt : "</span> + queue.preemptContainer());</span><br><span class="line">    <span class="comment">// 检查是否抢占</span></span><br><span class="line">    scheduler.preemptTasksIfNecessary();</span><br><span class="line">    System.out.println(<span class="string">"preemptResources() should have been called "</span> + <span class="number">1024</span> + <span class="string">" , "</span> +</span><br><span class="line">            scheduler.getSchedulerApp(app1).getPreemptionContainers().iterator().next().getContainer().getResource());</span><br><span class="line">    System.out.println(<span class="string">"===================================================================="</span>);</span><br><span class="line">    <span class="comment">// 停顿超过15s，将container杀掉，释放资源</span></span><br><span class="line">    clock.tick(<span class="number">18</span>);</span><br><span class="line">    <span class="comment">// 将container杀掉，释放资源</span></span><br><span class="line">    scheduler.preemptTasksIfNecessary();</span><br><span class="line">    System.out.println(<span class="string">"preemptResources() should have been called "</span> + <span class="number">1024</span> + <span class="string">" , "</span> +</span><br><span class="line">            scheduler.getSchedulerApp(app1).getPreemptionContainers());</span><br><span class="line">    System.out.println( <span class="string">"queueA : "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">            <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">            <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">            <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">            <span class="string">", running : "</span> + queue.getResourceUsage() +</span><br><span class="line">            <span class="string">", preempt : "</span> + queue.preemptContainer());</span><br><span class="line"></span><br><span class="line">    resourceManager.stop();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> container </tag>
            
            <tag> preempt </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之Fair Scheduler part1]]></title>
      <url>http://bigdatadecode.club/YARN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BFair%20Scheduler%20part1.html</url>
      <content type="html"><![CDATA[<p>想看fair Scheduler的源码已经很久了，只是一直没有合适的时间，更没有找到合适的方法去读src，导致每次读一点就不想继续读了，最近实在是太无聊了，也不知道该读点什么，于是就又想起了这个搁置很久的任务。</p>
<p>这次读代码时我直接从fair Scheduler的test类中进行跟读，这样我感觉会比较清晰也容易debug。</p>
<a id="more"></a>
<h2 id="环境初始化"><a href="#环境初始化" class="headerlink" title="环境初始化"></a>环境初始化</h2><p>要想测试Fair Scheduler，首先要虚拟出一个yarn环境，并加载fair相关的配置。<br>下面就来看下<em>TestFairScheduler</em>这个类是怎么对环境进行初始化的。</p>
<p>TestFairScheduler继承自<em>FairSchedulerTestBase</em>，一些公共常用方法被提到FairSchedulerTestBase中，yarn和相关配置环境的初始化在setUp中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setUp</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// new 出一个fair Scheduler实例</span></span><br><span class="line">  scheduler = <span class="keyword">new</span> FairScheduler();</span><br><span class="line">  <span class="comment">// 在FairSchedulerTestBase中实现</span></span><br><span class="line">  conf = createConfiguration();</span><br><span class="line">  <span class="comment">// new 出一个rm</span></span><br><span class="line">  resourceManager = <span class="keyword">new</span> ResourceManager();</span><br><span class="line">  resourceManager.init(conf);</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> This test should really be using MockRM. For now starting stuff</span></span><br><span class="line">  <span class="comment">// 启动rm的异步调度器</span></span><br><span class="line">  ((AsyncDispatcher)resourceManager.getRMContext().getDispatcher()).start();</span><br><span class="line">  resourceManager.getRMContext().getStateStore().start();</span><br><span class="line">  <span class="comment">// to initialize the master key</span></span><br><span class="line">  resourceManager.getRMContext().getContainerTokenSecretManager().rollMasterKey();</span><br><span class="line">  scheduler.setRMContext(resourceManager.getRMContext());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// FairSchedulerTestBase</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> Configuration <span class="title">createConfiguration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Configuration conf = <span class="keyword">new</span> YarnConfiguration();</span><br><span class="line">  conf.setClass(YarnConfiguration.RM_SCHEDULER, FairScheduler.class,</span><br><span class="line">      ResourceScheduler.class);</span><br><span class="line">  conf.setInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, <span class="number">0</span>);</span><br><span class="line">  conf.setInt(FairSchedulerConfiguration.RM_SCHEDULER_INCREMENT_ALLOCATION_MB,</span><br><span class="line">      <span class="number">1024</span>);</span><br><span class="line">  conf.setInt(YarnConfiguration.RM_SCHEDULER_MAXIMUM_ALLOCATION_MB, <span class="number">10240</span>);</span><br><span class="line">  conf.setBoolean(FairSchedulerConfiguration.ASSIGN_MULTIPLE, <span class="keyword">false</span>);</span><br><span class="line">  conf.setFloat(FairSchedulerConfiguration.PREEMPTION_THRESHOLD, <span class="number">0f</span>);</span><br><span class="line">  <span class="keyword">return</span> conf;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>环境初始化之后，我们先来看个简单的例子，我们能从这个例子中知道每个队列的FairShare是如何算出来的。</p>
<h2 id="FairShare计算逻辑"><a href="#FairShare计算逻辑" class="headerlink" title="FairShare计算逻辑"></a>FairShare计算逻辑</h2><p>测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testFairShareWithMaxResources</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="comment">// 设置fair-scheduler.xml的加载地址，由AllocationFileLoaderService进行加载文件内容</span></span><br><span class="line">  conf.set(FairSchedulerConfiguration.ALLOCATION_FILE, ALLOC_FILE);</span><br><span class="line">  <span class="comment">// set queueA and queueB maxResources,</span></span><br><span class="line">  <span class="comment">// the sum of queueA and queueB maxResources is more than</span></span><br><span class="line">  <span class="comment">// Integer.MAX_VALUE.</span></span><br><span class="line">  <span class="comment">// 将fair的配置信息写入fair-sheduler.xml中</span></span><br><span class="line">  PrintWriter out = <span class="keyword">new</span> PrintWriter(<span class="keyword">new</span> FileWriter(ALLOC_FILE));</span><br><span class="line">  out.println(<span class="string">"&lt;?xml version=\"1.0\"?&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;allocations&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;queue name=\"queueA\"&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;maxResources&gt;1073741824 mb 1000 vcores&lt;/maxResources&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;weight&gt;.25&lt;/weight&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;queue name=\"queueB\"&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;maxResources&gt;1073741824 mb 1000 vcores&lt;/maxResources&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;weight&gt;.75&lt;/weight&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;/queue&gt;"</span>);</span><br><span class="line">  out.println(<span class="string">"&lt;/allocations&gt;"</span>);</span><br><span class="line">  out.close();</span><br><span class="line"></span><br><span class="line">  scheduler.init(conf);</span><br><span class="line">  scheduler.start();</span><br><span class="line">  scheduler.reinitialize(conf, resourceManager.getRMContext());</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Add one big node (only care about aggregate capacity)</span></span><br><span class="line">  RMNode node1 =</span><br><span class="line">      MockNodes.newNodeInfo(<span class="number">1</span>, Resources.createResource(<span class="number">8</span> * <span class="number">1024</span>, <span class="number">8</span>), <span class="number">1</span>,</span><br><span class="line">          <span class="string">"127.0.0.1"</span>);</span><br><span class="line">  NodeAddedSchedulerEvent nodeEvent1 = <span class="keyword">new</span> NodeAddedSchedulerEvent(node1);</span><br><span class="line">  scheduler.handle(nodeEvent1);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Queue A wants 1 * 1024.</span></span><br><span class="line">  createSchedulingRequest(<span class="number">1</span> * <span class="number">1024</span>, <span class="string">"queueA"</span>, <span class="string">"user1"</span>);</span><br><span class="line">  <span class="comment">// Queue B wants 6 * 1024</span></span><br><span class="line">  createSchedulingRequest(<span class="number">6</span> * <span class="number">1024</span>, <span class="string">"queueB"</span>, <span class="string">"user1"</span>);</span><br><span class="line">  <span class="comment">// createSchedulingRequest(1 * 1024, "root.default", "user1");</span></span><br><span class="line"></span><br><span class="line">  scheduler.update();</span><br><span class="line"></span><br><span class="line">  FSLeafQueue queue = scheduler.getQueueManager().getLeafQueue(</span><br><span class="line">      <span class="string">"queueA"</span>, <span class="keyword">false</span>);</span><br><span class="line">  <span class="comment">// queueA's weight is 0.25, so its fair share should be 2 * 1024.</span></span><br><span class="line">  System.out.println( <span class="string">"queueA FairShare: "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">          <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">          <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">          <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">          <span class="string">", max/min : "</span> + queue.getMaxShare() + <span class="string">"/"</span> + queue.getMinShare());</span><br><span class="line">  <span class="comment">// queueB's weight is 0.75, so its fair share should be 6 * 1024.</span></span><br><span class="line">  queue = scheduler.getQueueManager().getLeafQueue(</span><br><span class="line">      <span class="string">"queueB"</span>, <span class="keyword">false</span>);</span><br><span class="line">  System.out.println( <span class="string">"queueB FairShare: "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">          <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">          <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">          <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">          <span class="string">", max/min : "</span> + queue.getMaxShare() + <span class="string">"/"</span> + queue.getMinShare());</span><br><span class="line">  queue = scheduler.getQueueManager().getLeafQueue(</span><br><span class="line">          <span class="string">"default"</span>, <span class="keyword">false</span>);</span><br><span class="line">  System.out.println( <span class="string">"default FairShare: "</span> + queue.getFairShare().getMemory() +</span><br><span class="line">          <span class="string">", weight : "</span> + queue.getWeights().getWeight(ResourceType.MEMORY) +</span><br><span class="line">          <span class="string">", steadyShare : "</span> + queue.getSteadyFairShare() +</span><br><span class="line">          <span class="string">", demand : "</span> + queue.getDemand() +</span><br><span class="line">          <span class="string">", max/min : "</span> + queue.getMaxShare() + <span class="string">"/"</span> + queue.getMinShare());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码的运行结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">queueA FairShare: 2048, weight : 0.25, steadyShare : &lt;memory:1024, vCores:0&gt;, demand : &lt;memory:1024, vCores:1&gt;, max/min : &lt;memory:1073741824, vCores:1000&gt;/&lt;memory:0, vCores:0&gt;</span><br><span class="line">queueB FairShare: 6144, weight : 0.75, steadyShare : &lt;memory:3072, vCores:0&gt;, demand : &lt;memory:6144, vCores:1&gt;, max/min : &lt;memory:1073741824, vCores:1000&gt;/&lt;memory:0, vCores:0&gt;</span><br><span class="line">default FairShare: 0, weight : 1.0, steadyShare : &lt;memory:4096, vCores:0&gt;, demand : &lt;memory:0, vCores:0&gt;, max/min : &lt;memory:2147483647, vCores:2147483647&gt;/&lt;memory:0, vCores:0&gt;</span><br></pre></td></tr></table></figure>
<p>由上面的运行结果我们可以猜出<strong>Weight的默认值是1.0</strong>，<strong>maxShare和minShare(即maxResources和minResources)的默认值分别为Integer.MAX_VALUE(2147483647)和0</strong>，但是FairShare和steadyFairShare是什么鬼？</p>
<p>我们先将FairShare和steadyFairShare放下，先介绍下与他们相关的<em>Weight</em>和<em>maxResources/minResources</em></p>
<h3 id="Weight"><a href="#Weight" class="headerlink" title="Weight"></a>Weight</h3><p>Weight 值的类型为大于等于0.0的数，默认为1.0。Weight是队列的一个属性，作为一个权值，使各个队列得到的资源成比例。</p>
<blockquote>
<p>注意事项：</p>
</blockquote>
<ul>
<li><p>weigth的值决定了一个队列相对于其它<em>兄弟队列</em>而言应该得到的资源，假设：<br>集群资源为1000GB、200个vcore，queueX的weight是0.25，其它队列的weight总和为0.75，<br><em>则queueX的FairShare是250GB、50个vcore</em>。  <strong>这里的FairShare是指steadyFairShare，原因在下面介绍</strong></p>
</li>
<li><p><em>Weight不只用来计算steadyFairShare也用来计算FairShare</em>。假如这个队列或者其子队列中至少有一个active Application，则<em>FairShare</em>就会被强制计算(<em>这里的FairShare是指Instantaneous FairShare</em>)。</p>
</li>
<li><p>weigth的值是和集群相关的，所以当集群的资源改变之后FairShare也会发生变化，</p>
</li>
</ul>
<p><strong>思考</strong> Weight的值应该怎么设置？怎么设置最合理？？？</p>
<h3 id="minResources和maxResources"><a href="#minResources和maxResources" class="headerlink" title="minResources和maxResources"></a>minResources和maxResources</h3><p>minResources和maxResources是队列的资源限制。默认是0和Integer.MAX_VALUE</p>
<blockquote>
<p>注意事项:</p>
</blockquote>
<ul>
<li>minResources是一个软性的限制。满足下面这两种情况时，minResources会强制这个队列的总资源大于或者等于minResources配置的大小。<br>1) 资源是可用的或者可以从其它队列中抢占<br>2) 所有队列的minResources的总和不超过集群的总资源</li>
<li>maxResources是一个硬性的限制。也就是说该队列的子队列或者后代队列正在使用资源的总和不会超过此值。</li>
<li>minResources和maxResources并不被推荐。这两个配置有一些缺点：<br>1) minResources和maxResources的值都是静态的。因此集群资源发生变化的话此值需要更新。(<strong>那为什么不设置为百分比？是否可以自己优化下？？？</strong>)<br>2) maxResources限制了集群资源的使用，队列超过maxResources之后不能再使用任何空闲的资源。(这个在不同的场景优缺点的性质也不一样)<br>3) 如果一个队列的minResources超过了FairShare，它可能会对其他队列的FairShare造成影响。<br>4) In the past, one specified minResources when using preemption to get a chunk of resources sooner. This is no longer necessary as FairShare-based preemption has been improved significantly. We will discuss this subject in more detail later.</li>
</ul>
<h3 id="FairShare和SteadyFairShare"><a href="#FairShare和SteadyFairShare" class="headerlink" title="FairShare和SteadyFairShare"></a>FairShare和SteadyFairShare</h3><p>Fair scheduler包含两种FairShare，分别是<em>Instantaneous FairShare</em>和<em>Steady FairShare</em>，其中<em>Instantaneous FairShare</em>一般被简称为<strong>FairShare</strong>(本文中的FairShare是指Instantaneous FairShare的简称)。</p>
<p><em>Steady FairShare是一个队列的理想值</em>，这个值是由集群资源和weigths计算出来的，并不会被经常计算，只是在集群启动或者集群的总资源发生增减的时候才会被重新计算。<em>每个队列的Steady FairShare的计算公式是`totalResources(集群总资源)/weights(所有队列的weight总和)</em>weight(某个队列的weight)`*</p>
<p>Instantaneous FairShare计算集群中<em>每个active队列</em>的FairShare。Steady FairShare是计算集群中所有的队列。这两者的区别为：</p>
<ul>
<li>空队列也就是没有分配任何资源的队列不会计算Instantaneous FairShare，其值为0。</li>
<li><em>如果集群中所有的队列都是active，则Steady FairShare和Instantaneous FairShare相等</em>。<br><em>每个队列的Instantaneous FairShare的计算公式是`totalResources(集群总资源)/activeWeights(active队列的weight总和)</em>activeWeight(active队列的weight)`*</li>
</ul>
<p>上面的两个计算公式都不太严谨，仅供参考，代码中真正的计算逻辑比较复杂，先看下计算Steady FairShare代码的流程。</p>
<blockquote>
<p>FairShare<br>每一个<em>队列/作业</em>会有一个FairShare值，表示该队列/作业当前应得的资源。调度器后台会有一个线程不停的根据当前集群整体情况，动态的更新每个作业的FairShare值。通常当某个作业实际获取到资源不满足其FairShare时，该作业会更有可能获取到新的资源，同样当作业实际获取到资源超出其FairShare，则很难再获取到新的资源，甚至现有的资源也会被抢占。<br>FairShare的计算也是一个自顶向下资源分配的过程，通常情况下同一个队列内的各个作业会尽量均分队列资源。同时具体某个作业的FairShare会受到其他一些参数的修正。</p>
</blockquote>
<p>上面提到Steady FairShare只是在集群总资源发生变化时才会被计算，则其入口函数是<code>scheduler.handle(nodeEvent1);</code>,scheduler捕获到<code>NODE_ADDED</code>事件，调用<code>addNode</code>，然后继续调用<code>queueMgr.getRootQueue().setSteadyFairShare(clusterResource);queueMgr.getRootQueue().recomputeSteadyShares()</code>先设置整个集群的steadyFairShare，然后计算每个队列的steadyFairShare，这里从recomputeSteadyShares开始屡下代码的思路：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">recomputeSteadyShares</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 根据不同的调度策略计算steadyFairShare</span></span><br><span class="line">  <span class="comment">// fair scheduler中可以为每个队列设置调度策略，这里以fair为例</span></span><br><span class="line">  policy.computeSteadyShares(childQueues, getSteadyFairShare());</span><br><span class="line">  <span class="comment">// 将上面计算的steadyFairShare赋值给每个队列</span></span><br><span class="line">  <span class="comment">// 如果队列是父队列，则继续steadyFairShare</span></span><br><span class="line">  <span class="keyword">for</span> (FSQueue childQueue : childQueues) &#123;</span><br><span class="line">    childQueue.getMetrics().setSteadyFairShare(childQueue.getSteadyFairShare());</span><br><span class="line">    <span class="keyword">if</span> (childQueue <span class="keyword">instanceof</span> FSParentQueue) &#123;</span><br><span class="line">      ((FSParentQueue) childQueue).recomputeSteadyShares();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// FairSharePolicy.java</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">computeSteadyShares</span><span class="params">(Collection&lt;? extends FSQueue&gt; queues,</span></span></span><br><span class="line"><span class="function"><span class="params">    Resource totalResources)</span> </span>&#123;</span><br><span class="line">  ComputeFairShares.computeSteadyShares(queues, totalResources,</span><br><span class="line">      ResourceType.MEMORY);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里计算steadyFairShare用的是fair策略，则调用FairSharePolicy.computeSteadyShares，调用<code>ComputeFairShares.computeSteadyShares</code>来计算steadyFairShare，<code>ComputeFairShares</code>是计算FairShare的主要逻辑实现。先来看下computeSteadyShares方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">computeSteadyShares</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;? extends FSQueue&gt; queues, Resource totalResources,</span></span></span><br><span class="line"><span class="function"><span class="params">    ResourceType type)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 计算steadyFairShare和FairShare，最后一个参数是标识位，true为计算steadyFairShare</span></span><br><span class="line">  computeSharesInternal(queues, totalResources, type, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由于FairShare和steadyFairShare都是在ComputeFairShares类中，而且其计算逻辑类似，所以放在同一个方法中计算，提出一个标识位来标识计算的是FairShare还是steadyFairShare，这个方法就是<code>computeSharesInternal</code>。</p>
<p>computeSteadyShares计算的是steadyFairShare，则调用<code>computeSharesInternal</code>时，将标识位设为true，computeSharesInternal的计算逻辑如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">computeSharesInternal</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;? extends Schedulable&gt; allSchedulables,</span></span></span><br><span class="line"><span class="function"><span class="params">    Resource totalResources, ResourceType type, <span class="keyword">boolean</span> isSteadyShare)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  Collection&lt;Schedulable&gt; schedulables = <span class="keyword">new</span> ArrayList&lt;Schedulable&gt;();</span><br><span class="line">  <span class="comment">// 得到不用计算FairShare或者SteadyFairShare的队列和这些队列的返回的资源</span></span><br><span class="line">  <span class="keyword">int</span> takenResources = handleFixedFairShares(</span><br><span class="line">      allSchedulables, schedulables, isSteadyShare, type);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (schedulables.isEmpty()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Find an upper bound on R that we can use in our binary search. We start</span></span><br><span class="line">  <span class="comment">// at R = 1 and double it until we have either used all the resources or we</span></span><br><span class="line">  <span class="comment">// have met all Schedulables' max shares.</span></span><br><span class="line">  <span class="comment">// 对需要计算FairShare的队列的maxShare进行sum</span></span><br><span class="line">  <span class="keyword">int</span> totalMaxShare = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (Schedulable sched : schedulables) &#123;</span><br><span class="line">    <span class="keyword">int</span> maxShare = getResourceValue(sched.getMaxShare(), type);</span><br><span class="line">    totalMaxShare = (<span class="keyword">int</span>) Math.min((<span class="keyword">long</span>)maxShare + (<span class="keyword">long</span>)totalMaxShare,</span><br><span class="line">        Integer.MAX_VALUE);</span><br><span class="line">    <span class="keyword">if</span> (totalMaxShare == Integer.MAX_VALUE) &#123;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> totalResource = Math.max((getResourceValue(totalResources, type) -</span><br><span class="line">      takenResources), <span class="number">0</span>);</span><br><span class="line">  <span class="comment">// 可用资源的总和</span></span><br><span class="line">  totalResource = Math.min(totalMaxShare, totalResource);</span><br><span class="line">  <span class="comment">// 找到R的上限</span></span><br><span class="line">  <span class="keyword">double</span> rMax = <span class="number">1.0</span>;</span><br><span class="line">  <span class="keyword">while</span> (resourceUsedWithWeightToResourceRatio(rMax, schedulables, type)</span><br><span class="line">      &lt; totalResource) &#123;</span><br><span class="line">    rMax *= <span class="number">2.0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Perform the binary search for up to COMPUTE_FAIR_SHARES_ITERATIONS steps</span></span><br><span class="line">  <span class="keyword">double</span> left = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">double</span> right = rMax;</span><br><span class="line">  <span class="comment">// 二分查找，有迭代上限，COMPUTE_FAIR_SHARES_ITERATIONS是25</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; COMPUTE_FAIR_SHARES_ITERATIONS; i++) &#123;</span><br><span class="line">    <span class="keyword">double</span> mid = (left + right) / <span class="number">2.0</span>;</span><br><span class="line">    <span class="keyword">int</span> plannedResourceUsed = resourceUsedWithWeightToResourceRatio(</span><br><span class="line">        mid, schedulables, type);</span><br><span class="line">    <span class="keyword">if</span> (plannedResourceUsed == totalResource) &#123;</span><br><span class="line">      right = mid;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (plannedResourceUsed &lt; totalResource) &#123;</span><br><span class="line">      left = mid;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      right = mid;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Set the fair shares based on the value of R we've converged to</span></span><br><span class="line">  <span class="comment">// 对每个队列设置FairShare或者SteadyFairShare，</span></span><br><span class="line">  <span class="comment">// right值就是所要求的FairShare或者SteadyFairShare值</span></span><br><span class="line">  <span class="keyword">for</span> (Schedulable sched : schedulables) &#123;</span><br><span class="line">    <span class="keyword">if</span> (isSteadyShare) &#123;</span><br><span class="line">      setResourceValue(computeShare(sched, right, type),</span><br><span class="line">          ((FSQueue) sched).getSteadyFairShare(), type);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      setResourceValue(</span><br><span class="line">          computeShare(sched, right, type), sched.getFairShare(), type);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>computeSharesInternal可以用来计算FairShare和SteadyFairShare，但是这两个计算的队列集合是不一样的，那这个队列集合是在哪进行筛选的呢？从上面的代码中可以看到有个<code>handleFixedFairShares</code>方法，看下其具体的实现:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">handleFixedFairShares</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;? extends Schedulable&gt; schedulables,</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;Schedulable&gt; nonFixedSchedulables,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isSteadyShare, ResourceType type)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 如果队列是fixed，则返回其队列 fixedShare 的总和</span></span><br><span class="line">  <span class="keyword">int</span> totalResource = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (Schedulable sched : schedulables) &#123;</span><br><span class="line">  	<span class="comment">// 判断队列是否是fixed</span></span><br><span class="line">    <span class="keyword">int</span> fixedShare = getFairShareIfFixed(sched, isSteadyShare, type);</span><br><span class="line">    <span class="keyword">if</span> (fixedShare &lt; <span class="number">0</span>) &#123;</span><br><span class="line">      nonFixedSchedulables.add(sched);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      setResourceValue(fixedShare,</span><br><span class="line">          isSteadyShare</span><br><span class="line">              ? ((FSQueue)sched).getSteadyFairShare()</span><br><span class="line">              : sched.getFairShare(),</span><br><span class="line">          type);</span><br><span class="line">      totalResource = (<span class="keyword">int</span>) Math.min((<span class="keyword">long</span>)totalResource + (<span class="keyword">long</span>)fixedShare,</span><br><span class="line">          Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> totalResource;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>handleFixedFairShares用来对队列进行处理，将fixed队列的fixed fairshare进行求和返回，并将非fixed的队列放入nonFixedSchedulables中。判断某个队列是否fixed是由方法<code>getFairShareIfFixed</code>判断的，判断标准如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">getFairShareIfFixed</span><span class="params">(Schedulable sched,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">boolean</span> isSteadyShare, ResourceType type)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 当maxResources小于等于0时，该队列是fixed</span></span><br><span class="line">  <span class="keyword">if</span> (getResourceValue(sched.getMaxShare(), type) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// isSteadyShare是false，用来求FairShare，则判断队列是否为active</span></span><br><span class="line">  <span class="comment">// 该队列不是active时，返回0，代表该队列是fixed</span></span><br><span class="line">  <span class="comment">// For instantaneous fairshares, check if queue is active</span></span><br><span class="line">  <span class="keyword">if</span> (!isSteadyShare &amp;&amp;</span><br><span class="line">      (sched <span class="keyword">instanceof</span> FSQueue) &amp;&amp; !((FSQueue)sched).isActive()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 当队列的weight小于等于0时，该队列是fixed，返回0或者minShare</span></span><br><span class="line">  <span class="comment">// Check if weight is 0</span></span><br><span class="line">  <span class="keyword">if</span> (sched.getWeights().getWeight(type) &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> minShare = getResourceValue(sched.getMinShare(), type);</span><br><span class="line">    <span class="keyword">return</span> (minShare &lt;= <span class="number">0</span>) ? <span class="number">0</span> : minShare;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 当队列是非fixed时，返回-1</span></span><br><span class="line">  <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>判断一个队列是fixed的条件是：</p>
<ul>
<li>maxResources小于等于0</li>
<li>weight小于等于0</li>
<li>当求FairShare时，如果队列是非active时</li>
</ul>
<p>computeSharesInternal通过handleFixedFairShares将<code>nonFixedSchedulables</code>放入<code>schedulables</code>中，schedulables集合中存放的就是需要计算FairShare或者SteadyFairShare的队列。</p>
<p>求出所需计算的队列集合之后，则对这些队列应得的资源进行计算，要计算应得资源则需求出这些队列的总资源(<em>这里的总资源并不是集群的总资源，而是所需计算队列的总资源</em>)。<em>所求队列的总资源就是这些队列所配置的maxResources之和</em>，其计算方式为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这部分代码在computeSharesInternal中</span></span><br><span class="line"><span class="keyword">int</span> totalMaxShare = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (Schedulable sched : schedulables) &#123;</span><br><span class="line">  <span class="keyword">int</span> maxShare = getResourceValue(sched.getMaxShare(), type);</span><br><span class="line">  totalMaxShare = (<span class="keyword">int</span>) Math.min((<span class="keyword">long</span>)maxShare + (<span class="keyword">long</span>)totalMaxShare,</span><br><span class="line">      Integer.MAX_VALUE);</span><br><span class="line">  <span class="keyword">if</span> (totalMaxShare == Integer.MAX_VALUE) &#123;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这些队列的总和有可能超过Integer.MAX_VALUE，则需要对其总资源进行校验，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这部分代码在computeSharesInternal中</span></span><br><span class="line"><span class="comment">// totalResources 集群总资源，takenResources为不需要计算队列(即fixed 队列)的资源总和</span></span><br><span class="line"><span class="keyword">int</span> totalResource = Math.max((getResourceValue(totalResources, type) -</span><br><span class="line">    takenResources), <span class="number">0</span>);</span><br><span class="line">totalResource = Math.min(totalMaxShare, totalResource);</span><br></pre></td></tr></table></figure>
<p>求出这些队列的总资源，则下面就是将这些资源根据各个队列的weight进行分配。</p>
<p>在考虑minResources和maxResources时尽可能的进行公平分配资源，<em>fair scheduler规定FairShare需在minResources和maxResources之间</em>。</p>
<p>fair scheduler定义一个比值R，则各个队列应分配的资源分为如下三种情况：</p>
<ul>
<li>当队列S的<em>minShare &gt; R*weight</em>，则分配minShare</li>
<li>当队列S的<em>manShare &lt; R*weight</em>，则分配manShare</li>
<li>其它情况直接分配<em>R*weight</em><br>这些分配的总和等于totalSlots。这个比值R也称为weight-to-slots，因为其值将队列的weight转换为实际的资源个数。</li>
</ul>
<p>那么R的取值是关键，R过小则导致分配给队列的slots总和小于totalSlots，R过大则导致分配的slots总和多余totalSlots。</p>
<p>R的查找可以使用二分查找，则另一个关键点就是R上限的确定，由上面对R的定义，得知R的上限就是尽可能的让分配的slots接近totalSlots。R上限的代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这部分代码在computeSharesInternal中</span></span><br><span class="line"><span class="keyword">double</span> rMax = <span class="number">1.0</span>;</span><br><span class="line"><span class="comment">// rMax不满足上限的标准则使其乘以2，继续循环</span></span><br><span class="line"><span class="keyword">while</span> (resourceUsedWithWeightToResourceRatio(rMax, schedulables, type)</span><br><span class="line">    &lt; totalResource) &#123;</span><br><span class="line">  rMax *= <span class="number">2.0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>resourceUsedWithWeightToResourceRatio返回的值是当R为rMax时，各个队列分配的slots总和。而各个队列应该分配的slots是通过computeShare计算的。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">resourceUsedWithWeightToResourceRatio</span><span class="params">(<span class="keyword">double</span> w2rRatio,</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;? extends Schedulable&gt; schedulables, ResourceType type)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> resourcesTaken = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (Schedulable sched : schedulables) &#123;</span><br><span class="line">    <span class="keyword">int</span> share = computeShare(sched, w2rRatio, type);</span><br><span class="line">    resourcesTaken += share;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> resourcesTaken;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">computeShare</span><span class="params">(Schedulable sched, <span class="keyword">double</span> w2rRatio,</span></span></span><br><span class="line"><span class="function"><span class="params">    ResourceType type)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">double</span> share = sched.getWeights().getWeight(type) * w2rRatio;</span><br><span class="line">  share = Math.max(share, getResourceValue(sched.getMinShare(), type));</span><br><span class="line">  share = Math.min(share, getResourceValue(sched.getMaxShare(), type));</span><br><span class="line">  <span class="keyword">return</span> (<span class="keyword">int</span>) share;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>找到R的最大值之后，就是进行二分查找，找到最公平的分配方案，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这部分代码在computeSharesInternal中</span></span><br><span class="line"><span class="keyword">double</span> left = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">double</span> right = rMax;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; COMPUTE_FAIR_SHARES_ITERATIONS; i++) &#123;</span><br><span class="line">  <span class="keyword">double</span> mid = (left + right) / <span class="number">2.0</span>;</span><br><span class="line">  <span class="keyword">int</span> plannedResourceUsed = resourceUsedWithWeightToResourceRatio(</span><br><span class="line">      mid, schedulables, type);</span><br><span class="line">  <span class="keyword">if</span> (plannedResourceUsed == totalResource) &#123;</span><br><span class="line">    right = mid;</span><br><span class="line">    <span class="keyword">break</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (plannedResourceUsed &lt; totalResource) &#123;</span><br><span class="line">    left = mid;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    right = mid;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后根据<code>isSteadyShare</code>标识设置每个队列的FairShare或者SteadyFairShare的值。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本篇主要解析了下队列FairShare和SteadyFairShare的计算过程，其中<em>FairShare和SteadyFairShare的区别为FairShare分为Instantaneous FairShare和SteadyFairShare，但是Instantaneous FairShare一般简称为FairShare</em>，则FairShare和SteadyFairShare的区别为前者计算时不包括未active的队列，后者计算时包括所有的队列。</p>
<p>FairShare和SteadyFairShare的计算思想为：<br>先找到一个比值R，则各个队列应分配的资源分为如下三种情况：</p>
<ul>
<li>当队列S的<em>minShare &gt; R*weight</em>，则分配minShare</li>
<li>当队列S的<em>maxShare &lt; R*weight</em>，则分配maxShare</li>
<li>其它情况直接分配<em>R*weight</em><br>这些分配的总和等于totalSlots。这个比值R也称为weight-to-slots，因为其值将队列的weight转换为实际的资源个数。</li>
</ul>
<p>其中比值R的查找比较麻烦，平时如果想简单的评估下各个队列应分配的资源可以使用如下公式：<br>Steady FairShare的计算公式是<code>totalResources(集群总资源)/weights(所有队列的weight总和)*weight(某个队列的weight)</code><br>FairShare的计算公式是<code>totalResources(集群总资源)/activeWeights(active队列的weight总和)*activeWeight(active队列的weight)</code></p>
<p>这两个公式成立的<strong>前提是所求出的SteadyFairShare和FairShare在minResources和maxResources之间</strong>。如果小于minResources(大于maxResources)则steadyFairShare或者FairShare应该为minResources(maxResources)，这种情况分配给队列的slots总和会超出totalSlots。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> FairShare </tag>
            
            <tag> SteadyFairShare </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之leetcode Longest Palindromic]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bleetcode%20Longest%20Palindromic.html</url>
      <content type="html"><![CDATA[<p>给定一个字符串，求最长回文<em>子串</em>(假设字符串中只有唯一的一个最长回文子串)。</p>
<p><em>注意子串和子序列的区别，子串是连续的，子序列是非连续的</em><br>例如：<br>字符串”xyzabccbad”, 最长回文为”abccba”<br>字符串”aaa”, 最长回文为”aaa”<br>字符串”bananas”, 最长回文为”anana”</p>
<a id="more"></a>
<blockquote>
<p>回文就是顺着读和逆着读是一样的。</p>
</blockquote>
<h2 id="动态规划算法"><a href="#动态规划算法" class="headerlink" title="动态规划算法"></a>动态规划算法</h2><p>最长回文子串可见是求最优解，并且可以对将此问题拆分，则观察能否用动态规划去尝试。</p>
<p>要用动态规划首先要找到<em>转移方程</em>，</p>
<blockquote>
<p>这里需要注意，假如你发现自己的转移方程的特别繁琐或者需要考虑很多不同的情况更或者是总一些情况无法用转移方程表示时，这时你就应该考虑是否应该<strong>重新定义状态，进行重新整理转移方程</strong>。</p>
</blockquote>
<p>假设：dp[i][j]表示i为开始j为结尾的字符串是否为回文，则转移方程如下：<br>dp[i][j] = true (chars[j] == chars[i] &amp;&amp; dp[i+1][j-1])</p>
<p>初始条件是dp[i][i] = true (0&lt;i&lt;chars.length); dp[i][i+1] = chars[i] == chars<a href="i到i+1时不适用上面的转移方程">i+1</a></p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">dp</span><span class="params">(String str)</span></span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span>[][] dp = <span class="keyword">new</span> <span class="keyword">boolean</span>[str.length()][str.length()];</span><br><span class="line">    <span class="keyword">char</span>[] chars = str.toCharArray();</span><br><span class="line">    <span class="keyword">int</span> longest = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line">    StringBuffer stringBuffer = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    <span class="comment">// 初始化dp数组，数组的值是当前子串是否为回文</span></span><br><span class="line">    <span class="comment">// 单个字符是回文，当chars[i] == chars[i+1]时，dp[i][i+1]的值为true</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;chars.length; i++)&#123;</span><br><span class="line">        dp[i][i] = <span class="keyword">true</span>;</span><br><span class="line">        <span class="keyword">if</span> ((i - i + <span class="number">1</span>) &gt; longest)&#123;</span><br><span class="line">            start = i;</span><br><span class="line">            longest = i - i + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (i+<span class="number">1</span>&lt;chars.length &amp;&amp; chars[i] == chars[i+<span class="number">1</span>])&#123;</span><br><span class="line">            dp[i][i+<span class="number">1</span>] = <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (((i+<span class="number">1</span>) - i + <span class="number">1</span>) &gt; longest)&#123;</span><br><span class="line">                start = i;</span><br><span class="line">                longest = (i+<span class="number">1</span>) - i + <span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (i+<span class="number">1</span> &lt; chars.length)&#123;</span><br><span class="line">            dp[i][i+<span class="number">1</span>] = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// k 是步长，k=1即i+1已初始化，则从2开始</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k=<span class="number">2</span>; k&lt;chars.length; k++)&#123;</span><br><span class="line">        <span class="keyword">int</span> j = k;</span><br><span class="line">        <span class="comment">// i j组成一个二维数组(右上半角矩阵)，按照斜线向上填补矩阵</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;chars.length-k; i++)&#123;</span><br><span class="line">        	<span class="comment">// k从2开始的好处是当i=0，j=2时，dp[i+1][j-1]的值已被初始化</span></span><br><span class="line">            <span class="keyword">if</span> (chars[i] == chars[j] &amp;&amp; dp[i+<span class="number">1</span>][j-<span class="number">1</span>])&#123;</span><br><span class="line">                dp[i][j] = <span class="keyword">true</span>;</span><br><span class="line">                <span class="keyword">if</span> ((j - i + <span class="number">1</span>) &gt; longest)&#123;</span><br><span class="line">                    start = i;</span><br><span class="line">                    longest = j - i + <span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                dp[i][j] = <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;longest; i++)&#123;</span><br><span class="line">        stringBuffer.append(chars[start+i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> stringBuffer.toString();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>时间复杂度是n的平方，空间复杂度也是n的平方</p>
<p><em>这也是个二维动态规划，这种情况下最好画出矩阵图，然后从矩阵中寻找dp数组的求解规律</em></p>
<h2 id="Manacher算法"><a href="#Manacher算法" class="headerlink" title="Manacher算法"></a>Manacher算法</h2><p>在思考的过程中，或许已经注意到回文的是对称的，则对称就涉及到<em>奇偶性的对称轴</em>，则我们可以<em>想办法将字符串无论奇偶统一为奇数或者偶数</em>。</p>
<p>方法是在字符首位和之间添加特殊字符(即不会在原字符串中出现的字符)，使字符串统一变为奇数。</p>
<p>如字符串aba，添加#字符变为#a#b#a#<br>字符串abba，添加#字符变为#a#b#b#a#</p>
<p><em>我们把一个回文串中最左或最右位置的字符与其对称轴的距离称为回文半径</em>。对于已经预处理好的字符串我们用数组rl[i]来记录以字符S[i]为中心的最长回文子串向左/右扩张的长度(<strong>注意包括S[i]</strong>)。我们一般对字符串从左往右处理，因此这里定义RL[i]为第i个字符为对称轴的回文串的最右一个字符与字符i的距离。对于上面插入分隔符之后的两个串，可以得到RL数组：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">char:    # a # b # a #</span><br><span class="line"> RL :    <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">4</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span></span><br><span class="line">RL-<span class="number">1</span>:    <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">3</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span></span><br><span class="line">  i :    <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span></span><br><span class="line"></span><br><span class="line">char:    # a # b # b # a #</span><br><span class="line"> RL :    <span class="number">1</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">5</span> <span class="number">2</span> <span class="number">1</span> <span class="number">2</span> <span class="number">1</span></span><br><span class="line">RL-<span class="number">1</span>:    <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">4</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span></span><br><span class="line">  i :    <span class="number">0</span> <span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span> <span class="number">5</span> <span class="number">6</span> <span class="number">7</span> <span class="number">8</span></span><br></pre></td></tr></table></figure>
<p>上面我们还求了一下RL[i]-1。通过观察可以发现，RL[i]-1的值，正是在原本那个没有插入过分隔符的串中，以位置char[i]为对称轴的最长回文串的长度。那么只要我们求出了RL数组，就能得到最长回文子串的长度。</p>
<p><em>于是问题变成了，怎样高效地求的RL数组。基本思路是利用回文串的对称性，扩展回文串。</em></p>
<p>我们再引入一个辅助变量<em>MaxRight，表示当前访问到的所有回文子串，所能触及的最右一个字符的位置</em>。另外还要记录下MaxRight对应的回文串的对称轴所在的位置，记为pos，它们的位置关系如下。<br><img src="/blogimgs/LongestPalindromic/01.png" alt=""><br>我们从左往右地访问字符串来求RL，假设当前访问到的位置为i，即要求RL[i]，在对应上图，i必然是在<code>pos</code>右边的。但我们更关注的是，<em>i是在MaxRight的左边还是右边</em>。我们分情况来讨论。</p>
<p>1、i在MaxRight左边<br>i在左边右分为两种情况，</p>
<ul>
<li>第一种情况用图表示如下<br><img src="/blogimgs/LongestPalindromic/02.png" alt=""></li>
</ul>
<p>我们知道，图中两个红色块之间（包括红色块）的串是回文。并且<em>以i为对称轴的回文串，是与红色块间的回文串有所重叠的</em>。我们找到i关于pos的对称位置j，这个j对应的RL[j]我们是已经算过的。根据回文串的对称性，<em>以i为对称轴的回文串和以j为对称轴的回文串，有一部分是相同的</em>。这里又有两种细分的情况。</p>
<ul>
<li>以j为对称轴的回文串比较短，短到像下图这样(即rl[j] &lt;= maxRigth - i)。<br><img src="/blogimgs/LongestPalindromic/03.png" alt=""><br>这时我们知道RL[i]至少不会小于RL[j]，并且已经知道了部分的以i为中心的回文串，于是可以令RL[i]=RL[j]。但是以i为对称轴的回文串可能实际上更长，因此我们试着以i为对称轴，继续往左右两边扩展，直到左右两边字符不同，或者到达边界。<br>或者看这个图<br><img src="/blogimgs/LongestPalindromic/031.png" alt=""><br>当mx – i &gt;= rl[j], 这时候以S[j]为中心的回文子串包含在以S[id]为中心的回文子串中，由于i和j对称，以S[i]为中心的回文子串必然包含在以S[id]为中心的回文子串中，所以P[i]至少等于p[j], 后面的再继续匹配。</li>
</ul>
<blockquote>
<p>注：上图中其实rl[i]一定等于rl[j],后面不用再匹配了。因为如果rl[i]后面还可以继续匹配，根据对称性，rl[j]也可以继续扩展了</p>
</blockquote>
<ul>
<li>以j为对称轴的回文串很长，像下图(即rl[j] &gt; maxRigth - i)：<br><img src="/blogimgs/LongestPalindromic/04.png" alt=""><br>这时，我们只能确定，两条蓝线之间的部分（即不超过MaxRight的部分）是回文的，于是从这个长度开始，尝试以i为中心向左右两边扩展，，直到左右两边字符不同，或者到达边界。<br>或者看这个图<br><img src="/blogimgs/LongestPalindromic/041.png" alt=""><br>当mx – i &lt; rl[j]，以S[j]为中心的回文子串不完全包含于以S[id]为中心的回文子串中，但是基于对称性可知，上图中两个绿框所包围的部分是相同的，也就是说以S[i]为中心的回文子串，其向右至少会扩张到mx的位置，也就是说rl[i] 至少等于 mx - i，至于mx之后的部分是否对称，就只能老老实实去匹配了。</li>
</ul>
<blockquote>
<p>当i在MaxRight左边时，主要是求chars[i]向右查找回文的初始步长是多少，<em>其实完全可以无论i落在何处，直接将rl[i]初始化为1，然后向右查找。</em>这样分情况讨论只是以免重复计算。</p>
</blockquote>
<p>不论以上哪种情况，之后都要尝试更新MaxRight和pos，因为有可能得到更大的MaxRight。</p>
<p>具体操作如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">step <span class="number">1</span>: 令RL[i]=min(RL[<span class="number">2</span>*pos-i], MaxRight-i)</span><br><span class="line">step <span class="number">2</span>: 以i为中心扩展回文串，直到左右两边字符不同，或者到达边界。</span><br><span class="line">step <span class="number">3</span>: 更新MaxRight和pos</span><br></pre></td></tr></table></figure>
<p>2、当i在MaxRight的右边<br><img src="/blogimgs/LongestPalindromic/05.png" alt=""><br>遇到这种情况，说明以i为对称轴的回文串还没有任何一个部分被访问过，于是只能从i的左右两边开始尝试扩展了，当左右两边字符不同，或者到达字符串边界时停止。然后更新MaxRight和pos。</p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">proString</span><span class="params">(String s)</span></span>&#123;</span><br><span class="line">    StringBuffer stringBuffer = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;s.length(); i++)&#123;</span><br><span class="line">        stringBuffer.append(<span class="string">"#"</span>).append(s.substring(i, i+<span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> stringBuffer.append(<span class="string">"#"</span>).toString();</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">manacher</span><span class="params">(String s)</span></span>&#123;</span><br><span class="line">    String proStr = proString(s);</span><br><span class="line">    <span class="keyword">char</span>[] chars = proStr.toCharArray();</span><br><span class="line">    <span class="keyword">int</span>[] rl = <span class="keyword">new</span> <span class="keyword">int</span>[chars.length];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> pos = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> maxRight = <span class="number">0</span>;</span><br><span class="line">    rl[<span class="number">0</span>] = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;chars.length; i++)&#123;</span><br><span class="line">    	<span class="comment">// 分情况对rl[i]赋初始值</span></span><br><span class="line">        <span class="keyword">if</span> (i &gt; maxRight)&#123;</span><br><span class="line">            rl[i] = <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 2*pos-1 是 pos - (pos - i)</span></span><br><span class="line">            rl[i] = Math.min(rl[<span class="number">2</span> * pos - i], maxRight - i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> ((i - rl[i] &gt;= <span class="number">0</span>) &amp;&amp; (i + rl[i] &lt; chars.length) )&#123;</span><br><span class="line">            <span class="keyword">if</span> (chars[i+rl[i]] == chars[i-rl[i]])&#123;</span><br><span class="line">                <span class="keyword">if</span> (rl[i] &gt;= maxRight)&#123;</span><br><span class="line">                    maxRight = i + rl[i];</span><br><span class="line">                    pos = i;</span><br><span class="line">                &#125;</span><br><span class="line">                rl[i]++;</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> longest = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line">    <span class="comment">// 从rl中找出最大的半径</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;rl.length; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span> (rl[i] &gt; longest )&#123;</span><br><span class="line">            longest = rl[i] - <span class="number">1</span>;</span><br><span class="line">            start = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    StringBuffer stringBuffer = <span class="keyword">new</span> StringBuffer();</span><br><span class="line">    <span class="comment">// 从start为中心，分别向左向右拼字符串</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=longest; i&gt;<span class="number">0</span>; i--)&#123;</span><br><span class="line">        stringBuffer.append(chars[start-i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;longest; i++)&#123;</span><br><span class="line">        stringBuffer.append(chars[start + i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> stringBuffer.toString().replace(<span class="string">"#"</span>,<span class="string">""</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此算法中解决奇偶的方法值得借鉴。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://segmentfault.com/a/1190000003914228" target="_blank" rel="noopener">最长回文子串——Manacher 算法</a><br><a href="http://www.cnblogs.com/TenosDoIt/p/3675788.html" target="_blank" rel="noopener">LeetCode:Longest Palindromic Substring 最长回文子串</a></p>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
            <tag> Longest Palindromic </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之leetcode Longest Substring]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bleetcode%20Longest%20Substring.html</url>
      <content type="html"><![CDATA[<p>给定一个字符串，找到没有重复字符的最长子串的长度。</p>
<p>例如:<br>字符串”abcabcbb”, 最长非重复子串长度是3(“abc”).<br>字符串”pwwkew”, 最长非重复子串长度是3(“wke”).</p>
<h2 id="暴力求解"><a href="#暴力求解" class="headerlink" title="暴力求解"></a>暴力求解</h2><p>简单粗暴的方法就是找到以字母i开头的非重复子串，比较其长度，找到最大的值。代码如下：</p>
<a id="more"></a>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        Map&lt;Character, Integer&gt; hashmap = <span class="keyword">new</span> HashMap&lt;Character, Integer&gt;();</span><br><span class="line">        <span class="keyword">char</span>[] charArr = s.toCharArray();</span><br><span class="line">        <span class="keyword">int</span> lengthest = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;charArr.length; i++)&#123;</span><br><span class="line">            hashmap.put(charArr[i],<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">int</span> length = <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j=i+<span class="number">1</span>; j&lt;charArr.length; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span> (hashmap.containsKey(charArr[j]))&#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                hashmap.put(charArr[j], <span class="number">1</span>);</span><br><span class="line">                length++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (length &gt; lengthest)&#123;</span><br><span class="line">                lengthest = length;</span><br><span class="line">            &#125;</span><br><span class="line">            hashmap.clear();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> lengthest;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以i为前缀，然后遍历i+1，用HashMap存放遍历过的字符。</p>
<h2 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h2><p>通过两个指针start和end来标识一个非重复的子串sub，然后遍历字符串中的每个字符，判断是否在sub中有重复，没有则通过移动end指针，将当前字符加入sub中，有重复的则通过移动start指针对sub的起始位置进行重新标识(<em>可以一个字符一个字符的移动，也可以直接移动到sub中发生重复字符的下一个位置</em>)。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> lengthest = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">char</span>[] charArr = s.toCharArray();</span><br><span class="line">        <span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> end = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> length = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>; i&lt;charArr.length; i++)&#123;</span><br><span class="line">        	<span class="comment">// 遍历当前字符之前的字符串</span></span><br><span class="line">        	<span class="comment">// 记录当前子串的起始位置start</span></span><br><span class="line">        	<span class="comment">// 当前子串的结束位置是正在遍历的第i个字符的前一个位置</span></span><br><span class="line">            end = i - <span class="number">1</span>;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j=start; j&lt;i; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span> (charArr[i] == charArr[j])&#123;</span><br><span class="line">                    length = end - start + <span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">if</span> (length &gt; lengthest)&#123;</span><br><span class="line">                        lengthest = length;</span><br><span class="line">                    &#125;</span><br><span class="line">                    start = j + <span class="number">1</span>;</span><br><span class="line">                    length = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 计算最后一组子串的长度</span></span><br><span class="line">        <span class="comment">// 最后一个字符可能和当前子串组成一个新的非重复子串</span></span><br><span class="line">        <span class="comment">// 也可能独自组成一个非重复的子串</span></span><br><span class="line">        length = charArr.length-<span class="number">1</span> - start + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (length &gt; lengthest)&#123;</span><br><span class="line">            lengthest = length;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> lengthest;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>时间复杂度是n的平方，但是空间复杂度是0，则是否可以通过增加空间复杂度来减少时间复杂度。从代码中可以看到，<em>第二个for循环主要就是从当前子串中查找是否有重复的字符并找到该字符的索引</em>，这明显是一个key/value的结构，则可以使用map，通过O(1)的时间复杂度来找到重复的字符对应的索引。</p>
<p>这种平滑指针的方法也叫<em>平滑窗口</em>，平滑窗口是一个抽象的概念，通常用于解决数组和字符串的问题。<br>下面看下优化后的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> lengthest = <span class="number">0</span>;</span><br><span class="line">        Map&lt;Character, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Character, Integer&gt;();</span><br><span class="line">        <span class="keyword">char</span>[] chars = src.toCharArray();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> start=<span class="number">0</span>,end=<span class="number">0</span>; end&lt;chars.length; end++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (map.containsKey(chars[end]))&#123;</span><br><span class="line">            	<span class="comment">// 出现重复的，则直接将重复字符的下一位赋值给start</span></span><br><span class="line">            	<span class="comment">// 查找重复字符是在start之后，则将重复字符的索引与start进行比较，</span></span><br><span class="line">            	<span class="comment">// 取较大的对start进行赋值</span></span><br><span class="line">                start = Math.max(map.get(chars[end]), start);</span><br><span class="line">            &#125;</span><br><span class="line">            lengthest = Math.max(lengthest, end - start + <span class="number">1</span>);</span><br><span class="line">            <span class="comment">// 直接将end处字符的下一位索引进行赋值</span></span><br><span class="line">            map.put(chars[end], end + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> lengthest;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><p>还有一种思路是动态规划，这也是最优的一种。<br>动态规划往往用于求解最优解(最大值、最短路径、最长公共子序列)问题。</p>
<h3 id="动态规划简介"><a href="#动态规划简介" class="headerlink" title="动态规划简介"></a>动态规划简介</h3><p>动态规划的基本思想与分治法类似，也是将<em>待求解的问题分解为若干个子问题(阶段)</em>。按顺序求解子阶段，<em>前一子问题的解，为后一子问题的求解提供了有用的信息</em>。在<strong>求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解()最优解</strong>。依次解决各子问题，最后一个子问题就是初始问题的解。</p>
<p>动态规划是通过<em>拆分问题</em>，定义<em>问题状态和状态之间的关系</em>，使得问题能够以<em>递推</em>(或者说分治)的方式去解决。则<em>动态规划的本质</em>是<strong>状态的定义</strong>和<strong>状态转移方程</strong></p>
<p>动态规划通过拆分问题，将原始问题拆分为子问题，而各子问题之间的关系是<em>后一子问题的解往往又前一子问题的解求出</em>，则<strong>子问题之间是重叠的(则不是相互独立的)</strong>，为减少重复计算，对每一个子问题只解一次，将其不同阶段的不同状态保存在一个二维数组中。</p>
<p>动态规划与分治法<em>最大的差别</em>是:适合于用动态规划法求解的问题，经分解后得到的子问题往往<em>不是互相独立</em>的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。</p>
<h3 id="适用条件"><a href="#适用条件" class="headerlink" title="适用条件"></a>适用条件</h3><p>能采用动态规划求解的问题的一般要具有3个性质：<br>(1) <strong>最优化原理</strong>：如果问题的最优解所包含的子问题的解也是最优的，就称该问题具有最优子结构，即满足最优化原理。<br>(2) <strong>无后效性</strong>：即某阶段状态一旦确定，就不受这个状态以后决策的影响。也就是说，某状态以后的过程不会影响以前的状态，只与当前状态有关。<br>(3) <strong>有重叠子问题</strong>：即子问题之间是<em>不独立</em>的，一个子问题在下一阶段决策中可能被多次使用到。（该性质并不是动态规划适用的必要条件，但是如果没有这条性质，动态规划算法同其他算法相比就不具备优势）</p>
<p>下面来看下用动态规矩解决此问题的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">lengthOfLongestSubstring</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> lengthest = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">char</span>[] chars = src.toCharArray();</span><br><span class="line">        <span class="comment">// 状态数组</span></span><br><span class="line">        <span class="keyword">int</span>[] dp_status = <span class="keyword">new</span> <span class="keyword">int</span>[chars.length];</span><br><span class="line">        Map&lt;Character, Integer&gt; hashMap = <span class="keyword">new</span> HashMap&lt;Character, Integer&gt;();</span><br><span class="line">        <span class="keyword">int</span> start = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;chars.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span> (hashMap.containsKey(chars[i]))&#123;</span><br><span class="line">                start = Math.max(start, hashMap.get(chars[i]));</span><br><span class="line">                dp_status[i] = i - start + <span class="number">1</span>;</span><br><span class="line">                hashMap.put(chars[i], i+<span class="number">1</span>);</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            hashMap.put(chars[i], i+<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span> (i == <span class="number">0</span>)&#123;</span><br><span class="line">                dp_status[i] = <span class="number">1</span>;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            dp_status[i] = dp_status[i-<span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> length : dp_status)&#123;</span><br><span class="line">            <span class="keyword">if</span> (length &gt; lengthest)&#123;</span><br><span class="line">                lengthest = length;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> lengthest;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过在leetcode上提交代码发现，<em>使用HashMap来查询重复字符的方法貌似没有直接用for循环逐个字符匹配执行的快</em>。</p>
<h2 id="附加：递归与递推"><a href="#附加：递归与递推" class="headerlink" title="附加：递归与递推"></a>附加：递归与递推</h2><p>递归是一个程序调用自身<br>递推就是迭代</p>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
            <tag> Longest Substring </tag>
            
            <tag> Without Repeating Characters </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之leetcode Median of two arrays]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bleetcode%20Median%20of%20two%20arrays.html</url>
      <content type="html"><![CDATA[<p>两个排好序的数组nums1和nums2，长度分别为m和n。找到这两个数组的中位数，如果是偶数，则中位数是上下中位数的平均值。</p>
<p>Example 1:</p>
<blockquote>
<p>nums1 = [1, 3]<br>nums2 = [2]<br>The median is 2.0</p>
</blockquote>
<p>Example 2:</p>
<blockquote>
<p>nums1 = [1, 2]<br>nums2 = [3, 4]<br>The median is (2 + 3)/2 = 2.5</p>
</blockquote>
<h2 id="暴力求解"><a href="#暴力求解" class="headerlink" title="暴力求解"></a>暴力求解</h2><p>按照惯例先来个最简单也最粗暴的方法，将两个数组合并为一个数组，然后根据数组的索引找到中位数。</p>
<a id="more"></a>
<p>由于两个数组都是排好序的，则可以使用两个指针进行一边比较元素的大小一边放入第三个数组中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[] num3 = <span class="keyword">new</span> <span class="keyword">int</span>[nums1.length+nums2.length];</span><br><span class="line">        <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">double</span> median = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span> (i&lt;nums1.length &amp;&amp; j&lt;nums2.length)&#123;</span><br><span class="line">            <span class="keyword">if</span> (nums1[i] &lt; nums2[j])&#123;</span><br><span class="line">                num3[index++] = nums1[i];</span><br><span class="line">                i++;</span><br><span class="line">            &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">                num3[index++] = nums2[j];</span><br><span class="line">                j++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (i &lt; nums1.length)&#123;</span><br><span class="line">            num3[index++] = nums1[i];</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span> (j &lt; nums2.length)&#123;</span><br><span class="line">            num3[index++] = nums2[j];</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (num3.length%<span class="number">2</span> == <span class="number">0</span>)&#123;</span><br><span class="line">            median = (num3[num3.length/<span class="number">2</span>] + num3[num3.length/<span class="number">2</span> - <span class="number">1</span>]) / <span class="number">2.0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            median = num3[num3.length/<span class="number">2</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> median;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="利用折半查找的思想"><a href="#利用折半查找的思想" class="headerlink" title="利用折半查找的思想"></a>利用折半查找的思想</h2><p>在进行思路解读前，先介绍两个概念，</p>
<ul>
<li>概念1：某个数组中有一半的元素不超过数组的中位数，有一半的元素不小于中位数（如果数组中元素个数是偶数，那么这里的一半并不是严格意义的1/2）</li>
<li>概念2：如果我们去掉数组比中位数小的k个数，再去掉比中位数大的k个数，得到的子数组的中位数和原来的中位数相同</li>
</ul>
<h3 id="弯路"><a href="#弯路" class="headerlink" title="弯路"></a>弯路</h3><p>折半的思路是nums1的中位数med1和nums2的中位数med2做比较(<em>如果数组是偶数，则中位数是上中位数和下中位数之和的平均值</em>)，有3中比较结果：<br>1、med1 == med2 则med1就是两个数组的中位数<br>2、med1 &lt; med2 则中位数只可能出现在nums1[nums1.length/2 - 1]~nums[nums1.length]和nums2[0]~nums2[nums2.length - nums1.length/2 - 1]中。<br>3、med1 &gt; med2 则中位数只可能出现在nums1[0]~nums1[nums1.length/2]和nums2[nums2.length-nums1.length/2]~nums2[nums2.length]区间中。</p>
<blockquote>
<p>这里假设nums1的长度小于等于nums2.length，由上面的概念2得知，每次减去的个数应该是两个数组折半的较小值。</p>
</blockquote>
<p>按照这个思路去敲代码，发现代码尼玛越写越长，考虑的情况越来越多，如两个数组一个是奇数一个是偶数；一个数组只有两个元素并且另一个数组只有一个元素，或者另一个数组是多个元素(奇偶也不定)，各种情况中位数都不一样，(<em>网上有很多帖子是用上面的思路解决的，那是因为他们遇到偶数的情况取的中位数是上中位数或者下中位数，而本题中却要上下中位数的平均值，这就要求需要保留并且去比较上下中位数，<strong>因为这两个数字可能来自于同一个数组，也可能来自两个数组</strong>这种情况就比较繁琐，很容易漏掉某种情况</em>)。撸到半夜都没有搞定，感觉可能不是这么回事，还是google下吧。</p>
<h3 id="扩展问题至查找第k个元素"><a href="#扩展问题至查找第k个元素" class="headerlink" title="扩展问题至查找第k个元素"></a>扩展问题至查找第k个元素</h3><p>由于安装上面的思路撸了两百多行代码都没有搞定，感觉必有蹊跷，然后google下，发现有同命相连者，观其思路的核心思想为<br><em>将其转化为去找两个数组的从小到大排的第k个数</em>。<strong>两个数组共有m+n个数，若m+n是奇数，那么就是找第(m+n)/2+1个数，偶数的话就是找第(m+n)/2个数和第(m+n)/2+1个数的平均数</strong>。转换成找第k个元素之后，在二分查找时就避开了奇数偶数情况不同的问题，只管去第k个元素。</p>
<p>具体思路如下：<br>假设要在数组A和数组B中查找第k个数(<em>假设A的长度m不大于B的长度n，这里k一定不大于m+n</em>)。也就是找A和B的第k个数。(<strong>很显然，数列“前x个数中的最后一个数”就是数列的“第x个数”。所以找第x个数和找前x个数是一样的。因为一但确定了前x个数，这些数的最后一个数就是第x个数</strong>)。</p>
<p><em>先假定最终的前k个数中有一半(k/2)在A中，另一半(k-k/2)在B中。当然，如果A中总个数m少于k/2，只好假定最终的前k个数中有m个在A中，另外k-m个在B中。</em></p>
<p><strong>做好上面的假定之后</strong>，根据之前的假定，<em>A中的在前k个数中的元素的最后一个数是第pa个数，B中的在前k个数中的数的最后一个数叫第pb个数</em>。<br>1、<em>如果第pa数等于第pb数</em>，那么最终的前k个数的最后一个数一定等于第pa数（是pa还是pb无所谓了），也就是说最终的第k个数就是第pa数。<br>2、<em>如果第pa数大于第pb数</em>，那么说明，我所假定的B中目前属于前k个数的数确实是属于最终的前k个数，并且后面还有部分数也属于。我所假定的A中目前属于前k个数的数不一定都属于最终的前k个数。好了，于是我就把B中确实是属于最终的前k个数的这pb个数（即第pb和第pb之前的这些数）切掉，变成B’。问题就变为去找A和B’中的前k-pb个数。<br>3、<em>如果第pa数小于第pb数</em>，那么说明，我所假定的A中目前属于前k个数的数确实是属于最终的前k个数，并且后面还有部分数也属于（有可能后面已经没数了）。我所假定的B中目前属于前k个数的数不一定都属于最终的前k个数。好了，于是我就把A中确实是属于最终的前k个数的这pa个数（即第pa和第pa之前的这些数，有可能就是A中所有的数）切掉，变成了A’（可能是空的）。问题变为去找A’和B中的前k-pa个数。</p>
<p>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">findMedianSortedArrays</span><span class="params">(<span class="keyword">int</span>[] nums1, <span class="keyword">int</span>[] nums2)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> length = nums1.length + nums2.length;</span><br><span class="line">        <span class="keyword">if</span> (length % <span class="number">2</span> == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> (findKth(nums1, nums2, length/<span class="number">2</span>) + findKth(nums1, nums2, length/<span class="number">2</span> + <span class="number">1</span>))/<span class="number">2.0</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> findKth(nums1, nums2, length/<span class="number">2</span> + <span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">findKth</span><span class="params">(<span class="keyword">int</span>[] arr1, <span class="keyword">int</span>[] arr2, <span class="keyword">int</span> k)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 编码技巧：在算法中，你会假定许多东西，比如两个同等地位的数组，</span></span><br><span class="line">        <span class="comment">// 假定一个比另一个长，那么在编码的时候，</span></span><br><span class="line">        <span class="comment">// 完全没有必要将对称的情况重写一边对称的代码，而是应该将参数反过来递归调用一次！</span></span><br><span class="line">        <span class="keyword">if</span> (arr1.length &gt; arr2.length)&#123;</span><br><span class="line">            <span class="keyword">return</span> findKth(arr2, arr1, k);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// arr1 为空</span></span><br><span class="line">        <span class="keyword">if</span> (arr1.length == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> arr2[k - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> arr1[<span class="number">0</span>] &gt; arr2[<span class="number">0</span>] ? arr2[<span class="number">0</span>] : arr1[<span class="number">0</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> pos1 = k/<span class="number">2</span> &lt; arr1.length ? k/<span class="number">2</span> : arr1.length;</span><br><span class="line">        <span class="keyword">int</span> pos2 = k - pos1;</span><br><span class="line">        <span class="keyword">if</span> (arr1.length == <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> arr2[k - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (arr1[pos1 - <span class="number">1</span>] &gt; arr2[pos2 - <span class="number">1</span>])&#123;</span><br><span class="line">            <span class="comment">// copyOfRange的区间是[from, to)</span></span><br><span class="line">            arr2 = Arrays.copyOfRange(arr2, pos2, arr2.length);</span><br><span class="line">            <span class="keyword">return</span> findKth(arr1, arr2, k - pos2);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (arr1[pos1 - <span class="number">1</span>] &lt; arr2[pos2 - <span class="number">1</span>])&#123;</span><br><span class="line">            arr1 = Arrays.copyOfRange(arr1, pos1, arr1.length);</span><br><span class="line">            <span class="keyword">return</span> findKth(arr1, arr2, k - pos1);</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> arr1[pos1 - <span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
            <tag> median </tag>
            
            <tag> two arrays </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[NameNode监控用户使用资源]]></title>
      <url>http://bigdatadecode.club/NameNode%E7%9B%91%E6%8E%A7%E7%94%A8%E6%88%B7%E4%BD%BF%E7%94%A8%E8%B5%84%E6%BA%90.html</url>
      <content type="html"><![CDATA[<p>HDFS是Hadoop的基石，对其的使用情况进行监控显的尤为重要。那么怎么来衡量一个用户对hdfs的使用情况呢，用什么来衡量呢？众所周知HDFS是由NameNode和DataNode组成，而NameNode又是HDFS的核心，NameNode中最重要的就是记录整个集群状态的元数据。了解集群的使用情况也就是目前的状态，这些状态记录在元数据中，而元数据中是通过记录各个用户对HDFS的操作来描绘集群的状态，那么是不是可以通过统计各个用户在某个时间段对HDFS的操作数来衡量他们使用HDFS的资源。答案是肯定是，而且此功能已经merge到2.7版本中，下面就来了解下这个<a href="https://issues.apache.org/jira/browse/HDFS-6982" target="_blank" rel="noopener">patch</a>。</p>
<a id="more"></a>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>nntop的架构图如下：<br><img src="/blogimgs/nntop/nntop-architecture.png" alt="nntop架构图" title="nntop架构图"><br>nntop是在NN中的audit loggers中进行拦截，audit log从NN中接收所有user的操作。在audit log中进行拦截能够很好的扩展到其余的NN中。<br>HDFS默认的审计日志是DefaultAuditLogger，nntop是在HDFS中添加了一个新的审计日志类TopAuditLogger，由TopAuditLogger解析审计事件并传送给TopMetrics。TopMetrics中记录每个操作的top user list，TopMetrics也向Hadoop metrics system注册此metrics，实现了getMetrics方法，以便得到当前时间段的top user list。<br>TopMetrics能得到多个时间区间的top users，默认是1m，5m和25m，这是为了弥补没有画图接口。</p>
<h2 id="细节设计"><a href="#细节设计" class="headerlink" title="细节设计"></a>细节设计</h2><p>此功能的主要就是统计每个user的操作数，但是怎么统计呢？这是个问题。</p>
<p>提交patch的这位大神采用的<em>滑动窗口</em>的思想，并把<em>当前窗口分为n个bucket</em>(默认是10)，分别在每个bucket中进行计数，然后对其窗口内的bucket进行求和得到总和。每个bucket有一个时间标识updatetime，当updatetime与now的差值超过了窗口的长度，则将此bucket置0，更新updatetime，窗口也就右移了一个bucket。</p>
<p>这样设计很巧妙没毛病，但是HDFS中的操作类型和用户都很多，统计应该怎样逐级统计呢？又<em>为了弥补此功能没有友好的画图接口，此patch支持对多个时间间隔进行统计</em>，则大神将统计的流程设计为树形结构，统计的入口是TopMetrics，然后TopMetrics会根据设置的需要统计的时间区间个数初始化对应的RollingWindowManager(一个区间一个RollingWindowManager)，RollingWindowManager中又有一个metricsMap，用来记录metrics与RollingWindowMap的映射，RollingWindowMap中又是user和RollingWindow的映射，RollingWindow就是所谓的滑动窗口，里面由n个bucket进行统计。树形图如下：<br><img src="/blogimgs/nntop/统计流程图.png" alt="统计流程" title="统计流程"></p>
<h2 id="代码跟读"><a href="#代码跟读" class="headerlink" title="代码跟读"></a>代码跟读</h2><p>从上图的nntop架构图中可以看出是在写入auditlog之前进行了拦截，也就是在<code>FSNamesystem.logAuditEvent()</code>中进行判断的，logAuditEvent是将该操作在注册的各个auditsLoggers中都记录一边，auditsLoggers是通过<code>initAuditLoggers</code>向nn注册的，看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> List&lt;AuditLogger&gt; <span class="title">initAuditLoggers</span><span class="params">(Configuration conf)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Initialize the custom access loggers if configured.</span></span><br><span class="line">  Collection&lt;String&gt; alClasses = conf.getStringCollection(DFS_NAMENODE_AUDIT_LOGGERS_KEY);</span><br><span class="line">  List&lt;AuditLogger&gt; auditLoggers = Lists.newArrayList();</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// Make sure there is at least one logger installed.</span></span><br><span class="line">  <span class="keyword">if</span> (auditLoggers.isEmpty()) &#123;</span><br><span class="line">    auditLoggers.add(<span class="keyword">new</span> DefaultAuditLogger());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 开启nntop功能时，向auditsLoggers里注册TopAuditLogger</span></span><br><span class="line">  <span class="comment">// 开启的开关由dfs.namenode.top.enabled控制</span></span><br><span class="line">  <span class="comment">// Add audit logger to calculate top users</span></span><br><span class="line">  <span class="keyword">if</span> (topConf.isEnabled) &#123;</span><br><span class="line">    topMetrics = <span class="keyword">new</span> TopMetrics(conf, topConf.nntopReportingPeriodsMs);</span><br><span class="line">    auditLoggers.add(<span class="keyword">new</span> TopAuditLogger(topMetrics));</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> Collections.unmodifiableList(auditLoggers);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由代码可以看出<code>DefaultAuditLogger</code>和<code>TopAuditLogger</code>都向auditsLoggers中注册，则这两个auditLogger的功能应该类似，DefaultAuditLogger只是将操作相关的信息记录在audit-log中，而TopAuditLogger是在记录之前进行了一次metrics的report，此时的metrics是TopMetrics的对象，在构造TopAuditLogger对象时被传入。</p>
<p>TopAuditLogger初始化并向auditsLoggers中注册之后，当有hdfs操作时，会调用<code>FSNamesystem.logAuditEvent()</code>方法对操作进行记录，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">logAuditEvent</span><span class="params">(<span class="keyword">boolean</span> succeeded,</span></span></span><br><span class="line"><span class="function"><span class="params">    UserGroupInformation ugi, InetAddress addr, String cmd, String src,</span></span></span><br><span class="line"><span class="function"><span class="params">    String dst, HdfsFileStatus stat)</span> </span>&#123;</span><br><span class="line">  FileStatus status = <span class="keyword">null</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">for</span> (AuditLogger logger : auditLoggers) &#123;</span><br><span class="line">  	<span class="comment">// DefaultAuditLogger extends HdfsAuditLogger</span></span><br><span class="line">  	<span class="comment">// HdfsAuditLogger implements AuditLogger</span></span><br><span class="line">    <span class="keyword">if</span> (logger <span class="keyword">instanceof</span> HdfsAuditLogger) &#123;</span><br><span class="line">      HdfsAuditLogger hdfsLogger = (HdfsAuditLogger) logger;</span><br><span class="line">      hdfsLogger.logAuditEvent(succeeded, ugi.toString(), addr, cmd, src, dst,</span><br><span class="line">          status, ugi, dtSecretManager);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// TopAuditLogger implements AuditLogger </span></span><br><span class="line">      <span class="comment">// 则此处调用TopAuditLogger的logAuditEvent方法</span></span><br><span class="line">      logger.logAuditEvent(succeeded, ugi.toString(), addr,</span><br><span class="line">          cmd, src, dst, status);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>FSNamesystem.logAuditEvent()</code>中会对auditsLoggers进行遍历，将操作记录在所有的auditsLogger中，通过调用auditsLogger的<code>logAuditEvent</code>方法，看下<code>TopAuditLogger.logAuditEvent</code>方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">logAuditEvent</span><span class="params">(<span class="keyword">boolean</span> succeeded, String userName,</span></span></span><br><span class="line"><span class="function"><span class="params">    InetAddress addr, String cmd, String src, String dst, FileStatus status)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 核心代码</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    topMetrics.report(succeeded, userName, addr, cmd, src, dst, status);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    LOG.error(<span class="string">"An error occurred while reflecting the event in top service, "</span></span><br><span class="line">        + <span class="string">"event: (cmd=&#123;&#125;,userName=&#123;&#125;)"</span>, cmd, userName);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 与DefaultAuditLogger中的logAuditEvent类似</span></span><br><span class="line">  <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">    <span class="keyword">final</span> StringBuilder sb = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">    sb.append(<span class="string">"allowed="</span>).append(succeeded).append(<span class="string">"\t"</span>);</span><br><span class="line">    sb.append(<span class="string">"ugi="</span>).append(userName).append(<span class="string">"\t"</span>);</span><br><span class="line">    sb.append(<span class="string">"ip="</span>).append(addr).append(<span class="string">"\t"</span>);</span><br><span class="line">    sb.append(<span class="string">"cmd="</span>).append(cmd).append(<span class="string">"\t"</span>);</span><br><span class="line">    sb.append(<span class="string">"src="</span>).append(src).append(<span class="string">"\t"</span>);</span><br><span class="line">    sb.append(<span class="string">"dst="</span>).append(dst).append(<span class="string">"\t"</span>);</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">null</span> == status) &#123;</span><br><span class="line">      sb.append(<span class="string">"perm=null"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      sb.append(<span class="string">"perm="</span>);</span><br><span class="line">      sb.append(status.getOwner()).append(<span class="string">":"</span>);</span><br><span class="line">      sb.append(status.getGroup()).append(<span class="string">":"</span>);</span><br><span class="line">      sb.append(status.getPermission());</span><br><span class="line">    &#125;</span><br><span class="line">    LOG.debug(<span class="string">"------------------- logged event for top service: "</span> + sb);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>logAuditEvent在写入audit-log之前先向metrics系统report，report代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">report</span><span class="params">(<span class="keyword">long</span> currTime, String userName, String cmd)</span> </span>&#123;</span><br><span class="line">  LOG.debug(<span class="string">"a metric is reported: cmd: &#123;&#125; user: &#123;&#125;"</span>, cmd, userName);</span><br><span class="line">  userName = UserGroupInformation.trimLoginMethod(userName);</span><br><span class="line">  <span class="comment">// 一个时间区间一个rollingWindowManager</span></span><br><span class="line">  <span class="comment">// 遍历所有的manager，让所有区间中的metrics加1</span></span><br><span class="line">  <span class="keyword">for</span> (RollingWindowManager rollingWindowManager : rollingWindowManagers</span><br><span class="line">      .values()) &#123;</span><br><span class="line">    rollingWindowManager.recordMetric(currTime, cmd, userName, <span class="number">1</span>);</span><br><span class="line">    rollingWindowManager.recordMetric(currTime,</span><br><span class="line">        TopConf.ALL_CMDS, userName, <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中有一个重要的属性需要说一下<code>rollingWindowManagers</code>，rollingWindowManagers是一个key为Integer，value为RollingWindowManager的map，map的长度由<code>dfs.namenode.top.windows.minutes</code>属性的元素个数控制，key的值就是该属性的元素，该属性的值是一个数组，默认是<code>{&quot;1&quot;,&quot;5&quot;,&quot;25&quot;}</code>。此属性代表这我要统计三个时间区间的值，三个区间分别为1分钟、5分钟和25分钟。这样做是为了观察一个趋势。</p>
<p>每个时间区间对应一个<code>RollingWindowManager</code>，而rollingWindowManagers是存放这些manager的map，各个区间具体的metrics统计由各自的manager控制。manager通过调用<code>recordMetric</code>对metrics进行更新，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">recordMetric</span><span class="params">(<span class="keyword">long</span> time, String command, String user, <span class="keyword">long</span> delta)</span> </span>&#123;</span><br><span class="line">  RollingWindow window = getRollingWindow(command, user);</span><br><span class="line">  window.incAt(time, delta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RollingWindow是通过<code>getRollingWindow</code>得到的，从上面统计流程的分析中得知RollingWindow位于统计中的最底层，由RollingWindow进行滑动窗口进行统计，下面看下getRollingWindow代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> RollingWindow <span class="title">getRollingWindow</span><span class="params">(String metric, String user)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ConcurrentHashMap&lt;String, RollingWindowMap&gt; metricMap</span></span><br><span class="line">  RollingWindowMap rwMap = metricMap.get(metric);</span><br><span class="line">  <span class="keyword">if</span> (rwMap == <span class="keyword">null</span>) &#123;</span><br><span class="line">    rwMap = <span class="keyword">new</span> RollingWindowMap();</span><br><span class="line">    RollingWindowMap prevRwMap = metricMap.putIfAbsent(metric, rwMap);</span><br><span class="line">    <span class="keyword">if</span> (prevRwMap != <span class="keyword">null</span>) &#123;</span><br><span class="line">      rwMap = prevRwMap;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  RollingWindow window = rwMap.get(user);</span><br><span class="line">  <span class="keyword">if</span> (window != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> window;</span><br><span class="line">  &#125;</span><br><span class="line">  window = <span class="keyword">new</span> RollingWindow(windowLenMs, bucketsPerWindow);</span><br><span class="line">  RollingWindow prevWindow = rwMap.putIfAbsent(user, window);</span><br><span class="line">  <span class="keyword">if</span> (prevWindow != <span class="keyword">null</span>) &#123;</span><br><span class="line">    window = prevWindow;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> window;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由此代码可以看出RollingWindow、RollingWindowMap、metricsMap和RollingWindowManager的关系，metricsMap是RollingWindowManager的一个属性，metricsMap是ConcurrentHashMap(<em>线程安全</em>)类型，key是操作名，value是RollingWindowMap，而RollingWindowMap也是ConcurrentHashMap类型的map，key是user name，value是RollingWindow。</p>
<p>recordMetric时通过command和user定位到RollingWindow，然后调用RollingWindow.incAt进行累加，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">incAt</span><span class="params">(<span class="keyword">long</span> time, <span class="keyword">long</span> delta)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> bi = computeBucketIndex(time);</span><br><span class="line">  Bucket bucket = buckets[bi];</span><br><span class="line">  <span class="comment">// If the last time the bucket was updated is out of the scope of the</span></span><br><span class="line">  <span class="comment">// rolling window, reset the bucket.</span></span><br><span class="line">  <span class="keyword">if</span> (bucket.isStaleNow(time)) &#123;</span><br><span class="line">    bucket.safeReset(time);</span><br><span class="line">  &#125;</span><br><span class="line">  bucket.inc(delta);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RollingWindow进行metrics累加时，通过当前time定位到某个bucket中，让bucket进行累加。bucket进行累加时先判断当前bucket是否过时，也就是说当前bucket是否还在以当前time为结尾的时间窗口中，不在则进行重置。</p>
<p>定位bucket的代码是在<code>computeBucketIndex</code>中，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">computeBucketIndex</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// time%windwoLenMs 得到time所在window中的偏移量</span></span><br><span class="line">  <span class="keyword">int</span> positionOnWindow = (<span class="keyword">int</span>) (time % windowLenMs);</span><br><span class="line">  <span class="keyword">int</span> bucketIndex = positionOnWindow * buckets.length / windowLenMs;</span><br><span class="line">  <span class="keyword">return</span> bucketIndex;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>计算time所在的bucket时，先计算time所在window的偏移量positionOnWindow<em>(time%windowLenMs)</em>，然后计算每个bucket的时间长度time_length<em>(windowLenMs/buckets.length)</em>，然后让<code>positionOnWindow/time_length</code>就得到了bucketIndex，也就是上面的代码<code>bucketIndex = positionOnWindow * buckets.length / windowLenMs</code></p>
<p>然后调用bucket.isStaleNow判断是否过时，过时则重置。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">isStaleNow</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> utime = updateTime.get();</span><br><span class="line">  <span class="keyword">return</span> time - utime &gt;= windowLenMs;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">safeReset</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// At any point in time, only one thread is allowed to reset the</span></span><br><span class="line">  <span class="comment">// bucket</span></span><br><span class="line">  <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (isStaleNow(time)) &#123;</span><br><span class="line">      <span class="comment">// reset the value before setting the time, it allows other</span></span><br><span class="line">      <span class="comment">// threads to safely assume that the value is updated if the</span></span><br><span class="line">      <span class="comment">// time is not stale</span></span><br><span class="line">      value.set(<span class="number">0</span>);</span><br><span class="line">      updateTime.set(time);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// else a concurrent thread has already reset it: do nothing</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Bucket是RollingWindow的一个内部类，有两个属性value和updateTime，都是<em>AtomicLong</em>类型的，这里需要注意的是updateTime并不是在value每次递增的时候改变，updateTime只改变一次，其实相当于bucket开始计数的startTime，当次startTime与当前时间time的差值大于windowLenMs时，就认为bucket过时了，需要重置。</p>
<h2 id="get统计数据"><a href="#get统计数据" class="headerlink" title="get统计数据"></a>get统计数据</h2><p>通过jmx获得数据的入口函数是getTopUserOpCounts，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">getTopUserOpCounts</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  Date now = <span class="keyword">new</span> Date();</span><br><span class="line">  <span class="comment">// get 统计结果</span></span><br><span class="line">  <span class="comment">// private TopMetrics topMetrics;</span></span><br><span class="line">  <span class="keyword">final</span> List&lt;RollingWindowManager.TopWindow&gt; topWindows =</span><br><span class="line">      topMetrics.getTopWindows();</span><br><span class="line">  Map&lt;String, Object&gt; topMap = <span class="keyword">new</span> TreeMap&lt;String, Object&gt;();</span><br><span class="line">  topMap.put(<span class="string">"windows"</span>, topWindows);</span><br><span class="line">  topMap.put(<span class="string">"timestamp"</span>, DFSUtil.dateToIso8601String(now));</span><br><span class="line">  ObjectMapper mapper = <span class="keyword">new</span> ObjectMapper();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> mapper.writeValueAsString(topMap);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Failed to fetch TopUser metrics"</span>, e);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过TopMetrics.getTopWindows得到</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;TopWindow&gt; <span class="title">getTopWindows</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> monoTime = Time.monotonicNow();</span><br><span class="line">  List&lt;TopWindow&gt; windows = Lists.newArrayListWithCapacity</span><br><span class="line">      (rollingWindowManagers.size());</span><br><span class="line">  <span class="keyword">for</span> (Entry&lt;Integer, RollingWindowManager&gt; entry : rollingWindowManagers</span><br><span class="line">      .entrySet()) &#123;</span><br><span class="line">    TopWindow window = entry.getValue().snapshot(monoTime);</span><br><span class="line">    windows.add(window);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> windows;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>getTopWindows只是遍历rollingWindowManagers得到多个时间段的统计结果，而真正取得topuser的是各个时间区间对应的RollingWindowManager.snapshot。</p>
<p>在跟读snapshot代码之前，先跟读下RollingWindowManager类，此类中有一些内部类，</p>
<blockquote>
<p>首先看下<code>TopWindow</code>、<code>Op</code>和<code>User</code>，这三者的关系是<code>TopWindow</code>中有个属性top，类型<code>List&lt;Op&gt;</code>，<code>Op</code>有一个属性topUsers，类型是<code>List&lt;User&gt;</code>。TopWindow是当前window中各个metrics的一个快照，各个metrics以Op为对象存放在top的list中，list中一个Op就是一个metrics，Op中存放的是操作此metrics的所有user及其操作总次数，Op中的各个user信息是存放在User对象中，User对象中记录着当前user对Op的操作次数。</p>
</blockquote>
<blockquote>
<p>还有两个内部类<code>TopN</code>和<code>NameValuePair</code>，TopN是一个优先级队列(PriorityQueue，关于优先级队列会在随后的blog中进行分析)，存放的元素是NameValuePair对象，NameValuePair实现了<code>Comparable</code>接口，重写compareTo方法，实现NameValuePair对象以value的大小作为比较的依据<em>(NameValuePair中的name是user，value是user对Op的操作次数)</em>。NameValuePair实现了自己定义的compareTo方法之后在TopN的优先级队列中就可以依靠value的值进行排序，则TopN的对象就是操作过Op的所有user的topN排序的结果。</p>
</blockquote>
<p>RollingWindowManager中的内部类的关系屡清楚之后就来看下snapshot代码，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> TopWindow <span class="title">snapshot</span><span class="params">(<span class="keyword">long</span> time)</span> </span>&#123;</span><br><span class="line">  TopWindow window = <span class="keyword">new</span> TopWindow(windowLenMs);</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// metricMap 存放的是 metrics -&gt; RollingWindowMap</span></span><br><span class="line">  <span class="keyword">for</span> (Map.Entry&lt;String, RollingWindowMap&gt; entry : metricMap.entrySet()) &#123;</span><br><span class="line">    String metricName = entry.getKey();</span><br><span class="line">    <span class="comment">// RollingWindowMap 存放的是 username -&gt; RollingWindow</span></span><br><span class="line">    RollingWindowMap rollingWindows = entry.getValue();</span><br><span class="line">    <span class="comment">// 通过metricName和time得到当前window中user的topN</span></span><br><span class="line">    <span class="comment">// 顺序是从小到大，升序</span></span><br><span class="line">    TopN topN = getTopUsersForMetric(time, metricName, rollingWindows);</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> size = topN.size();</span><br><span class="line">    <span class="keyword">if</span> (size == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    Op op = <span class="keyword">new</span> Op(metricName, topN.getTotal());</span><br><span class="line">    window.addOp(op);</span><br><span class="line">    <span class="comment">// Reverse the users from the TopUsers using a stack, </span></span><br><span class="line">    <span class="comment">// since we'd like them sorted in descending rather than ascending order</span></span><br><span class="line">    <span class="comment">// 栈，利用栈先进后出的特点，将topN中的升序变为降序</span></span><br><span class="line">    Stack&lt;NameValuePair&gt; reverse = <span class="keyword">new</span> Stack&lt;NameValuePair&gt;();</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">      reverse.push(topN.poll());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; size; i++) &#123;</span><br><span class="line">      NameValuePair userEntry = reverse.pop();</span><br><span class="line">      <span class="comment">// topN中的NameValuePair以User的形态存放到Op的topUsers list中</span></span><br><span class="line">      User user = <span class="keyword">new</span> User(userEntry.name, Long.valueOf(userEntry.value));</span><br><span class="line">      op.addUser(user);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> window;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>snapshot将当前状态存放在TopWindow中返回，每个Op的topUsers是通过方法<code>getTopUsersForMetric</code>得到的，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> TopN <span class="title">getTopUsersForMetric</span><span class="params">(<span class="keyword">long</span> time, String metricName, </span></span></span><br><span class="line"><span class="function"><span class="params">    RollingWindowMap rollingWindows)</span> </span>&#123;</span><br><span class="line">  TopN topN = <span class="keyword">new</span> TopN(topUsersCnt);</span><br><span class="line">  Iterator&lt;Map.Entry&lt;String, RollingWindow&gt;&gt; iterator =</span><br><span class="line">      rollingWindows.entrySet().iterator();</span><br><span class="line">  <span class="keyword">while</span> (iterator.hasNext()) &#123;</span><br><span class="line">    Map.Entry&lt;String, RollingWindow&gt; entry = iterator.next();</span><br><span class="line">    String userName = entry.getKey();</span><br><span class="line">    RollingWindow aWindow = entry.getValue();</span><br><span class="line">    <span class="comment">// getSum 得到当前window中各个bucket计数的总和</span></span><br><span class="line">    <span class="keyword">long</span> windowSum = aWindow.getSum(time);</span><br><span class="line">    <span class="comment">// do the gc here</span></span><br><span class="line">    <span class="keyword">if</span> (windowSum == <span class="number">0</span>) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"gc window of metric: &#123;&#125; userName: &#123;&#125;"</span>,</span><br><span class="line">          metricName, userName);</span><br><span class="line">      iterator.remove();</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    LOG.debug(<span class="string">"offer window of metric: &#123;&#125; userName: &#123;&#125; sum: &#123;&#125;"</span>,</span><br><span class="line">        metricName, userName, windowSum);</span><br><span class="line">    <span class="comment">// 将NameValuePair放入TopN中，重写offer，对NameValuePair进行排序放入堆中</span></span><br><span class="line">    topN.offer(<span class="keyword">new</span> NameValuePair(userName, windowSum));</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.info(<span class="string">"topN size for command &#123;&#125; is: &#123;&#125;"</span>, metricName, topN.size());</span><br><span class="line">  <span class="keyword">return</span> topN;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="附加"><a href="#附加" class="headerlink" title="附加"></a>附加</h2><ul>
<li><p>window中bucket的个数关系到统计的精度，window中bucket的个数越多，精度越高。<br>解析：window中bucket中的统计次数是以bucket的updateTime为开始时间，则如果window的长度是60s，bucket的个数是6个，则每个bucket的长度是10s。如果从时间0开始统计，则bucket0的updateTime是第0s，bucket1的updateTime是第10s，bucket9的updateTime是第50s，在65时，用户调用getTopUserOpCounts方法统计第65s时的topN user，则当前window应该是5s到65s，可是bucket0统计的时间区间是0-10s，此时bucket0的updateTime已经超过了统计的阈值，bucket0已经过时，则此时统计的区间只能从bucket1，也就是从10s处开始统计，从10s-65s处，<em>也就是少统计了5s，即5s-10s区间中的值</em>，误差是5s，如果从bucket的长度为5s，则统计的结果值就是正确的，不会出现误差，则得出结论，bucket个数越多，则精度越高。但是bucket也不能太多，会损耗性能。</p>
</li>
<li><p>为什么采用滑动窗口</p>
</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://issues.apache.org/jira/browse/HDFS-6982" target="_blank" rel="noopener">Patch地址</a><br><a href="https://issues.apache.org/jira/secure/attachment/12665990/nntop-design-v1.pdf" target="_blank" rel="noopener">HDFS-6982设计文档</a><br><a href="http://blog.csdn.net/androidlushangderen/article/details/52586560" target="_blank" rel="noopener">HDFS nnTop统计功能</a></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> nntop </tag>
            
            <tag> 使用资源 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之leetcode Add Two Numbers]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bleetcode%20Add%20Two%20Numbers.html</url>
      <content type="html"><![CDATA[<p>两个非负整数的列表，每个元素都是一个数字，按照由低位到高位排序，求两个链表中的数相加并已链表的方式返回。</p>
<p>例如：<br>Input: (2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)<br>Output: 7 -&gt; 0 -&gt; 8</p>
<p>这里貌似没有什么高效算法，对两个链表同时遍历相加，并设置一个标识位用来表示是否需要进位。<br><a id="more"></a><br>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * public class ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">addTwoNumbers</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">        ListNode result = <span class="keyword">null</span>;</span><br><span class="line">        Stack&lt;ListNode&gt; stack = <span class="keyword">new</span> Stack&lt;ListNode&gt;(); </span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(l1 != <span class="keyword">null</span> &amp;&amp; l2 != <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = l1.val + l2.val + flag;</span><br><span class="line">            <span class="keyword">int</span> val = sum - <span class="number">10</span>;</span><br><span class="line">            flag = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span>(val &gt;= <span class="number">0</span>)&#123;</span><br><span class="line">                flag = <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                val = sum;</span><br><span class="line">            &#125;</span><br><span class="line">            ListNode nt = <span class="keyword">new</span> ListNode(val);</span><br><span class="line">            stack.push(nt);</span><br><span class="line">            l1 = l1.next;</span><br><span class="line">            l2 = l2.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(l1 != <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = l1.val + flag;</span><br><span class="line">            <span class="keyword">int</span> val = sum - <span class="number">10</span>;</span><br><span class="line">            flag = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span>(val &gt;= <span class="number">0</span>)&#123;</span><br><span class="line">                flag = <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                val = sum;</span><br><span class="line">            &#125;</span><br><span class="line">            ListNode nt = <span class="keyword">new</span> ListNode(val);</span><br><span class="line">            stack.push(nt);</span><br><span class="line">            l1 = l1.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(l2 != <span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = l2.val + flag;</span><br><span class="line">            <span class="keyword">int</span> val = sum - <span class="number">10</span>;</span><br><span class="line">            flag = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">if</span>(val &gt;= <span class="number">0</span>)&#123;</span><br><span class="line">                flag = <span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                val = sum;</span><br><span class="line">            &#125;</span><br><span class="line">            ListNode nt = <span class="keyword">new</span> ListNode(val);</span><br><span class="line">            stack.push(nt);</span><br><span class="line">            l2 = l2.next;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span>(flag &gt; <span class="number">0</span>)&#123;</span><br><span class="line">            ListNode nt = <span class="keyword">new</span> ListNode(<span class="number">1</span>);</span><br><span class="line">            stack.push(nt);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(!stack.empty())&#123;</span><br><span class="line">            ListNode temp = <span class="keyword">null</span>;</span><br><span class="line">            temp = stack.pop();</span><br><span class="line">            <span class="keyword">if</span>(result == <span class="keyword">null</span>)&#123;</span><br><span class="line">                temp.next = <span class="keyword">null</span>;</span><br><span class="line">                result = temp;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                temp.next = result;</span><br><span class="line">                result = temp;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>是不是很长，这里还用到了Stack，用Stack来存放各个链表中的各个ListNode。用Stack主要是为了把各个ListNode按照从后往前的顺序拼成链表。</p>
<blockquote>
<p>链表的组建方式有两种，一种是从后往前建立连接，这样只需要一个指针；另一种是按照从前往后建立连接，此时需要两个指针，一个是指向链头的first指针，并且first在后续中不会发生变化，另一个指针是last，last会根据链表的元素向后移动，last始终指向链表的最后一个元素。</p>
</blockquote>
<p>下面看下从链表头组建链表的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"> * public class ListNode &#123;</span></span><br><span class="line"><span class="comment"> *     int val;</span></span><br><span class="line"><span class="comment"> *     ListNode next;</span></span><br><span class="line"><span class="comment"> *     ListNode(int x) &#123; val = x; &#125;</span></span><br><span class="line"><span class="comment"> * &#125;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> ListNode <span class="title">addTwoNumbers</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">        ListNode first = <span class="keyword">null</span>;</span><br><span class="line">        ListNode last = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">int</span> flag = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">while</span>(l1 != <span class="keyword">null</span> || l2 != <span class="keyword">null</span> || flag != <span class="number">0</span>)&#123;</span><br><span class="line">            <span class="keyword">int</span> sum = flag;</span><br><span class="line">            <span class="keyword">if</span>(l1 != <span class="keyword">null</span>)&#123;</span><br><span class="line">                sum += l1.val;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(l2 != <span class="keyword">null</span>)&#123;</span><br><span class="line">                sum += l2.val;</span><br><span class="line">            &#125;</span><br><span class="line">            flag = sum / <span class="number">10</span>;</span><br><span class="line">            <span class="keyword">int</span> val = sum % <span class="number">10</span>;</span><br><span class="line">            ListNode temp = <span class="keyword">new</span> ListNode(val);</span><br><span class="line">            <span class="keyword">if</span>(first == <span class="keyword">null</span>)&#123;</span><br><span class="line">                first = temp;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(last == <span class="keyword">null</span>)&#123;</span><br><span class="line">                last = temp;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                last.next = temp;</span><br><span class="line">                last = temp;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(l1 != <span class="keyword">null</span>)&#123;</span><br><span class="line">                l1 = l1.next;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(l2 != <span class="keyword">null</span>)&#123;</span><br><span class="line">                l2 = l2.next;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> first;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>虽然这里多声明了一个变量指针，但是相较于第一个代码也算是一种优化，这里不需要额外的空间去存储相加之后的各个ListNode。时间复杂度都一样只是空间复杂度为O(1)</p>
<p>读上面代码链表组建中first和last指针的赋值是不是有一种一头雾水的感觉，得仔细读下才能撸明白，下面看下leetcode上面的解答代码，感觉比较清晰。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> ListNode <span class="title">addTwoNumbers</span><span class="params">(ListNode l1, ListNode l2)</span> </span>&#123;</span><br><span class="line">    ListNode dummyHead = <span class="keyword">new</span> ListNode(<span class="number">0</span>);</span><br><span class="line">    ListNode p = l1, q = l2, curr = dummyHead;</span><br><span class="line">    <span class="keyword">int</span> carry = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (p != <span class="keyword">null</span> || q != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">int</span> x = (p != <span class="keyword">null</span>) ? p.val : <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> y = (q != <span class="keyword">null</span>) ? q.val : <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> sum = carry + x + y;</span><br><span class="line">        carry = sum / <span class="number">10</span>;</span><br><span class="line">        curr.next = <span class="keyword">new</span> ListNode(sum % <span class="number">10</span>);</span><br><span class="line">        curr = curr.next;</span><br><span class="line">        <span class="keyword">if</span> (p != <span class="keyword">null</span>) p = p.next;</span><br><span class="line">        <span class="keyword">if</span> (q != <span class="keyword">null</span>) q = q.next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (carry &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        curr.next = <span class="keyword">new</span> ListNode(carry);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dummyHead.next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>这里声明了一个val为0的dummyHead，使dummyHead作为链表的头节点</strong>，并声明一个移动指针curr也指向该节点，这样在链表创建的过程中不用进行太多的判断，只需移动指针curr即可(<em>这也是链表的一种创建方法，貌似当初学数据结构时教科书就是用这种方法创建链表的</em>)。</p>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
            <tag> add two numbers </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Markdown 及 Sublime Text使用技巧]]></title>
      <url>http://bigdatadecode.club/Markdown%20%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7.html</url>
      <content type="html"><![CDATA[<h1 id="Markdown-及-Sublime-Text使用技巧"><a href="#Markdown-及-Sublime-Text使用技巧" class="headerlink" title="Markdown 及 Sublime Text使用技巧"></a>Markdown 及 Sublime Text使用技巧</h1><p>在已打开的文件中随意跳转</p>
<blockquote>
<p><code>ctrl+p</code>, 然后输入文件名，按<code>Esc</code> 退出该功能</p>
</blockquote>
<p>在浏览器中查看效果</p>
<blockquote>
<p><code>ctrl</code> + <code>shift</code> + <code>p</code> 然后输入<code>mp</code>，选择<code>Preview in Browser</code> then 选择<code>markdown</code></p>
</blockquote>
<p>回车空行表示一段<br><code>#</code>表示一级标题，<code>##</code>表示二级，依次类推，一共六级</p>
<p>强调</p>
<blockquote>
<p>被<code>*</code>或者<code>_</code>包围的内容为斜体，被<code>**</code>或者<code>__</code>包围的内容为黑体</p>
</blockquote>
<p>无序列表</p>
<blockquote>
<p><code>*</code></p>
</blockquote>
<p>有序列表</p>
<blockquote>
<p><code>1</code></p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> markdown </tag>
            
            <tag> sublime text </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之leetcode Two Sum]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bleetcode%20Two%20Sum.html</url>
      <content type="html"><![CDATA[<p>给定一个整形数组和一个整数n，从数组中找到两个数的索引使这两个数之和等于n，以数组的形式返回这两个数的索引。(假设数组中只存在一组这样的数)</p>
<p>例如：<br>Given nums = [2, 7, 11, 15], target = 9,</p>
<p>Because nums[0] + nums[1] = 2 + 7 = 9,<br>return [0, 1].<br><a id="more"></a></p>
<h2 id="循环遍历"><a href="#循环遍历" class="headerlink" title="循环遍历"></a>循环遍历</h2><p>首先映入脑海的解决方案，逐步遍历数组中的每个元素，查找是否存在。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] result = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt; nums.length; i++)   &#123;</span><br><span class="line">            <span class="keyword">int</span> first = nums[i];</span><br><span class="line">            result[<span class="number">0</span>] = i;</span><br><span class="line">            <span class="keyword">int</span> second = target - first;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i+<span class="number">1</span>; j&lt;nums.length; j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(second == nums[j])&#123;</span><br><span class="line">                    result[<span class="number">1</span>] = j;</span><br><span class="line">                    <span class="keyword">break</span>;    </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(result[<span class="number">1</span>] != <span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>代码中涉及两个for循环，注意到第二个for循环其实是在剩余的数组元素中<em>查找是否存在目标数字second</em>，则可以想到如果数组是有序的，则可以使用二分查找来提高效率。</p>
<blockquote>
<p>则对上面思路的一种改进是假如数组是无序的，则先使用快排对其进行排序，然后遍历数组中的每一个元素，使用二分查找再数组中查看是否存在second，存在则找到second对应的索引i。</p>
</blockquote>
<h2 id="使用hashmap进行改进"><a href="#使用hashmap进行改进" class="headerlink" title="使用hashmap进行改进"></a>使用hashmap进行改进</h2><p>从上面的思路中可以看出第一个for循环是不可少的，第二个for循环其实是充当一个查找的功能，则可以使用二分查找进行改进，但是是否可以借助别的数据结构使其能够更快的找到second的索引i。</p>
<p>目的是能够快速的找到second对应的索引i，则second和i是一一对应的关系，存放这种关系的数据结构很容易想到HashMap，<em>也就是将数组中的元素和索引放入map中，元素作为key，这样直接去map中get key对应的value就ok了</em>。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; numsMap = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">null</span> == numsMap.get(nums[i]))&#123;</span><br><span class="line">                numsMap.put(nums[i], i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span>[] result = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.length; i++)&#123;</span><br><span class="line">            Integer j = numsMap.get(target - nums[i]);</span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">null</span> != j)&#123;</span><br><span class="line">                <span class="keyword">if</span>(j &lt; i)&#123;</span><br><span class="line">                    result[<span class="number">0</span>] = j;</span><br><span class="line">                    result[<span class="number">1</span>] = i;</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(j &gt; i)&#123;</span><br><span class="line">                    result[<span class="number">0</span>] = i;</span><br><span class="line">                    result[<span class="number">1</span>] = j;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于上述代码依然可以精简，但只是精简代码行数而已，并不能提高时间复杂度。</p>
<p>精简的方法是在第一遍遍历数组的时候就对HashMap进行判断，找到则退出，没有找到则继续循环。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] twoSum(<span class="keyword">int</span>[] nums, <span class="keyword">int</span> target) &#123;</span><br><span class="line">        Map&lt;Integer, Integer&gt; numsMap = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line">        <span class="keyword">int</span>[] result = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">2</span>];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;nums.length; i++)&#123;</span><br><span class="line">            <span class="keyword">int</span> second = target - nums[i];</span><br><span class="line">            <span class="keyword">if</span>(numsMap.containsKey(second))&#123;</span><br><span class="line">                Integer j = numsMap.get(second);</span><br><span class="line">                <span class="keyword">if</span>(j &lt; i)&#123;</span><br><span class="line">                    result[<span class="number">0</span>] = j;</span><br><span class="line">                    result[<span class="number">1</span>] = i;</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(j &gt; i)&#123;</span><br><span class="line">                    result[<span class="number">0</span>] = i;</span><br><span class="line">                    result[<span class="number">1</span>] = j;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">null</span> == numsMap.get(nums[i]))&#123;</span><br><span class="line">                numsMap.put(nums[i], i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>遇到此题首先想到的是使用循环遍历找到两个数的索引，其次在遍历的过程中发现第二个for循环其实是遍历查找的功能，说到查找的优化很容易想到的就是二分查找，然后查看是否可以用二分查找，如果不可以则去创造条件使其满足二分查找的条件。</p>
<p>再者<em>在数组中查找一个数是否在数组中，使用hash映射查找只需O(1)的时间复杂度</em>，则构建一个HashMap，使用hash映射查找优化二分查找。</p>
<blockquote>
<p>注意，并不是在任何情况下构建HashMap进行查找都会比二分查找要快。因为构建HashMap需要O(n)的时间复杂度去遍历数组。</p>
</blockquote>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> leetcode </tag>
            
            <tag> Two Sum </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[数据结构算法之n的平方根保留m位小数]]></title>
      <url>http://bigdatadecode.club/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E7%AE%97%E6%B3%95%E4%B9%8Bn%E7%9A%84%E5%B9%B3%E6%96%B9%E6%A0%B9%E4%BF%9D%E7%95%99m%E4%BD%8D%E5%B0%8F%E6%95%B0.html</url>
      <content type="html"><![CDATA[<p>求n的平方根x，x精确到m位小数。例如求n精确到小数点后4位的平方根。</p>
<p>思路：</p>
<blockquote>
<p>求n的平方根x，则首先想到的是可不可以从1开始，分别求1、2、3等的平方，看是否等于n。这里就有个问题我为什么首先从1开始，而且为什么各个数的步长为1？也就是说我们应该从哪里开始去试，每次去试时，各个数的步长应该怎么选？</p>
</blockquote>
<p>从上面的分析中得出求n的平方根其实就是从小于n的数中找到x，使x*x等于n，这就变成了一个查找的问题，而且是在有序数据集中查找，则最容易想到的就是二分查找，则从哪里开始去试，每次去试时，各个数的步长问题就都解决了。</p>
<p>下面看下二分查找的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(<span class="keyword">int</span>[] arr, <span class="keyword">int</span> target)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> high = arr.length-<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (low &lt;= high)&#123;</span><br><span class="line">        <span class="keyword">int</span> mid = (low + high) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span> (target &gt; arr[mid])&#123;</span><br><span class="line">            low = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (target &lt; arr[mid])&#123;</span><br><span class="line">            high = mid - <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">return</span> mid;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="使用二分查找找到平方根的范围然后递增步长"><a href="#使用二分查找找到平方根的范围然后递增步长" class="headerlink" title="使用二分查找找到平方根的范围然后递增步长"></a>使用二分查找找到平方根的范围然后递增步长</h2><p>对于一个数的平方根能够找到该跟的范围，即<em>x<em>x &lt; n &lt; y</em>y</em>，则n的平方根在x和y之间，且<em>x+1=y</em>。<br>找到平方根所在的区域之后，把所要保留的<em>精度的平方根</em>做为步长对x进行递增，直到<em>|n-x*x|&lt;0.0001(精度)</em>为止。</p>
<p>例如求12的平方根，精度为小数点后2位。代码示例如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">sqrtByInc</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">double</span> precision)</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> low = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> high = n;</span><br><span class="line">    <span class="keyword">int</span> mid = (low + high) / <span class="number">2</span>;</span><br><span class="line">    <span class="comment">// 二分查找找到平方根的区域</span></span><br><span class="line">    <span class="keyword">while</span> (low &lt;= high)&#123;</span><br><span class="line">        <span class="keyword">if</span> (mid * mid &gt; n)&#123;</span><br><span class="line">            high = mid - <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (mid * mid &lt; n)&#123;</span><br><span class="line">            <span class="keyword">if</span> ((mid+<span class="number">1</span>)*(mid+<span class="number">1</span>) &gt; n)&#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            low = mid + <span class="number">1</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mid = (low + high) / <span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 按照精度的平方根做为步长</span></span><br><span class="line">    <span class="keyword">double</span> r = mid;</span><br><span class="line">    <span class="keyword">while</span> (Math.abs(n-r*r) &gt; <span class="number">0.0001</span>)&#123;</span><br><span class="line">        <span class="keyword">if</span> (r * r &lt; n)&#123;</span><br><span class="line">            r += <span class="number">0.01</span>;</span><br><span class="line">            r = BigDecimal.valueOf(r).setScale(<span class="number">2</span>, RoundingMode.HALF_UP).doubleValue();</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;	</span><br><span class="line">    <span class="keyword">return</span> r;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><p>上面的方法只是用二分查找找到平方根的范围，然后递增步长进行尝试，虽然能够快速找到根的范围，但是递增步长将是一个漫长的等待。</p>
<p>由<em>|n-x*x|&lt;0.0001(精度)</em>可得n的平方根减去x小于0.01，n的平方根和x都是根的候选者，则只要只要两个候选者的差值小于0.01，则x就是所要求的平方根。这样就可以直接使用二分查找进行查找。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">sqrt</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">double</span> precision)</span></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> start = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">double</span> end = (<span class="keyword">double</span>) n;</span><br><span class="line">    <span class="keyword">double</span> last = end;</span><br><span class="line">    <span class="keyword">double</span> mid = (start + end) / <span class="number">2.0</span>;</span><br><span class="line">    <span class="keyword">while</span> (Math.abs(last - mid) &gt; precision)&#123;</span><br><span class="line">        <span class="keyword">if</span> (mid * mid &gt; n)&#123;</span><br><span class="line">            end = mid;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            start = mid;</span><br><span class="line">        &#125;</span><br><span class="line">        last = mid;</span><br><span class="line">        mid = (start + end) / <span class="number">2.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    DecimalFormat df = <span class="keyword">new</span> DecimalFormat(<span class="string">"0.00"</span>);</span><br><span class="line">    <span class="keyword">return</span> df.format(mid);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="迭代计算平方根"><a href="#迭代计算平方根" class="headerlink" title="迭代计算平方根"></a>迭代计算平方根</h2><p>对于这种数学类型的问题，使用数学公式应该是最快的。求n的平方根有一个公式可以使用，叫牛顿迭代法。<br>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">SqrtByNewton</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">double</span> precision)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> val = n; <span class="comment">//最终</span></span><br><span class="line">    <span class="keyword">double</span> last; <span class="comment">//保存上一个计算的值</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">    &#123;</span><br><span class="line">        last = val;</span><br><span class="line">        val =(val + n/val) / <span class="number">2</span>;</span><br><span class="line">    &#125;<span class="keyword">while</span>(Math.abs(val-last) &gt; precision);</span><br><span class="line">    <span class="keyword">return</span> val;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> algorithm </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 算法 </tag>
            
            <tag> 平方根 </tag>
            
            <tag> m位小数 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS中LightWeightGSet与HashMap结构解析]]></title>
      <url>http://bigdatadecode.club/HDFS%E4%B8%ADLightWeightGSet%E4%B8%8EHashMap%E7%BB%93%E6%9E%84%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p>看见HashMap我就想起了一道HashMap的面试题，先来瞅下这个面试题：<br>HashMap和HashTable的区别？</p>
<ol>
<li>HashMap是非线程安全的，HashTable是线程安全的。</li>
<li>HashMap的键值都可以为null，HashTable则不行。</li>
<li>HashMap是非线程安全的则效率会高于HashTable，这也是一般都用HashMap的原因。</li>
</ol>
<p>深入的问题，Java中另一个线程安全的与HashMap类似的类是？<br>ConcurrentHashMap也是一个线程安全类，与HashTable不同的是提供的锁机制不一样(与SynchronizedMap也不一样)<br>HashTable中采用的锁机制是一次锁住整个hash表，从而同一时刻只能由一个线程对其进行操作；<br>ConcurrentHashMap是一次锁住一个桶，hash表默认是16个桶，诸如get、put、remove等操作只锁住当前需要的桶。</p>
<p>上面简单回忆了下HashMap，下面说下LightWeightGSet，LightWeightGSet是HDFS中的一个数据结构，类似HashMap，用来存储block和副本所在dn的映射，是Namenode中存储全部数据块信息类BlocksMap的一个重要的数据结构。</p>
<p>LightWeightGSet使用数组来存储元素，使用链表来解决冲突，非线程安全。<em>这点与HashMap类似，但是LightWeightGSet中数组的大小不会发生变化，而HashMap会根据其内部空间利用率对数组的大小进行再分配，进行重新哈希分区</em>。再者就是LightWeightGSet不能存null元素。</p>
<a id="more"></a>
<p>下面从源码角度对比一下LightWeightGSet和HashMap的区别。</p>
<h2 id="LightWeightGSet和HashMap的初始化"><a href="#LightWeightGSet和HashMap的初始化" class="headerlink" title="LightWeightGSet和HashMap的初始化"></a>LightWeightGSet和HashMap的初始化</h2><h3 id="接口实现"><a href="#接口实现" class="headerlink" title="接口实现"></a>接口实现</h3><p>LightWeightGSet实现了GSet接口，HashMap实现了Map接口。其中GSet和Map接口分别定义了键映射到值的规则。</p>
<h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>LightWeightGSet只有一个构造函数，初始化时传入数组的大小，在BlocksMap中初始化代码如下：<br><code>blocks = new LightWeightGSet&lt;Block, BlockInfo&gt;(capacity)</code></p>
<p>HashMap提供了三个构造函数：<br>HashMap()：构造一个具有默认初始容量(16)和默认loadFactor(0.75)的空HashMap。<br>HashMap(int initialCapacity)：构造一个带指定初始容量和默认loadFactor(0.75)的空HashMap。<br>HashMap(int initialCapacity, float loadFactor)：构造一个带指定初始容量和loadFactor的空HashMap。</p>
<p>在这里提到了两个参数：初始容量，loadFactor。这两个参数是影响HashMap性能的重要参数，其中容量表示哈希表中桶的数量，初始容量是创建哈希表时的容量，<em>loadFactor是哈希表在其容量自动增加之前可以达到多满的一种尺度</em>，它衡量的是一个散列表的空间的使用程度，loadFactor越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。系统默认负载因子为0.75，一般情况下我们是无需修改的。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>我们知道在Java中最常用的两种结构是数组和模拟指针(引用)，几乎所有的数据结构都可以利用这两种来组合实现，HashMap和LightWeightGSet就是如此。</p>
<p>数组的特点：连续空间，寻址迅速，但是在删除或者添加元素的时候需要有较大幅度移动，<em>所以查询速度快，增删较慢</em>。<br>链表正好相反，由于空间不连续，寻址困难，增删元素只需修改指针，<em>所以查询慢，增删快</em>。</p>
<h3 id="HashMap数据结构"><a href="#HashMap数据结构" class="headerlink" title="HashMap数据结构"></a>HashMap数据结构</h3><p>实际上HashMap和LightWeightGSet都是一个“链表散列”，如下是HashMap数据结构：<br><img src="/blogimgs/LightWeightGSet与HashMap/hashmap结构.png" alt="HashMap数据结构" title="HashMap数据结构"><br>从上图我们可以看出HashMap底层实现还是数组，只是数组的每一项都是一条链。其中参数initialCapacity就代表了该数组的长度。下面为HashMap构造函数的源码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//初始容量不能&lt;0</span></span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span></span><br><span class="line">                + initialCapacity);</span><br><span class="line">    <span class="comment">//初始容量不能 &gt; 最大容量值，HashMap的最大容量值为2^30</span></span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">        initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">    <span class="comment">//负载因子不能 &lt; 0</span></span><br><span class="line">    <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span></span><br><span class="line">                + loadFactor);</span><br><span class="line">    <span class="comment">// 计算出大于 initialCapacity 的最小的 2 的 n 次方值。</span></span><br><span class="line">    <span class="keyword">int</span> capacity = <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// 这里保证了table数组的长度是2的n次方，这样会出现传入的initialCapacity比实际</span></span><br><span class="line">    <span class="keyword">while</span> (capacity &lt; initialCapacity)     </span><br><span class="line">        <span class="comment">// 分配的capacity小。这样的好处是在利用hash寻址时方便，快速，且key分布均匀</span></span><br><span class="line">        capacity &lt;&lt;= <span class="number">1</span>;                    </span><br><span class="line">    <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">    <span class="comment">//设置HashMap的容量极限，当HashMap的容量达到该极限时就会进行扩容操作</span></span><br><span class="line">    threshold = (<span class="keyword">int</span>) (capacity * loadFactor);</span><br><span class="line">    <span class="comment">//初始化table数组</span></span><br><span class="line">    table = <span class="keyword">new</span> Entry[capacity];</span><br><span class="line">    init();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从源码中可以看出，每次新建一个HashMap时，都会初始化一个table数组。table数组的元素为Entry节点。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> K key;</span><br><span class="line">    V value;</span><br><span class="line">    Entry&lt;K,V&gt; next;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Creates new entry.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    Entry(<span class="keyword">int</span> h, K k, V v, Entry&lt;K,V&gt; n) &#123;</span><br><span class="line">        value = v;</span><br><span class="line">        next = n;</span><br><span class="line">        key = k;</span><br><span class="line">        hash = h;</span><br><span class="line">    &#125;</span><br><span class="line">    .......</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中Entry为HashMap的内部类，它包含了键key、值value、下一个节点next，以及hash值（这个hash值是key的hash赋值的），这是非常重要的，正是由于Entry才构成了table数组的项为链表。</p>
<h3 id="LightWeightGSet数据结构"><a href="#LightWeightGSet数据结构" class="headerlink" title="LightWeightGSet数据结构"></a>LightWeightGSet数据结构</h3><p>先来看下LightWeightGSet的构造函数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LightWeightGSet</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> recommended_length)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> actual = actualArrayLength(recommended_length);</span><br><span class="line">  ...</span><br><span class="line">  entries = <span class="keyword">new</span> LinkedElement[actual];</span><br><span class="line">  hash_mask = entries.length - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由代码可以看出LightWeightGSet的数据结构和HashMap类似，LightWeightGSet初始化时会创建一个LinkedElement类型的数组，LinkedElement是LightWeightGSet的内部接口，由此解决了元素的冲突问题，使冲突的元素形成一个链表。<em>BlocksMap的结构中通过BlockInfo实现LinkedElement接口，通过nextLinkedElement连接下一个BlockInfo</em>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">interface</span> <span class="title">LinkedElement</span> </span>&#123;</span><br><span class="line">  <span class="comment">/** Set the next element. */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setNext</span><span class="params">(LinkedElement next)</span></span>;</span><br><span class="line">  <span class="comment">/** Get the next element. */</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> LinkedElement <span class="title">getNext</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>LightWeightGSet与HashMap类似，都是创建一个数组，LightWeightGSet的数组中存储LinkedElement类型的元素，HashMap的数组中存储Entry类型的元素，这些元素都会将key冲突的元素通过引用连成一个链表。</p>
<p>上面简单分析了LightWeightGSet和HashMap的数据结构，下面将探讨他们是如何实现快速存取的。</p>
<h2 id="存储实现put"><a href="#存储实现put" class="headerlink" title="存储实现put"></a>存储实现put</h2><p>分别看下LightWeightGSet和HashMap的put方法<br><code>LightWeightGSet.put</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// LightWeightGSet</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">put</span><span class="params">(<span class="keyword">final</span> E element)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//validate element</span></span><br><span class="line">  <span class="keyword">if</span> (element == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">"Null element is not supported."</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!(element <span class="keyword">instanceof</span> LinkedElement)) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HadoopIllegalArgumentException(</span><br><span class="line">        <span class="string">"!(element instanceof LinkedElement), element.getClass()="</span></span><br><span class="line">        + element.getClass());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">final</span> LinkedElement e = (LinkedElement)element;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//find index</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> index = getIndex(element);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//remove if it already exists</span></span><br><span class="line">  <span class="keyword">final</span> E existing = remove(index, element);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//insert the element to the head of the linked list</span></span><br><span class="line">  modification++;</span><br><span class="line">  size++;</span><br><span class="line">  e.setNext(entries[index]);</span><br><span class="line">  entries[index] = e;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> existing;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>HashMap.put</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//当key为null，调用putForNullKey方法，保存null与table第一个位置中，这是HashMap允许为null的原因</span></span><br><span class="line">        <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> putForNullKey(value);</span><br><span class="line">        <span class="comment">//计算key的hash值</span></span><br><span class="line">        <span class="keyword">int</span> hash = hash(key.hashCode());           </span><br><span class="line">        <span class="comment">//计算key hash 值在 table 数组中的位置</span></span><br><span class="line">        <span class="keyword">int</span> i = indexFor(hash, table.length); </span><br><span class="line">        <span class="comment">//从i出开始迭代 e,找到 key 保存的位置</span></span><br><span class="line">        <span class="keyword">for</span> (Entry&lt;K, V&gt; e = table[i]; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">            Object k;</span><br><span class="line">            <span class="comment">//判断该条链上是否有hash值相同的(key相同)</span></span><br><span class="line">            <span class="comment">//若存在相同，则直接覆盖value，返回旧value</span></span><br><span class="line">            <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123;</span><br><span class="line">                V oldValue = e.value;    <span class="comment">//旧值 = 新值</span></span><br><span class="line">                e.value = value;</span><br><span class="line">                e.recordAccess(<span class="keyword">this</span>);</span><br><span class="line">                <span class="keyword">return</span> oldValue;     <span class="comment">//返回旧值            </span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//修改次数增加1</span></span><br><span class="line">        modCount++;</span><br><span class="line">        <span class="comment">//将key、value添加至i位置处       </span></span><br><span class="line">        addEntry(hash, key, value, i);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">int</span> bucketIndex)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 保存“bucketIndex”位置的值到“e”中</span></span><br><span class="line">    Entry&lt;K,V&gt; e = table[bucketIndex];</span><br><span class="line">    <span class="comment">// 设置“bucketIndex”位置的元素为“新Entry”，</span></span><br><span class="line">    <span class="comment">// 设置“e”为“新Entry的下一个节点”</span></span><br><span class="line">    table[bucketIndex] = <span class="keyword">new</span> Entry&lt;K,V&gt;(hash, key, value, e);</span><br><span class="line">    <span class="comment">// 若HashMap的实际大小 不小于 “阈值”，则调整HashMap的大小</span></span><br><span class="line">    <span class="keyword">if</span> (size++ &gt;= threshold)</span><br><span class="line">        resize(<span class="number">2</span> * table.length);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>两个put都是先对element进行校验，然后拿到key对应数组的index，其index都是对key取hashcode值与<em>运算因</em>子进行&amp;操作得出的。两部分代码如下：<br><em>LightWeightGSet</em></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">getIndex</span><span class="params">(<span class="keyword">final</span> K key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> key.hashCode() &amp; hash_mask;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// BlockInfo.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Super implementation is sufficient</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">super</span>.hashCode();</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Block.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">//GenerationStamp is IRRELEVANT and should not be used here</span></span><br><span class="line">  <span class="keyword">return</span> (<span class="keyword">int</span>)(blockId^(blockId&gt;&gt;&gt;<span class="number">32</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>HashMap</em></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(<span class="keyword">int</span> h)</span> </span>&#123; </span><br><span class="line">	h ^= (h &gt;&gt;&gt; <span class="number">20</span>) ^ (h &gt;&gt;&gt; <span class="number">12</span>); </span><br><span class="line">	<span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">7</span>) ^ (h &gt;&gt;&gt; <span class="number">4</span>); </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">indexFor</span><span class="params">(<span class="keyword">int</span> h, <span class="keyword">int</span> length)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> h &amp; (length-<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这里重点说下<em>运算因子</em>，LightWeightGSet的运算因子是<em>hash_mask</em>，在构造函数中赋值，<code>hash_mask = entries.length - 1</code>，是entries数组长度减一。HashMap的运算因子也是entry数组的长度减一。之所以这样是为了让数据在LightWeightGSet和HashMap中的分布尽量均匀(最好每项都只有一个元素，这样就可以直接找到)，不能太紧也不能太松，太紧会导致查询速度慢，太松则浪费空间。</p>
<p>由于LightWeightGSet和HashMap底层数组的长度都是2的n次方，LightWeightGSet中数组的长度计算如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">actualArrayLength</span><span class="params">(<span class="keyword">int</span> recommended)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (recommended &gt; MAX_ARRAY_LENGTH) &#123;</span><br><span class="line">    <span class="keyword">return</span> MAX_ARRAY_LENGTH;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (recommended &lt; MIN_ARRAY_LENGTH) &#123;</span><br><span class="line">    <span class="keyword">return</span> MIN_ARRAY_LENGTH;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> a = Integer.highestOneBit(recommended);</span><br><span class="line">    <span class="keyword">return</span> a == recommended? a: a &lt;&lt; <span class="number">1</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>HashMap中数组的长度计算为<code>capacity &lt;&lt;= 1</code>。则使用<code>h&amp;(length - 1)</code>对length取模。同时运算因子<code>length-1</code>还有一个非常重要的责任：<strong>均匀分布table数据和充分利用空间</strong>。</p>
<blockquote>
<p>当length为2的n次方时，h&amp;(length - 1)就相当于对length取模(只有具备length为2的n次方的条件时，才成立)，也就是h%length，而且速度比直接取模(%)快得多，这是HashMap在速度上的一个优化。</p>
</blockquote>
<p>得到key对应的index之后，进行查重put，LightWeightGSet通过<code>remove</code>方法进行查重，如果链表中的第一个元素不等于此值，则遍历该链表，查看是否有相同值，有则删除。如果等于链表中的第一个值则直接删除。LightWeightGSet的插入链表操作比较简单，直接调用<code>setNext</code>方法指向下一个元素，并将此值放入index处就可以了(这里实际存储的是BlockInfo对象，BlockInfo实现了<code>LightWeightGSet.LinkedElement</code>接口，并且声明了一个<code>nextLinkedElement</code>属性，该属性是下一个元素的引用)。remove代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> E <span class="title">remove</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> index, <span class="keyword">final</span> K key)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (entries[index] == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (entries[index].equals(key)) &#123;</span><br><span class="line">  	<span class="comment">// 等于链表中的第一个元素</span></span><br><span class="line">    <span class="comment">//remove the head of the linked list</span></span><br><span class="line">    modification++;</span><br><span class="line">    size--;</span><br><span class="line">    <span class="comment">// 得到index处的值</span></span><br><span class="line">    <span class="keyword">final</span> LinkedElement e = entries[index];</span><br><span class="line">    <span class="comment">// 将index指向下一个元素</span></span><br><span class="line">    entries[index] = e.getNext();</span><br><span class="line">    <span class="comment">// 将元素e从链表中移除</span></span><br><span class="line">    e.setNext(<span class="keyword">null</span>);</span><br><span class="line">    <span class="keyword">return</span> convert(e);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">//head != null and key is not equal to head</span></span><br><span class="line">    <span class="comment">//search the element</span></span><br><span class="line">    <span class="comment">// 如果不等于第一个元素则遍历该链表查找是否有相同值</span></span><br><span class="line">    LinkedElement prev = entries[index];</span><br><span class="line">    <span class="keyword">for</span>(LinkedElement curr = prev.getNext(); curr != <span class="keyword">null</span>; ) &#123;</span><br><span class="line">      <span class="keyword">if</span> (curr.equals(key)) &#123;</span><br><span class="line">        <span class="comment">//found the element, remove it</span></span><br><span class="line">        modification++;</span><br><span class="line">        size--;</span><br><span class="line">        prev.setNext(curr.getNext());</span><br><span class="line">        curr.setNext(<span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">return</span> convert(curr);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        prev = curr;</span><br><span class="line">        curr = curr.getNext();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//element not found</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>HashMap是在put中实现，若该位置没有元素，则直接插入。否则迭代该处元素链表并依此比较其key的hash值。如果两个hash值相等且key值相等<code>(e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k)))</code>,则用新的Entry的value覆盖原来节点的value。如果两个hash值相等但key值不等 ，则将该节点插入该链表的链头。具体的实现过程见addEntry方法，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addEntry</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">int</span> bucketIndex)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//获取bucketIndex处的Entry</span></span><br><span class="line">    Entry&lt;K, V&gt; e = table[bucketIndex];</span><br><span class="line">    <span class="comment">//将新创建的Entry放入bucketIndex 索引处，并让新的Entry指向原来的Entry </span></span><br><span class="line">    table[bucketIndex] = <span class="keyword">new</span> Entry&lt;K, V&gt;(hash, key, value, e);</span><br><span class="line">    <span class="comment">//若HashMap中元素的个数超过极限了，则容量扩大两倍</span></span><br><span class="line">    <span class="keyword">if</span> (size++ &gt;= threshold)</span><br><span class="line">        resize(<span class="number">2</span> * table.length);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里需要注意一点，<em>LightWeightGSet不会根据数据的多少而进行二次扩容</em>，<em>而HashMap会有个临界点来触发扩容</em>。该临界点在当HashMap中元素的数量等于table数组长度*加载因子。但是扩容是一个非常耗时的过程，因为它需要重新计算这些数据在新table数组中的位置并进行复制处理。所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。</p>
<h2 id="读取实现get"><a href="#读取实现get" class="headerlink" title="读取实现get"></a>读取实现get</h2><p>get就比较简单，都是通过key的hash值找到在底层数组的index，然后遍历该链表找到key对应的value。<br><code>LightWeightGSet.get</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">get</span><span class="params">(<span class="keyword">final</span> K key)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//validate key</span></span><br><span class="line">  <span class="keyword">if</span> (key == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">"key == null"</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//find element</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> index = getIndex(key);</span><br><span class="line">  <span class="keyword">for</span>(LinkedElement e = entries[index]; e != <span class="keyword">null</span>; e = e.getNext()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (e.equals(key)) &#123;</span><br><span class="line">      <span class="keyword">return</span> convert(e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//element not found</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>HashMap.get</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 若为null，调用getForNullKey方法返回相对应的value</span></span><br><span class="line">    <span class="keyword">if</span> (key == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> getForNullKey();</span><br><span class="line">    <span class="comment">// 根据该 key 的 hashCode 值计算它的 hash 码  </span></span><br><span class="line">    <span class="keyword">int</span> hash = hash(key.hashCode());</span><br><span class="line">    <span class="comment">// 取出 table 数组中指定索引处的值</span></span><br><span class="line">    <span class="keyword">for</span> (Entry&lt;K, V&gt; e = table[indexFor(hash, table.length)]; e != <span class="keyword">null</span>; e = e.next) &#123;</span><br><span class="line">        Object k;</span><br><span class="line">        <span class="comment">//若搜索的key与查找的key相同，则返回相对应的value</span></span><br><span class="line">        <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k)))</span><br><span class="line">            <span class="keyword">return</span> e.value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在HashMap中能够根据key快速的取到value除了和HashMap的数据结构密不可分外，还和Entry有莫大的关系，在前面就提到过，<em>HashMap在存储过程中并没有将key，value分开来存储，而是当做一个整体key-value来处理的，这个整体就是Entry对象</em>。同时value也只相当于key的附属而已。在存储的过程中，系统根据key的hashcode来决定Entry在table数组中的存储位置，在取的过程中同样根据key的hashcode取出相对应的Entry对象。</p>
<p>在LightWeightGSet中，key和value都是BlockInfo对象。</p>
<h2 id="附加"><a href="#附加" class="headerlink" title="附加"></a>附加</h2><p>LightWeightGSet中底层数组的大小是在构造函数中固定的，并且其数组的大小不会扩容，则其数组的初始化就尤为重要，下面看下BlocksMap设置的LightWeightGSet数组的大小。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Let t = percentage of max memory.</span></span><br><span class="line"><span class="comment"> * Let e = round(log_2 t).</span></span><br><span class="line"><span class="comment"> * Then, we choose capacity = 2^e/(size of reference),</span></span><br><span class="line"><span class="comment"> * unless it is outside the close interval [1, 2^30].</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">computeCapacity</span><span class="params">(<span class="keyword">double</span> percentage, String mapName)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> computeCapacity(Runtime.getRuntime().maxMemory(), percentage,</span><br><span class="line">      mapName);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">computeCapacity</span><span class="params">(<span class="keyword">long</span> maxMemory, <span class="keyword">double</span> percentage,</span></span></span><br><span class="line"><span class="function"><span class="params">    String mapName)</span> </span>&#123;</span><br><span class="line">  ... <span class="comment">// 参数校验</span></span><br><span class="line">  <span class="comment">//VM detection</span></span><br><span class="line">  <span class="comment">//See http://java.sun.com/docs/hotspot/HotSpotFAQ.html#64bit_detection</span></span><br><span class="line">  <span class="keyword">final</span> String vmBit = System.getProperty(<span class="string">"sun.arch.data.model"</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">//Percentage of max memory</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">double</span> percentDivisor = <span class="number">100.0</span>/percentage;</span><br><span class="line">  <span class="comment">// 运行时的最大内存Runtime.getRuntime().maxMemory()</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">double</span> percentMemory = maxMemory/percentDivisor;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">//compute capacity</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> e1 = (<span class="keyword">int</span>)(Math.log(percentMemory)/Math.log(<span class="number">2.0</span>) + <span class="number">0.5</span>);</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> e2 = e1 - (<span class="string">"32"</span>.equals(vmBit)? <span class="number">2</span>: <span class="number">3</span>);</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> exponent = e2 &lt; <span class="number">0</span>? <span class="number">0</span>: e2 &gt; <span class="number">30</span>? <span class="number">30</span>: e2;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> c = <span class="number">1</span> &lt;&lt; exponent;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> LightWeightGSet </tag>
            
            <tag> HashMap </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之StateMachineFactory状态机]]></title>
      <url>http://bigdatadecode.club/YARN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BStateMachineFactory%E7%8A%B6%E6%80%81%E6%9C%BA.html</url>
      <content type="html"><![CDATA[<p>状态机由一组状态组成，这些状态大体分为三类，分别为初始状态、中间状态和最终状态。状态机首先由初始状态A开始运行，经过一系列的中间状态后到达最终状态，并在最终状态退出，从而形成一个有向无环图。其<em>状态处理的逻辑是收到一个事件，触发状态A到状态B的转换，而转换操作是由事件对应的hook完成的</em>。</p>
<p>YARN中引入了事件机制和状态机机制，事件机制可以在<a href="http://bigdatadecode.club/YARN源码分析之AsyncDispatcher事件调度器.html">这篇文章</a>中了解下事件机制的调度器，本篇主要从源码的角度解析下状态机机制中的关键类StateMachineFactory，以ApplicationMaster的状态转换为例。</p>
<a id="more"></a>
<h2 id="RMAppImpl中的StateMachineFactory"><a href="#RMAppImpl中的StateMachineFactory" class="headerlink" title="RMAppImpl中的StateMachineFactory"></a>RMAppImpl中的StateMachineFactory</h2><p>ApplicationMaster的实现在RMAPPImpl类中，其状态转换在RMAppImpl中声明，首先声明了一个静态final类型的属性stateMachineFactory，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> StateMachineFactory&lt;RMAppImpl,</span><br><span class="line">                                         RMAppState,</span><br><span class="line">                                         RMAppEventType,</span><br><span class="line">                                         RMAppEvent&gt; stateMachineFactory</span><br><span class="line">                             = <span class="keyword">new</span> StateMachineFactory&lt;RMAppImpl,</span><br><span class="line">                                         RMAppState,</span><br><span class="line">                                         RMAppEventType,</span><br><span class="line">                                         RMAppEvent&gt;(RMAppState.NEW)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   <span class="comment">// Transitions from NEW state</span></span><br><span class="line">  .addTransition(RMAppState.NEW, RMAppState.NEW,</span><br><span class="line">      RMAppEventType.NODE_UPDATE, <span class="keyword">new</span> RMAppNodeUpdateTransition())</span><br><span class="line">  .addTransition(RMAppState.NEW, RMAppState.NEW_SAVING,</span><br><span class="line">      RMAppEventType.START, <span class="keyword">new</span> RMAppNewlySavingTransition())</span><br><span class="line">  ...<span class="comment">// 若干状态转换的定义</span></span><br><span class="line">  .installTopology();</span><br></pre></td></tr></table></figure>
<p>StateMachineFactory从名字可以看出其是一个工厂，负责产生状态机，则RMAPPImpl中必有一个属性来接收该工厂产生的状态机类，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> StateMachine&lt;RMAppState, RMAppEventType, RMAppEvent&gt; stateMachine;</span><br><span class="line"><span class="comment">// 从stateMachineFactory中得到一个stateMachine对象</span></span><br><span class="line"><span class="keyword">this</span>.stateMachine = stateMachineFactory.make(<span class="keyword">this</span>);</span><br></pre></td></tr></table></figure>
<p>下面从状态机的调用流程中解析下StateMachineFactory中的方法。</p>
<p>首先看下StateMachineFactory类的声明：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * State machine topology.</span></span><br><span class="line"><span class="comment"> * This object is semantically immutable.  If you have a</span></span><br><span class="line"><span class="comment"> * StateMachineFactory there's no operation in the API that changes</span></span><br><span class="line"><span class="comment"> * its semantic properties.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;OPERAND&gt; The object type on which this state machine operates.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;STATE&gt; The state of the entity.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;EVENTTYPE&gt; The external eventType to be handled.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> &lt;EVENT&gt; The event object.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StateMachineFactory</span></span></span><br><span class="line"><span class="class">             &lt;<span class="title">OPERAND</span>, <span class="title">STATE</span> <span class="keyword">extends</span> <span class="title">Enum</span>&lt;<span class="title">STATE</span>&gt;,</span></span><br><span class="line"><span class="class">              <span class="title">EVENTTYPE</span> <span class="keyword">extends</span> <span class="title">Enum</span>&lt;<span class="title">EVENTTYPE</span>&gt;, <span class="title">EVENT</span>&gt; </span>&#123;...&#125;</span><br></pre></td></tr></table></figure>
<p>从类的注释中可以得知StateMachineFactory是一组状态的拓扑图，OPERAND是这组状态机的操作者，STATE是这组状态机中的状态，EVENTTYPE是触发状态转移的事件类型，EVENT是触发状态转移的事件。</p>
<p><em>StateMachineFactory的状态拓扑图是通过多种addTransition让用户添加各种状态转移，最后通过installTopology完成一个状态机拓扑的搭建，其中初始状态是通过StateMachineFactory的构造函数指定的</em>。下面看下构造函数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">StateMachineFactory</span><span class="params">(STATE defaultInitialState)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 构成一个transition链</span></span><br><span class="line">  <span class="keyword">this</span>.transitionsListNode = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">this</span>.defaultInitialState = defaultInitialState;</span><br><span class="line">  <span class="keyword">this</span>.optimized = <span class="keyword">false</span>;</span><br><span class="line">  <span class="comment">// 主要用于存放preState、eventType和transition的映射关系</span></span><br><span class="line">  <span class="keyword">this</span>.stateMachineTable = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>RMAPPImpl中的初始状态是<code>RMAppState.NEW</code>，由其初始状态初始化一个StateMachineFactory实例，然后通过addTransition注册各种状态转移。</p>
<h2 id="addTransition"><a href="#addTransition" class="headerlink" title="addTransition"></a>addTransition</h2><p>StateMachineFactory中有五个addTransition方法，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> StateMachineFactory</span><br><span class="line">           &lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">        addTransition(STATE preState, STATE postState, EVENTTYPE eventType) &#123;</span><br><span class="line">  <span class="keyword">return</span> addTransition(preState, postState, eventType, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; <span class="title">addTransition</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    STATE preState, STATE postState, Set&lt;EVENTTYPE&gt; eventTypes)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> addTransition(preState, postState, eventTypes, <span class="keyword">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; <span class="title">addTransition</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    STATE preState, STATE postState, Set&lt;EVENTTYPE&gt; eventTypes,</span></span></span><br><span class="line"><span class="function"><span class="params">    SingleArcTransition&lt;OPERAND, EVENT&gt; hook)</span> </span>&#123;</span><br><span class="line">  StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; factory = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">for</span> (EVENTTYPE event : eventTypes) &#123;</span><br><span class="line">    <span class="keyword">if</span> (factory == <span class="keyword">null</span>) &#123;</span><br><span class="line">      factory = addTransition(preState, postState, event, hook);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      factory = factory.addTransition(preState, postState, event, hook);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> factory;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> StateMachineFactory</span><br><span class="line">           &lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">        addTransition(STATE preState, STATE postState,</span><br><span class="line">                      EVENTTYPE eventType,</span><br><span class="line">                      SingleArcTransition&lt;OPERAND, EVENT&gt; hook)&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">      (<span class="keyword">this</span>, <span class="keyword">new</span> ApplicableSingleOrMultipleTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">         (preState, eventType, <span class="keyword">new</span> SingleInternalArc(postState, hook)));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> StateMachineFactory</span><br><span class="line">           &lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">        addTransition(STATE preState, Set&lt;STATE&gt; postStates,</span><br><span class="line">                      EVENTTYPE eventType,</span><br><span class="line">                      MultipleArcTransition&lt;OPERAND, EVENT, STATE&gt; hook)&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">      (<span class="keyword">this</span>,</span><br><span class="line">       <span class="keyword">new</span> ApplicableSingleOrMultipleTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">         (preState, eventType, <span class="keyword">new</span> MultipleInternalArc(postStates, hook)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>由其上的addTransition方法可以看出定于了三种状态转换方式，分别是</p>
<ol>
<li>preState通过<em>某个事件</em>转换为postState，也就是状态机在preState时，接收到Event事件后，执行对应的hook，并在执行完成后将当前的状态转换为postState。<br><code>addTransition(STATE preState, STATE postState, EVENTTYPE eventType, SingleArcTransition&lt;OPERAND, EVENT&gt; hook)</code></li>
<li>preState通过<em>多个事件</em>转换为postState，也就是状态机在preState时，接收到某些Event事件后，执行对应的hook，并在执行完成后将当前的状态转换为postState。<br><code>addTransition(STATE preState, STATE postState, Set&lt;EVENTTYPE&gt; eventTypes, SingleArcTransition&lt;OPERAND, EVENT&gt; hook)</code></li>
<li>preState通过某个事件转换为<em>多个postState</em>，也就是状态机在preState时，接收到Event事件后，执行对应的hook，并在执行完成后将返回hook的返回值所表示的状态。<br><code>addTransition(STATE preState, Set&lt;STATE&gt; postStates, EVENTTYPE eventType, MultipleArcTransition&lt;OPERAND, EVENT, STATE&gt; hook)</code></li>
</ol>
<p>下面先看下1中的addTransition</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> StateMachineFactory</span><br><span class="line">           &lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">        addTransition(STATE preState, STATE postState,</span><br><span class="line">                      EVENTTYPE eventType,</span><br><span class="line">                      SingleArcTransition&lt;OPERAND, EVENT&gt; hook)&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">      (<span class="keyword">this</span>, <span class="keyword">new</span> ApplicableSingleOrMultipleTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">         (preState, eventType, <span class="keyword">new</span> SingleInternalArc(postState, hook)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从其代码可以看出在addTransition中又new了一个新的StateMachineFactory。这里涉及到两个类<code>ApplicableSingleOrMultipleTransition</code>和<code>SingleInternalArc</code>。</p>
<p>先来看下SingleInternalArc类</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">SingleInternalArc</span></span></span><br><span class="line"><span class="class">                  <span class="keyword">implements</span> <span class="title">Transition</span>&lt;<span class="title">OPERAND</span>, <span class="title">STATE</span>, <span class="title">EVENTTYPE</span>, <span class="title">EVENT</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> STATE postState;</span><br><span class="line">  <span class="keyword">private</span> SingleArcTransition&lt;OPERAND, EVENT&gt; hook; <span class="comment">// transition hook</span></span><br><span class="line"></span><br><span class="line">  SingleInternalArc(STATE postState,</span><br><span class="line">      SingleArcTransition&lt;OPERAND, EVENT&gt; hook) &#123;</span><br><span class="line">    <span class="keyword">this</span>.postState = postState;</span><br><span class="line">    <span class="keyword">this</span>.hook = hook;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> STATE <span class="title">doTransition</span><span class="params">(OPERAND operand, STATE oldState,</span></span></span><br><span class="line"><span class="function"><span class="params">                            EVENT event, EVENTTYPE eventType)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (hook != <span class="keyword">null</span>) &#123;</span><br><span class="line">      hook.transition(operand, event);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> postState;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该类有两个属性，分别为表示STATE的postState属性和表示事件发生之后调用对应hook进行处理的SingleArcTransition属性。</p>
<p>该类只有一个<code>doTransition</code>方法，该方法中会调用<code>hook.transition</code>去处理发生该事件之后的状态变化，hook正常处理结束之后，返回postState状态。</p>
<p>该类是用来处理<em>一个状态被一个事件触发之后转移到下一个状态</em>的，还有一个对应的处理多个状态<code>MultipleInternalArc</code>类，其逻辑结构和<code>SingleInternalArc</code>类似，只是在hook处理结束之后，判断下postState是否在备选的状态集中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">MultipleInternalArc</span></span></span><br><span class="line"><span class="class">            <span class="keyword">implements</span> <span class="title">Transition</span>&lt;<span class="title">OPERAND</span>, <span class="title">STATE</span>, <span class="title">EVENTTYPE</span>, <span class="title">EVENT</span>&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Fields</span></span><br><span class="line">  <span class="comment">// 存储可供选择的postState状态</span></span><br><span class="line">  <span class="keyword">private</span> Set&lt;STATE&gt; validPostStates;</span><br><span class="line">  <span class="comment">// 事件对应的hook</span></span><br><span class="line">  <span class="keyword">private</span> MultipleArcTransition&lt;OPERAND, EVENT, STATE&gt; hook;  <span class="comment">// transition hook</span></span><br><span class="line"></span><br><span class="line">  MultipleInternalArc(Set&lt;STATE&gt; postStates,</span><br><span class="line">                 MultipleArcTransition&lt;OPERAND, EVENT, STATE&gt; hook) &#123;</span><br><span class="line">    <span class="keyword">this</span>.validPostStates = postStates;</span><br><span class="line">    <span class="keyword">this</span>.hook = hook;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> STATE <span class="title">doTransition</span><span class="params">(OPERAND operand, STATE oldState,</span></span></span><br><span class="line"><span class="function"><span class="params">                            EVENT event, EVENTTYPE eventType)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> InvalidStateTransitonException </span>&#123;</span><br><span class="line">    STATE postState = hook.transition(operand, event);</span><br><span class="line">    <span class="comment">// 校验postState是否在可选的状态集中</span></span><br><span class="line">    <span class="keyword">if</span> (!validPostStates.contains(postState)) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> InvalidStateTransitonException(oldState, eventType);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> postState;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来看下<code>ApplicableSingleOrMultipleTransition</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">ApplicableSingleOrMultipleTransition</span></span></span><br><span class="line"><span class="class">           &lt;<span class="title">OPERAND</span>, <span class="title">STATE</span> <span class="keyword">extends</span> <span class="title">Enum</span>&lt;<span class="title">STATE</span>&gt;,</span></span><br><span class="line"><span class="class">            <span class="title">EVENTTYPE</span> <span class="keyword">extends</span> <span class="title">Enum</span>&lt;<span class="title">EVENTTYPE</span>&gt;, <span class="title">EVENT</span>&gt;</span></span><br><span class="line"><span class="class">        <span class="keyword">implements</span> <span class="title">ApplicableTransition</span>&lt;<span class="title">OPERAND</span>, <span class="title">STATE</span>, <span class="title">EVENTTYPE</span>, <span class="title">EVENT</span>&gt; </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> STATE preState;</span><br><span class="line">  <span class="keyword">final</span> EVENTTYPE eventType;</span><br><span class="line">  <span class="keyword">final</span> Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; transition;</span><br><span class="line"></span><br><span class="line">  ApplicableSingleOrMultipleTransition</span><br><span class="line">      (STATE preState, EVENTTYPE eventType,</span><br><span class="line">       Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; transition) &#123;</span><br><span class="line">    <span class="keyword">this</span>.preState = preState;</span><br><span class="line">    <span class="keyword">this</span>.eventType = eventType;</span><br><span class="line">    <span class="keyword">this</span>.transition = transition;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> apply</span><br><span class="line">           (StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; subject) &#123;</span><br><span class="line">    Map&lt;EVENTTYPE, Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt; transitionMap</span><br><span class="line">      = subject.stateMachineTable.get(preState);</span><br><span class="line">    <span class="keyword">if</span> (transitionMap == <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// I use HashMap here because I would expect most EVENTTYPE's to not</span></span><br><span class="line">      <span class="comment">//  apply out of a particular state, so FSM sizes would be </span></span><br><span class="line">      <span class="comment">//  quadratic if I use EnumMap's here as I do at the top level.</span></span><br><span class="line">      transitionMap = <span class="keyword">new</span> HashMap&lt;EVENTTYPE,</span><br><span class="line">        Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt;();</span><br><span class="line">      subject.stateMachineTable.put(preState, transitionMap);</span><br><span class="line">    &#125;</span><br><span class="line">    transitionMap.put(eventType, transition);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>ApplicableSingleOrMultipleTransition</code>主要是将preState、eventType和transition的映射关系放入<code>stateMachineTable</code>属性中。</p>
<p>addTransition调用的构造方法为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> StateMachineFactory</span><br><span class="line">    (StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; that,</span><br><span class="line">     ApplicableTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; t) &#123;</span><br><span class="line">  <span class="keyword">this</span>.defaultInitialState = that.defaultInitialState;</span><br><span class="line">  <span class="keyword">this</span>.transitionsListNode </span><br><span class="line">      = <span class="keyword">new</span> TransitionsListNode(t, that.transitionsListNode);</span><br><span class="line">  <span class="keyword">this</span>.optimized = <span class="keyword">false</span>;</span><br><span class="line">  <span class="keyword">this</span>.stateMachineTable = <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个构造函数主要是对属性<code>transitionsListNode</code>进行实例化，transitionsListNode的主要作用的把状态机中的transition按照<em>状态转移的顺利逆序</em>的链成一个链表。下面看下transitionsListNode是怎么实现这个链表的，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">TransitionsListNode</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> ApplicableTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; transition;</span><br><span class="line">  <span class="keyword">final</span> TransitionsListNode next;</span><br><span class="line"></span><br><span class="line">  TransitionsListNode</span><br><span class="line">      (ApplicableTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; transition,</span><br><span class="line">      TransitionsListNode next) &#123;</span><br><span class="line">    <span class="keyword">this</span>.transition = transition;</span><br><span class="line">    <span class="keyword">this</span>.next = next;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有两个属性，分别为ApplicableTransition(一个接口，ApplicableSingleOrMultipleTransition实现了该接口)的transition和TransitionsListNode的next属性。从构造函数中可以看出transition是当前状态转移对应的处理类，next指向的是下一个TransitionsListNode，<em>此时的下一个TransitionsListNode其实是上一个StateMachineFactory中的TransitionListNode</em>。</p>
<p>跳过2中的addTransition，先看下3中的addTransition，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> StateMachineFactory</span><br><span class="line">           &lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">        addTransition(STATE preState, Set&lt;STATE&gt; postStates,</span><br><span class="line">                      EVENTTYPE eventType,</span><br><span class="line">                      MultipleArcTransition&lt;OPERAND, EVENT, STATE&gt; hook)&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">      (<span class="keyword">this</span>,</span><br><span class="line">       <span class="keyword">new</span> ApplicableSingleOrMultipleTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">         (preState, eventType, <span class="keyword">new</span> MultipleInternalArc(postStates, hook)));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和1中的addTransition类似，只是将<code>SingleArcTransition</code>换成了<code>MultipleInternalArc</code>，这两个类的区别在上面已经介绍过，其余的代码逻辑是一样的。</p>
<p>现在看下2中的addTransition</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; <span class="title">addTransition</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    STATE preState, STATE postState, Set&lt;EVENTTYPE&gt; eventTypes,</span></span></span><br><span class="line"><span class="function"><span class="params">    SingleArcTransition&lt;OPERAND, EVENT&gt; hook)</span> </span>&#123;</span><br><span class="line">  StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; factory = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">for</span> (EVENTTYPE event : eventTypes) &#123;</span><br><span class="line">    <span class="keyword">if</span> (factory == <span class="keyword">null</span>) &#123;</span><br><span class="line">      factory = addTransition(preState, postState, event, hook);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      factory = factory.addTransition(preState, postState, event, hook);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> factory;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2中只是循环所有的事件类型对每一个事件类型调用1中的addTransition。</p>
<p>通过对所有addTransition的分析发现每个addTransition都会new一个新的StateMachineFactory，并将上一个StateMachineFactory的一些属性值赋值到当前StateMachineFactory中。</p>
<h2 id="installTopology"><a href="#installTopology" class="headerlink" title="installTopology"></a>installTopology</h2><p>addTransition把状态都添加到StateMachineFactory中之后，通过调用installTopology进行状态链的初始化。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> StateMachineFactory</span><br><span class="line">           &lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;</span><br><span class="line">        installTopology() &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;(<span class="keyword">this</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里也实例化了一个新的StateMachineFactory，不同的是将属性<code>optimized</code>设置为true。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> StateMachineFactory</span><br><span class="line">    (StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; that,</span><br><span class="line">     <span class="keyword">boolean</span> optimized) &#123;</span><br><span class="line">  <span class="keyword">this</span>.defaultInitialState = that.defaultInitialState;</span><br><span class="line">  <span class="keyword">this</span>.transitionsListNode = that.transitionsListNode;</span><br><span class="line">  <span class="keyword">this</span>.optimized = optimized;</span><br><span class="line">  <span class="keyword">if</span> (optimized) &#123;</span><br><span class="line">    makeStateMachineTable();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    stateMachineTable = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当optimized为true是，会在构造函数中调用<code>makeStateMachineTable</code>对<code>stateMachineTable</code>进行赋值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">makeStateMachineTable</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 声明一个stack数据结构，用来存储TransitionsListNode链中的TransitionsListNode</span></span><br><span class="line">  <span class="comment">// 之所以用stack，是因为TransitionsListNode链是按照状态转移的逆序排列的</span></span><br><span class="line">  <span class="comment">// 也就是说TransitionsListNode链中的第一个是状态转移中最后一个状态对应的ApplicableSingleOrMultipleTransition</span></span><br><span class="line">  Stack&lt;ApplicableTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt; stack =</span><br><span class="line">    <span class="keyword">new</span> Stack&lt;ApplicableTransition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt;();</span><br><span class="line"></span><br><span class="line">  Map&lt;STATE, Map&lt;EVENTTYPE, Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt;&gt;</span><br><span class="line">    prototype = <span class="keyword">new</span> HashMap&lt;STATE, Map&lt;EVENTTYPE, Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt;&gt;();</span><br><span class="line"></span><br><span class="line">  prototype.put(defaultInitialState, <span class="keyword">null</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// I use EnumMap here because it'll be faster and denser.  I would</span></span><br><span class="line">  <span class="comment">//  expect most of the states to have at least one transition.</span></span><br><span class="line">  stateMachineTable</span><br><span class="line">     = <span class="keyword">new</span> EnumMap&lt;STATE, Map&lt;EVENTTYPE,</span><br><span class="line">                         Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt;&gt;(prototype);</span><br><span class="line">  <span class="comment">// 将TransitionsListNode链中的ApplicableSingleOrMultipleTransition入stack</span></span><br><span class="line">  <span class="keyword">for</span> (TransitionsListNode cursor = transitionsListNode;</span><br><span class="line">       cursor != <span class="keyword">null</span>;</span><br><span class="line">       cursor = cursor.next) &#123;</span><br><span class="line">    stack.push(cursor.transition);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将ApplicableSingleOrMultipleTransition出stack，</span></span><br><span class="line">  <span class="comment">// 调用apply对stateMachineTable进行赋值</span></span><br><span class="line">  <span class="keyword">while</span> (!stack.isEmpty()) &#123;</span><br><span class="line">    stack.pop().apply(<span class="keyword">this</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面看下<code>ApplicableSingleOrMultipleTransition.apply</code>方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> apply</span><br><span class="line">         (StateMachineFactory&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; subject) &#123;</span><br><span class="line">  <span class="comment">// 从stateMachineTable中拿到preState对应的transitionMap</span></span><br><span class="line">  Map&lt;EVENTTYPE, Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt; transitionMap</span><br><span class="line">    = subject.stateMachineTable.get(preState);</span><br><span class="line">  <span class="comment">// transitionMap为null则new一个transitionMap的HashMap</span></span><br><span class="line">  <span class="keyword">if</span> (transitionMap == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// I use HashMap here because I would expect most EVENTTYPE's to not</span></span><br><span class="line">    <span class="comment">//  apply out of a particular state, so FSM sizes would be </span></span><br><span class="line">    <span class="comment">//  quadratic if I use EnumMap's here as I do at the top level.</span></span><br><span class="line">    transitionMap = <span class="keyword">new</span> HashMap&lt;EVENTTYPE,</span><br><span class="line">      Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt;();</span><br><span class="line">    subject.stateMachineTable.put(preState, transitionMap);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将eventType对应的Transition放入transitionMap中</span></span><br><span class="line">  transitionMap.put(eventType, transition);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="触发状态转移"><a href="#触发状态转移" class="headerlink" title="触发状态转移"></a>触发状态转移</h2><p>RMAPPImpl中状态转移的触发是在<code>RMAPPImpl.handle</code>中触发的，在handle中调用<code>this.stateMachine.doTransition(event.getType(), event)</code>，其中stateMachine是在RMAPPImpl的构造方法中调用<code>stateMachineFactory.make(this)</code>进行实例化的。</p>
<p>看下make方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> StateMachine&lt;STATE, EVENTTYPE, EVENT&gt; <span class="title">make</span><span class="params">(OPERAND operand)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> InternalStateMachine(operand, defaultInitialState);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在make中new了一个InternalStateMachine对象，则stateMachine其实是InternalStateMachine类的对象，<code>stateMachine.doTransition</code>的调用其实就是stateMachine.doTransition的doTransition方法，然而在<code>stateMachine.doTransition</code>方法中又调用了StateMachineFactory的doTransition方法，<code>StateMachineFactory.doTransition</code>代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// StateMachineFactory.doTransition</span></span><br><span class="line"><span class="keyword">private</span> STATE doTransition</span><br><span class="line">         (OPERAND operand, STATE oldState, EVENTTYPE eventType, EVENT event)</span><br><span class="line">    <span class="keyword">throws</span> InvalidStateTransitonException &#123;</span><br><span class="line">  <span class="comment">// We can assume that stateMachineTable is non-null because we call</span></span><br><span class="line">  <span class="comment">//  maybeMakeStateMachineTable() when we build an InnerStateMachine ,</span></span><br><span class="line">  <span class="comment">//  and this code only gets called from inside a working InnerStateMachine .</span></span><br><span class="line">  Map&lt;EVENTTYPE, Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt;&gt; transitionMap</span><br><span class="line">    = stateMachineTable.get(oldState);</span><br><span class="line">  <span class="keyword">if</span> (transitionMap != <span class="keyword">null</span>) &#123;</span><br><span class="line">    Transition&lt;OPERAND, STATE, EVENTTYPE, EVENT&gt; transition</span><br><span class="line">        = transitionMap.get(eventType);</span><br><span class="line">    <span class="keyword">if</span> (transition != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> transition.doTransition(operand, oldState, event, eventType);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">throw</span> <span class="keyword">new</span> InvalidStateTransitonException(oldState, eventType);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>StateMachineFactory.doTransition</code>只能通过内部类<code>InnerStateMachine</code>的doTransition方法调用，调用<code>StateMachineFactory.doTransition</code>时假设<code>stateMachineTable</code>不为null，因为在InnerStateMachine的构造方法中可能会调用<code>maybeMakeStateMachineTable</code>方法。</p>
<p>从stateMachineTable中得到当前state和eventType对应的transition，然后调用<em>transition.doTransition</em>方法，调用eventType对应的hook去执行相关逻辑。</p>
<p>transition是一个接口，实现该接口的有两个类SingleInternalArc和MultipleInternalArc，相应的hook处理完之后，doTransition返回结束时的状态。</p>
<p>至此一次状态转移就完成了。</p>
<h2 id="状态转移代码示例"><a href="#状态转移代码示例" class="headerlink" title="状态转移代码示例"></a>状态转移代码示例</h2><p>下面以RMAppEventType.START事件类型被触发之后，发送的状态转移。</p>
<p>首先该事件在RMAppImpl.handle中被处理，调用<code>this.stateMachine.doTransition(event.getType(), event)</code>方法，跟踪到<code>InternalStateMachine.doTransition</code>，在其内又继续调用<code>StateMachineFactory.this.doTransition</code>，然后根据<em>RMAppEventType.START</em>事件被触发时的状态<em>RMAppState.NEW</em>，从<code>stateMachineTable</code>中EventType和Transition的映射关系transitionMap，接着从transitionMap中拿到<em>RMAppEventType.START</em>对应的transition<em>(SingleInternalArc)</em>，接着调用transition的doTransition方法，这里才调用到该状态转移涉及到的hook，也就是在addTransition中注册的hook类<code>RMAppNewlySavingTransition</code></p>
<p>代码流程为：<br><em>stateMachine__[InternalStateMachine]__.doTransition</em> -&gt; <em>StateMachineFactory.this.doTransition</em> -&gt; <em>transition__[SingleInternalArc]__.doTransition</em> -&gt; <em>hook__[RMAppNewlySavingTransition]__.transition</em></p>
<p>此流程结束之后RMAppMaster的状态由<em>RMAppState.NEW</em>转移为<em>RMAppState.NEW_SAVING</em>，这套流程是在<code>addTransition(RMAppState.NEW, RMAppState.NEW_SAVING, RMAppEventType.START, new RMAppNewlySavingTransition())</code>中规定的。</p>
<p>最后列一个RMApp的状态转移流程图<br><img src="/blogimgs/StateMachine/RMApp.png" alt="RMApp状态机" title="RMApp状态机"><br>图中的顶点是<em>状态</em>，边是触发状态转移的<em>事件类型</em>。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> StateMachineFactory </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[YARN源码分析之AsyncDispatcher事件调度器]]></title>
      <url>http://bigdatadecode.club/YARN%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E4%B9%8BAsyncDispatcher%E4%BA%8B%E4%BB%B6%E8%B0%83%E5%BA%A6%E5%99%A8.html</url>
      <content type="html"><![CDATA[<p>YARN采用了事件驱动机制，其核心服务实际上都是一个异步调度器，包括Resourcemanager、Nodemanager、MRAppMaster等。本篇以MRAppMaster为例，其内部包含一个异步调度器AsyncDispatcher，AsyncDispatcher在yarn中的主要作用是对发生的一系列事件找到各个事件对应的handle进行处理，从其功能上可以看出其内部应该有一个队列，队列主要用来存放等待调度的事件，还应该有一个事件与handle的映射表，用来处理各个事件。</p>
<p>通过查看代码首先可以发现AsyncDispatcher是一个服务，继承了AbstractService，其次是通过<em>阻塞队列</em>存放事件，然后单独起一个线程从阻塞队列中消费事件，通过事先定义好的事件和处理器的映射表找到各自的处理器进行处理。</p>
<a id="more"></a>
<p>下面看下代码内容，首先看下属性：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 阻塞队列，用于存放发生的事件</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> BlockingQueue&lt;Event&gt; eventQueue;</span><br><span class="line"><span class="comment">// AsyncDispatcher event handler线程是否停止的标识</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> stopped = <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">// Configuration flag for enabling/disabling draining dispatcher's events on</span></span><br><span class="line"><span class="comment">// stop functionality.</span></span><br><span class="line"><span class="comment">// 当停止AsyncDispatcher服务时，是否等待eventQueue中的事件被处理完</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> drainEventsOnStop = <span class="keyword">false</span>;</span><br><span class="line"><span class="comment">// Indicates all the remaining dispatcher's events on stop have been drained</span></span><br><span class="line"><span class="comment">// and processed.</span></span><br><span class="line"><span class="comment">// 在停止AsyncDispatcher服务时，标识所有剩余的事件被处理完</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> drained = <span class="keyword">true</span>;</span><br><span class="line"><span class="comment">// 对象锁</span></span><br><span class="line"><span class="keyword">private</span> Object waitForDrained = <span class="keyword">new</span> Object();</span><br><span class="line"><span class="comment">// For drainEventsOnStop enabled only, block newly coming events into the</span></span><br><span class="line"><span class="comment">// queue while stopping.</span></span><br><span class="line"><span class="comment">// 在停止AsyncDispatcher服务时，</span></span><br><span class="line"><span class="comment">// 如果drainEventsOnStop为true，则阻塞新的事件进入queue</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> blockNewEvents = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> EventHandler handlerInstance = <span class="keyword">null</span>;</span><br><span class="line"><span class="comment">// 消费queue中事件的线程</span></span><br><span class="line"><span class="keyword">private</span> Thread eventHandlingThread;</span><br><span class="line"><span class="comment">// 存放事件和事件处理器的映射</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">final</span> Map&lt;Class&lt;? extends Enum&gt;, EventHandler&gt; eventDispatchers;</span><br><span class="line"><span class="comment">// 当调度器发生异常时，rm是否退出</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">boolean</span> exitOnDispatchException;</span><br></pre></td></tr></table></figure>
<p>类在使用之前需要进行实例化，一般都是通过构造函数进行实例化，下面就看下该类的构造函数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AsyncDispatcher</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>(<span class="keyword">new</span> LinkedBlockingQueue&lt;Event&gt;());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">AsyncDispatcher</span><span class="params">(BlockingQueue&lt;Event&gt; eventQueue)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">super</span>(<span class="string">"Dispatcher"</span>);</span><br><span class="line">  <span class="keyword">this</span>.eventQueue = eventQueue;</span><br><span class="line">  <span class="keyword">this</span>.eventDispatchers = <span class="keyword">new</span> HashMap&lt;Class&lt;? extends Enum&gt;, EventHandler&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该类有两个构造函数，一个是默认的构造函数，一个是带一个BlockingQueue参数的构造函数，而默认的构造函数在其内部又调用了带BlockingQueue参数的构造函数。</p>
<p>构造函数中对其关键属性<code>eventQueue</code>和<code>eventDispatchers</code>进行了赋值，其中如果eventQueue不指定的话就实例化一个LinkedBlockingQueue对象。</p>
<p>AsyncDispatcher是在Resourcemanager中被当做一个服务而启动的，看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> Dispatcher <span class="title">createDispatcher</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> AsyncDispatcher();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rmDispatcher = setupDispatcher();</span><br><span class="line">addIfService(rmDispatcher);</span><br></pre></td></tr></table></figure>
<p>将AsyncDispatcher实例赋值给rmDispatcher，然后将rmDispatcher作为一个服务启动。服务启动时都会先进行init然后start，init和start代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceInit</span><span class="params">(Configuration conf)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.exitOnDispatchException =</span><br><span class="line">      conf.getBoolean(Dispatcher.DISPATCHER_EXIT_ON_ERROR_KEY,</span><br><span class="line">        Dispatcher.DEFAULT_DISPATCHER_EXIT_ON_ERROR);</span><br><span class="line">  <span class="keyword">super</span>.serviceInit(conf);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceStart</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="comment">//start all the components</span></span><br><span class="line">  <span class="keyword">super</span>.serviceStart();</span><br><span class="line">  eventHandlingThread = <span class="keyword">new</span> Thread(createThread());</span><br><span class="line">  eventHandlingThread.setName(<span class="string">"AsyncDispatcher event handler"</span>);</span><br><span class="line">  eventHandlingThread.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>服务启动时，在serviceStart方法中起一个<em>AsyncDispatcher event handler</em>线程，从<em>eventQueue</em>中取出event进行调度。<br>看下eventHandlingThread线程的run方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Runnable <span class="title">createThread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">while</span> (!stopped &amp;&amp; !Thread.currentThread().isInterrupted()) &#123;</span><br><span class="line">      	<span class="comment">// 标识eventQueue是否为空</span></span><br><span class="line">        drained = eventQueue.isEmpty();</span><br><span class="line">        <span class="comment">// blockNewEvents is only set when dispatcher is draining to stop,</span></span><br><span class="line">        <span class="comment">// adding this check is to avoid the overhead of acquiring the lock</span></span><br><span class="line">        <span class="comment">// and calling notify every time in the normal run of the loop.</span></span><br><span class="line">        <span class="keyword">if</span> (blockNewEvents) &#123;</span><br><span class="line">          <span class="keyword">synchronized</span> (waitForDrained) &#123;</span><br><span class="line">            <span class="keyword">if</span> (drained) &#123;</span><br><span class="line">              waitForDrained.notify();</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        Event event;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="comment">// 从eventQueue中移除第一个event</span></span><br><span class="line">          event = eventQueue.take();</span><br><span class="line">        &#125; <span class="keyword">catch</span>(InterruptedException ie) &#123;</span><br><span class="line">          <span class="keyword">if</span> (!stopped) &#123;</span><br><span class="line">            LOG.warn(<span class="string">"AsyncDispatcher thread interrupted"</span>, ie);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// event不为null则调度事件，让事件处理器处理</span></span><br><span class="line">        <span class="keyword">if</span> (event != <span class="keyword">null</span>) &#123;</span><br><span class="line">          dispatch(event);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在run中，首先判断该服务是否处于正在stop过程中，如果正在stop并且<code>drainEventsOnStop</code>为true，则进入<code>if (blockNewEvents)</code>语句中(<em>blockNewEvents在serviceStop中，当drainEventsOnStop为true时，blockNewEvents被赋值为true</em>)，通过<code>drained</code>判断eventQueue中是否还有剩余的event，如果没有剩余event则通知在<code>serviceStop</code>中阻塞的线程继续进行stop操作。如果有剩余则和正常逻辑(正常逻辑指在没有进行stop操作时的逻辑)一样，从eventQueue中取出一个event，通过<code>dispatch</code>进行调度。dispatch代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">dispatch</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">//all events go thru this loop</span></span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// 得到event的class名</span></span><br><span class="line">  Class&lt;? extends Enum&gt; type = event.getType().getDeclaringClass();</span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">  	<span class="comment">// 从map集合eventDispatchers中得到该事件注册的处理器</span></span><br><span class="line">    EventHandler handler = eventDispatchers.get(type);</span><br><span class="line">    <span class="keyword">if</span>(handler != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// 事件处理器的handle方法进行处理event</span></span><br><span class="line">      handler.handle(event);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> Exception(<span class="string">"No handler for registered for "</span> + type);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    <span class="comment">//TODO Maybe log the state of the queue</span></span><br><span class="line">    LOG.fatal(<span class="string">"Error in dispatcher thread"</span>, t);</span><br><span class="line">    <span class="comment">// If serviceStop is called, we should exit this thread gracefully.</span></span><br><span class="line">    <span class="keyword">if</span> (exitOnDispatchException</span><br><span class="line">        &amp;&amp; (ShutdownHookManager.get().isShutdownInProgress()) == <span class="keyword">false</span></span><br><span class="line">        &amp;&amp; stopped == <span class="keyword">false</span>) &#123;</span><br><span class="line">      LOG.info(<span class="string">"Exiting, bbye.."</span>);</span><br><span class="line">      System.exit(-<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里涉及到一个属性<code>eventDispatchers</code>，这个map中存放的是事件类型和对应的事件处理器，通过key事件类型得到事件处理器之后，用该事件处理器的<code>handle</code>方法进行处理。</p>
<p>这里只是从<code>eventDispatchers</code>中取出key对应的value，那么<code>eventDispatchers</code>中的key和value是怎么put进去的呢？在<code>ResourceManager.java</code>中不难发现eventDispatchers中的值是通过<code>register</code>方法注册进去的，下面看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(Class&lt;? extends Enum&gt; eventType,</span></span></span><br><span class="line"><span class="function"><span class="params">    EventHandler handler)</span> </span>&#123;</span><br><span class="line">  <span class="comment">/* check to see if we have a listener registered */</span></span><br><span class="line">  <span class="comment">// 检查是否已经注册了该事件类型的处理器</span></span><br><span class="line">  EventHandler&lt;Event&gt; registeredHandler = (EventHandler&lt;Event&gt;)</span><br><span class="line">  	eventDispatchers.get(eventType);</span><br><span class="line">  LOG.info(<span class="string">"Registering "</span> + eventType + <span class="string">" for "</span> + handler.getClass());</span><br><span class="line">  <span class="comment">// 如果没有则直接put</span></span><br><span class="line">  <span class="keyword">if</span> (registeredHandler == <span class="keyword">null</span>) &#123;</span><br><span class="line">    eventDispatchers.put(eventType, handler);</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!(registeredHandler <span class="keyword">instanceof</span> MultiListenerHandler))&#123;</span><br><span class="line">    <span class="comment">/* for multiple listeners of an event add the multiple listener handler */</span></span><br><span class="line">    <span class="comment">// 如果已经注册了该事件类型的处理器，</span></span><br><span class="line">    <span class="comment">// 并且registeredHandler不是MultiListenerHandler类型</span></span><br><span class="line">    <span class="comment">// 则将已存在的registeredHandler和新来的handler都add到MultiListenerHandler中</span></span><br><span class="line">    MultiListenerHandler multiHandler = <span class="keyword">new</span> MultiListenerHandler();</span><br><span class="line">    multiHandler.addHandler(registeredHandler);</span><br><span class="line">    multiHandler.addHandler(handler);</span><br><span class="line">    eventDispatchers.put(eventType, multiHandler);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">/* already a multilistener, just add to it */</span></span><br><span class="line">    <span class="comment">// 如果registeredHandler已经是MultiListenerHandler类型</span></span><br><span class="line">    <span class="comment">// 则直接加入MultiListenerHandler中</span></span><br><span class="line">    MultiListenerHandler multiHandler</span><br><span class="line">    = (MultiListenerHandler) registeredHandler;</span><br><span class="line">    multiHandler.addHandler(handler);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从register方法中可以得出可以对同一个事件类型注册多个事件处理器，多个事件处理器用<code>MultiListenerHandler</code>存储。</p>
<p>对某一个事件注册事件处理器时，先判断eventDispatchers是否存在该事件的处理器，没有则直接注册，如果存在并且不是<code>MultiListenerHandler</code>类型，则构建一个<code>MultiListenerHandler</code>的实例，将已经存在的处理器和新添加的处理器都添加到<code>MultiListenerHandler</code>中，如果存在并且是<code>MultiListenerHandler</code>类型，则直接向其追加处理器handler。下面看下<code>MultiListenerHandler</code>是个什么鬼</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiListenerHandler</span> <span class="keyword">implements</span> <span class="title">EventHandler</span>&lt;<span class="title">Event</span>&gt; </span>&#123;</span><br><span class="line">  List&lt;EventHandler&lt;Event&gt;&gt; listofHandlers;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">MultiListenerHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    listofHandlers = <span class="keyword">new</span> ArrayList&lt;EventHandler&lt;Event&gt;&gt;();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (EventHandler&lt;Event&gt; handler: listofHandlers) &#123;</span><br><span class="line">      handler.handle(event);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">addHandler</span><span class="params">(EventHandler&lt;Event&gt; handler)</span> </span>&#123;</span><br><span class="line">    listofHandlers.add(handler);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>MultiListenerHandler是AsyncDispatcher的一个内部静态类，有一个list属性<code>listofHandlers</code>来存放多个事件处理器。该类也实现了<code>EventHandler</code>接口，通过调用<code>handle</code>方法，将事件依次通过列表中的事件处理器handler来处理。</p>
<p>细心的朋友可能已经在想eventQueue中的event是在哪put进去的呢？</p>
<p>在AsyncDispatcher中查看eventQueue的put方法都在哪里调用了。其实在AsyncDispatcher中只有一处调用了<code>eventQueue.put</code>方法，那就是在<code>GenericEventHandler</code>类的handle中。GenericEventHandler是AsyncDispatcher的一个内部类，在<code>AsyncDispatcher.getEventHandler()</code>方法中实例化，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> EventHandler <span class="title">getEventHandler</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (handlerInstance == <span class="keyword">null</span>) &#123;</span><br><span class="line">    handlerInstance = <span class="keyword">new</span> GenericEventHandler();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> handlerInstance;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>可以看出一个调度器里实例化一个GenericEventHandler对象，下次获取就可以直接返回handlerInstance了。</p>
<p>向eventQueue中put数据时，先通过<code>AsyncDispatcher.getEventHandler()</code>方法，得到GenericEventHandler实例handlerInstance，然后调用<code>GenericEventHandler.handle(Event)</code>方法put进去的，下面看下GenericEventHandler.handle方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 当drainEventsOnStop为true并且当前调度器正在stop时，</span></span><br><span class="line">  <span class="comment">// 禁止新添加event，直接return</span></span><br><span class="line">  <span class="keyword">if</span> (blockNewEvents) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  drained = <span class="keyword">false</span>;</span><br><span class="line">  <span class="comment">/* all this method does is enqueue all the events onto the queue */</span></span><br><span class="line">  <span class="keyword">int</span> qSize = eventQueue.size();</span><br><span class="line">  <span class="comment">// eventQueue size不为0且是1000的整数倍则打印一条log</span></span><br><span class="line">  <span class="keyword">if</span> (qSize !=<span class="number">0</span> &amp;&amp; qSize %<span class="number">1000</span> == <span class="number">0</span>) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Size of event-queue is "</span> + qSize);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 得到剩余的空间</span></span><br><span class="line">  <span class="keyword">int</span> remCapacity = eventQueue.remainingCapacity();</span><br><span class="line">  <span class="comment">// 剩余的空间小于1000时打印一个warn log</span></span><br><span class="line">  <span class="keyword">if</span> (remCapacity &lt; <span class="number">1000</span>) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Very low remaining capacity in the event-queue: "</span></span><br><span class="line">        + remCapacity);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// put进eventQueue中</span></span><br><span class="line">    eventQueue.put(event);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!stopped) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"AsyncDispatcher thread interrupted"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> YarnRuntimeException(e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>向eventQueue中put数据时，先统计下当前eventQueue是的使用情况，如果剩余空间小于1000，则打印一条warn日志。eventQueue是LinkedBlockingQueue类型的对象，<em>调用LinkedBlockingQueue默认构造函数在实例化时会将Integer.MAX_VALUE作为空间大小。</em></p>
<p>至此AsyncDispatcher类从start、put、take都已介绍完，最后介绍下AsyncDispatcher的stop。看下<code>serviceStop</code>方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">serviceStop</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="comment">// 这里首先校验drainEventsOnStop，默认为false</span></span><br><span class="line">  <span class="comment">// 如果为true则等待eventQueue中的event处理完之后再stop调度器</span></span><br><span class="line">  <span class="keyword">if</span> (drainEventsOnStop) &#123;</span><br><span class="line">  	<span class="comment">// blockNewEvents在此设为true，在eventHandlingThread线程中检查是否已处理完</span></span><br><span class="line">    blockNewEvents = <span class="keyword">true</span>;</span><br><span class="line">    LOG.info(<span class="string">"AsyncDispatcher is draining to stop, igonring any new events."</span>);</span><br><span class="line">    <span class="comment">// 等待eventHandlingThread线程的notify</span></span><br><span class="line">    <span class="keyword">synchronized</span> (waitForDrained) &#123;</span><br><span class="line">      <span class="keyword">while</span> (!drained &amp;&amp; eventHandlingThread.isAlive()) &#123;</span><br><span class="line">        waitForDrained.wait(<span class="number">1000</span>);</span><br><span class="line">        LOG.info(<span class="string">"Waiting for AsyncDispatcher to drain."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  stopped = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">if</span> (eventHandlingThread != <span class="keyword">null</span>) &#123;</span><br><span class="line">    eventHandlingThread.interrupt();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      eventHandlingThread.join();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"Interrupted Exception while stopping"</span>, ie);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// stop all the components</span></span><br><span class="line">  <span class="keyword">super</span>.serviceStop();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调度器stop时，主要是校验下drainEventsOnStop的值，为false则直接stop掉调度器，为true则阻塞新eventput进eventQueue，等待eventQueue中的event被处理完再stop。</p>
<p><strong>事件驱动设计思想的引入，使得YARN具有低耦合，高内聚的特点，各个模块只需完成各自的功能，而模块之间则采用事件联系起来，系统设计简单且维护方便。</strong></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> YARN </tag>
            
            <tag> AsyncDispatcher </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hadoop RPC 解析]]></title>
      <url>http://bigdatadecode.club/Hadoop%20RPC%20%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<h2 id="RPC"><a href="#RPC" class="headerlink" title="RPC"></a>RPC</h2><p>RPC由四个模块组成：<br>1、通信模块。<br>两个相互协作的通信模块实现请求-应答协议,它们在客户和服务器之间传递请求和应答消息,一般不会对数据包进行任何处理。请求–应答协议的实现方式有同步方式和异步方式两种。同步模式下客户端程序一直阻塞到服务器端发送的应答请求到达本地; 而异步模式不同,客户端将请求发送到服务器端后,不必等待应答返回,可以做其他事情,待服务器端处理完请求后,主动通知客户端。在高并发应用场景中,一般采用异步模式以降低访问延迟和提高带宽利用率。<br>2、Stub 程序（代理程序）。<br>客户端和服务器端均包含Stub程序,可将之看做<strong>代理程序</strong>。它使得远程函数调用表现得跟本地调用一样,对用户程序完全透明。在客户端,它表现得就像一个本地程序,但不直接执行本地调用,而是将请求信息通过网络模块发送给服务器端。此外,当服务器发送应答后,它会解码对应结果。在服务器端,Stub程序依次进行解码请求消息中的参数、调用相应的服务过程和编码应答结果的返回值等处理。<br>3、调度程序。<br>调度程序接收来自通信模块的请求消息,并根据其中的标识选择一个Stub程序进行处理。通常客户端并发请求量比较大时,会采用线程池提高处理效率。<br>4、客户程序/服务过程。<br>请求的发出者和请求的处理者。</p>
<a id="more"></a>
<p>通常而言,一个 RPC请求从发送到获取处理结果,所经历的步骤如下所示。</p>
<ol>
<li>客户程序以本地方式通过系统产生的Stub程序调用客户程序; </li>
<li>该Stub程序将函数调用信息按照网络通信模块的要求封装成消息包,并交给通信模块发送到远程服务器端。 </li>
<li>远程服务器端接收此消息后,将此消息发送给相应的Stub程序;</li>
<li>Stub程序拆封消息,形成被调过程要求的形式,并调用对应函数;</li>
<li>被调用函数按照所获参数执行,并将结果返回给Stub程序;</li>
<li>Stub程序将此结果封装成消息,通过网络通信模块逐级地传送给客户程序。</li>
</ol>
<h2 id="Hadoop-RPC"><a href="#Hadoop-RPC" class="headerlink" title="Hadoop RPC"></a>Hadoop RPC</h2><p>Hadoop RPC主要分为四个部分,分别是序列化层、函数调用层、网络传输层和服务器端处理框架,具体实现机制如下:</p>
<p>序列化层。序列化主要作用是将结构化对象转为字节流以便于通过网络进行传输或写入持久存储,在RPC框架中,<br>          它主要用于将用户请求中的参数或者应答转化成字节流以便跨机器传输。Hadoop2.0之后，<br>          主要用Protocol Buffers和Apache Avro，Hadoop本身也提供了一套序列化框架，<br>          一个类只要实现Writable接口即可支持对象序列化与反序列化。<br>函数调用层。函数调用层主要功能是定位要调用的函数并执行该函数，<br>            Hadoop RPC采用了Java反射机制（<strong>服务器端</strong>）与动态代理（<strong>客户端</strong>）实现了函数调用。<br>网络传输层。网络传输层描述了Client与Server之间消息传输的方式，Hadoop RPC采用了<strong>基于TCP/IP的Socket机制</strong>。<br>服务器端处理框架。服务器端处理框架可被<strong>抽象为网络I/O模型</strong>，它描述了客户端与服务器端间信息交互方式,<br>                  它的设计直接决定着服务器端的并发处理能力,常见的网络 I/O 模型有阻塞式 I/O、非阻塞式 I/O、事件驱动 I/O 等,而Hadoop RPC采用了<strong>基于Reactor设计模式的事件驱动 I/O 模型（NIO）</strong>。</p>
<h3 id="Hadoop-RPC-Demo"><a href="#Hadoop-RPC-Demo" class="headerlink" title="Hadoop RPC Demo"></a>Hadoop RPC Demo</h3><p>使用Hadoop RPC前要先定义一个RPC协议，这个协议其实就是一个接口类，接口中的方法就是对外提供的远程调用方法。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hadoop中所有自定义 RPC 接口都需要继承 VersionedProtocol 接口</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">MyClientProtocol</span> <span class="keyword">extends</span> <span class="title">VersionedProtocol</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 版本号,默认情况下,不同版本号的 RPC Client 和 Server 之间不能相互通信</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> versionID = <span class="number">1L</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">echo</span><span class="params">(String str)</span> <span class="keyword">throws</span> IOException</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> <span class="keyword">throws</span>  IOException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>再声明一个类去实现这个协议，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyClientProtocolImpl</span> <span class="keyword">implements</span> <span class="title">MyClientProtocol</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// RPC 协议对外提供方法的具体实现</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">echo</span><span class="params">(String str)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> str;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">add</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 下面两个方法是从 VersionedProtocol 中重写的</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getProtocolVersion</span><span class="params">(String s, <span class="keyword">long</span> l)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> MyClientProtocol.versionID;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ProtocolSignature <span class="title">getProtocolSignature</span><span class="params">(String s, <span class="keyword">long</span> l, <span class="keyword">int</span> i)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ProtocolSignature(MyClientProtocol.versionID, <span class="keyword">null</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有了RPC协议，再创建server端和client端就可以使用了，下面通过Hadoop RPC 创建server端。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyServer</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">		<span class="comment">// 使用RPC类get一个sever  默认情况下使用 WritableRpcEngine，</span></span><br><span class="line">		<span class="comment">// 可以使用RPC.setProtocolEngine 设置序列号引擎</span></span><br><span class="line">		<span class="comment">// server 通过 Builder模式 得到一个server对象</span></span><br><span class="line">        RPC.Server server = <span class="keyword">new</span> RPC.Builder(conf).setProtocol(MyClientProtocol.class)</span><br><span class="line">                .setInstance(<span class="keyword">new</span> MyClientProtocolImpl()).setBindAddress(<span class="string">"127.0.0.1"</span>).setPort(<span class="number">9876</span>)</span><br><span class="line">                .setNumHandlers(<span class="number">10</span>).build();</span><br><span class="line">        server.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>现在就可以在client端调用RPC协议对外提供的接口方法了</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MyClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">long</span> startTime = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">30000</span>; i++)&#123;</span><br><span class="line">            Thread t = <span class="keyword">new</span> Thread(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">                <span class="meta">@Override</span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">                    MyClientProtocol proxy = <span class="keyword">null</span>;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                    	<span class="comment">// 从RPC.getProxy方法的名字可以猜出client其实就是一个代理</span></span><br><span class="line">                    	<span class="comment">// Hadoop RPC客户端是通过java 动态代理实现远程调用的</span></span><br><span class="line">                        proxy = (MyClientProtocol) RPC.getProxy(MyClientProtocol.class, MyClientProtocol.versionID,</span><br><span class="line">                                <span class="keyword">new</span> InetSocketAddress(<span class="string">"127.0.0.1"</span>, <span class="number">9876</span>), conf);</span><br><span class="line">                        <span class="keyword">int</span> result = proxy.add(<span class="number">5</span>, <span class="number">6</span>);</span><br><span class="line"><span class="comment">//                        System.out.println(result);</span></span><br><span class="line">                        String echoResult = proxy.echo(result + <span class="string">""</span>); <span class="comment">// just for string</span></span><br><span class="line"><span class="comment">//                        System.out.println(echoResult);</span></span><br><span class="line">                    &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">            t.start();</span><br><span class="line">            t.join();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"end"</span>);</span><br><span class="line">        System.out.println(System.currentTimeMillis() - startTime);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>如果只是想写个demo，client不用写for循环，我写这个for循环是想测试下载server端设置不同的<strong>handler</strong>数对其性能的影响，但是通过上面的代码并没有达到我想要的结果。可能是我思路不对吧，有哪位大神看见了给我指点下。。。</p>
</blockquote>
<h2 id="Hadoop-RPC-源码解析"><a href="#Hadoop-RPC-源码解析" class="headerlink" title="Hadoop RPC 源码解析"></a>Hadoop RPC 源码解析</h2><p>通过上面的Demo，可以看出只有RPC协议是自己实现的，server和client都是通过RPC提供的接口get到的。则具体上面的Demo来看下RPC相关的源码。<br>与RPC相关的类在common中的ipc中，ipc是inter-process communication 的缩写<br>RPC主要向外提供了一些编程接口，用于get server 和 client，是对底层客户机–服务器网络模型的封装。<br><em>client可以通过RPC提供的getProxy和waitForProxy两种方法得到</em>，看下getProxy的具体实现：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">T <span class="title">getProxy</span><span class="params">(Class&lt;T&gt; protocol, <span class="keyword">long</span> clientVersion, InetSocketAddress addr, Configuration conf)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> getProtocolProxy(protocol, clientVersion, addr, conf).getProxy();</span><br><span class="line">&#125;</span><br><span class="line">....</span><br><span class="line"><span class="comment">// getProtocolProxy 通过一些列的方法调用，基本都是方法的重写，最后定位到如下：</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">ProtocolProxy&lt;T&gt; <span class="title">getProtocolProxy</span><span class="params">(Class&lt;T&gt; protocol, <span class="keyword">long</span> clientVersion, InetSocketAddress addr, UserGroupInformation ticket, Configuration conf, SocketFactory factory, <span class="keyword">int</span> rpcTimeout, RetryPolicy connectionRetryPolicy, AtomicBoolean fallbackToSimpleAuth)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(UserGroupInformation.isSecurityEnabled()) &#123;</span><br><span class="line">        SaslRpcServer.init(conf);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> getProtocolEngine(protocol, conf).getProxy(protocol, clientVersion, addr, ticket, conf, factory, rpcTimeout, connectionRetryPolicy, fallbackToSimpleAuth);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Hadoop2.0之后支持protocol buffer序列化，所以在原Hadoop RPC的基础上进行了修改，提出一个RpcEngine接口，以支持第三方序列化方法，hadoop本身只实现了protocol 和 Writable序列化的engine。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">synchronized</span> RpcEngine <span class="title">getProtocolEngine</span><span class="params">(Class&lt;?&gt; protocol, Configuration conf)</span> </span>&#123;</span><br><span class="line">    RpcEngine engine = (RpcEngine)PROTOCOL_ENGINES.get(protocol);</span><br><span class="line">    <span class="comment">// Hadoop 默认使用Writable序列化</span></span><br><span class="line">    <span class="keyword">if</span>(engine == <span class="keyword">null</span>) &#123;</span><br><span class="line">        Class impl = conf.getClass(<span class="string">"rpc.engine."</span> + protocol.getName(), WritableRpcEngine.class);</span><br><span class="line">        engine = (RpcEngine)ReflectionUtils.newInstance(impl, conf);</span><br><span class="line">        PROTOCOL_ENGINES.put(protocol, engine);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> engine;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后调用对应RpcEngine的getProxy方法，这里以WritableRPCEngine为例，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> &lt;T&gt; <span class="function">ProtocolProxy&lt;T&gt; <span class="title">getProxy</span><span class="params">(Class&lt;T&gt; protocol, <span class="keyword">long</span> clientVersion, InetSocketAddress addr, UserGroupInformation ticket, Configuration conf, SocketFactory factory, <span class="keyword">int</span> rpcTimeout, RetryPolicy connectionRetryPolicy, AtomicBoolean fallbackToSimpleAuth)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(connectionRetryPolicy != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UnsupportedOperationException(<span class="string">"Not supported: connectionRetryPolicy="</span> + connectionRetryPolicy);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//Static Object newProxyInstance(ClassLoader loader, Class[] interfaces, InvocationHandler h)</span></span><br><span class="line">        <span class="comment">//返回代理类的一个实例，返回后的代理类可以当作被代理类使用</span></span><br><span class="line">        <span class="comment">//(可使用被代理类的在Subject接口中声明过的方法)。</span></span><br><span class="line">        <span class="comment">//InvocationHandler 是代理角色，具体方法的调用在这里invoke方法中</span></span><br><span class="line">        Object proxy = Proxy.newProxyInstance(protocol.getClassLoader(), <span class="keyword">new</span> Class[]&#123;protocol&#125;, <span class="keyword">new</span> WritableRpcEngine.Invoker(protocol, addr, ticket, conf, factory, rpcTimeout, fallbackToSimpleAuth));</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> ProtocolProxy(protocol, proxy, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Proxy实例化时传进去的InvocationHandler的实现类是WritableRpcEngine的内部类Invoker，构造方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Invoker</span><span class="params">(Class&lt;?&gt; protocol, InetSocketAddress address, UserGroupInformation ticket, Configuration conf, SocketFactory factory, <span class="keyword">int</span> rpcTimeout, AtomicBoolean fallbackToSimpleAuth)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.remoteId = ConnectionId.getConnectionId(address, protocol, ticket, rpcTimeout, conf);</span><br><span class="line">    <span class="keyword">this</span>.client = WritableRpcEngine.CLIENTS.getClient(conf, factory);</span><br><span class="line">    <span class="keyword">this</span>.fallbackToSimpleAuth = fallbackToSimpleAuth;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当client端通过Proxy的实例化对象调用协议的相关接口时（即demo中<code>proxy.add(5, 6)</code>）,会调用WritableRpcEngine.Invoker中的invoke方法，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Object <span class="title">invoke</span><span class="params">(Object proxy, Method method, Object[] args)</span> <span class="keyword">throws</span> Throwable </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    ObjectWritable value;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        value = (ObjectWritable)<span class="keyword">this</span>.client.call(RpcKind.RPC_WRITABLE, <span class="keyword">new</span> WritableRpcEngine.Invocation(method, args), <span class="keyword">this</span>.remoteId, <span class="keyword">this</span>.fallbackToSimpleAuth);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">if</span>(traceScope != <span class="keyword">null</span>) &#123;</span><br><span class="line">            traceScope.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> value.get();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里调用了Client类的call方法，<strong>WritableRpcEngine.Invocationclient实现了Writable接口，这里的作用是将method 和 args 进行序列化</strong>。client是在Invoker的构造方法中实例化的，call的具体实现如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Writable <span class="title">call</span><span class="params">(RpcKind rpcKind, Writable rpcRequest, Client.ConnectionId remoteId, <span class="keyword">int</span> serviceClass, AtomicBoolean fallbackToSimpleAuth)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="comment">// 将远程调用信息封装成一个Client.Call对象 每个Call都有一个唯一的callId</span></span><br><span class="line">    Client.Call call = <span class="keyword">this</span>.createCall(rpcKind, rpcRequest);</span><br><span class="line">    <span class="comment">// 根据remoteId创建一个connection对象，并将call放到该对象的hashtable calls中</span></span><br><span class="line">    Client.Connection connection = <span class="keyword">this</span>.getConnection(remoteId, call, serviceClass, fallbackToSimpleAuth);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在call方法中先将远程调用信息封装成一个<code>Client.Call</code>对象，然后通过getConnection得到connection对象，将封装好的call对象放入connection对象的hashtable calls中，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> Client.<span class="function">Connection <span class="title">getConnection</span><span class="params">(Client.ConnectionId remoteId, Client.Call call, <span class="keyword">int</span> serviceClass, AtomicBoolean fallbackToSimpleAuth)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(!<span class="keyword">this</span>.running.get()) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"The client is stopped"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        Client.Connection connection;</span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            Hashtable var6 = <span class="keyword">this</span>.connections;  <span class="comment">// connections 是个 hashtable</span></span><br><span class="line">            <span class="keyword">synchronized</span>(<span class="keyword">this</span>.connections) &#123;</span><br><span class="line">                <span class="comment">// 先从 connections中查找是否存在，不存在则创建</span></span><br><span class="line">                connection = (Client.Connection)<span class="keyword">this</span>.connections.get(remoteId);</span><br><span class="line">                <span class="keyword">if</span>(connection == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">// 这里new 只是对一些相关属性进行赋值，并没有真正的建立连接</span></span><br><span class="line">                    connection = <span class="keyword">new</span> Client.Connection(remoteId, serviceClass);</span><br><span class="line">                    <span class="keyword">this</span>.connections.put(remoteId, connection);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">while</span>(!connection.addCall(call)); <span class="comment">// 得到connection之后将call放入calls的hashtable中</span></span><br><span class="line">        <span class="comment">// 建立连接</span></span><br><span class="line">        connection.setupIOstreams(fallbackToSimpleAuth);</span><br><span class="line">        <span class="keyword">return</span> connection;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>setupIOstreams</code>中建立连接，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** Connect to the server and set up the I/O streams. It then sends</span></span><br><span class="line"><span class="comment"> * a header to the server and starts</span></span><br><span class="line"><span class="comment"> * the connection thread that waits for responses.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">setupIOstreams</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    AtomicBoolean fallbackToSimpleAuth)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (socket != <span class="keyword">null</span> || shouldCloseConnection.get()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125; </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"Connecting to "</span>+server);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (Trace.isTracing()) &#123;</span><br><span class="line">      Trace.addTimelineAnnotation(<span class="string">"IPC client connecting to "</span> + server);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">short</span> numRetries = <span class="number">0</span>;</span><br><span class="line">    Random rand = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">      <span class="comment">// 建立socket进行连接     可见client是用socket进行通信</span></span><br><span class="line">      setupConnection();</span><br><span class="line">      InputStream inStream = NetUtils.getInputStream(socket);</span><br><span class="line">      OutputStream outStream = NetUtils.getOutputStream(socket);</span><br><span class="line">      <span class="comment">// Write the connection header - this is sent when connection is established</span></span><br><span class="line">      writeConnectionHeader(outStream); </span><br><span class="line">      <span class="keyword">if</span> (authProtocol == AuthProtocol.SASL) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 发送ping message，</span></span><br><span class="line">      <span class="comment">// The time after which a RPC will timeout.</span></span><br><span class="line">      <span class="comment">// If ping is not enabled (via ipc.client.ping), then the timeout value is the</span></span><br><span class="line">      <span class="comment">// same as the pingInterval.</span></span><br><span class="line">      <span class="comment">// If ping is enabled, then there is no timeout value.</span></span><br><span class="line">      <span class="keyword">if</span> (doPing) &#123;</span><br><span class="line">        inStream = <span class="keyword">new</span> PingInputStream(inStream);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">this</span>.in = <span class="keyword">new</span> DataInputStream(<span class="keyword">new</span> BufferedInputStream(inStream));</span><br><span class="line"></span><br><span class="line">      <span class="comment">// SASL may have already buffered the stream</span></span><br><span class="line">      <span class="keyword">if</span> (!(outStream <span class="keyword">instanceof</span> BufferedOutputStream)) &#123;</span><br><span class="line">        outStream = <span class="keyword">new</span> BufferedOutputStream(outStream);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">this</span>.out = <span class="keyword">new</span> DataOutputStream(outStream);</span><br><span class="line">      <span class="comment">// 向内容中写入消息，这里面将 connectionContextHeader的序列化协议写死了，不知道为什么？？</span></span><br><span class="line">      <span class="comment">// RpcRequestHeaderProto connectionContextHeader = ProtoUtil</span></span><br><span class="line">      <span class="comment">//  .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,</span></span><br><span class="line">      <span class="comment">//      OperationProto.RPC_FINAL_PACKET, CONNECTION_CONTEXT_CALL_ID,</span></span><br><span class="line">      <span class="comment">//      RpcConstants.INVALID_RETRY_COUNT, clientId);</span></span><br><span class="line">      <span class="comment">// 这个方法与 writeConnectionHeader()的区别是什么 ，暂时还没有搞清。。。。。。。。</span></span><br><span class="line">      writeConnectionContext(remoteId, authMethod);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// update last activity time</span></span><br><span class="line">      touch();</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (Trace.isTracing()) &#123;</span><br><span class="line">        Trace.addTimelineAnnotation(<span class="string">"IPC client connected to "</span> + server);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// start the receiver thread after the socket connection has been set</span></span><br><span class="line">      <span class="comment">// up</span></span><br><span class="line">      start();    <span class="comment">// 启动connection线程，等待接受server的response</span></span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    <span class="keyword">if</span> (t <span class="keyword">instanceof</span> IOException) &#123;</span><br><span class="line">      markClosed((IOException)t);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      markClosed(<span class="keyword">new</span> IOException(<span class="string">"Couldn't set up IO streams"</span>, t));</span><br><span class="line">    &#125;</span><br><span class="line">    close();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过<code>setupConnection</code>方法进行socket连接</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">setupConnection</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">short</span> ioFailures = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">short</span> timeoutFailures = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 创建一个网络socket</span></span><br><span class="line">      <span class="keyword">this</span>.socket = socketFactory.createSocket();</span><br><span class="line">      <span class="keyword">this</span>.socket.setTcpNoDelay(tcpNoDelay);</span><br><span class="line">      <span class="keyword">this</span>.socket.setKeepAlive(<span class="keyword">true</span>);</span><br><span class="line">      </span><br><span class="line">      <span class="comment">/*</span></span><br><span class="line"><span class="comment">       * Bind the socket to the host specified in the principal name of the</span></span><br><span class="line"><span class="comment">       * client, to ensure Server matching address of the client connection</span></span><br><span class="line"><span class="comment">       * to host name in principal passed.</span></span><br><span class="line"><span class="comment">       */</span></span><br><span class="line">      UserGroupInformation ticket = remoteId.getTicket();</span><br><span class="line">      <span class="keyword">if</span> (ticket != <span class="keyword">null</span> &amp;&amp; ticket.hasKerberosCredentials()) &#123;</span><br><span class="line">        KerberosInfo krbInfo = </span><br><span class="line">          remoteId.getProtocol().getAnnotation(KerberosInfo.class);</span><br><span class="line">        <span class="keyword">if</span> (krbInfo != <span class="keyword">null</span> &amp;&amp; krbInfo.clientPrincipal() != <span class="keyword">null</span>) &#123;</span><br><span class="line">          String host = </span><br><span class="line">            SecurityUtil.getHostFromPrincipal(remoteId.getTicket().getUserName());</span><br><span class="line">          </span><br><span class="line">          <span class="comment">// If host name is a valid local address then bind socket to it</span></span><br><span class="line">          InetAddress localAddr = NetUtils.getLocalInetAddress(host);</span><br><span class="line">          <span class="keyword">if</span> (localAddr != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">this</span>.socket.bind(<span class="keyword">new</span> InetSocketAddress(localAddr, <span class="number">0</span>));</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// server 在 connection的构造方法中进行赋值，</span></span><br><span class="line">      <span class="comment">// this.server = remoteId.getAddress();</span></span><br><span class="line">      <span class="comment">// 在connect中进行socket与ip的绑定连接</span></span><br><span class="line">      NetUtils.connect(<span class="keyword">this</span>.socket, server, connectionTimeout);</span><br><span class="line">      <span class="keyword">if</span> (rpcTimeout &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        pingInterval = rpcTimeout;  <span class="comment">// rpcTimeout overwrites pingInterval</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">this</span>.socket.setSoTimeout(pingInterval);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ConnectTimeoutException toe) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ie) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>建立连接之后，启动connection线程，运行<code>run</code>方法，等待server端的response。代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (LOG.isDebugEnabled())</span><br><span class="line">    LOG.debug(getName() + <span class="string">": starting, having connections "</span> </span><br><span class="line">        + connections.size());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (waitForWork()) &#123;<span class="comment">//wait here for work - read or close connection</span></span><br><span class="line">      receiveRpcResponse();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    <span class="comment">// This truly is unexpected, since we catch IOException in receiveResponse</span></span><br><span class="line">    <span class="comment">// -- this is only to be really sure that we don't leave a client hanging</span></span><br><span class="line">    <span class="comment">// forever.</span></span><br><span class="line">    LOG.warn(<span class="string">"Unexpected error reading responses on connection "</span> + <span class="keyword">this</span>, t);</span><br><span class="line">    markClosed(<span class="keyword">new</span> IOException(<span class="string">"Error reading responses"</span>, t));</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  close();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (LOG.isDebugEnabled())</span><br><span class="line">    LOG.debug(getName() + <span class="string">": stopped, remaining connections "</span></span><br><span class="line">        + connections.size());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>getConnection</code>逻辑已经初步完结，现在回到<code>call</code>代码中，继续分析其代码，下面的关键代码是<code>connection.sendRpcRequest(call)</code>，发送call对象到server端，并进入阻塞状态等待server的response。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Writable <span class="title">call</span><span class="params">(RpcKind rpcKind, Writable rpcRequest, Client.ConnectionId remoteId, <span class="keyword">int</span> serviceClass, AtomicBoolean fallbackToSimpleAuth)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 将远程调用信息发送给server端</span></span><br><span class="line">        connection.sendRpcRequest(call);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (RejectedExecutionException var13) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"connection has been closed"</span>, var13);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException var14) &#123;</span><br><span class="line">        Thread.currentThread().interrupt();</span><br><span class="line">        LOG.warn(<span class="string">"interrupted waiting to send rpc request to server"</span>, var14);</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IOException(var14);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> interrupted = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">synchronized</span>(call) &#123;</span><br><span class="line">        <span class="comment">// 判断call是否完成，等待server端notify</span></span><br><span class="line">        <span class="keyword">while</span>(!call.done) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                 call.wait();   <span class="comment">// 当前线程blocking住，等待Connection线程中receiveRpcResponse调用call.notify</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException var12) &#123;</span><br><span class="line">                interrupted = <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(interrupted) &#123;</span><br><span class="line">            Thread.currentThread().interrupt();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span>(call.error != <span class="keyword">null</span>) &#123;</span><br><span class="line">            ...</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// get server 的结果</span></span><br><span class="line">            <span class="keyword">return</span> call.getRpcResponse();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendRpcRequest</span><span class="params">(<span class="keyword">final</span> Call call)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> InterruptedException, IOException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (shouldCloseConnection.get()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Serialize the call to be sent. This is done from the actual</span></span><br><span class="line">  <span class="comment">// caller thread, rather than the sendParamsExecutor thread,</span></span><br><span class="line">  </span><br><span class="line">  <span class="comment">// so that if the serialization throws an error, it is reported</span></span><br><span class="line">  <span class="comment">// properly. This also parallelizes the serialization.</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Format of a call on the wire:</span></span><br><span class="line">  <span class="comment">// 0) Length of rest below (1 + 2)</span></span><br><span class="line">  <span class="comment">// 1) RpcRequestHeader  - is serialized Delimited hence contains length</span></span><br><span class="line">  <span class="comment">// 2) RpcRequest</span></span><br><span class="line">  <span class="comment">//</span></span><br><span class="line">  <span class="comment">// Items '1' and '2' are prepared here. </span></span><br><span class="line">  <span class="keyword">final</span> DataOutputBuffer d = <span class="keyword">new</span> DataOutputBuffer();</span><br><span class="line">  RpcRequestHeaderProto header = ProtoUtil.makeRpcRequestHeader(</span><br><span class="line">      call.rpcKind, OperationProto.RPC_FINAL_PACKET, call.id, call.retry,</span><br><span class="line">      clientId);</span><br><span class="line">  header.writeDelimitedTo(d);</span><br><span class="line">  call.rpcRequest.write(d);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">synchronized</span> (sendRpcRequestLock) &#123;</span><br><span class="line">    Future&lt;?&gt; senderFuture = sendParamsExecutor.submit(<span class="keyword">new</span> Runnable() &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">synchronized</span> (Connection.<span class="keyword">this</span>.out) &#123;</span><br><span class="line">            <span class="keyword">if</span> (shouldCloseConnection.get()) &#123;</span><br><span class="line">              <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> (LOG.isDebugEnabled())</span><br><span class="line">              LOG.debug(getName() + <span class="string">" sending #"</span> + call.id);</span><br><span class="line">     </span><br><span class="line">            <span class="keyword">byte</span>[] data = d.getData();</span><br><span class="line">            <span class="keyword">int</span> totalLength = d.getLength();</span><br><span class="line">            out.writeInt(totalLength); <span class="comment">// Total Length</span></span><br><span class="line">            out.write(data, <span class="number">0</span>, totalLength);<span class="comment">// RpcRequestHeader + RpcRequest</span></span><br><span class="line">            out.flush();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          <span class="comment">// exception at this point would leave the connection in an</span></span><br><span class="line">          <span class="comment">// unrecoverable state (eg half a call left on the wire).</span></span><br><span class="line">          <span class="comment">// So, close the connection, killing any outstanding calls</span></span><br><span class="line">          markClosed(e);</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">          <span class="comment">//the buffer is just an in-memory buffer, but it is still polite to</span></span><br><span class="line">          <span class="comment">// close early</span></span><br><span class="line">          IOUtils.closeStream(d);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 等待call发送完毕之后才退出该方法，回到call方法中继续执行</span></span><br><span class="line">      senderFuture.get();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</span><br><span class="line">      Throwable cause = e.getCause();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// cause should only be a RuntimeException as the Runnable above</span></span><br><span class="line">      <span class="comment">// catches IOException</span></span><br><span class="line">      <span class="keyword">if</span> (cause <span class="keyword">instanceof</span> RuntimeException) &#123;</span><br><span class="line">        <span class="keyword">throw</span> (RuntimeException) cause;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"unexpected checked exception"</span>, cause);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来看下server端的代码，server是通过RPC.Builder的build方法构建出来的，来看下build代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Server <span class="title">build</span><span class="params">()</span> <span class="keyword">throws</span> IOException, HadoopIllegalArgumentException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> getProtocolEngine(<span class="keyword">this</span>.protocol, <span class="keyword">this</span>.conf).getServer(</span><br><span class="line">      <span class="keyword">this</span>.protocol, <span class="keyword">this</span>.instance, <span class="keyword">this</span>.bindAddress, <span class="keyword">this</span>.port,</span><br><span class="line">      <span class="keyword">this</span>.numHandlers, <span class="keyword">this</span>.numReaders, <span class="keyword">this</span>.queueSizePerHandler,</span><br><span class="line">      <span class="keyword">this</span>.verbose, <span class="keyword">this</span>.conf, <span class="keyword">this</span>.secretManager, <span class="keyword">this</span>.portRangeConfig);</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="keyword">public</span> RPC.<span class="function">Server <span class="title">getServer</span><span class="params">(Class&lt;?&gt; protocolClass,</span></span></span><br><span class="line"><span class="function"><span class="params">                    Object protocolImpl, String bindAddress, <span class="keyword">int</span> port,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">int</span> numHandlers, <span class="keyword">int</span> numReaders, <span class="keyword">int</span> queueSizePerHandler,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">boolean</span> verbose, Configuration conf,</span></span></span><br><span class="line"><span class="function"><span class="params">                    SecretManager&lt;? extends TokenIdentifier&gt; secretManager,</span></span></span><br><span class="line"><span class="function"><span class="params">                    String portRangeConfig)</span> </span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> Server(protocolClass, protocolImpl, conf, bindAddress, port,</span><br><span class="line">      numHandlers, numReaders, queueSizePerHandler, verbose, secretManager,</span><br><span class="line">      portRangeConfig);</span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line"><span class="comment">//在 Server的构造方法中，一追追溯到ipc.Server的构造方法</span></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="title">Server</span><span class="params">(String bindAddress, <span class="keyword">int</span> port,</span></span></span><br><span class="line"><span class="function"><span class="params">    Class&lt;? extends Writable&gt; rpcRequestClass, <span class="keyword">int</span> handlerCount,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> numReaders, <span class="keyword">int</span> queueSizePerHandler, Configuration conf,</span></span></span><br><span class="line"><span class="function"><span class="params">    String serverName, SecretManager&lt;? extends TokenIdentifier&gt; secretManager,</span></span></span><br><span class="line"><span class="function"><span class="params">    String portRangeConfig)</span></span></span><br><span class="line"><span class="function">  <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  ...  </span><br><span class="line">  <span class="comment">// Start the listener here and let it bind to the port</span></span><br><span class="line">  listener = <span class="keyword">new</span> Listener();</span><br><span class="line">  <span class="keyword">this</span>.port = listener.getAddress().getPort();    </span><br><span class="line">  connectionManager = <span class="keyword">new</span> ConnectionManager();</span><br><span class="line">  <span class="keyword">this</span>.rpcMetrics = RpcMetrics.create(<span class="keyword">this</span>, conf);</span><br><span class="line">  <span class="keyword">this</span>.rpcDetailedMetrics = RpcDetailedMetrics.create(<span class="keyword">this</span>.port);</span><br><span class="line">  <span class="keyword">this</span>.tcpNoDelay = conf.getBoolean(</span><br><span class="line">      CommonConfigurationKeysPublic.IPC_SERVER_TCPNODELAY_KEY,</span><br><span class="line">      CommonConfigurationKeysPublic.IPC_SERVER_TCPNODELAY_DEFAULT);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Create the responder here</span></span><br><span class="line">  responder = <span class="keyword">new</span> Responder();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (secretManager != <span class="keyword">null</span> || UserGroupInformation.isSecurityEnabled()) &#123;</span><br><span class="line">    SaslRpcServer.init(conf);</span><br><span class="line">    saslPropsResolver = SaslPropertiesResolver.getInstance(conf);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">this</span>.exceptionsHandler.addTerseExceptions(StandbyException.class);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在ipc.Server的构造方法中会实例化<code>Listener</code>和<code>Responder</code>两个线程，先看下Listener的构造方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Listener</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  address = <span class="keyword">new</span> InetSocketAddress(bindAddress, port);</span><br><span class="line">  <span class="comment">// Create a new server socket and set to non blocking mode</span></span><br><span class="line">  acceptChannel = ServerSocketChannel.open();</span><br><span class="line">  acceptChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Bind the server socket to the local host and port</span></span><br><span class="line">  bind(acceptChannel.socket(), address, backlogLength, conf, portRangeConfig);</span><br><span class="line">  port = acceptChannel.socket().getLocalPort(); <span class="comment">//Could be an ephemeral port</span></span><br><span class="line">  <span class="comment">// create a selector;</span></span><br><span class="line">  selector= Selector.open();</span><br><span class="line">  <span class="comment">// 创建reader数组，默认长度为1</span></span><br><span class="line">  readers = <span class="keyword">new</span> Reader[readThreads];</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; readThreads; i++) &#123;</span><br><span class="line">    Reader reader = <span class="keyword">new</span> Reader(</span><br><span class="line">        <span class="string">"Socket Reader #"</span> + (i + <span class="number">1</span>) + <span class="string">" for port "</span> + port);</span><br><span class="line">    readers[i] = reader;</span><br><span class="line">    reader.start();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Register accepts on the server socket with the selector.</span></span><br><span class="line">  acceptChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">  <span class="keyword">this</span>.setName(<span class="string">"IPC Server listener on "</span> + port);</span><br><span class="line">  <span class="keyword">this</span>.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整个Server只有一个Listener线程，在Listener线程中使用Java NIO来监听client发来的request连接，初始化Reader数组readers，Reader主要用于反序列化数据，生成服务器端的Call对象。Listener注册的事件是SelectionKey.OP_ACCEPT，Reader注册的事件是SelectionKey.OP_READ。<br>Server中还实例化了一个<code>Responder</code>线程，构造方法中只是得到一个Selector对象，Listener和Reader中也各自含有一个Selector对象，用来选择自己关心的事件。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Responder() <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="keyword">this</span>.setName(<span class="string">"IPC Server Responder"</span>);</span><br><span class="line">  <span class="keyword">this</span>.setDaemon(<span class="keyword">true</span>);</span><br><span class="line">  writeSelector = Selector.open(); <span class="comment">// create a selector</span></span><br><span class="line">  pending = <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>至此Server初始化完毕，然后调用<code>start</code>方法，启动server，启动Server中<code>responder</code>、<code>listener</code>还有<code>handers</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  responder.start();</span><br><span class="line">  listener.start();</span><br><span class="line">  <span class="comment">//启动Hander线程，这个个数是初始化Server时通过setHander设置的</span></span><br><span class="line">  handlers = <span class="keyword">new</span> Handler[handlerCount];</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; handlerCount; i++) &#123;</span><br><span class="line">    handlers[i] = <span class="keyword">new</span> Handler(i);</span><br><span class="line">    handlers[i].start();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先来看下listener的run方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  LOG.info(Thread.currentThread().getName() + <span class="string">": starting"</span>);</span><br><span class="line">  SERVER.set(Server.<span class="keyword">this</span>);  <span class="comment">// ThreadLocal&lt;Server&gt; SERVER    线程局部变量</span></span><br><span class="line">  connectionManager.startIdleScan();</span><br><span class="line">  <span class="keyword">while</span> (running) &#123;</span><br><span class="line">    SelectionKey key = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// 得到selector  </span></span><br><span class="line">      getSelector().select();</span><br><span class="line">      Iterator&lt;SelectionKey&gt; iter = getSelector().selectedKeys().iterator();</span><br><span class="line">      <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        key = iter.next();</span><br><span class="line">        iter.remove();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">if</span> (key.isValid()) &#123;</span><br><span class="line">            <span class="keyword">if</span> (key.isAcceptable())</span><br><span class="line">              <span class="comment">// SelectionKey.OP_ACCEPT 发生后由doAccept来处理</span></span><br><span class="line">              doAccept(key);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">        &#125;</span><br><span class="line">        key = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">      <span class="comment">// we can run out of memory if we have too many threads</span></span><br><span class="line">      <span class="comment">// log the event and sleep for a minute and give </span></span><br><span class="line">      <span class="comment">// some thread(s) a chance to finish</span></span><br><span class="line">      LOG.warn(<span class="string">"Out of Memory in server select"</span>, e);</span><br><span class="line">      closeCurrentConnection(key, e);</span><br><span class="line">      connectionManager.closeIdle(<span class="keyword">true</span>);</span><br><span class="line">      <span class="keyword">try</span> &#123; Thread.sleep(<span class="number">60000</span>); &#125; <span class="keyword">catch</span> (Exception ie) &#123;&#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      closeCurrentConnection(key, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Listener通过selector监听SelectionKey.OP_ACCEPT事件，<em>客户端Client.call中的getConnection会触发该事件</em>，当事件发生后调用<code>doAccept</code>，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">doAccept</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> InterruptedException, IOException,  OutOfMemoryError </span>&#123;</span><br><span class="line">  ServerSocketChannel server = (ServerSocketChannel) key.channel();</span><br><span class="line">  SocketChannel channel;</span><br><span class="line">  <span class="keyword">while</span> ((channel = server.accept()) != <span class="keyword">null</span>) &#123;</span><br><span class="line"></span><br><span class="line">    channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">    channel.socket().setTcpNoDelay(tcpNoDelay);</span><br><span class="line">    channel.socket().setKeepAlive(<span class="keyword">true</span>);</span><br><span class="line">    <span class="comment">// Listener 得到client的连接之后，交给Reader处理</span></span><br><span class="line">    <span class="comment">// 从readers数组中得到一个Reader</span></span><br><span class="line">    Reader reader = getReader();</span><br><span class="line">    <span class="comment">// Server 端的Connection不是一个线程，注意和Client的Connection的区别</span></span><br><span class="line">    <span class="comment">// Connection相当于hander</span></span><br><span class="line">    Connection c = connectionManager.register(channel);</span><br><span class="line">    <span class="comment">// 将当前Connection已经被建立连接，等待closeCurrentConnection关闭连接</span></span><br><span class="line">    key.attach(c);  <span class="comment">// so closeCurrentConnection can get the object</span></span><br><span class="line">    <span class="comment">// 将Connection放入Reader.pendingConnections，等待Reader处理</span></span><br><span class="line">    reader.addConnection(c);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>reader.addConnection(c)</code>的代码是：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addConnection</span><span class="params">(Connection conn)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  pendingConnections.put(conn);</span><br><span class="line">  <span class="comment">// 调用wakeup 是让线程从select()方法的阻塞中跳出来</span></span><br><span class="line">  <span class="comment">// 因为pendingConnections已经加入了新的Connection</span></span><br><span class="line">  readSelector.wakeup();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>线程从<code>select()</code>中跳出来之后，继续运行<code>Reader.run()</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  LOG.info(<span class="string">"Starting "</span> + Thread.currentThread().getName());</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    doRunLoop();</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      readSelector.close();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ioe) &#123;</span><br><span class="line">      LOG.error(<span class="string">"Error closing read selector in "</span> + Thread.currentThread().getName(), ioe);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">doRunLoop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (running) &#123;</span><br><span class="line">    SelectionKey key = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// consume as many connections as currently queued to avoid</span></span><br><span class="line">      <span class="comment">// unbridled acceptance of connections that starves the select</span></span><br><span class="line">      <span class="keyword">int</span> size = pendingConnections.size();</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i=size; i&gt;<span class="number">0</span>; i--) &#123;</span><br><span class="line">        <span class="comment">// pendingConnections 是一个 BlockingQueue</span></span><br><span class="line">        Connection conn = pendingConnections.take();</span><br><span class="line">        conn.channel.register(readSelector, SelectionKey.OP_READ, conn);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 此方法会阻塞，调用readSelector.wakeup()跳出阻塞</span></span><br><span class="line">      readSelector.select();</span><br><span class="line"></span><br><span class="line">      Iterator&lt;SelectionKey&gt; iter = readSelector.selectedKeys().iterator();</span><br><span class="line">      <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        key = iter.next();</span><br><span class="line">        iter.remove();</span><br><span class="line">        <span class="keyword">if</span> (key.isValid()) &#123;</span><br><span class="line">          <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">            doRead(key);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        key = <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      <span class="keyword">if</span> (running) &#123;                      <span class="comment">// unexpected -- log it</span></span><br><span class="line">        LOG.info(Thread.currentThread().getName() + <span class="string">" unexpectedly interrupted"</span>, e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IOException ex) &#123;</span><br><span class="line">      LOG.error(<span class="string">"Error in Reader"</span>, ex);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">doRead</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">  Connection c = (Connection)key.attachment();</span><br><span class="line">  <span class="keyword">if</span> (c == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;  </span><br><span class="line">  &#125;</span><br><span class="line">  c.setLastContact(Time.now());</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    count = c.readAndProcess();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (InterruptedException ieo) &#123;</span><br><span class="line">    LOG.info(Thread.currentThread().getName() + <span class="string">": readAndProcess caught InterruptedException"</span>, ieo);</span><br><span class="line">    <span class="keyword">throw</span> ieo;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    <span class="comment">// a WrappedRpcServerException is an exception that has been sent</span></span><br><span class="line">    <span class="comment">// to the client, so the stacktrace is unnecessary; any other</span></span><br><span class="line">    <span class="comment">// exceptions are unexpected internal server errors and thus the</span></span><br><span class="line">    <span class="comment">// stacktrace should be logged</span></span><br><span class="line">    LOG.info(Thread.currentThread().getName() + <span class="string">": readAndProcess from client "</span> +</span><br><span class="line">        c.getHostAddress() + <span class="string">" threw exception ["</span> + e + <span class="string">"]"</span>,</span><br><span class="line">        (e <span class="keyword">instanceof</span> WrappedRpcServerException) ? <span class="keyword">null</span> : e);</span><br><span class="line">    count = -<span class="number">1</span>; <span class="comment">//so that the (count &lt; 0) block is executed</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (count &lt; <span class="number">0</span>) &#123;</span><br><span class="line">    closeConnection(c);</span><br><span class="line">    c = <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">else</span> &#123;</span><br><span class="line">    c.setLastContact(Time.now());</span><br><span class="line">  &#125;</span><br><span class="line">&#125;  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">readAndProcess</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> WrappedRpcServerException, IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="comment">/* Read at most one RPC. If the header is not read completely yet</span></span><br><span class="line"><span class="comment">     * then iterate until we read first RPC or until there is no data left.</span></span><br><span class="line"><span class="comment">     */</span>    </span><br><span class="line">    <span class="keyword">int</span> count = -<span class="number">1</span>;</span><br><span class="line">    <span class="comment">// this.dataLengthBuffer = ByteBuffer.allocate(4)</span></span><br><span class="line">    <span class="keyword">if</span> (dataLengthBuffer.remaining() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      count = channelRead(channel, dataLengthBuffer);       </span><br><span class="line">      <span class="keyword">if</span> (count &lt; <span class="number">0</span> || dataLengthBuffer.remaining() &gt; <span class="number">0</span>) </span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 读取RPC header RPC header一共4部分</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Write the connection header - this is sent when connection is established</span></span><br><span class="line"><span class="comment">     * +----------------------------------+</span></span><br><span class="line"><span class="comment">     * |  "hrpc" 4 bytes                  |   hrpc 在上面的if语句中读取     </span></span><br><span class="line"><span class="comment">     * +----------------------------------+</span></span><br><span class="line"><span class="comment">     * |  Version (1 byte)                |</span></span><br><span class="line"><span class="comment">     * +----------------------------------+</span></span><br><span class="line"><span class="comment">     * |  Service Class (1 byte)          |</span></span><br><span class="line"><span class="comment">     * +----------------------------------+</span></span><br><span class="line"><span class="comment">     * |  AuthProtocol (1 byte)           |      </span></span><br><span class="line"><span class="comment">     * +----------------------------------+</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">if</span> (!connectionHeaderRead) &#123;</span><br><span class="line">      <span class="comment">//Every connection is expected to send the header.</span></span><br><span class="line">      <span class="keyword">if</span> (connectionHeaderBuf == <span class="keyword">null</span>) &#123;</span><br><span class="line">        connectionHeaderBuf = ByteBuffer.allocate(<span class="number">3</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 将 Version、Service Class、AuthProtocol读出 </span></span><br><span class="line">      count = channelRead(channel, connectionHeaderBuf);</span><br><span class="line">      <span class="keyword">if</span> (count &lt; <span class="number">0</span> || connectionHeaderBuf.remaining() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">int</span> version = connectionHeaderBuf.get(<span class="number">0</span>);</span><br><span class="line">      <span class="comment">// TODO we should add handler for service class later</span></span><br><span class="line">      <span class="keyword">this</span>.setServiceClass(connectionHeaderBuf.get(<span class="number">1</span>));</span><br><span class="line">      dataLengthBuffer.flip();</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Check if it looks like the user is hitting an IPC port</span></span><br><span class="line">      <span class="comment">// with an HTTP GET - this is a common error, so we can</span></span><br><span class="line">      <span class="comment">// send back a simple string indicating as much.</span></span><br><span class="line">      <span class="keyword">if</span> (HTTP_GET_BYTES.equals(dataLengthBuffer)) &#123;</span><br><span class="line">        setupHttpRequestOnIpcPortResponse();</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">if</span> (!RpcConstants.HEADER.equals(dataLengthBuffer)</span><br><span class="line">          || version != CURRENT_VERSION) &#123;</span><br><span class="line">        <span class="comment">//Warning is ok since this is not supposed to happen.</span></span><br><span class="line">        LOG.warn(<span class="string">"Incorrect header or version mismatch from "</span> + </span><br><span class="line">                 hostAddress + <span class="string">":"</span> + remotePort +</span><br><span class="line">                 <span class="string">" got version "</span> + version + </span><br><span class="line">                 <span class="string">" expected version "</span> + CURRENT_VERSION);</span><br><span class="line">        setupBadVersionResponse(version);</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// this may switch us into SIMPLE</span></span><br><span class="line">      authProtocol = initializeAuthContext(connectionHeaderBuf.get(<span class="number">2</span>));          </span><br><span class="line">      </span><br><span class="line">      dataLengthBuffer.clear();</span><br><span class="line">      connectionHeaderBuf = <span class="keyword">null</span>;</span><br><span class="line">      connectionHeaderRead = <span class="keyword">true</span>;</span><br><span class="line">      <span class="comment">// 读完rpc head之后跳出此次循环</span></span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 读取rpcrequest的内容</span></span><br><span class="line">    <span class="keyword">if</span> (data == <span class="keyword">null</span>) &#123;</span><br><span class="line">      dataLengthBuffer.flip();</span><br><span class="line">      dataLength = dataLengthBuffer.getInt();</span><br><span class="line">      checkDataLength(dataLength);</span><br><span class="line">      data = ByteBuffer.allocate(dataLength);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    count = channelRead(channel, data);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (data.remaining() == <span class="number">0</span>) &#123;</span><br><span class="line">      dataLengthBuffer.clear();</span><br><span class="line">      data.flip();</span><br><span class="line">      <span class="keyword">boolean</span> isHeaderRead = connectionContextRead;</span><br><span class="line">      <span class="comment">// 先进行授权然后进行内容的读取</span></span><br><span class="line">      processOneRpc(data.array());</span><br><span class="line">      data = <span class="keyword">null</span>;</span><br><span class="line">      <span class="keyword">if</span> (!isHeaderRead) &#123;</span><br><span class="line">        <span class="comment">// 读取request内容时先进行授权，授权成功之后connectionContextRead变为true</span></span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">    <span class="keyword">return</span> count;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processOneRpc</span><span class="params">(<span class="keyword">byte</span>[] buf)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, WrappedRpcServerException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> callId = -<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">int</span> retry = RpcConstants.INVALID_RETRY_COUNT;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">final</span> DataInputStream dis =</span><br><span class="line">        <span class="keyword">new</span> DataInputStream(<span class="keyword">new</span> ByteArrayInputStream(buf));</span><br><span class="line">    <span class="keyword">final</span> RpcRequestHeaderProto header =</span><br><span class="line">        decodeProtobufFromStream(RpcRequestHeaderProto.newBuilder(), dis);</span><br><span class="line">    callId = header.getCallId();</span><br><span class="line">    retry = header.getRetryCount();</span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">" got #"</span> + callId);</span><br><span class="line">    &#125;</span><br><span class="line">    checkRpcHeaders(header);</span><br><span class="line">    <span class="comment">// 第一次连接callId是CONNECTION_CONTEXT_CALL_ID的值为</span></span><br><span class="line">    <span class="comment">// -3，处理授权，验证通过后设置connectionContextRead的值为true</span></span><br><span class="line">    <span class="keyword">if</span> (callId &lt; <span class="number">0</span>) &#123; <span class="comment">// callIds typically used during connection setup</span></span><br><span class="line">      processRpcOutOfBandRequest(header, dis);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (!connectionContextRead) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> WrappedRpcServerException(</span><br><span class="line">          RpcErrorCodeProto.FATAL_INVALID_RPC_HEADER,</span><br><span class="line">          <span class="string">"Connection context not established"</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 随后的连接处理逻辑  </span></span><br><span class="line">      processRpcRequest(header, dis);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (WrappedRpcServerException wrse) &#123; <span class="comment">// inform client of error</span></span><br><span class="line">    Throwable ioe = wrse.getCause();</span><br><span class="line">    <span class="keyword">final</span> Call call = <span class="keyword">new</span> Call(callId, retry, <span class="keyword">null</span>, <span class="keyword">this</span>);</span><br><span class="line">    setupResponse(authFailedResponse, call,</span><br><span class="line">        RpcStatusProto.FATAL, wrse.getRpcErrorCodeProto(), <span class="keyword">null</span>,</span><br><span class="line">        ioe.getClass().getName(), ioe.getMessage());</span><br><span class="line">    responder.doRespond(call);</span><br><span class="line">    <span class="keyword">throw</span> wrse;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processRpcRequest</span><span class="params">(RpcRequestHeaderProto header,</span></span></span><br><span class="line"><span class="function"><span class="params">     DataInputStream dis)</span> <span class="keyword">throws</span> WrappedRpcServerException,</span></span><br><span class="line"><span class="function">     InterruptedException </span>&#123;</span><br><span class="line">   Class&lt;? extends Writable&gt; rpcRequestClass = </span><br><span class="line">       getRpcRequestWrapper(header.getRpcKind());</span><br><span class="line">   ...</span><br><span class="line">   Writable rpcRequest;</span><br><span class="line">   <span class="keyword">try</span> &#123; <span class="comment">//Read the rpc request</span></span><br><span class="line">     rpcRequest = ReflectionUtils.newInstance(rpcRequestClass, conf);</span><br><span class="line">     <span class="comment">// 进行反序列化，从Writable流中读取数据</span></span><br><span class="line">     rpcRequest.readFields(dis);</span><br><span class="line">   &#125; <span class="keyword">catch</span> (Throwable t) &#123; <span class="comment">// includes runtime exception from newInstance</span></span><br><span class="line">     ...</span><br><span class="line">   &#125;</span><br><span class="line">   ...</span><br><span class="line">   <span class="comment">// 实例化Server端的Call对象，然后放入callQueue中，等待handler来处理</span></span><br><span class="line">   Call call = <span class="keyword">new</span> Call(header.getCallId(), header.getRetryCount(),</span><br><span class="line">       rpcRequest, <span class="keyword">this</span>, ProtoUtil.convert(header.getRpcKind()),</span><br><span class="line">       header.getClientId().toByteArray(), traceSpan);</span><br><span class="line"></span><br><span class="line">   callQueue.put(call);              <span class="comment">// queue the call; maybe blocked here</span></span><br><span class="line">   incRpcCount();  <span class="comment">// Increment the rpc count</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>至此Server端的接受请求阶段已经处理完成，下面由各个handler区共享队列callQueue中取出call进行处理。Handler有多个线程组成，则看Handler的run方法，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  LOG.debug(Thread.currentThread().getName() + <span class="string">": starting"</span>);</span><br><span class="line">  SERVER.set(Server.<span class="keyword">this</span>);</span><br><span class="line">  ByteArrayOutputStream buf = </span><br><span class="line">    <span class="keyword">new</span> ByteArrayOutputStream(INITIAL_RESP_BUF_SIZE);</span><br><span class="line">  <span class="keyword">while</span> (running) &#123;</span><br><span class="line">    TraceScope traceScope = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">final</span> Call call = callQueue.take(); <span class="comment">// pop the queue; maybe blocked here</span></span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(Thread.currentThread().getName() + <span class="string">": "</span> + call + <span class="string">" for RpcKind "</span> + call.rpcKind);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!call.connection.channel.isOpen()) &#123;</span><br><span class="line">        LOG.info(Thread.currentThread().getName() + <span class="string">": skipped "</span> + call);</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      String errorClass = <span class="keyword">null</span>;</span><br><span class="line">      String error = <span class="keyword">null</span>;</span><br><span class="line">      RpcStatusProto returnStatus = RpcStatusProto.SUCCESS;</span><br><span class="line">      RpcErrorCodeProto detailedErr = <span class="keyword">null</span>;</span><br><span class="line">      Writable value = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">      CurCall.set(call);</span><br><span class="line">      <span class="keyword">if</span> (call.traceSpan != <span class="keyword">null</span>) &#123;</span><br><span class="line">        traceScope = Trace.continueSpan(call.traceSpan);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// Make the call as the user via Subject.doAs, thus associating</span></span><br><span class="line">        <span class="comment">// the call with the Subject</span></span><br><span class="line">        <span class="keyword">if</span> (call.connection.user == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// 对call对象进行处理</span></span><br><span class="line">          value = call(call.rpcKind, call.connection.protocolName, call.rpcRequest, </span><br><span class="line">                       call.timestamp);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          value = </span><br><span class="line">            call.connection.user.doAs</span><br><span class="line">              (<span class="keyword">new</span> PrivilegedExceptionAction&lt;Writable&gt;() &#123;</span><br><span class="line">                 <span class="meta">@Override</span></span><br><span class="line">                 <span class="function"><span class="keyword">public</span> Writable <span class="title">run</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                   <span class="comment">// make the call</span></span><br><span class="line">                   <span class="keyword">return</span> call(call.rpcKind, call.connection.protocolName, </span><br><span class="line">                               call.rpcRequest, call.timestamp);</span><br><span class="line"></span><br><span class="line">                 &#125;</span><br><span class="line">               &#125;</span><br><span class="line">              );</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">        ...</span><br><span class="line">      &#125;</span><br><span class="line">      CurCall.set(<span class="keyword">null</span>);</span><br><span class="line">      <span class="keyword">synchronized</span> (call.connection.responseQueue) &#123;</span><br><span class="line">        <span class="comment">// setupResponse() needs to be sync'ed together with </span></span><br><span class="line">        <span class="comment">// responder.doResponse() since setupResponse may use</span></span><br><span class="line">        <span class="comment">// SASL to encrypt response data and SASL enforces</span></span><br><span class="line">        <span class="comment">// its own message ordering.</span></span><br><span class="line">        setupResponse(buf, call, returnStatus, detailedErr, </span><br><span class="line">            value, errorClass, error);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Discard the large buf and reset it back to smaller size </span></span><br><span class="line">        <span class="comment">// to free up heap</span></span><br><span class="line">        <span class="keyword">if</span> (buf.size() &gt; maxRespSize) &#123;</span><br><span class="line">          LOG.warn(<span class="string">"Large response size "</span> + buf.size() + <span class="string">" for call "</span></span><br><span class="line">              + call.toString());</span><br><span class="line">          buf = <span class="keyword">new</span> ByteArrayOutputStream(INITIAL_RESP_BUF_SIZE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 处理完之后将call放入responseQueue中</span></span><br><span class="line">        responder.doRespond(call);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">      <span class="keyword">if</span> (traceScope != <span class="keyword">null</span>) &#123;</span><br><span class="line">        traceScope.close();</span><br><span class="line">      &#125;</span><br><span class="line">      IOUtils.cleanup(LOG, traceScope);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.debug(Thread.currentThread().getName() + <span class="string">": exiting"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>handler中处理call的代码<code>value = call(call.rpcKind, call.connection.protocolName, call.rpcRequest, call.timestamp)</code>，实现是在<code>RPC.Server.call</code>中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Writable <span class="title">call</span><span class="params">(RPC.RpcKind rpcKind, String protocol,</span></span></span><br><span class="line"><span class="function"><span class="params">    Writable rpcRequest, <span class="keyword">long</span> receiveTime)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  <span class="comment">// getPpcInvoker 得到序列化Engine      </span></span><br><span class="line">  <span class="keyword">return</span> getRpcInvoker(rpcKind).call(<span class="keyword">this</span>, protocol, rpcRequest,</span><br><span class="line">      receiveTime);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// WritableRpcEngine.Server中cal的实现</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Writable <span class="title">call</span><span class="params">(org.apache.hadoop.ipc.RPC.Server server,</span></span></span><br><span class="line"><span class="function"><span class="params">    String protocolName, Writable rpcRequest, <span class="keyword">long</span> receivedTime)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> IOException, RPC.VersionMismatch </span>&#123;</span><br><span class="line"> ...</span><br><span class="line">    <span class="comment">// Invoke the protocol method</span></span><br><span class="line"> <span class="keyword">long</span> startTime = Time.now();</span><br><span class="line"> <span class="keyword">int</span> qTime = (<span class="keyword">int</span>) (startTime-receivedTime);</span><br><span class="line"> Exception exception = <span class="keyword">null</span>;</span><br><span class="line"> <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 得到Method</span></span><br><span class="line">    Method method =</span><br><span class="line">        protocolImpl.protocolClass.getMethod(call.getMethodName(),</span><br><span class="line">        call.getParameterClasses());</span><br><span class="line">    method.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">    server.rpcDetailedMetrics.init(protocolImpl.protocolClass);</span><br><span class="line">    <span class="comment">// 方法的调用，由协议的实现类执行方法    反射</span></span><br><span class="line">    Object value = </span><br><span class="line">        method.invoke(protocolImpl.protocolImpl, call.getParameters());</span><br><span class="line">    <span class="keyword">if</span> (server.verbose) log(<span class="string">"Return: "</span>+value);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ObjectWritable(method.getReturnType(), value);</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">catch</span> (InvocationTargetException e) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>call执行完之后，返回到Handler的run方法中继续执行，将call交给<code>responder.doRespond</code>处理，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">doRespond</span><span class="params">(Call call)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">synchronized</span> (call.connection.responseQueue) &#123;</span><br><span class="line">    <span class="comment">// 将call加入到responseQueue中，每个connection都有一个responseQueue</span></span><br><span class="line">    call.connection.responseQueue.addLast(call);</span><br><span class="line">    <span class="comment">// 当responseQueue的大小为1时，直接由Handler线程进行处理</span></span><br><span class="line">    <span class="comment">// 当responseQueue的大小大于1时，由Responder线程进行处理</span></span><br><span class="line">    <span class="keyword">if</span> (call.connection.responseQueue.size() == <span class="number">1</span>) &#123;</span><br><span class="line">      processResponse(call.connection.responseQueue, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>请求已经处理完成，如果responseQueue大小为1，则直接由Handler调用<code>processResponse</code>返回结果，如果responseQueue的大小大于1，则由Responder线程返回结果，先看下run代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  LOG.info(Thread.currentThread().getName() + <span class="string">": starting"</span>);</span><br><span class="line">  SERVER.set(Server.<span class="keyword">this</span>);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    doRunLoop();</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doRunLoop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> lastPurgeTime = <span class="number">0</span>;   <span class="comment">// last check for old calls.</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (running) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      waitPending();     <span class="comment">// If a channel is being registered, wait.</span></span><br><span class="line">      writeSelector.select(PURGE_INTERVAL);</span><br><span class="line">      Iterator&lt;SelectionKey&gt; iter = writeSelector.selectedKeys().iterator();</span><br><span class="line">      <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">        SelectionKey key = iter.next();</span><br><span class="line">        iter.remove();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">if</span> (key.isValid() &amp;&amp; key.isWritable()) &#123;</span><br><span class="line">            <span class="comment">// 从名字来看是异步处理，但怎么体现出来的？</span></span><br><span class="line">              doAsyncWrite(key);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">          LOG.info(Thread.currentThread().getName() + <span class="string">": doAsyncWrite threw exception "</span> + e);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">long</span> now = Time.now();</span><br><span class="line">      <span class="keyword">if</span> (now &lt; lastPurgeTime + PURGE_INTERVAL) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      lastPurgeTime = now;</span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// If there were some calls that have not been sent out for a</span></span><br><span class="line">      <span class="comment">// long time, discard them.</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="keyword">if</span>(LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(<span class="string">"Checking for old call responses."</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      ArrayList&lt;Call&gt; calls;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// get the list of channels from list of keys.</span></span><br><span class="line">      <span class="comment">// 得到所有的注册键的集合</span></span><br><span class="line">      <span class="keyword">synchronized</span> (writeSelector.keys()) &#123;</span><br><span class="line">        calls = <span class="keyword">new</span> ArrayList&lt;Call&gt;(writeSelector.keys().size());</span><br><span class="line">        iter = writeSelector.keys().iterator();</span><br><span class="line">        <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">          SelectionKey key = iter.next();</span><br><span class="line">          Call call = (Call)key.attachment();</span><br><span class="line">          <span class="comment">// 这里得到的list是什么？？？？ 没有处理完再次进入responseQueue的call</span></span><br><span class="line">          <span class="keyword">if</span> (call != <span class="keyword">null</span> &amp;&amp; key.channel() == call.connection.channel) &#123; </span><br><span class="line">            calls.add(call);</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">for</span>(Call call : calls) &#123;</span><br><span class="line">        doPurge(call, now);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (OutOfMemoryError e) &#123;</span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// we can run out of memory if we have too many threads</span></span><br><span class="line">      <span class="comment">// log the event and sleep for a minute and give</span></span><br><span class="line">      <span class="comment">// some thread(s) a chance to finish</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      LOG.warn(<span class="string">"Out of Memory in server select"</span>, e);</span><br><span class="line">      <span class="keyword">try</span> &#123; Thread.sleep(<span class="number">60000</span>); &#125; <span class="keyword">catch</span> (Exception ie) &#123;&#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"Exception in Responder"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doAsyncWrite</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  Call call = (Call)key.attachment();</span><br><span class="line">  <span class="keyword">if</span> (call == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (key.channel() != call.connection.channel) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> IOException(<span class="string">"doAsyncWrite: bad channel"</span>);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">synchronized</span>(call.connection.responseQueue) &#123;</span><br><span class="line">    <span class="keyword">if</span> (processResponse(call.connection.responseQueue, <span class="keyword">false</span>)) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        key.interestOps(<span class="number">0</span>);</span><br><span class="line">      &#125; <span class="keyword">catch</span> (CancelledKeyException e) &#123;</span><br><span class="line">        <span class="comment">/* The Listener/reader might have closed the socket.</span></span><br><span class="line"><span class="comment">         * We don't explicitly cancel the key, so not sure if this will</span></span><br><span class="line"><span class="comment">         * ever fire.</span></span><br><span class="line"><span class="comment">         * This warning could be removed.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        LOG.warn(<span class="string">"Exception while changing ops : "</span> + e);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Processes one response. Returns true if there are no more pending</span></span><br><span class="line"><span class="comment">// data for this channel.</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">processResponse</span><span class="params">(LinkedList&lt;Call&gt; responseQueue,</span></span></span><br><span class="line"><span class="function"><span class="params">                                <span class="keyword">boolean</span> inHandler)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  <span class="keyword">boolean</span> error = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">boolean</span> done = <span class="keyword">false</span>;       <span class="comment">// there is more data for this channel.</span></span><br><span class="line">  <span class="keyword">int</span> numElements = <span class="number">0</span>;</span><br><span class="line">  Call call = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (responseQueue) &#123;</span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// If there are no items for this channel, then we are done</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      numElements = responseQueue.size();</span><br><span class="line">      <span class="keyword">if</span> (numElements == <span class="number">0</span>) &#123;</span><br><span class="line">        error = <span class="keyword">false</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;              <span class="comment">// no more data for this channel.</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Extract the first call</span></span><br><span class="line">      call = responseQueue.removeFirst();</span><br><span class="line">      SocketChannel channel = call.connection.channel;</span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(Thread.currentThread().getName() + <span class="string">": responding to "</span> + call);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="comment">// Send as much data as we can in the non-blocking fashion</span></span><br><span class="line">      <span class="comment">//</span></span><br><span class="line">      <span class="keyword">int</span> numBytes = channelWrite(channel, call.rpcResponse);</span><br><span class="line">      <span class="keyword">if</span> (numBytes &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 如果call.rpcResponse写完了则将call.rpcResponse清空</span></span><br><span class="line">      <span class="comment">// 如果没有写完，则再将其放入responseQueue的连头</span></span><br><span class="line">      <span class="comment">// 当Handler没能将结果一次性发送到客户端时,会向该Selector对象注册SelectionKey.OP_WRITE事件</span></span><br><span class="line">      <span class="keyword">if</span> (!call.rpcResponse.hasRemaining()) &#123;</span><br><span class="line">        <span class="comment">//Clear out the response buffer so it can be collected</span></span><br><span class="line">        call.rpcResponse = <span class="keyword">null</span>;</span><br><span class="line">        call.connection.decRpcCount();</span><br><span class="line">        <span class="keyword">if</span> (numElements == <span class="number">1</span>) &#123;    <span class="comment">// last call fully processes.</span></span><br><span class="line">          done = <span class="keyword">true</span>;             <span class="comment">// no more data for this channel.</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          done = <span class="keyword">false</span>;            <span class="comment">// more calls pending to be sent.</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">          LOG.debug(Thread.currentThread().getName() + <span class="string">": responding to "</span> + call</span><br><span class="line">              + <span class="string">" Wrote "</span> + numBytes + <span class="string">" bytes."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">// If we were unable to write the entire response out, then </span></span><br><span class="line">        <span class="comment">// insert in Selector queue. </span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        call.connection.responseQueue.addFirst(call);</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (inHandler) &#123;</span><br><span class="line">          <span class="comment">// set the serve time when the response has to be sent later</span></span><br><span class="line">          call.timestamp = Time.now();</span><br><span class="line">          </span><br><span class="line">          incPending();</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// Wakeup the thread blocked on select, only then can the call </span></span><br><span class="line">            <span class="comment">// to channel.register() complete.</span></span><br><span class="line">            writeSelector.wakeup();</span><br><span class="line">            channel.register(writeSelector, SelectionKey.OP_WRITE, call);</span><br><span class="line">          &#125; <span class="keyword">catch</span> (ClosedChannelException e) &#123;</span><br><span class="line">            <span class="comment">//Its ok. channel might be closed else where.</span></span><br><span class="line">            done = <span class="keyword">true</span>;</span><br><span class="line">          &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            decPending();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">          LOG.debug(Thread.currentThread().getName() + <span class="string">": responding to "</span> + call</span><br><span class="line">              + <span class="string">" Wrote partial "</span> + numBytes + <span class="string">" bytes."</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      error = <span class="keyword">false</span>;              <span class="comment">// everything went off well</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (error &amp;&amp; call != <span class="keyword">null</span>) &#123;</span><br><span class="line">      LOG.warn(Thread.currentThread().getName()+<span class="string">", call "</span> + call + <span class="string">": output error"</span>);</span><br><span class="line">      done = <span class="keyword">true</span>;               <span class="comment">// error. no more data for this channel.</span></span><br><span class="line">      closeConnection(call.connection);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> done;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Server端返回结果的过程到此结束，接下来又回到了clinet端，由Connection线程接受Server的Response。代码在Connection中run方法中的receiveRpcResponse，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Receive a response.</span></span><br><span class="line"><span class="comment"> * Because only one receiver, so no synchronization on in.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">receiveRpcResponse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (shouldCloseConnection.get()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  touch();</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">int</span> totalLen = in.readInt();</span><br><span class="line">    RpcResponseHeaderProto header = </span><br><span class="line">        RpcResponseHeaderProto.parseDelimitedFrom(in);</span><br><span class="line">    checkResponse(header);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> headerLen = header.getSerializedSize();</span><br><span class="line">    headerLen += CodedOutputStream.computeRawVarint32Size(headerLen);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> callId = header.getCallId();</span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled())</span><br><span class="line">      LOG.debug(getName() + <span class="string">" got value #"</span> + callId);</span><br><span class="line"></span><br><span class="line">    Call call = calls.get(callId);</span><br><span class="line">    RpcStatusProto status = header.getStatus();</span><br><span class="line">    <span class="keyword">if</span> (status == RpcStatusProto.SUCCESS) &#123;</span><br><span class="line">      Writable value = ReflectionUtils.newInstance(valueClass, conf);</span><br><span class="line">      value.readFields(in);                 <span class="comment">// read value</span></span><br><span class="line">      calls.remove(callId);</span><br><span class="line">      <span class="comment">// 将 value 值设置为call的Response</span></span><br><span class="line">      call.setRpcResponse(value);</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// verify that length was correct</span></span><br><span class="line">      <span class="comment">// only for ProtobufEngine where len can be verified easily</span></span><br><span class="line">      <span class="keyword">if</span> (call.getRpcResponse() <span class="keyword">instanceof</span> ProtobufRpcEngine.RpcWrapper) &#123;</span><br><span class="line">        ProtobufRpcEngine.RpcWrapper resWrapper = </span><br><span class="line">            (ProtobufRpcEngine.RpcWrapper) call.getRpcResponse();</span><br><span class="line">        <span class="keyword">if</span> (totalLen != headerLen + resWrapper.getLength()) &#123; </span><br><span class="line">          <span class="keyword">throw</span> <span class="keyword">new</span> RpcClientException(</span><br><span class="line">              <span class="string">"RPC response length mismatch on rpc success"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;<span class="keyword">else</span> &#123; <span class="comment">// Rpc Request failed</span></span><br><span class="line">      ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">    markClosed(e);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">setRpcResponse</span><span class="params">(Writable rpcResponse)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.rpcResponse = rpcResponse;</span><br><span class="line">  callComplete();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">callComplete</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">this</span>.done = <span class="keyword">true</span>;</span><br><span class="line">  <span class="comment">// 通知在call中由connection.sendRpcRequest之后调用call.wait()的线程</span></span><br><span class="line">  notify();                                 <span class="comment">// notify caller</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>notify之后再次回到Client.call的线程中执行<code>call.getRpcResponse()</code>,</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> Writable <span class="title">getRpcResponse</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> rpcResponse;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>代码分析完毕，用文字总结下Hadoop RPC的大致流程：</p>
<blockquote>
<p>Client通过代理在invoke中调用client.call之后的流程</p>
</blockquote>
<ol>
<li>远程方法调用信息封装成Call对象，查看当前client与server是否已经建立connection，如果没有则创建一个Connection对象，否则直接get一个connection，将Call对象放到Connection对象中的哈希表calls中; </li>
<li>调用 Connection 类中的sendRpcRequest()方法将当前Call对象发送给Server端，并调用call.wait()阻塞线程; </li>
<li>Server端处理完RPC请求后,将结果通过网络返回给Client端,Client端通过Connection线程调用receiveRpcResponse()函数获取结果; </li>
<li>Client检查结果处理状态(成功还是失败),并将对应 Call 对象从哈希表calls中删除，将结果赋值给call.rpcResponse。 </li>
</ol>
<blockquote>
<p>Server</p>
</blockquote>
<ol>
<li><p>接收请求;该阶段主要任务是接收来自各个客户端的RPC请求,并将它们封装成固定的格式(Call类)放到一个共享队列(callQueue)中,以便进行后续处理。<br>该阶段内部又分为建立连接和接收请求两个子阶段,分别由Listener和Reader两种线程完成。整个Server<strong>只有一个</strong>Listener线程,统一负责监听来自客户端的连接请求,一旦有新的请求到达,它会采用轮询的方式从线程池中选择一个Reader线程进行处理,而Reader线程可同时存在多个,它们分别负责接收一部分客户端连接的RPC请求,至于每个Reader线程负责哪些客户端连接,完全由Listener决定,当前Listener只是采用了简单的轮询分配机制。Listener和Reader线程内部各自包含一个Selector对象,分别用于监听SelectionKey.OP_ACCEPT和SelectionKey.OP_READ 事件。对于Listener线程,主循环的实现体是监听是否有新的连接请求到达,并采用轮询策略选择一个Reader线程处理新连接;对于Reader线程,主循环的实现体是监听(它负责的那部分)客户端连接中是否有新的RPC请求到达,并将新的RPC请求封装成Call对象,放到共享队列callQueue 中。</p>
</li>
<li><p>处理请求;该阶段主要任务是从共享队列callQueue中获取Call对象,执行对应的函数调用,并将结果返回给客户端,这全部由<strong>Handler线程完成</strong>。Server 端可同时存在多个Handler线程,它们并行从<em>共享队列</em>中读取Call对象,经执行对应的函数调用后,将尝试着直接将结果返回给对应的客户端。但考虑到某些函数调用返回结果很大或者网络速度过慢,可能难以将结果一次性发送到客户端,此时Handler将尝试着将后续发送任务交给Responder线程。</p>
</li>
<li><p>返回结果;前面提到,每个Handler线程执行完函数调用后,会尝试着将执行结果返回给客户端,但对于特殊情况,比如函数调用返回结果过大或者网络异常情况(网速过慢),会将发送任务交给Responder线程。Server端<strong>仅存在一个</strong>Responder线程,它的内部包含一个Selector对象,用于监听SelectionKey.OP_WRITE事件。当Handler没能将结果一次性发送到客户端时,会向该Selector对象注册SelectionKey.OP_WRITE事件,进而由Responder 线程采用<em>异步方式</em>继续发送未发送完成的结果</p>
</li>
</ol>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://jomolangma.com/?p=130" target="_blank" rel="noopener">http://jomolangma.com/?p=130</a></p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> RPC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[NameNode元数据及checkpoint分析]]></title>
      <url>http://bigdatadecode.club/NameNode%E5%85%83%E6%95%B0%E6%8D%AE%E5%8F%8Acheckpoint%E5%88%86%E6%9E%90.html</url>
      <content type="html"><![CDATA[<h2 id="NamNode"><a href="#NamNode" class="headerlink" title="NamNode"></a>NamNode</h2><p>NameNode 的主要作用是</p>
<ol>
<li>负责管理文件系统的命名空间、集群配置信息和存储块的复制；</li>
<li>维护着整个文件系统的文件目录树和文件根目录的元信息和每个文件对应的数据块列表；</li>
<li>接收用户的操作请求；</li>
<li>管理文件与block之间的关系，block与DataNode之间的关系；</li>
</ol>
<p>NameNode 的启动流程为：</p>
<ol>
<li>Loading fsimage - 从fsimage file中读取最新的文件系统的元数据快照(最近生成的fsimage_xx)</li>
<li>Loading edits - 读取包含fsimage_xx之后的所有tx的edit logs并将edit logs中的操作从新操作一遍更新到元数据中，则此时NN更新到上次停止时的状态。</li>
<li>checkpoint - 将当前状态写入新的checkpoint中，即产生一个新的fsimage_xx文件</li>
<li>Safe mode - 等待各个<em>datanodes report</em>各自的block信息，形成blockMap，然后退出安全模式。</li>
</ol>
<p>此时NN启动结束，等待接受用户的操作请求，并把各种操作写入新的edit log中，定期进行checkpoint，对元数据进行快照。</p>
<a id="more"></a>
<h2 id="NameNode-元数据"><a href="#NameNode-元数据" class="headerlink" title="NameNode 元数据"></a>NameNode 元数据</h2><p>NameNode的所有操作及整个集群的状态都存储在<em>元数据</em>中。NN的元数据存储是由fsimage和edits文件组成。fsimage存放上次checkpoint生成的文件系统元数据，Edits存放文件系统<em>操作日志</em>。checkpoint的过程，就是合并fsimage和Edits文件，然后生成最新的fsimage的过程。</p>
<p>NameNode在执行HDFS客户端提交的创建文件或者移动文件这样的<em>写操作</em>的时候，会首先把这些操作记录在Edit Log 文件之中，然后再更新内存中的文件系统镜像。内存中的<em>文件系统镜像</em>用于NameNode向客户端提供<em>读服务</em>，而 EditLog仅仅只是在数据恢复的时候起作用。记录在 EditLog之中的每一个操作又称为一个事务，每个事务有一个整数形式的事务id作为编号。EditLog会被切割为很多段，每一段称为一个Segment。正在写入的EditLog Segment处于in-progress状态，其文件名形如edits_inprogress_${start_txid}，其中${start_txid}表示这个segment的起始事务id。而已经写入完成的EditLog Segment处于finalized状态，其文件名形如edits_${start_txid}-${end_txid}，其中${start_txid}表示这个segment的起始事务id，${end_txid}表示这个segment 的结束事务id。</p>
<p>NameNode会定期对内存中的文件系统镜像进行checkpoint操作，在磁盘上生成FSImage文件，FSImage文件的文件名形如fsimage_${end_txid}，其中${end_txid}表示这个fsimage文件的结束事务id。在NameNode启动的时候会进行数据恢复，首先把FSImage文件加载到内存中形成文件系统镜像，然后再把EditLog之中<strong>FsImage的结束事务id之后的EditLog</strong>回放到这个文件系统镜像上。</p>
<h2 id="元数据在磁盘中的目录结构"><a href="#元数据在磁盘中的目录结构" class="headerlink" title="元数据在磁盘中的目录结构"></a>元数据在磁盘中的目录结构</h2><h3 id="NameNode中dfs-namenode-name-dir下的元数据"><a href="#NameNode中dfs-namenode-name-dir下的元数据" class="headerlink" title="NameNode中dfs.namenode.name.dir下的元数据"></a>NameNode中dfs.namenode.name.dir下的元数据</h3><p>NameNode元数据会周期性的固化到磁盘，所在磁盘目录是在<code>hdfs-site.xml</code>中由<code>dfs.namenode.name.dir</code>配置的。目录结构如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; ll <span class="variable">$dfs</span>.namenode.name.dir</span><br><span class="line">drwxrwxr-x 2 hadoop hadoop 4096 Aug  1 19:03 current</span><br><span class="line">-rw-rw-r-- 1 hadoop hadoop   14 Jul 29 15:49 in_use.lock</span><br></pre></td></tr></table></figure>
<p>current里的内容如下：<br><img src="/blogimgs/namenode-checkpoint/namenode-metadata-dir.png" alt="current目录" title="current目录"></p>
<p>上面是将fsimage和edits都放在一个目录中，也可以通过配置将fsimage和edits分别放在不同的目录中。下面就具体介绍下目录中各个文件的作用：</p>
<ul>
<li>in_use.lock – 看名字可以得知这是一个锁文件，由NameNode持有，用来阻止多个NameNode同时修改该目录</li>
<li>VERSION - Java属性文件，内容大致如下</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Fri Jul 29 15:50:00 CST 2016</span></span><br><span class="line">namespaceID=1793378918</span><br><span class="line">clusterID=CID-0bcbc37e-90e2-40c5-91c2-101db9fc4f9b</span><br><span class="line">cTime=0</span><br><span class="line">storageType=NAME_NODE</span><br><span class="line">blockpoolID=BP-2041947102-172.16.2.126-1451322470514</span><br><span class="line">layoutVersion=-60</span><br></pre></td></tr></table></figure>
<ul>
<li>layoutVersion – HDFS元数据格式化的版本。如果给HDFS添加新的feature而需要改变元数据的格式化版本，则改变此属性，版本号是递减的。</li>
<li>storageType – 说明这个文件存储的是什么进程的数据结构信息。(NAME_NODE或者JOURNAL_NODE，JOURNAL_NODE是JouranlNode的元数据，在DataNode中是DATA_NODE)</li>
<li>cTime – 文件系统创建的时间，随着HDFS的升级而改变。(这里没有对HDFS升级，则记录值为0)</li>
<li>namespaceID/clusterID/blockpoolID – 这些都唯一标识了HDFS集群。这些标识主要是用来防止DataNode注册到别的其它集群的NameNode中。这些标识符在联邦部署中尤其重要。在联邦模式下，每个NameSpace都唯一的namespaceID，管理着对应的唯一blockpoolID，而clusterID则是整个联邦集群的唯一逻辑单元，集群中所有的节点都相同。</li>
<li>seen_txid – 这个文件里记录了最后一次checkpoint(将edits合并到fsimage中)或者edit回滚(将edits_inprogress_xx文件回滚成一个新的edits文件)之后的transactionID。注意这里记录的不是NameNode接受的最后一个transactionID，此文件不会在每次transaction都会更新，只在checkpoint和edit回滚时更新<strong>(但是通过观察2.6.0版本的本地元数据磁盘目录中记录的此值，是实时更新的，每次transaction都会更新，这个具体随后更代码看下什么情况，在此只做记录下)</strong>。此文件的目的是在NameNode启动过程中发现edits文件丢失的情况。如果edits文件丢失，NameNode启动的过程中加载fsimage文件，此时fsimage并不是最新的NameNode状态，而此时又缺失一些edits文件，但NameNode并不知道，而是正常启动了，此时就会造成一些数据丢失。seen_txid能用来防止这种情况发生，如果发现seen_txid中记录的值和edits的值不一样，则启动失败。</li>
</ul>
<h3 id="JournalNode下的元数据"><a href="#JournalNode下的元数据" class="headerlink" title="JournalNode下的元数据"></a>JournalNode下的元数据</h3><p>在HA模式下，edits由一组独立的守护进程JournalNodes进行收集。JournalNode的元数据目录配置在hdfs-site.xml的<code>dfs.journalnode.edits.dir</code>。JournalNode的元数据包含一个VERSION文件，多个edits_xx文件和一个edits_inprogress_xx，还包含一些与HA实现相关的文件，这些文件主要是为了防止脑裂，<em>但是JournalNode并不包含fsimage和seen_txid</em>。</p>
<p>下面主要介绍下与NameNode元数据不一样的文件：</p>
<ul>
<li>committed-txid – 记录由NameNode提交的最后一个transaction ID</li>
<li>last-promised-epoch – 这个文件记录了epoch，epoch是一个单调递增的数字。当standby变为active时，JournalNode会会增加epoch并存储。NameNode主要通过该值来告诉JournalNode谁是active，小于该值的NameNode禁止对JournalNode元数据写操作，写请求被忽略。</li>
<li>last-writer-epoch – 和上面的值类似，该文件记录下最后一次发生写操作的epoch。</li>
<li>paxos – 此目录包含一些临时文件，主要在实现paxos分布式算法协议中使用。这个目录通常是空的。</li>
</ul>
<h2 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h2><blockquote>
<p>每个写操作都会写入Edit log中，随着时间的积累edit log会变的很大，极端情况下不仅会占满整个磁盘，而且在NN启动的时候会延长启动时间，因为NN需要将edits log中的操作重新执行一遍。这就需要checkpoint定期对元数据进行合并。</p>
</blockquote>
<p>Checkpoint主要是将fsimage和edit log的内容进行合并生成一个新的fsimage。这样在NN启动的时候就不用将巨大的edits里的事务再次执行一遍了，而是直接加载合并之后的新fsimage，然后重新执行未被合并的edits文件就可以了。</p>
<p><em>创建新fsimage的过程需要大量的I/O、内存等资源，而且namesystem在Checkpoint的时候会限制用户的访问。则NN将Checkpoint过程放在SecondaryNameNode或者StandbyNameNode中。</em></p>
<p>Checkpoint的触发条件有两个，满足其中一个即可：</p>
<ol>
<li>两次checkpoint的时间间隔达到阈值，由属性<code>dfs.namenode.checkpoint.period</code>控制，默认是3600s</li>
<li>新生成的edit log中积累的事务数量达到了阈值，由属性<code>dfs.namenode.checkpoint.txns</code>控制，默认1000000</li>
</ol>
<p>SecondaryNameNode或者StandbyNameNode周期性的去检查是否符合触发Checkpoint的条件，间隔周期是由<code>dfs.namenode.checkpoint.check.period</code>控制的，默认是60s</p>
<blockquote>
<p>Fsimage回滚条件</p>
</blockquote>
<ol>
<li>fsimage会在每次checkpoint时生成一个新的fsimage</li>
<li>NN重启的时候也会生成一个新的fsimage</li>
</ol>
<p><em>fsimage默认会保存两个</em>，由属性<code>dfs.namenode.num.checkpoints.retained</code>控制</p>
<blockquote>
<p>Edits log回滚条件</p>
</blockquote>
<ol>
<li>NameNode(active)周期性的检查当前的事务数是否超过了edits回滚阈值。<br>间隔周期是由<code>dfs.namenode.edit.log.autoroll.check.interval.ms</code>控制，默认是300000ms。<br>回滚的阈值是<code>dfs.namenode.edit.log.autoroll.multiplier.threshold</code>和<code>dfs.namenode.checkpoint.txns</code>的乘积，<code>dfs.namenode.edit.log.autoroll.multiplier.threshold</code>默认是2.0f</li>
<li>在HA模式下，standby NN会周期的让active NN对edits进行回滚，间隔周期由<code>dfs.ha.log-roll.period</code><br>控制，默认是120s</li>
</ol>
<p>standby NN之所以周期的让active NN回滚edits log是因为standby NN不会读取<em>inprogress</em>的edits，只是周期（<code>dfs.ha.tail-edits.period</code>，默认是60s）的去检测已经完成的edits文件，并将该edits文件通过JournalNode读取到内存更新fsimage在内存中的状态。</p>
<p><strong>HA模式下，client只和active进行通信，将写操作信息分别写入本地的edits中和JournalNode中的edits中，standby NN周期的去JournalNode中读取进行同步。只有在active宕机之后，standby才对外提供服务，平时只是实现了active的热备</strong></p>
<p>edits log默认会保存<code>dfs.namenode.num.extra.edits.retained</code>条事务，默认是1000000条</p>
<h2 id="查看fsimage和edits内容的命令"><a href="#查看fsimage和edits内容的命令" class="headerlink" title="查看fsimage和edits内容的命令"></a>查看fsimage和edits内容的命令</h2><blockquote>
<p>查看fsimage命令</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oiv -p XML -i fsimage -o fsimage.xml</span><br></pre></td></tr></table></figure>
<p><code>-i</code>是输入的fsimage文件名，<code>-o</code>是输出的文件名，<code>-p</code>是输出的格式。具体的细节可以查看官网或者使用help命令查看。</p>
<blockquote>
<p>查看edits命令</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs oev -i edits -o edits.xml</span><br></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> Checkpoint </tag>
            
            <tag> Fsimage </tag>
            
            <tag> Edits </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS ReplicationMonitor副本监控线程解析]]></title>
      <url>http://bigdatadecode.club/HDFS%20ReplicationMonitor%E5%89%AF%E6%9C%AC%E7%9B%91%E6%8E%A7%E7%BA%BF%E7%A8%8B%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<p><a href="http://bigdatadecode.club/HDFS维持副本平衡的流程.html">上篇</a>文章介绍了HDFS中副本数的维持，当某个block的副本数大于期望的副本数时，通过<code>BlockManager.processOverReplicatedBlock</code>，对副本进行处理，根据规则选择要删除副本的dn，将dn和block放入<em>invalidateBlocks</em>中，然后ReplicationMonitor线程会从中取出block副本进行删除。当某个block的副本数少于期望的副本数时，通过<code>BlockManager.processMisReplicatedBlock</code>，对副本根据其复制优先级进行划分，放入<em>neededReplications</em>，然后ReplicationMonitor线程会从中取出block副本进行复制。</p>
<a id="more"></a>
<h2 id="ReplicationMonitor线程"><a href="#ReplicationMonitor线程" class="headerlink" title="ReplicationMonitor线程"></a>ReplicationMonitor线程</h2><p>ReplicationMonitor实现了Runnable接口，通过<code>FSNameSystem.startCommonServices -&gt; blockManager.activate(conf) -&gt; this.replicationThread.start()</code>被启动，主要作用就是计算DataNode工作，并将复制请求超时的块重新加入到待调度队列。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (namesystem.isRunning()) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// Process replication work only when active NN is out of safe mode.</span></span><br><span class="line">      <span class="keyword">if</span> (namesystem.isPopulatingReplQueues()) &#123;</span><br><span class="line">        computeDatanodeWork();</span><br><span class="line">        processPendingReplications();</span><br><span class="line">      &#125;</span><br><span class="line">      Thread.sleep(replicationRecheckInterval);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      ...</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>线程中通过<code>computeDatanodeWork</code>计算DataNode的工作，通过<code>processPendingReplications</code>将超时的请求放入<em>neededReplication</em>队列。</p>
<p>Datanode的工作包括复制和删除，看下<code>computeDatanodeWork</code>的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Compute block replication and block invalidation work that can be scheduled</span></span><br><span class="line"><span class="comment"> * on data-nodes. The datanode will be informed of this work at the next</span></span><br><span class="line"><span class="comment"> * heartbeat.</span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> number of blocks scheduled for replication or removal.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">computeDatanodeWork</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Blocks should not be replicated or removed if in safe mode.</span></span><br><span class="line">  <span class="comment">// It's OK to check safe mode here w/o holding lock, in the worst</span></span><br><span class="line">  <span class="comment">// case extra replications will be scheduled, and these will get</span></span><br><span class="line">  <span class="comment">// fixed up later.</span></span><br><span class="line">  <span class="keyword">if</span> (namesystem.isInSafeMode()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numlive = heartbeatManager.getLiveDatanodeCount();</span><br><span class="line">  <span class="comment">// dfs.namenode.replication.work.multiplier.per.iteration 默认为2</span></span><br><span class="line">  <span class="comment">// 一次心跳总共有多少个block进行转移</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> blocksToProcess = numlive</span><br><span class="line">      * <span class="keyword">this</span>.blocksReplWorkMultiplier;</span><br><span class="line">  <span class="comment">// 一次心跳删除多个dn上的invalidate block，计数单位是x个dn</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> nodesToProcess = (<span class="keyword">int</span>) Math.ceil(numlive</span><br><span class="line">      * <span class="keyword">this</span>.blocksInvalidateWorkPct);</span><br><span class="line">  <span class="comment">// 计算复制的工作量</span></span><br><span class="line">  <span class="keyword">int</span> workFound = <span class="keyword">this</span>.computeReplicationWork(blocksToProcess);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Update counters</span></span><br><span class="line">  namesystem.writeLock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">this</span>.updateState();</span><br><span class="line">    <span class="keyword">this</span>.scheduledReplicationBlocksCount = workFound;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    namesystem.writeUnlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 计算删除的工作量</span></span><br><span class="line">  workFound += <span class="keyword">this</span>.computeInvalidateWork(nodesToProcess);</span><br><span class="line">  <span class="keyword">return</span> workFound;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>computeDatanodeWork通过numLive得到一次心跳需要复制副本的期望个数<em>blocksToProcess</em>和一次心跳需要删除副本的期望个数<em>nodesToProcess</em>，然后分别有<em>computeReplicationWork</em>和<em>computeInvalidateWork</em>分别进行复制和删除。</p>
<h2 id="复制"><a href="#复制" class="headerlink" title="复制"></a>复制</h2><p>下面先来看下复制工作<code>computeReplicationWork</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">computeReplicationWork</span><span class="params">(<span class="keyword">int</span> blocksToProcess)</span> </span>&#123;</span><br><span class="line">  List&lt;List&lt;Block&gt;&gt; blocksToReplicate = <span class="keyword">null</span>;</span><br><span class="line">  namesystem.writeLock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// Choose the blocks to be replicated</span></span><br><span class="line">    <span class="comment">// 从neededReplications中按照优先级挑选出block</span></span><br><span class="line">    blocksToReplicate = neededReplications</span><br><span class="line">        .chooseUnderReplicatedBlocks(blocksToProcess);</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    namesystem.writeUnlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 对选中的block list进行复制</span></span><br><span class="line">  <span class="keyword">return</span> computeReplicationWorkForBlocks(blocksToReplicate);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>computeReplicationWork的功能是从<em>neededReplications</em>中按照优先级选取blocksToProcess个block，然后调用<em>computeReplicationWorkForBlocks</em>进行复制。<em>neededReplications.chooseUnderReplicatedBlocks</em>的选取规则如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> List&lt;List&lt;Block&gt;&gt; chooseUnderReplicatedBlocks(</span><br><span class="line">    <span class="keyword">int</span> blocksToProcess) &#123;</span><br><span class="line">  <span class="comment">// initialize data structure for the return value</span></span><br><span class="line">  List&lt;List&lt;Block&gt;&gt; blocksToReplicate = <span class="keyword">new</span> ArrayList&lt;List&lt;Block&gt;&gt;(LEVEL);</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; LEVEL; i++) &#123;</span><br><span class="line">    blocksToReplicate.add(<span class="keyword">new</span> ArrayList&lt;Block&gt;());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (size() == <span class="number">0</span>) &#123; <span class="comment">// There are no blocks to collect.</span></span><br><span class="line">    <span class="keyword">return</span> blocksToReplicate;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">int</span> blockCount = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> priority = <span class="number">0</span>; priority &lt; LEVEL; priority++) &#123; </span><br><span class="line">    <span class="comment">// Go through all blocks that need replications with current priority.</span></span><br><span class="line">    <span class="comment">// 从priorityQueues中取出对应优先级的list，并转换为iterator</span></span><br><span class="line">    BlockIterator neededReplicationsIterator = iterator(priority);</span><br><span class="line">    <span class="comment">// priorityToReplIdx是一个map，存放各个优先级中需要复制副本在list中的index</span></span><br><span class="line">    <span class="comment">// 得到priority开始复制的index</span></span><br><span class="line">    Integer replIndex = priorityToReplIdx.get(priority);</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// skip to the first unprocessed block, which is at replIndex</span></span><br><span class="line">    <span class="comment">// 从neededReplicationsIterator中跳过找到replIndex对应的block</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; replIndex &amp;&amp; neededReplicationsIterator.hasNext(); i++) &#123;</span><br><span class="line">      neededReplicationsIterator.next();</span><br><span class="line">    &#125;</span><br><span class="line">    blocksToProcess = Math.min(blocksToProcess, size());</span><br><span class="line">    <span class="comment">// blockCount统计复制了多个block，达到blocksToProcess则跳出循环</span></span><br><span class="line">    <span class="keyword">if</span> (blockCount == blocksToProcess) &#123;</span><br><span class="line">      <span class="keyword">break</span>;  <span class="comment">// break if already expected blocks are obtained</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Loop through all remaining blocks in the list.</span></span><br><span class="line">    <span class="comment">// 将block添加到blocksToReplicate对应的优先级list中</span></span><br><span class="line">    <span class="keyword">while</span> (blockCount &lt; blocksToProcess</span><br><span class="line">        &amp;&amp; neededReplicationsIterator.hasNext()) &#123;</span><br><span class="line">      Block block = neededReplicationsIterator.next();</span><br><span class="line">      blocksToReplicate.get(priority).add(block);</span><br><span class="line">      replIndex++;</span><br><span class="line">      blockCount++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果neededReplicationsIterator中没有block，并且此时的优先级为4，即最低优先级</span></span><br><span class="line">    <span class="comment">// 则说明block已被复制结束，priorityToReplIdx进行重新赋值</span></span><br><span class="line">    <span class="keyword">if</span> (!neededReplicationsIterator.hasNext()</span><br><span class="line">        &amp;&amp; neededReplicationsIterator.getPriority() == LEVEL - <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="comment">// reset all priorities replication index to 0 because there is no</span></span><br><span class="line">      <span class="comment">// recently added blocks in any list.</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; LEVEL; i++) &#123;</span><br><span class="line">        priorityToReplIdx.put(i, <span class="number">0</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 如果neededReplicationsIterator中没有block，则进行下一次循环，取出下优先级的list</span></span><br><span class="line">    <span class="comment">// 将当前优先级复制的index写入priorityToReplIdx</span></span><br><span class="line">    priorityToReplIdx.put(priority, replIndex); </span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> blocksToReplicate;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><em>chooseUnderReplicatedBlocks</em>负责选取<em>blocksToProcess</em>个block，先从priorityQueues中按照优先级取出对应的block list，利用blockCount进行计数，如果达到blocksToProcess，则跳出for，返回blocksToReplicate，否则取下一优先级的block list，接着计数，直到blocksToProcess为止。</p>
<p>选出blocksToReplicate，则调用<code>computeReplicationWorkForBlocks</code>进行复制</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">computeReplicationWorkForBlocks</span><span class="params">(List&lt;List&lt;Block&gt;&gt; blocksToReplicate)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> requiredReplication, numEffectiveReplicas;</span><br><span class="line">  List&lt;DatanodeDescriptor&gt; containingNodes;</span><br><span class="line">  DatanodeDescriptor srcNode;</span><br><span class="line">  BlockCollection bc = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">int</span> additionalReplRequired;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">int</span> scheduledWork = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 存放需要copy的block列表</span></span><br><span class="line">  List&lt;ReplicationWork&gt; work = <span class="keyword">new</span> LinkedList&lt;ReplicationWork&gt;();</span><br><span class="line">  namesystem.writeLock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (neededReplications) &#123;</span><br><span class="line">    	<span class="comment">// 按照优先级进行复制，先复制高优先级的</span></span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> priority = <span class="number">0</span>; priority &lt; blocksToReplicate.size(); priority++) &#123;</span><br><span class="line">      	<span class="comment">// 得到对应优先级的block list</span></span><br><span class="line">        <span class="keyword">for</span> (Block block : blocksToReplicate.get(priority)) &#123;</span><br><span class="line">          <span class="comment">// block should belong to a file</span></span><br><span class="line">          bc = blocksMap.getBlockCollection(block);</span><br><span class="line">          <span class="comment">// abandoned block or block reopened for append</span></span><br><span class="line">          <span class="comment">// 如果block被遗弃(该block没有对应的文件)或者该block正在被追加，则不复制</span></span><br><span class="line">          <span class="keyword">if</span>(bc == <span class="keyword">null</span> || (bc.isUnderConstruction() &amp;&amp; block.equals(bc.getLastBlock()))) &#123;</span><br><span class="line">            neededReplications.remove(block, priority); <span class="comment">// remove from neededReplications</span></span><br><span class="line">            neededReplications.decrementReplicationIndex(priority);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 得到expect replication</span></span><br><span class="line">          requiredReplication = bc.getBlockReplication();</span><br><span class="line">          <span class="comment">// get a source data-node</span></span><br><span class="line">          <span class="comment">// 存放该block所有副本(包括live、corrupt、excess)的datanode</span></span><br><span class="line">          <span class="comment">// 在chooseSourceDatanode中赋值</span></span><br><span class="line">          containingNodes = <span class="keyword">new</span> ArrayList&lt;DatanodeDescriptor&gt;();</span><br><span class="line">          List&lt;DatanodeStorageInfo&gt; liveReplicaNodes = <span class="keyword">new</span> ArrayList&lt;DatanodeStorageInfo&gt;();</span><br><span class="line">          NumberReplicas numReplicas = <span class="keyword">new</span> NumberReplicas();</span><br><span class="line">          <span class="comment">// 选择一个复制源点srcDode，</span></span><br><span class="line">          srcNode = chooseSourceDatanode(</span><br><span class="line">              block, containingNodes, liveReplicaNodes, numReplicas,</span><br><span class="line">              priority);</span><br><span class="line">          <span class="keyword">if</span>(srcNode == <span class="keyword">null</span>) &#123; <span class="comment">// block can not be replicated from any node</span></span><br><span class="line">            LOG.debug(<span class="string">"Block "</span> + block + <span class="string">" cannot be repl from any node"</span>);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line"></span><br><span class="line">          <span class="comment">// liveReplicaNodes can include READ_ONLY_SHARED replicas which are </span></span><br><span class="line">          <span class="comment">// not included in the numReplicas.liveReplicas() count</span></span><br><span class="line">          <span class="keyword">assert</span> liveReplicaNodes.size() &gt;= numReplicas.liveReplicas();</span><br><span class="line">          <span class="comment">// do not schedule more if enough replicas is already pending</span></span><br><span class="line">          <span class="comment">// 有效副本的个数由live的个数+pending的个数(准备复制的个数)</span></span><br><span class="line">          numEffectiveReplicas = numReplicas.liveReplicas() +</span><br><span class="line">                                  pendingReplications.getNumReplicas(block);</span><br><span class="line">          <span class="comment">// live+准备复制的个数达到了requiredReplication，不进行再次复制</span></span><br><span class="line">          <span class="keyword">if</span> (numEffectiveReplicas &gt;= requiredReplication) &#123;</span><br><span class="line">            <span class="keyword">if</span> ( (pendingReplications.getNumReplicas(block) &gt; <span class="number">0</span>) ||</span><br><span class="line">                 (blockHasEnoughRacks(block)) ) &#123;</span><br><span class="line">              neededReplications.remove(block, priority); <span class="comment">// remove from neededReplications</span></span><br><span class="line">              neededReplications.decrementReplicationIndex(priority);</span><br><span class="line">              blockLog.info(<span class="string">"BLOCK* Removing "</span> + block</span><br><span class="line">                  + <span class="string">" from neededReplications as it has enough replicas"</span>);</span><br><span class="line">              <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// additionalReplRequired表示准备要复制的个数</span></span><br><span class="line">          <span class="keyword">if</span> (numReplicas.liveReplicas() &lt; requiredReplication) &#123;</span><br><span class="line">            additionalReplRequired = requiredReplication</span><br><span class="line">                - numEffectiveReplicas;</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            additionalReplRequired = <span class="number">1</span>; <span class="comment">// Needed on a new rack</span></span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// 将block、srcDode等信息包装成ReplicationWork，放入work的list中</span></span><br><span class="line">          work.add(<span class="keyword">new</span> ReplicationWork(block, bc, srcNode,</span><br><span class="line">              containingNodes, liveReplicaNodes, additionalReplRequired,</span><br><span class="line">              priority));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    namesystem.writeUnlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 用于存放block副本所在dn集合，避免选target时选到已有副本的dn</span></span><br><span class="line">  <span class="keyword">final</span> Set&lt;Node&gt; excludedNodes = <span class="keyword">new</span> HashSet&lt;Node&gt;();</span><br><span class="line">  <span class="keyword">for</span>(ReplicationWork rw : work)&#123;</span><br><span class="line">    <span class="comment">// Exclude all of the containing nodes from being targets.</span></span><br><span class="line">    <span class="comment">// This list includes decommissioning or corrupt nodes.</span></span><br><span class="line">    excludedNodes.clear();</span><br><span class="line">    <span class="keyword">for</span> (DatanodeDescriptor dn : rw.containingNodes) &#123;</span><br><span class="line">      excludedNodes.add(dn);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// choose replication targets: NOT HOLDING THE GLOBAL LOCK</span></span><br><span class="line">    <span class="comment">// It is costly to extract the filename for which chooseTargets is called,</span></span><br><span class="line">    <span class="comment">// so for now we pass in the block collection itself.</span></span><br><span class="line">    rw.chooseTargets(blockplacement, storagePolicySuite, excludedNodes);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  namesystem.writeLock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">for</span>(ReplicationWork rw : work)&#123;</span><br><span class="line">      <span class="keyword">final</span> DatanodeStorageInfo[] targets = rw.targets;</span><br><span class="line">      <span class="keyword">if</span>(targets == <span class="keyword">null</span> || targets.length == <span class="number">0</span>)&#123;</span><br><span class="line">        rw.targets = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">synchronized</span> (neededReplications) &#123;</span><br><span class="line">        Block block = rw.block;</span><br><span class="line">        <span class="keyword">int</span> priority = rw.priority;</span><br><span class="line">        <span class="comment">// Recheck since global lock was released</span></span><br><span class="line">        <span class="comment">// block should belong to a file</span></span><br><span class="line">        bc = blocksMap.getBlockCollection(block);</span><br><span class="line">        <span class="comment">// abandoned block or block reopened for append</span></span><br><span class="line">        <span class="keyword">if</span>(bc == <span class="keyword">null</span> || (bc.isUnderConstruction() &amp;&amp; block.equals(bc.getLastBlock()))) &#123;</span><br><span class="line">          neededReplications.remove(block, priority); <span class="comment">// remove from neededReplications</span></span><br><span class="line">          rw.targets = <span class="keyword">null</span>;</span><br><span class="line">          neededReplications.decrementReplicationIndex(priority);</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        requiredReplication = bc.getBlockReplication();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// do not schedule more if enough replicas is already pending</span></span><br><span class="line">        NumberReplicas numReplicas = countNodes(block);</span><br><span class="line">        numEffectiveReplicas = numReplicas.liveReplicas() +</span><br><span class="line">          pendingReplications.getNumReplicas(block);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (numEffectiveReplicas &gt;= requiredReplication) &#123;</span><br><span class="line">          <span class="keyword">if</span> ( (pendingReplications.getNumReplicas(block) &gt; <span class="number">0</span>) ||</span><br><span class="line">               (blockHasEnoughRacks(block)) ) &#123;</span><br><span class="line">            neededReplications.remove(block, priority); <span class="comment">// remove from neededReplications</span></span><br><span class="line">            neededReplications.decrementReplicationIndex(priority);</span><br><span class="line">            rw.targets = <span class="keyword">null</span>;</span><br><span class="line">            blockLog.info(<span class="string">"BLOCK* Removing "</span> + block</span><br><span class="line">                + <span class="string">" from neededReplications as it has enough replicas"</span>);</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ( (numReplicas.liveReplicas() &gt;= requiredReplication) &amp;&amp;</span><br><span class="line">             (!blockHasEnoughRacks(block)) ) &#123;</span><br><span class="line">          <span class="keyword">if</span> (rw.srcNode.getNetworkLocation().equals(</span><br><span class="line">              targets[<span class="number">0</span>].getDatanodeDescriptor().getNetworkLocation())) &#123;</span><br><span class="line">            <span class="comment">//No use continuing, unless a new rack in this case</span></span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Add block to the to be replicated list</span></span><br><span class="line">        <span class="comment">// 将复制block的个数放入dn中，用于统计dn上有多少个副本要复制，是否达到上限</span></span><br><span class="line">        rw.srcNode.addBlockToBeReplicated(block, targets);</span><br><span class="line">        scheduledWork++;</span><br><span class="line">        DatanodeStorageInfo.incrementBlocksScheduled(targets);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Move the block-replication into a "pending" state.</span></span><br><span class="line">        <span class="comment">// The reason we use 'pending' is so we can retry</span></span><br><span class="line">        <span class="comment">// replications that fail after an appropriate amount of time.</span></span><br><span class="line">        <span class="comment">// 放入pending队列等待调度</span></span><br><span class="line">        pendingReplications.increment(block,</span><br><span class="line">            DatanodeStorageInfo.toDatanodeDescriptors(targets));</span><br><span class="line">        <span class="keyword">if</span>(blockLog.isDebugEnabled()) &#123;</span><br><span class="line">          blockLog.debug(</span><br><span class="line">              <span class="string">"BLOCK* block "</span> + block</span><br><span class="line">              + <span class="string">" is moved from neededReplications to pendingReplications"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// remove from neededReplications</span></span><br><span class="line">        <span class="keyword">if</span>(numEffectiveReplicas + targets.length &gt;= requiredReplication) &#123;</span><br><span class="line">          neededReplications.remove(block, priority); <span class="comment">// remove from neededReplications</span></span><br><span class="line">          neededReplications.decrementReplicationIndex(priority);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    namesystem.writeUnlock();</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> scheduledWork;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>computeReplicationWorkForBlocks代码比较长，差不多200行，看的时候可以把代码逻辑写在纸上，慢慢分析。主要包括3个大for循环，第一个for循环是找到各个block的srcNode，第二个for循环是找到个人block的targets，第三个for循环则是把各个block放入pending队列，等待调度。</p>
<h3 id="第一个for循环"><a href="#第一个for循环" class="headerlink" title="第一个for循环"></a>第一个for循环</h3><p>第一个for循环中的srcNode是在<code>chooseSourceDatanode</code>中选取的，选取规则为，<strong>优先选择正在下线的节点，然后随机选择一个没有达到复制上限的节点，如果复制的优先级最高并且所以的节点都达到了上限，则随机选一个</strong>。下面看下代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function">DatanodeDescriptor <span class="title">chooseSourceDatanode</span><span class="params">(Block block,</span></span></span><br><span class="line"><span class="function"><span class="params">     List&lt;DatanodeDescriptor&gt; containingNodes,</span></span></span><br><span class="line"><span class="function"><span class="params">     List&lt;DatanodeStorageInfo&gt;  nodesContainingLiveReplicas,</span></span></span><br><span class="line"><span class="function"><span class="params">     NumberReplicas numReplicas,</span></span></span><br><span class="line"><span class="function"><span class="params">     <span class="keyword">int</span> priority)</span> </span>&#123;</span><br><span class="line">  containingNodes.clear();</span><br><span class="line">  nodesContainingLiveReplicas.clear();</span><br><span class="line">  DatanodeDescriptor srcNode = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">int</span> live = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> decommissioned = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> corrupt = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> excess = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">  Collection&lt;DatanodeDescriptor&gt; nodesCorrupt = corruptReplicas.getNodes(block);</span><br><span class="line">  <span class="keyword">for</span>(DatanodeStorageInfo storage : blocksMap.getStorages(block)) &#123;</span><br><span class="line">    <span class="keyword">final</span> DatanodeDescriptor node = storage.getDatanodeDescriptor();</span><br><span class="line">    LightWeightLinkedSet&lt;Block&gt; excessBlocks =</span><br><span class="line">      excessReplicateMap.get(node.getDatanodeUuid());</span><br><span class="line">    <span class="comment">// 统计的前提是当前磁盘正常</span></span><br><span class="line">    <span class="keyword">int</span> countableReplica = storage.getState() == State.NORMAL ? <span class="number">1</span> : <span class="number">0</span>; </span><br><span class="line">    <span class="keyword">if</span> ((nodesCorrupt != <span class="keyword">null</span>) &amp;&amp; (nodesCorrupt.contains(node)))</span><br><span class="line">      corrupt += countableReplica;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (node.isDecommissionInProgress() || node.isDecommissioned())</span><br><span class="line">      decommissioned += countableReplica;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (excessBlocks != <span class="keyword">null</span> &amp;&amp; excessBlocks.contains(block)) &#123;</span><br><span class="line">      excess += countableReplica;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// 统计包含read only的情况</span></span><br><span class="line">      <span class="comment">// 当State为read only时，countableReplica为0，live没有统计read only的情况</span></span><br><span class="line">      nodesContainingLiveReplicas.add(storage);</span><br><span class="line">      live += countableReplica;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 将block的副本所在dn都放入containingNodes中</span></span><br><span class="line">    containingNodes.add(node);</span><br><span class="line">    <span class="comment">// Check if this replica is corrupt</span></span><br><span class="line">    <span class="comment">// If so, do not select the node as src node</span></span><br><span class="line">    <span class="keyword">if</span> ((nodesCorrupt != <span class="keyword">null</span>) &amp;&amp; nodesCorrupt.contains(node))</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    <span class="comment">// 如果priority是最高优先级，则可以忽略是否达到复制的上线</span></span><br><span class="line">    <span class="keyword">if</span>(priority != UnderReplicatedBlocks.QUEUE_HIGHEST_PRIORITY</span><br><span class="line">        &amp;&amp; node.getNumberOfBlocksToBeReplicated() &gt;= maxReplicationStreams)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">continue</span>; <span class="comment">// already reached replication limit</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 但是如果当前node的复制个数超过了replicationStreamsHardLimit，不管什么优先级都跳过</span></span><br><span class="line">    <span class="keyword">if</span> (node.getNumberOfBlocksToBeReplicated() &gt;= replicationStreamsHardLimit)</span><br><span class="line">    &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// the block must not be scheduled for removal on srcNode</span></span><br><span class="line">    <span class="keyword">if</span>(excessBlocks != <span class="keyword">null</span> &amp;&amp; excessBlocks.contains(block))</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    <span class="comment">// never use already decommissioned nodes</span></span><br><span class="line">    <span class="keyword">if</span>(node.isDecommissioned())</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    <span class="comment">// we prefer nodes that are in DECOMMISSION_INPROGRESS state</span></span><br><span class="line">    <span class="comment">// 优先选择正在下线的dn</span></span><br><span class="line">    <span class="keyword">if</span>(node.isDecommissionInProgress() || srcNode == <span class="keyword">null</span>) &#123;</span><br><span class="line">      srcNode = node;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(srcNode.isDecommissionInProgress())</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    <span class="comment">// switch to a different node randomly</span></span><br><span class="line">    <span class="comment">// this to prevent from deterministically selecting the same node even</span></span><br><span class="line">    <span class="comment">// if the node failed to replicate the block on previous iterations</span></span><br><span class="line">    <span class="comment">// 没有正在下线的，则随机选一个</span></span><br><span class="line">    <span class="keyword">if</span>(DFSUtil.getRandom().nextBoolean())</span><br><span class="line">      srcNode = node;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span>(numReplicas != <span class="keyword">null</span>)</span><br><span class="line">    numReplicas.initialize(live, decommissioned, corrupt, excess, <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">return</span> srcNode;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>chooseSourceDatanode中主要是选择srcNode，选取规则上面已经介绍，这里介绍两个<em>限制值</em>：</p>
<ol>
<li>maxReplicationStreams：一个给定节点<em>除最高优先级复制外复制流的最大数目</em>，取参数dfs.namenode.replication.max-streams，参数未配置默认为2；</li>
<li>replicationStreamsHardLimit：一个给定节点<em>全部优先级复制复制流的最大数目</em>，取参数dfs.namenode.replication.max-streams-hard-limit，参数未配置默认为4。针对所有的优先级，算是一个硬性指标吧，所有为hard limit吧。</li>
</ol>
<h3 id="第二个for循环"><a href="#第二个for循环" class="headerlink" title="第二个for循环"></a>第二个for循环</h3><p>第二个for循环是调用<code>ReplicationWork.chooseTargets</code>为每个block选取targets，chooseTargets代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">chooseTargets</span><span class="params">(BlockPlacementPolicy blockplacement,</span></span></span><br><span class="line"><span class="function"><span class="params">    BlockStoragePolicySuite storagePolicySuite,</span></span></span><br><span class="line"><span class="function"><span class="params">    Set&lt;Node&gt; excludedNodes)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    targets = blockplacement.chooseTarget(bc.getName(),</span><br><span class="line">        additionalReplRequired, srcNode, liveReplicaStorages, <span class="keyword">false</span>,</span><br><span class="line">        excludedNodes, block.getNumBytes(),</span><br><span class="line">        storagePolicySuite.getPolicy(bc.getStoragePolicyID()));</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    srcNode.decrementPendingReplicationWithoutTargets();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>然后调用BlockPlacementPolicy的chooseTarget进行选取，这里<code>BlockPlacementPolicyDefault</code>对chooseTarget进行了重写，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> DatanodeStorageInfo[] chooseTarget(<span class="keyword">int</span> numOfReplicas,</span><br><span class="line">                                  Node writer,</span><br><span class="line">                                  List&lt;DatanodeStorageInfo&gt; chosenStorage,</span><br><span class="line">                                  <span class="keyword">boolean</span> returnChosenNodes,</span><br><span class="line">                                  Set&lt;Node&gt; excludedNodes,</span><br><span class="line">                                  <span class="keyword">long</span> blocksize,</span><br><span class="line">                                  <span class="keyword">final</span> BlockStoragePolicy storagePolicy) &#123;</span><br><span class="line">  ...</span><br><span class="line">   <span class="comment">// 相同block的副本在每个机架上最多的个数</span></span><br><span class="line">  <span class="keyword">int</span>[] result = getMaxNodesPerRack(chosenStorage.size(), numOfReplicas);</span><br><span class="line">  numOfReplicas = result[<span class="number">0</span>];</span><br><span class="line">  <span class="keyword">int</span> maxNodesPerRack = result[<span class="number">1</span>];</span><br><span class="line">  <span class="comment">// chosenStorage副本所在节点的list，这里的副本只包括正常的和read only</span></span><br><span class="line">  <span class="comment">// results为</span></span><br><span class="line">  <span class="keyword">final</span> List&lt;DatanodeStorageInfo&gt; results = <span class="keyword">new</span> ArrayList&lt;DatanodeStorageInfo&gt;(chosenStorage);</span><br><span class="line">  <span class="comment">// 将副本所在的节点加入excludeNodes中，避免其选为target</span></span><br><span class="line">  <span class="keyword">for</span> (DatanodeStorageInfo storage : chosenStorage) &#123;</span><br><span class="line">    <span class="comment">// add localMachine and related nodes to excludedNodes</span></span><br><span class="line">    addToExcludedNodes(storage.getDatanodeDescriptor(), excludedNodes);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">boolean</span> avoidStaleNodes = (stats != <span class="keyword">null</span></span><br><span class="line">      &amp;&amp; stats.isAvoidingStaleDataNodesForWrite());</span><br><span class="line">  <span class="comment">// 根据需要复制的副本数选择targets，将targets放入results中，返回srcNode</span></span><br><span class="line">  <span class="keyword">final</span> Node localNode = chooseTarget(numOfReplicas, writer, excludedNodes,</span><br><span class="line">      blocksize, maxNodesPerRack, results, avoidStaleNodes, storagePolicy,</span><br><span class="line">      EnumSet.noneOf(StorageType.class), results.isEmpty());</span><br><span class="line">  <span class="keyword">if</span> (!returnChosenNodes) &#123;  </span><br><span class="line">    results.removeAll(chosenStorage);</span><br><span class="line">  &#125;</span><br><span class="line">    </span><br><span class="line">  <span class="comment">// sorting nodes to form a pipeline</span></span><br><span class="line">  <span class="comment">// 对targets进行排序，得到pipeline</span></span><br><span class="line">  <span class="keyword">return</span> getPipeline(</span><br><span class="line">      (writer != <span class="keyword">null</span> &amp;&amp; writer <span class="keyword">instanceof</span> DatanodeDescriptor) ? writer</span><br><span class="line">          : localNode,</span><br><span class="line">      results.toArray(<span class="keyword">new</span> DatanodeStorageInfo[results.size()]));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>chooseTarget中又调用了一个同名函数<em>chooseTarget</em>来进行targets选取，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">chooseTarget</span><span class="params">(<span class="keyword">int</span> numOfReplicas,</span></span></span><br><span class="line"><span class="function"><span class="params">                          Node writer,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> Set&lt;Node&gt; excludedNodes,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">long</span> blocksize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">int</span> maxNodesPerRack,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> List&lt;DatanodeStorageInfo&gt; results,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">boolean</span> avoidStaleNodes,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> BlockStoragePolicy storagePolicy,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> EnumSet&lt;StorageType&gt; unavailableStorages,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">boolean</span> newBlock)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numOfResults = results.size();</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> totalReplicasExpected = numOfReplicas + numOfResults;</span><br><span class="line">  <span class="keyword">if</span> ((writer == <span class="keyword">null</span> || !(writer <span class="keyword">instanceof</span> DatanodeDescriptor)) &amp;&amp; !newBlock) &#123;</span><br><span class="line">    writer = results.get(<span class="number">0</span>).getDatanodeDescriptor();</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> ((numOfReplicas = requiredStorageTypes.size()) == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NotEnoughReplicasException(</span><br><span class="line">          <span class="string">"All required storage types are unavailable: "</span></span><br><span class="line">          + <span class="string">" unavailableStorages="</span> + unavailableStorages</span><br><span class="line">          + <span class="string">", storagePolicy="</span> + storagePolicy);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// munOfResults为0是说results中没有数据，也就是当前block没有副本</span></span><br><span class="line">    <span class="keyword">if</span> (numOfResults == <span class="number">0</span>) &#123;</span><br><span class="line">      writer = chooseLocalStorage(writer, excludedNodes, blocksize,</span><br><span class="line">          maxNodesPerRack, results, avoidStaleNodes, storageTypes, <span class="keyword">true</span>)</span><br><span class="line">              .getDatanodeDescriptor();</span><br><span class="line">      <span class="keyword">if</span> (--numOfReplicas == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> writer;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 从results中取出第一个副本所在节点</span></span><br><span class="line">    <span class="keyword">final</span> DatanodeDescriptor dn0 = results.get(<span class="number">0</span>).getDatanodeDescriptor();</span><br><span class="line">    <span class="comment">// numOfResults&lt;=1则当前block只有一个副本，则从别的机架上选一个节点放第二个副本</span></span><br><span class="line">    <span class="keyword">if</span> (numOfResults &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">      chooseRemoteRack(<span class="number">1</span>, dn0, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">          results, avoidStaleNodes, storageTypes);</span><br><span class="line">      <span class="keyword">if</span> (--numOfReplicas == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> writer;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// numOfResults&lt;=2则当前block有两个副本，则要判断当前两个副本是否在同一机架</span></span><br><span class="line">    <span class="keyword">if</span> (numOfResults &lt;= <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="keyword">final</span> DatanodeDescriptor dn1 = results.get(<span class="number">1</span>).getDatanodeDescriptor();</span><br><span class="line">      <span class="keyword">if</span> (clusterMap.isOnSameRack(dn0, dn1)) &#123;</span><br><span class="line">      	<span class="comment">// 在同一机架则从别的机架上选一个节点存放第三个副本</span></span><br><span class="line">        chooseRemoteRack(<span class="number">1</span>, dn0, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">            results, avoidStaleNodes, storageTypes);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (newBlock)&#123;</span><br><span class="line">      	<span class="comment">// 如果是新block则从dn1所在的机架上选择一个节点放第三个副本</span></span><br><span class="line">      	<span class="comment">// results.isEmpty则为newBlock</span></span><br><span class="line">        chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">            results, avoidStaleNodes, storageTypes);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      	<span class="comment">// 不在同一机架则从writer所在机架上选一个节点放第三个副本</span></span><br><span class="line">        chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">            results, avoidStaleNodes, storageTypes);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (--numOfReplicas == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> writer;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 超过3副本的话，剩余副本则随机选择</span></span><br><span class="line">    chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,</span><br><span class="line">        maxNodesPerRack, results, avoidStaleNodes, storageTypes);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (NotEnoughReplicasException e) &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> writer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>选完targets之后，还要调用<code>getPipeline</code>对targets进行排序，排序问题是个旅行家问题。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> DatanodeStorageInfo[] getPipeline(Node writer,</span><br><span class="line">    DatanodeStorageInfo[] storages) &#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">synchronized</span>(clusterMap) &#123;</span><br><span class="line">    <span class="keyword">int</span> index=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (writer == <span class="keyword">null</span> || !clusterMap.contains(writer)) &#123;</span><br><span class="line">      writer = storages[<span class="number">0</span>].getDatanodeDescriptor();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span>(; index &lt; storages.length; index++) &#123;</span><br><span class="line">      DatanodeStorageInfo shortestStorage = storages[index];</span><br><span class="line">      <span class="keyword">int</span> shortestDistance = clusterMap.getDistance(writer,</span><br><span class="line">          shortestStorage.getDatanodeDescriptor());</span><br><span class="line">      <span class="keyword">int</span> shortestIndex = index;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">int</span> i = index + <span class="number">1</span>; i &lt; storages.length; i++) &#123;</span><br><span class="line">        <span class="keyword">int</span> currentDistance = clusterMap.getDistance(writer,</span><br><span class="line">            storages[i].getDatanodeDescriptor());</span><br><span class="line">        <span class="keyword">if</span> (shortestDistance&gt;currentDistance) &#123;</span><br><span class="line">          shortestDistance = currentDistance;</span><br><span class="line">          shortestStorage = storages[i];</span><br><span class="line">          shortestIndex = i;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//switch position index &amp; shortestIndex</span></span><br><span class="line">      <span class="keyword">if</span> (index != shortestIndex) &#123;</span><br><span class="line">        storages[shortestIndex] = storages[index];</span><br><span class="line">        storages[index] = shortestStorage;</span><br><span class="line">      &#125;</span><br><span class="line">      writer = shortestStorage.getDatanodeDescriptor();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> storages;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="第三个for循环"><a href="#第三个for循环" class="headerlink" title="第三个for循环"></a>第三个for循环</h3><p>第三个for循环只是调用<code>pendingReplications.increment(block, DatanodeStorageInfo.toDatanodeDescriptors(targets))</code>，将block放入<code>PendingReplicationBlocks.pendingReplications</code>中</p>
<blockquote>
<p>pendingReplications 在哪被消费   PendingReplicationBlocks线程中？？？</p>
</blockquote>
<h2 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h2><p>回到<em>computeDatanodeWork</em>中，复制结束之后，对<em>pendingReplicationBlocksCount</em>、<em>underReplicatedBlocksCount</em>、<em>corruptReplicaBlocksCount</em>和<em>scheduledReplicationBlocksCount</em>进行状态更新之后，就开始进行计算删除工作<code>computeInvalidateWork</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">computeInvalidateWork</span><span class="params">(<span class="keyword">int</span> nodesToProcess)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 得到含有无效block的dn</span></span><br><span class="line">  <span class="keyword">final</span> List&lt;DatanodeInfo&gt; nodes = invalidateBlocks.getDatanodes();</span><br><span class="line">  Collections.shuffle(nodes);</span><br><span class="line">  nodesToProcess = Math.min(nodes.size(), nodesToProcess);</span><br><span class="line">  <span class="keyword">int</span> blockCnt = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">for</span> (DatanodeInfo dnInfo : nodes) &#123;</span><br><span class="line">  	<span class="comment">// 删除dn上的无效block</span></span><br><span class="line">    <span class="keyword">int</span> blocks = invalidateWorkForOneNode(dnInfo);</span><br><span class="line">    <span class="keyword">if</span> (blocks &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      blockCnt += blocks;</span><br><span class="line">      <span class="keyword">if</span> (--nodesToProcess == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> blockCnt;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>computeInvalidateWork传进去的参数是节点的个数，而不是要删除block的个数，并且删除block时没有优先级，则直接从<em>invalidateBlocks</em>中拿到所有含有无效block的dn，进行for循环判断nodesToProcess是否满足，由blockCnt统计删除的工作量。</p>
<p>具体的删除工作在<code>invalidateWorkForOneNode</code>中完成。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">invalidateWorkForOneNode</span><span class="params">(DatanodeInfo dn)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> List&lt;Block&gt; toInvalidate;</span><br><span class="line">  namesystem.writeLock();</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// blocks should not be replicated or removed if safe mode is on</span></span><br><span class="line">    <span class="keyword">if</span> (namesystem.isInSafeMode()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"In safemode, not computing replication work"</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    	<span class="comment">// 从InvalidateBlocks.node2blocks中拿到dn对应的block副本</span></span><br><span class="line">      toInvalidate = invalidateBlocks.invalidateWork(datanodeManager.getDatanode(dn));</span><br><span class="line">      </span><br><span class="line">      <span class="keyword">if</span> (toInvalidate == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(UnregisteredNodeException une) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    namesystem.writeUnlock();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (NameNode.stateChangeLog.isInfoEnabled()) &#123;</span><br><span class="line">    NameNode.stateChangeLog.info(<span class="string">"BLOCK* "</span> + getClass().getSimpleName()</span><br><span class="line">        + <span class="string">": ask "</span> + dn + <span class="string">" to delete "</span> + toInvalidate);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> toInvalidate.size();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>invalidateWork代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// InvalidateBlocks.class</span></span><br><span class="line"><span class="function"><span class="keyword">synchronized</span> List&lt;Block&gt; <span class="title">invalidateWork</span><span class="params">(<span class="keyword">final</span> DatanodeDescriptor dn)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">long</span> delay = getInvalidationDelay();</span><br><span class="line">  <span class="keyword">if</span> (delay &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (BlockManager.LOG.isDebugEnabled()) &#123;</span><br><span class="line">      BlockManager.LOG</span><br><span class="line">          .debug(<span class="string">"Block deletion is delayed during NameNode startup. "</span></span><br><span class="line">                     + <span class="string">"The deletion will start after "</span> + delay + <span class="string">" ms."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">final</span> LightWeightHashSet&lt;Block&gt; set = node2blocks.get(dn);</span><br><span class="line">  <span class="keyword">if</span> (set == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// # blocks that can be sent in one message is limited</span></span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> limit = blockInvalidateLimit;</span><br><span class="line">  <span class="keyword">final</span> List&lt;Block&gt; toInvalidate = set.pollN(limit);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If we send everything in this message, remove this node entry</span></span><br><span class="line">  <span class="keyword">if</span> (set.isEmpty()) &#123;</span><br><span class="line">    remove(dn);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将要删除的block放入dn中</span></span><br><span class="line">  dn.addBlocksToBeInvalidated(toInvalidate);</span><br><span class="line">  numBlocks -= toInvalidate.size();</span><br><span class="line">  <span class="keyword">return</span> toInvalidate;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>删除应该是在dn上被删除，通过<code>dn.addBlocksToBeInvalidated</code>将副本放入DatanodeDescriptor.invalidateBlocks中。</p>
<p>还是没有找到具体的删除操作，复制是等待调度，删除呢？只返回要删除的block个数？具体的删除操作应该在dn上，代码还没有去跟踪，有时间再跟踪验证想法</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> ReplicationMonitor </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS HA机制解析]]></title>
      <url>http://bigdatadecode.club/HDFS%20HA%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90.html</url>
      <content type="html"><![CDATA[<h2 id="HA整体架构"><a href="#HA整体架构" class="headerlink" title="HA整体架构"></a>HA整体架构</h2><p><img src="/blogimgs/HDFS HA机制解析/ha架构图.png" alt="HA整体架构图" title="HA整体架构图"></p>
<p>从上图中，我们可以看出NameNode的高可用架构主要分为下面几个部分：</p>
<p>Active NameNode和Standby NameNode：两台NameNode形成互备，一台处于Active状态，为主NameNode，另外一台处于Standby状态，为备NameNode，<strong>只有主NameNode才能对外提供读写服务</strong>。</p>
<p>主备切换控制器ZKFailoverController：ZKFailoverController作为独立的进程运行，对NameNode的主备切换进行总体控制（ZKFailoverController是抽象类，它的实现类是DFSZKFailoverController）。ZKFailoverController通过HealthMonitor线程能及时检测到NameNode的健康状况，在主NameNode故障时借助Zookeeper实现自动的主备选举和切换，当然NameNode目前也支持不依赖于Zookeeper的手动主备切换。</p>
<blockquote>
<p>为啥把监控分开<br>   显然，我们不能在NN进程内进行心跳等信息同步，最简单的原因，一次FullGC就可以让NN挂起十几分钟，所以，必须要有一个独立的短小精悍的watchdog来专门负责监控。这也是一个松耦合的设计，便于扩展或更改。</p>
</blockquote>
<p>Zookeeper集群：为主备切换控制器提供主备选举支持。</p>
<p>共享存储系统：共享存储系统是实现NameNode的高可用最为关键的部分，共享存储系统保存了NameNode在运行过程中所产生的HDFS的元数据。只有active namenode才能往共享存储系统中写数据，active NameNode和standby NameNode通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主NameNode在确认元数据完全同步之后才能继续对外提供服务。</p>
<p>DataNode节点：除了通过共享存储系统共享HDFS的元数据信息之外，<strong>主NameNode和备NameNode还需要共享HDFS的数据块和DataNode之间的映射关系</strong>。<em>DataNode会同时向主NameNode和备NameNode上报数据块的位置信息，但只接收来自active namenode的读写命令</em>。</p>
<a id="more"></a>
<p>这里主要介绍通过<strong>隔离和Quorum Journal Manager(QJM)共享存储空间</strong>实现HDFS HA。</p>
<h2 id="隔离（Fencing）"><a href="#隔离（Fencing）" class="headerlink" title="隔离（Fencing）"></a>隔离（Fencing）</h2><p><strong>隔离(Fencing)是为了防止脑裂，就是保证在任何时候HDFS只有一个Active NN</strong>，主要包括三个方面：</p>
<ul>
<li>共享存储fencing：确保只有一个NN可以写入edits。QJM中每一个JournalNode中均有一个epochnumber，匹配epochnumber的QJM才有权限更新JN。当NN由standby状态切换成active状态时，会重新生成一个epoch number，并更新JN中的epochnumber，以至于以前的ActiveNN中的QJM中的epoch number和JN的epochnumber不匹配，故而原ActiveNN上的QJM没法往JN中写入数据（后面会介绍源码），即形成了fencing</li>
<li>客户端fencing：确保只有一个NN可以响应客户端的请求。</li>
<li>DataNode fencing：确保只有一个NN可以向DN下发命令，譬如删除块，复制块，等等。</li>
</ul>
<p>QJM的Fencing方案只能让原来的Active NN失去对JN的写权限，但是原来的Active NN还是可以响应客户端的请求，对DN进行读。对客户端和DataNode的fence是通过配置dfs.ha.fencing.methods实现的。Hadoop公共库中有两种Fencing实现：sshfence、shell<br>   sshfence：ssh到原Active NN上，使用fuser结束进程（通过tcp端口号定位进程pid，该方法比jps命令更准确）。<br>   shell: run an arbitrary shell command to fence the Active NameNode，即执行一个用户事先定义的shell命令（脚本）完成隔离。</p>
<h2 id="QJM共享存储"><a href="#QJM共享存储" class="headerlink" title="QJM共享存储"></a>QJM共享存储</h2><p>Qurom Journal Manager(QJM)是一个基于Paxos算法实现的HDFS 元数据共享存储的方案。QJM的基本原理就是用2N+1台JournalNode存储EditLog，每次写数据操作有大多数（&gt;=N+1）返回成功时即认为该次写成功，数据不会丢失。这个算法所能容忍的是最多有N台机器挂掉，如果多于N台挂掉，这个算法就失效了。这个原理是基于Paxos算法的。<br>用QJM的方式来实现HA的主要好处有：1）不需要配置额外的高共享存储，这样对于基于commodity hardware的云计算数据中心来说，降低了复杂度和维护成本；2）不在需要单独配置fencing实现，因为QJM本身内置了fencing的功能；3）不存在Single Point Of Failure；4）系统鲁棒性的程度是可配置的（QJM基于Paxos算法，所以如果配置2N+1台JournalNode组成的集群，能容忍最多N台机器挂掉）；5）QJM中存储日志的JournalNode不会因为其中一台的延迟而影响整体的延迟，而且也不会因为JournalNode的数量增多而影响性能（因为NN向JournalNode发送日志是并行的）。</p>
<h2 id="源码分析主备切换"><a href="#源码分析主备切换" class="headerlink" title="源码分析主备切换"></a>源码分析主备切换</h2><p>主备切换主要是通过<code>ZKFailoverController</code>实现的，是一个独立的进程，在hdfs启动脚本之中的进程名为<em>zkfc</em>。<code>ZKFailoverController</code>是一个抽象类，其实现类的<code>DFSZKFailoverController</code>，其内部有三个组件，分别为<em>HealthMonitor、ActiveStandbyElector和FailoverController</em>。其中HealthMonitor是一个独立的线程，循环的检测nn的状态，ActiveStandbyElector主要用来与zk保持心跳和通过创建临时节点进行节点的选举，FailoverController是进行状态转换。</p>
<p>zkfc的程序入口在<code>DFSZKFailoverController</code>中的main方法中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  DFSZKFailoverController zkfc = DFSZKFailoverController.create(</span><br><span class="line">      parser.getConfiguration());</span><br><span class="line">  </span><br><span class="line">  System.exit(zkfc.run(parser.getRemainingArgs()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>DFSZKFailoverController</code>通过create创建一个实例，然后调用run方法启动zkfc。create方法里构造了一个NNHAServiceTarget对象，并由此构建DFSZKFailoverController对象。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> DFSZKFailoverController <span class="title">create</span><span class="params">(Configuration conf)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  NNHAServiceTarget localTarget = <span class="keyword">new</span> NNHAServiceTarget(</span><br><span class="line">      localNNConf, nsId, nnId);</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> DFSZKFailoverController(localNNConf, localTarget);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>NNHAServiceTarget主要是用来存放目标nn的fence相关的属性，源码对类的解释是<em>One of the NN NameNodes acting as the target of an administrative command(e.g. failover) ,译：NNs中的一个nn作为管理命令的目标</em>。在其构造方法中对nsId、nnId、addr、zkfc addr和fencer进行赋值。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">NNHAServiceTarget</span><span class="params">(Configuration conf,</span></span></span><br><span class="line"><span class="function"><span class="params">    String nsId, String nnId)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">this</span>.addr = NetUtils.createSocketAddr(serviceAddr,</span><br><span class="line">      NameNode.DEFAULT_PORT);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">this</span>.autoFailoverEnabled = targetConf.getBoolean(</span><br><span class="line">      DFSConfigKeys.DFS_HA_AUTO_FAILOVER_ENABLED_KEY,</span><br><span class="line">      DFSConfigKeys.DFS_HA_AUTO_FAILOVER_ENABLED_DEFAULT);</span><br><span class="line">  <span class="keyword">if</span> (autoFailoverEnabled) &#123;</span><br><span class="line">    <span class="keyword">int</span> port = DFSZKFailoverController.getZkfcPort(targetConf);</span><br><span class="line">    <span class="keyword">if</span> (port != <span class="number">0</span>) &#123;</span><br><span class="line">      setZkfcPort(port);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">this</span>.fencer = NodeFencer.create(targetConf,</span><br><span class="line">        DFSConfigKeys.DFS_HA_FENCE_METHODS_KEY);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (BadFencingConfigurationException e) &#123;</span><br><span class="line">    <span class="keyword">this</span>.fenceConfigError = e;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">this</span>.nnId = nnId;</span><br><span class="line">  <span class="keyword">this</span>.nsId = nsId;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>DFSZKFailoverController的对象zkfc创建成功之后，会执行run方法，run方法是在<code>ZKFailoverController</code>中实现的，<em>而run中又调用了doRun方法</em>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">doRun</span><span class="params">(String[] args)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> HadoopIllegalArgumentException, IOException, InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    initZK(); <span class="comment">// new ActiveStandbyElector，与zk建立连接</span></span><br><span class="line">  &#125; <span class="keyword">catch</span> (KeeperException ke) &#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> ERR_CODE_NO_ZK;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 在启动zkfc之前，要先对zk进行格式化</span></span><br><span class="line">  <span class="comment">// 格式化时输入参数，启动时不加参数</span></span><br><span class="line">  <span class="keyword">if</span> (args.length &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="string">"-formatZK"</span>.equals(args[<span class="number">0</span>])) &#123;</span><br><span class="line">      <span class="keyword">boolean</span> force = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">boolean</span> interactive = <span class="keyword">true</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; args.length; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">"-force"</span>.equals(args[i])) &#123;</span><br><span class="line">          force = <span class="keyword">true</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="string">"-nonInteractive"</span>.equals(args[i])) &#123;</span><br><span class="line">          interactive = <span class="keyword">false</span>;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          badArg(args[i]);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// 对zk格式化，默认会zk上创建/hadoop-ha节点</span></span><br><span class="line">      <span class="keyword">return</span> formatZK(force, interactive);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      badArg(args[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  initRPC(); <span class="comment">// 初始化rpcServer，创建ZKFCRpcServer对象，使用的是hadoop rpc接口和PB序列化</span></span><br><span class="line">  initHM();  <span class="comment">// 启动HealthMonitor线程</span></span><br><span class="line">  startRPC(); <span class="comment">// 启动rpcServer</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    mainLoop(); <span class="comment">// 循环阻塞等待fatalError错误，然后退出zkfc进程</span></span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    rpcServer.stopAndJoin();</span><br><span class="line">    elector.quitElection(<span class="keyword">true</span>); <span class="comment">// 关闭zk连接，退出选举</span></span><br><span class="line">    healthMonitor.shutdown();</span><br><span class="line">    healthMonitor.join();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先调用<code>initZK()</code>，与zk建立连接，与zk的连接是在<code>ActiveStandbyElector</code>类中，<code>ActiveStandbyElector</code>在构造函数中注册了一个回调函数<code>ElectorCallbacks</code>，而<code>ActiveStandbyElector</code>又实现了<code>StatCallback</code>和<code>StringCallback</code>，分别在调用<code>zkClient.exists</code>和<code>zkClient.create</code>之后通过<code>processResult</code>对其调用结果状态进行处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initZK</span><span class="params">()</span> <span class="keyword">throws</span> HadoopIllegalArgumentException, IOException,</span></span><br><span class="line"><span class="function">    KeeperException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  elector = <span class="keyword">new</span> ActiveStandbyElector(zkQuorum,</span><br><span class="line">      zkTimeout, getParentZnode(), zkAcls, zkAuths,</span><br><span class="line">      <span class="keyword">new</span> ElectorCallbacks(), maxRetryNum);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ActiveStandbyElector</span><span class="params">(String zookeeperHostPorts,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int</span> zookeeperSessionTimeout, String parentZnodeName, List&lt;ACL&gt; acl,</span></span></span><br><span class="line"><span class="function"><span class="params">    List&lt;ZKAuthInfo&gt; authInfo,</span></span></span><br><span class="line"><span class="function"><span class="params">    ActiveStandbyElectorCallback app, <span class="keyword">int</span> maxRetryNum)</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">    HadoopIllegalArgumentException, KeeperException </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (app == <span class="keyword">null</span> || acl == <span class="keyword">null</span> || parentZnodeName == <span class="keyword">null</span></span><br><span class="line">      || zookeeperHostPorts == <span class="keyword">null</span> || zookeeperSessionTimeout &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HadoopIllegalArgumentException(<span class="string">"Invalid argument"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  zkHostPort = zookeeperHostPorts;</span><br><span class="line">  zkSessionTimeout = zookeeperSessionTimeout;</span><br><span class="line">  zkAcl = acl;</span><br><span class="line">  zkAuthInfo = authInfo;</span><br><span class="line">  appClient = app;</span><br><span class="line">  znodeWorkingDir = parentZnodeName;</span><br><span class="line">  <span class="comment">// 临时节点ActiveStandbyElectorLock，用于标识锁</span></span><br><span class="line">  zkLockFilePath = znodeWorkingDir + <span class="string">"/"</span> + LOCK_FILENAME;</span><br><span class="line">  <span class="comment">// 永久节点ActiveBreadCrumb，用于存放active信息</span></span><br><span class="line">  zkBreadCrumbPath = znodeWorkingDir + <span class="string">"/"</span> + BREADCRUMB_FILENAME;</span><br><span class="line">  <span class="keyword">this</span>.maxRetryNum = maxRetryNum;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// createConnection for future API calls</span></span><br><span class="line">  <span class="comment">// 创建zk连接</span></span><br><span class="line">  createConnection();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">createConnection</span><span class="params">()</span> <span class="keyword">throws</span> IOException, KeeperException </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  zkClient = getNewZooKeeper();</span><br><span class="line">  LOG.debug(<span class="string">"Created new connection for "</span> + <span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> ZooKeeper <span class="title">getNewZooKeeper</span><span class="params">()</span> <span class="keyword">throws</span> IOException,</span></span><br><span class="line"><span class="function">    KeeperException </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// Unfortunately, the ZooKeeper constructor connects to ZooKeeper and</span></span><br><span class="line">  <span class="comment">// may trigger the Connected event immediately. So, if we register the</span></span><br><span class="line">  <span class="comment">// watcher after constructing ZooKeeper, we may miss that event. Instead,</span></span><br><span class="line">  <span class="comment">// we construct the watcher first, and have it block any events it receives</span></span><br><span class="line">  <span class="comment">// before we can set its ZooKeeper reference.</span></span><br><span class="line">  <span class="comment">// 不幸的是，zk的构造方法连接上zk之后，可能马上触发连接事件。</span></span><br><span class="line">  <span class="comment">// 因此如果构造zk之后注册watcher，可能不会捕获到连接事件。</span></span><br><span class="line">  <span class="comment">// 取而代之的方法是，先构造Watcher，在设置了zk的引用之前，使它阻塞所有的事件</span></span><br><span class="line">  watcher = <span class="keyword">new</span> WatcherWithClientRef();</span><br><span class="line">  ZooKeeper zk = <span class="keyword">new</span> ZooKeeper(zkHostPort, zkSessionTimeout, watcher);</span><br><span class="line">  <span class="comment">// 在watcher中设置zk的引用</span></span><br><span class="line">  watcher.setZooKeeperRef(zk);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Wait for the asynchronous success/failure. This may throw an exception</span></span><br><span class="line">  <span class="comment">// if we don't connect within the session timeout.</span></span><br><span class="line">  watcher.waitForZKConnectionEvent(zkSessionTimeout);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">for</span> (ZKAuthInfo auth : zkAuthInfo) &#123;</span><br><span class="line">    zk.addAuthInfo(auth.getScheme(), auth.getAuth());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> zk;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>initZk主要是通过实例化ActiveStandbyElector，从而得到zkClient，并向其注册一个watcher，这里简单介绍下watcher的实现类<code>WatcherWithClientRef</code>。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">WatcherWithClientRef</span> <span class="keyword">implements</span> <span class="title">Watcher</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> ZooKeeper zk;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Latch fired whenever any event arrives. This is used in order</span></span><br><span class="line"><span class="comment">   * to wait for the Connected event when the client is first created.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> CountDownLatch hasReceivedEvent = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Latch used to wait until the reference to ZooKeeper is set.</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> CountDownLatch hasSetZooKeeper = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Waits for the next event from ZooKeeper to arrive.</span></span><br><span class="line"><span class="comment">   * </span></span><br><span class="line"><span class="comment">   * <span class="doctag">@param</span> connectionTimeoutMs zookeeper connection timeout in milliseconds</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@throws</span> KeeperException if the connection attempt times out. This will</span></span><br><span class="line"><span class="comment">   * be a ZooKeeper ConnectionLoss exception code.</span></span><br><span class="line"><span class="comment">   * <span class="doctag">@throws</span> IOException if interrupted while connecting to ZooKeeper</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="comment">// 接收连接是否连接成功 </span></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">waitForZKConnectionEvent</span><span class="params">(<span class="keyword">int</span> connectionTimeoutMs)</span></span></span><br><span class="line"><span class="function">      <span class="keyword">throws</span> KeeperException, IOException </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    	<span class="comment">// await() 如果hasReceivedEvent为0则立即返回true，</span></span><br><span class="line">    	<span class="comment">// 如果在connectionTimeoutMs内hasReceivedEvent依然不为0，线程依然阻塞则返回false</span></span><br><span class="line">    	<span class="comment">// 当调用countDown()之后，hasReceivedEvent的值会发生变化减1</span></span><br><span class="line">      <span class="keyword">if</span> (!hasReceivedEvent.await(connectionTimeoutMs, TimeUnit.MILLISECONDS)) &#123;</span><br><span class="line">        LOG.error(<span class="string">"Connection timed out: couldn't connect to ZooKeeper in "</span></span><br><span class="line">            + connectionTimeoutMs + <span class="string">" milliseconds"</span>);</span><br><span class="line">        zk.close();</span><br><span class="line">        <span class="keyword">throw</span> KeeperException.create(Code.CONNECTIONLOSS);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">      Thread.currentThread().interrupt();</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> IOException(</span><br><span class="line">          <span class="string">"Interrupted when connecting to zookeeper server"</span>, e);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">setZooKeeperRef</span><span class="params">(ZooKeeper zk)</span> </span>&#123;</span><br><span class="line">    Preconditions.checkState(<span class="keyword">this</span>.zk == <span class="keyword">null</span>,</span><br><span class="line">        <span class="string">"zk already set -- must be set exactly once"</span>);</span><br><span class="line">    <span class="keyword">this</span>.zk = zk;</span><br><span class="line">    hasSetZooKeeper.countDown();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent event)</span> </span>&#123;</span><br><span class="line">  	<span class="comment">// 接收到事件之后，hasReceivedEvent的值减1</span></span><br><span class="line">    hasReceivedEvent.countDown();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      hasSetZooKeeper.await(zkSessionTimeout, TimeUnit.MILLISECONDS);</span><br><span class="line">      <span class="comment">// 捕获到事件之后具体的处理逻辑</span></span><br><span class="line">      ActiveStandbyElector.<span class="keyword">this</span>.processWatchEvent(</span><br><span class="line">          zk, event);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      fatalError(</span><br><span class="line">          <span class="string">"Failed to process watcher event "</span> + event + <span class="string">": "</span> +</span><br><span class="line">          StringUtils.stringifyException(t));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>WatcherWithClientRef在构造zk时被注册为默认watcher，主要监听连接或者断开事件。当调用initZk之后，watcher.process会对事件进行处理，连接、断开、过期的状态类型都是EventType.None。</p>
<p><code>initZK()</code>之后也就得到了zkClient，继续<code>doRun</code>，查看是否有参数<em>-formatZK</em>，有则执行formatZK，对zk进行格式化，然后结束程序。这里主要介绍对nn的FailoverController，是没有参数的情况，接下来是初始化rpc服务initRPC，zkfc的rpc类是<code>ZKFCRpcServer</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">initRPC</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">  InetSocketAddress bindAddr = getRpcAddressToBindTo();</span><br><span class="line">  rpcServer = <span class="keyword">new</span> ZKFCRpcServer(conf, bindAddr, <span class="keyword">this</span>, getPolicyProvider());</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ZKFCRpcServer.class</span></span><br><span class="line">ZKFCRpcServer(Configuration conf,</span><br><span class="line">    InetSocketAddress bindAddr,</span><br><span class="line">    ZKFailoverController zkfc,</span><br><span class="line">    PolicyProvider policy) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">  <span class="keyword">this</span>.zkfc = zkfc;</span><br><span class="line">  <span class="comment">// 使用protocol buffer序列化</span></span><br><span class="line">  RPC.setProtocolEngine(conf, ZKFCProtocolPB.class,</span><br><span class="line">      ProtobufRpcEngine.class);</span><br><span class="line">  ZKFCProtocolServerSideTranslatorPB translator =</span><br><span class="line">      <span class="keyword">new</span> ZKFCProtocolServerSideTranslatorPB(<span class="keyword">this</span>);</span><br><span class="line">  BlockingService service = ZKFCProtocolService</span><br><span class="line">      .newReflectiveBlockingService(translator);</span><br><span class="line">  <span class="comment">// 使用hadoop rpc接口得到rpc server</span></span><br><span class="line">  <span class="comment">// ZKFCProtocol是rpc协议，service是rpc协议的实现类</span></span><br><span class="line">  <span class="comment">// ZKFCProtocolPB是protobuf rpc接口的一个过渡类</span></span><br><span class="line">  <span class="keyword">this</span>.server = <span class="keyword">new</span> RPC.Builder(conf).setProtocol(ZKFCProtocolPB.class)</span><br><span class="line">      .setInstance(service).setBindAddress(bindAddr.getHostName())</span><br><span class="line">      .setPort(bindAddr.getPort()).setNumHandlers(HANDLER_COUNT)</span><br><span class="line">      .setVerbose(<span class="keyword">false</span>).build();</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// set service-level authorization security policy</span></span><br><span class="line">  <span class="keyword">if</span> (conf.getBoolean(</span><br><span class="line">      CommonConfigurationKeys.HADOOP_SECURITY_AUTHORIZATION, <span class="keyword">false</span>)) &#123;</span><br><span class="line">    server.refreshServiceAcl(conf, policy);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里主要是构造了一个zkfc的rpc server，此rpc使用protocol buffer序列化消息，hadoop rpc提供的接口来构造rpc server。rpc协议是在<code>ZKFCProtocol</code>接口中定义的，包含两个方法<code>cedeActive</code>和<code>gracefulFailover</code>，其接口的实现类是<code>ZKFCProtocolServerSideTranslatorPB</code>，消息格式传输的格式是在ZKFCProtocol.proto中定义的。有关hadoop rpc更详细的内容可以查看先前的博客<a href="http://bigdatadecode.club/Hadoop RPC 解析.html">Hadoop RPC 解析</a>。</p>
<p>initRPC之后开始调用initHM，初始化HealthMonitor</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">initHM</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  healthMonitor = <span class="keyword">new</span> HealthMonitor(conf, localTarget);</span><br><span class="line">  <span class="comment">// 添加回调函数</span></span><br><span class="line">  healthMonitor.addCallback(<span class="keyword">new</span> HealthCallbacks());</span><br><span class="line">  healthMonitor.addServiceStateCallback(<span class="keyword">new</span> ServiceStateCallBacks());</span><br><span class="line">  healthMonitor.start();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>先来看下HealthMonitor的构造函数，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">HealthMonitor(Configuration conf, HAServiceTarget target) &#123;</span><br><span class="line">  <span class="keyword">this</span>.targetToMonitor = target;</span><br><span class="line">  <span class="keyword">this</span>.conf = conf;</span><br><span class="line">  <span class="comment">// ha.health-monitor.sleep-after-disconnect.ms</span></span><br><span class="line">  <span class="keyword">this</span>.sleepAfterDisconnectMillis = conf.getLong(</span><br><span class="line">      HA_HM_SLEEP_AFTER_DISCONNECT_KEY,</span><br><span class="line">      HA_HM_SLEEP_AFTER_DISCONNECT_DEFAULT);</span><br><span class="line">  <span class="comment">// ha.health-monitor.check-interval.ms 隔多久去检查nn是否健康，默认是1000 </span></span><br><span class="line">  <span class="keyword">this</span>.checkIntervalMillis = conf.getLong(</span><br><span class="line">      HA_HM_CHECK_INTERVAL_KEY,</span><br><span class="line">      HA_HM_CHECK_INTERVAL_DEFAULT);</span><br><span class="line">  <span class="comment">// ha.health-monitor.connect-retry-interval.ms 默认是1000    </span></span><br><span class="line">  <span class="keyword">this</span>.connectRetryInterval = conf.getLong(</span><br><span class="line">      HA_HM_CONNECT_RETRY_INTERVAL_KEY,</span><br><span class="line">      HA_HM_CONNECT_RETRY_INTERVAL_DEFAULT);</span><br><span class="line">  <span class="comment">// ha.health-monitor.rpc-timeout.ms</span></span><br><span class="line">  <span class="keyword">this</span>.rpcTimeout = conf.getInt(</span><br><span class="line">      HA_HM_RPC_TIMEOUT_KEY,</span><br><span class="line">      HA_HM_RPC_TIMEOUT_DEFAULT);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">this</span>.daemon = <span class="keyword">new</span> MonitorDaemon();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>HealthMonitor构造完之后，添加回调类，然后将HealthMonitor线程作为一个<em>守护进程</em>去启动。查看其run方法</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MonitorDaemon.run HealthMonitor的内部类</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (shouldRun) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123; </span><br><span class="line">      <span class="comment">// 得到rpc的客户端，此时的rpc server是在nn中启动的rpc server</span></span><br><span class="line">      loopUntilConnected();</span><br><span class="line">      <span class="comment">// 对nn进行循环检查</span></span><br><span class="line">      doHealthChecks();</span><br><span class="line">    &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">      Preconditions.checkState(!shouldRun,</span><br><span class="line">          <span class="string">"Interrupted but still supposed to run"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doHealthChecks</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">  <span class="keyword">while</span> (shouldRun) &#123;</span><br><span class="line">    HAServiceStatus status = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">boolean</span> healthy = <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      status = proxy.getServiceStatus();</span><br><span class="line">      <span class="comment">// 健康状态检查，异常会抛出</span></span><br><span class="line">      proxy.monitorHealth();</span><br><span class="line">      healthy = <span class="keyword">true</span>;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (HealthCheckFailedException e) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"Service health check failed for "</span> + targetToMonitor</span><br><span class="line">          + <span class="string">": "</span> + e.getMessage());</span><br><span class="line">      enterState(State.SERVICE_UNHEALTHY);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"Transport-level exception trying to monitor health of "</span> +</span><br><span class="line">          targetToMonitor + <span class="string">": "</span> + t.getLocalizedMessage());</span><br><span class="line">      RPC.stopProxy(proxy);</span><br><span class="line">      proxy = <span class="keyword">null</span>;</span><br><span class="line">      enterState(State.SERVICE_NOT_RESPONDING);</span><br><span class="line">      Thread.sleep(sleepAfterDisconnectMillis);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (status != <span class="keyword">null</span>) &#123;</span><br><span class="line">      setLastServiceStatus(status);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (healthy) &#123;</span><br><span class="line">      enterState(State.SERVICE_HEALTHY);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 间隔checkIntervalMillis之后继续check healthy</span></span><br><span class="line">    Thread.sleep(checkIntervalMillis);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>健康状态的检测主要是在<code>doHealthChecks</code>中调用<code>monitorHealth</code>，其调用逻辑是NameNodeRpcServer.monitorHealth–&gt;NameNode.monitorHealth，该方法会调用<code>getNamesystem().checkAvailableResources()</code>去检查磁盘是否有足够的可用空间，不够则抛出<code>HealthCheckFailedException</code>异常，在<code>doHealthChecks</code>中被捕获，设置状态为_SERVICE_UNHEALTHY_，该方法也可能抛出别的异常被Throwable捕获，设置状态为_SERVICE_NOT_RESPONDING_。然后调用<code>enterState</code>进行状态的更新</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">enterState</span><span class="params">(State newState)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (newState != state) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Entering state "</span> + newState);</span><br><span class="line">    state = newState;</span><br><span class="line">    <span class="keyword">synchronized</span> (callbacks) &#123;</span><br><span class="line">      <span class="comment">// 调用在构造HealthMonitor时注册的回调类</span></span><br><span class="line">      <span class="keyword">for</span> (Callback cb : callbacks) &#123;</span><br><span class="line">        cb.enteredState(newState);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HealthCallbacks</span> <span class="keyword">implements</span> <span class="title">HealthMonitor</span>.<span class="title">Callback</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">enteredState</span><span class="params">(HealthMonitor.State newState)</span> </span>&#123;</span><br><span class="line">    setLastHealthState(newState);</span><br><span class="line">    <span class="comment">// 检查当前nn的状态，判断是否可用进行选举</span></span><br><span class="line">    recheckElectability();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">recheckElectability</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Maintain lock ordering of elector -&gt; ZKFC</span></span><br><span class="line">  <span class="keyword">synchronized</span> (elector) &#123;</span><br><span class="line">    <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">      <span class="keyword">boolean</span> healthy = lastHealthState == State.SERVICE_HEALTHY;</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">long</span> remainingDelay = delayJoiningUntilNanotime - System.nanoTime(); </span><br><span class="line">      <span class="keyword">if</span> (remainingDelay &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (healthy) &#123;</span><br><span class="line">          LOG.info(<span class="string">"Would have joined master election, but this node is "</span> +</span><br><span class="line">              <span class="string">"prohibited from doing so for "</span> +</span><br><span class="line">              TimeUnit.NANOSECONDS.toMillis(remainingDelay) + <span class="string">" more ms"</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        scheduleRecheck(remainingDelay);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">      &#125;</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">switch</span> (lastHealthState) &#123;</span><br><span class="line">      <span class="keyword">case</span> SERVICE_HEALTHY:</span><br><span class="line">        elector.joinElection(targetToData(localTarget));</span><br><span class="line">        <span class="keyword">if</span> (quitElectionOnBadState) &#123;</span><br><span class="line">          quitElectionOnBadState = <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        </span><br><span class="line">      <span class="keyword">case</span> INITIALIZING:</span><br><span class="line">        LOG.info(<span class="string">"Ensuring that "</span> + localTarget + <span class="string">" does not "</span> +</span><br><span class="line">            <span class="string">"participate in active master election"</span>);</span><br><span class="line">        elector.quitElection(<span class="keyword">false</span>);</span><br><span class="line">        serviceState = HAServiceState.INITIALIZING;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">  </span><br><span class="line">      <span class="keyword">case</span> SERVICE_UNHEALTHY:</span><br><span class="line">      <span class="keyword">case</span> SERVICE_NOT_RESPONDING:</span><br><span class="line">        LOG.info(<span class="string">"Quitting master election for "</span> + localTarget +</span><br><span class="line">            <span class="string">" and marking that fencing is necessary"</span>);</span><br><span class="line">        elector.quitElection(<span class="keyword">true</span>);</span><br><span class="line">        serviceState = HAServiceState.INITIALIZING;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        </span><br><span class="line">      <span class="keyword">case</span> HEALTH_MONITOR_FAILED:</span><br><span class="line">        fatalError(<span class="string">"Health monitor failed!"</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        </span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Unhandled state:"</span> + lastHealthState);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在<code>recheckElectability</code>中匹配到nn的状态是<em>SERVICE_UNHEALTHY</em>或者<em>SERVICE_NOT_RESPONDING</em>则调用<code>elector.quitElection(true)</code>放弃选举</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// needFence为true则需要执行fence</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">quitElection</span><span class="params">(<span class="keyword">boolean</span> needFence)</span> </span>&#123;</span><br><span class="line">  LOG.info(<span class="string">"Yielding from election"</span>);</span><br><span class="line">  <span class="keyword">if</span> (!needFence &amp;&amp; state == State.ACTIVE) &#123;</span><br><span class="line">    <span class="comment">// If active is gracefully going back to standby mode, remove</span></span><br><span class="line">    <span class="comment">// our permanent znode so no one fences us.</span></span><br><span class="line">    tryDeleteOwnBreadCrumbNode();</span><br><span class="line">  &#125;</span><br><span class="line">  reset();</span><br><span class="line">  wantToBeInElection = <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">reset</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  state = State.INIT;</span><br><span class="line">  terminateConnection();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">terminateConnection</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (zkClient == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  LOG.debug(<span class="string">"Terminating ZK connection for "</span> + <span class="keyword">this</span>);</span><br><span class="line">  ZooKeeper tempZk = zkClient;</span><br><span class="line">  zkClient = <span class="keyword">null</span>;</span><br><span class="line">  watcher = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    tempZk.close();</span><br><span class="line">  &#125; <span class="keyword">catch</span>(InterruptedException e) &#123;</span><br><span class="line">    LOG.warn(e);</span><br><span class="line">  &#125;</span><br><span class="line">  zkConnectionState = ConnectionState.TERMINATED;</span><br><span class="line">  wantToBeInElection = <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>放弃选举其实就是调用ActiveStandbyElector的quitElection，将zkClinet关闭，zk连接关闭之后，之前创建的临时节点<code>ActiveStandbyElectorLock</code>被删除，此时standby节点上的ActiveStandbyElector通过watcher监听到<em>NodeDeleted</em>事件进行选举抢锁（只有standby节点上的watcher能监听到NodeDeleted事件，因为active节点上的watcher随着zkClinet的关闭已经消失了，无法进行监听）。</p>
<p>active节点上的ActiveStandbyElector退出选举之后，HealthMonitor线程继续check nn，等到active nn恢复正常之后重新进行选举。而standby节点上的watcher监听到NodeDeleted事件，由watcher.process处理事件，在process中又调用了<code>ActiveStandbyElector.this.processWatchEvent</code>，下面看下processWatchEvent的代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">processWatchEvent</span><span class="params">(ZooKeeper zk, WatchedEvent event)</span> </span>&#123;</span><br><span class="line">  Event.EventType eventType = event.getType();</span><br><span class="line">  <span class="keyword">if</span> (isStaleClient(zk)) <span class="keyword">return</span>;</span><br><span class="line">  LOG.debug(<span class="string">"Watcher event type: "</span> + eventType + <span class="string">" with state:"</span></span><br><span class="line">      + event.getState() + <span class="string">" for path:"</span> + event.getPath()</span><br><span class="line">      + <span class="string">" connectionState: "</span> + zkConnectionState</span><br><span class="line">      + <span class="string">" for "</span> + <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (eventType == Event.EventType.None) &#123;</span><br><span class="line">    <span class="comment">// the connection state has changed</span></span><br><span class="line">    <span class="keyword">switch</span> (event.getState()) &#123;</span><br><span class="line">    <span class="keyword">case</span> SyncConnected:</span><br><span class="line">      LOG.info(<span class="string">"Session connected."</span>);</span><br><span class="line">      <span class="comment">// if the listener was asked to move to safe state then it needs to</span></span><br><span class="line">      <span class="comment">// be undone</span></span><br><span class="line">      ConnectionState prevConnectionState = zkConnectionState;</span><br><span class="line">      zkConnectionState = ConnectionState.CONNECTED;</span><br><span class="line">      <span class="keyword">if</span> (prevConnectionState == ConnectionState.DISCONNECTED &amp;&amp;</span><br><span class="line">          wantToBeInElection) &#123;</span><br><span class="line">        monitorActiveStatus();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> Disconnected:</span><br><span class="line">      LOG.info(<span class="string">"Session disconnected. Entering neutral mode..."</span>);</span><br><span class="line"></span><br><span class="line">      <span class="comment">// ask the app to move to safe state because zookeeper connection</span></span><br><span class="line">      <span class="comment">// is not active and we dont know our state</span></span><br><span class="line">      zkConnectionState = ConnectionState.DISCONNECTED;</span><br><span class="line">      enterNeutralMode();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> Expired:</span><br><span class="line">      <span class="comment">// the connection got terminated because of session timeout</span></span><br><span class="line">      <span class="comment">// call listener to reconnect</span></span><br><span class="line">      LOG.info(<span class="string">"Session expired. Entering neutral mode and rejoining..."</span>);</span><br><span class="line">      enterNeutralMode();</span><br><span class="line">      reJoinElection(<span class="number">0</span>);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> SaslAuthenticated:</span><br><span class="line">      LOG.info(<span class="string">"Successfully authenticated to ZooKeeper using SASL."</span>);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      fatalError(<span class="string">"Unexpected Zookeeper watch event state: "</span></span><br><span class="line">          + event.getState());</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// a watch on lock path in zookeeper has fired. so something has changed on</span></span><br><span class="line">  <span class="comment">// the lock. ideally we should check that the path is the same as the lock</span></span><br><span class="line">  <span class="comment">// path but trusting zookeeper for now</span></span><br><span class="line">  String path = event.getPath();</span><br><span class="line">  <span class="keyword">if</span> (path != <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">switch</span> (eventType) &#123;</span><br><span class="line">    <span class="keyword">case</span> NodeDeleted:</span><br><span class="line">      <span class="keyword">if</span> (state == State.ACTIVE) &#123;</span><br><span class="line">        enterNeutralMode();</span><br><span class="line">      &#125;</span><br><span class="line">      joinElectionInternal();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> NodeDataChanged:</span><br><span class="line">      monitorActiveStatus();</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      LOG.debug(<span class="string">"Unexpected node event: "</span> + eventType + <span class="string">" for path: "</span> + path);</span><br><span class="line">      monitorActiveStatus();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// some unexpected error has occurred</span></span><br><span class="line">  fatalError(<span class="string">"Unexpected watch error from Zookeeper"</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>匹配到<code>NodeDeleted</code>事件，然后执行<code>joinElectionInternal</code>去创建临时节点，进行抢锁,</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">joinElectionInternal</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  Preconditions.checkState(appData != <span class="keyword">null</span>,</span><br><span class="line">      <span class="string">"trying to join election without any app data"</span>);</span><br><span class="line">  <span class="keyword">if</span> (zkClient == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!reEstablishSession()) &#123;</span><br><span class="line">      fatalError(<span class="string">"Failed to reEstablish connection with ZooKeeper"</span>);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  createRetryCount = <span class="number">0</span>;</span><br><span class="line">  wantToBeInElection = <span class="keyword">true</span>;</span><br><span class="line">  createLockNodeAsync();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">createLockNodeAsync</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  zkClient.create(zkLockFilePath, appData, zkAcl, CreateMode.EPHEMERAL,</span><br><span class="line">      <span class="keyword">this</span>, zkClient);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>是否创建成功的结果是在<code>processResult</code>中进行捕获的，此时的<code>ActiveStandbyElector.processResult</code>是实现StringCallback接口需要重写的方法，该类中还有个同名的方法，是实现StatCallback接口需要重写的方法。先来看下捕获create结果的processResult代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * interface implementation of Zookeeper callback for create</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">processResult</span><span class="params">(<span class="keyword">int</span> rc, String path, Object ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">    String name)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  Code code = Code.get(rc);</span><br><span class="line">  <span class="keyword">if</span> (isSuccess(code)) &#123;</span><br><span class="line">    <span class="comment">// we successfully created the znode. we are the leader. start monitoring</span></span><br><span class="line">    <span class="comment">// 创建成功，则进行角色的转变</span></span><br><span class="line">    <span class="keyword">if</span> (becomeActive()) &#123;</span><br><span class="line">      monitorActiveStatus();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      reJoinElectionAfterFailureToBecomeActive();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 节点已存在</span></span><br><span class="line">  <span class="keyword">if</span> (isNodeExists(code)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (createRetryCount == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// znode exists and we did not retry the operation. so a different</span></span><br><span class="line">      <span class="comment">// instance has created it. become standby and monitor lock.</span></span><br><span class="line">      becomeStandby();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// if we had retried then the znode could have been created by our first</span></span><br><span class="line">    <span class="comment">// attempt to the server (that we lost) and this node exists response is</span></span><br><span class="line">    <span class="comment">// for the second attempt. verify this case via ephemeral node owner. this</span></span><br><span class="line">    <span class="comment">// will happen on the callback for monitoring the lock.</span></span><br><span class="line">    monitorActiveStatus();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">  fatalError(errorMessage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果创建成功则将当前节点转换为active，执行<code>becomeActive</code>，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">becomeActive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    Stat oldBreadcrumbStat = fenceOldActive();</span><br><span class="line">    writeBreadCrumbNode(oldBreadcrumbStat);</span><br><span class="line">    </span><br><span class="line">    LOG.debug(<span class="string">"Becoming active for "</span> + <span class="keyword">this</span>);</span><br><span class="line">    appClient.becomeActive();</span><br><span class="line">    state = State.ACTIVE;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">    LOG.warn(<span class="string">"Exception handling the winning of election"</span>, e);</span><br><span class="line">    <span class="comment">// Caller will handle quitting and rejoining the election.</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为防止脑裂，在变为active之前，先检查下是否需要fence，判断是否需要fence的依据是zk上是否有<em>breadcrumb</em>节点</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Stat <span class="title">fenceOldActive</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException, KeeperException </span>&#123;</span><br><span class="line">  <span class="keyword">final</span> Stat stat = <span class="keyword">new</span> Stat();</span><br><span class="line">  <span class="keyword">byte</span>[] data;</span><br><span class="line">  LOG.info(<span class="string">"Checking for any old active which needs to be fenced..."</span>);</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">  	<span class="comment">// 读取当前zk中节点的内容</span></span><br><span class="line">    data = zkDoWithRetries(<span class="keyword">new</span> ZKAction&lt;<span class="keyword">byte</span>[]&gt;() &#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> <span class="keyword">byte</span>[] run() <span class="keyword">throws</span> KeeperException, InterruptedException &#123;</span><br><span class="line">        <span class="keyword">return</span> zkClient.getData(zkBreadCrumbPath, <span class="keyword">false</span>, stat);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (KeeperException ke) &#123;</span><br><span class="line">    <span class="keyword">if</span> (isNodeDoesNotExist(ke.code())) &#123;</span><br><span class="line">      LOG.info(<span class="string">"No old node to fence"</span>);</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// If we failed to read for any other reason, then likely we lost</span></span><br><span class="line">    <span class="comment">// our session, or we don't have permissions, etc. In any case,</span></span><br><span class="line">    <span class="comment">// we probably shouldn't become active, and failing the whole</span></span><br><span class="line">    <span class="comment">// thing is the best bet.</span></span><br><span class="line">    <span class="keyword">throw</span> ke;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  LOG.info(<span class="string">"Old node exists: "</span> + StringUtils.byteToHexString(data));</span><br><span class="line">  <span class="comment">// appData是当前节点加入选举时的节点信息，也就是standby节点的信息</span></span><br><span class="line">  <span class="keyword">if</span> (Arrays.equals(data, appData)) &#123;</span><br><span class="line">    LOG.info(<span class="string">"But old node has our own data, so don't need to fence it."</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  	<span class="comment">// 当前zk节点的信息与APPData的信息不符，进行fence</span></span><br><span class="line">    appClient.fenceOldActive(data);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> stat;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>当前zk的ActiveBreadCrumb节点记录的是active节点的信息，与appData（记录的是standby节点的信息）不一样，则进行fenceOldActive操作，fenceOldActive调用的是在ActiveStandbyElector初始化时注册的回调类里的方法，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ElectorCallbacks.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">fenceOldActive</span><span class="params">(<span class="keyword">byte</span>[] data)</span> </span>&#123;</span><br><span class="line">  ZKFailoverController.<span class="keyword">this</span>.fenceOldActive(data);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ZKFailoverController.class</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">fenceOldActive</span><span class="params">(<span class="keyword">byte</span>[] data)</span> </span>&#123;</span><br><span class="line">  HAServiceTarget target = dataToTarget(data);</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    doFence(target);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (Throwable t) &#123;</span><br><span class="line">    recordActiveAttempt(<span class="keyword">new</span> ActiveAttemptRecord(<span class="keyword">false</span>, <span class="string">"Unable to fence old active: "</span> + StringUtils.stringifyException(t)));</span><br><span class="line">    Throwables.propagate(t);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">doFence</span><span class="params">(HAServiceTarget target)</span> </span>&#123;</span><br><span class="line">  LOG.info(<span class="string">"Should fence: "</span> + target);</span><br><span class="line">  <span class="comment">// 由FailoverController进行切换，如果没有切换成功则进行fence</span></span><br><span class="line">  <span class="keyword">boolean</span> gracefulWorked = <span class="keyword">new</span> FailoverController(conf,</span><br><span class="line">      RequestSource.REQUEST_BY_ZKFC).tryGracefulFence(target);</span><br><span class="line">  <span class="keyword">if</span> (gracefulWorked) &#123;</span><br><span class="line">    <span class="comment">// It's possible that it's in standby but just about to go into active,</span></span><br><span class="line">    <span class="comment">// no? Is there some race here?</span></span><br><span class="line">    LOG.info(<span class="string">"Successfully transitioned "</span> + target + <span class="string">" to standby "</span> +</span><br><span class="line">        <span class="string">"state without fencing"</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    target.checkFencingConfigured();</span><br><span class="line">  &#125; <span class="keyword">catch</span> (BadFencingConfigurationException e) &#123;</span><br><span class="line">    LOG.error(<span class="string">"Couldn't fence old active "</span> + target, e);</span><br><span class="line">    recordActiveAttempt(<span class="keyword">new</span> ActiveAttemptRecord(<span class="keyword">false</span>, <span class="string">"Unable to fence old active"</span>));</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 调用NodeFencer类，进行fence</span></span><br><span class="line">  <span class="keyword">if</span> (!target.getFencer().fence(target)) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Unable to fence "</span> + target);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>doFence</code>时先调用FailoverController.tryGracefulFence进行状态的转换，该方法通过rpc最终调用<em>NameNode.transitionToStandby()</em>方法，通过<code>state.setState(haContext, STANDBY_STATE)</code>将状态设置为standby，如果设置失败则调用NodeFencer类的fence方法进行强制fence。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">fence</span><span class="params">(HAServiceTarget fromSvc)</span> </span>&#123;</span><br><span class="line">  LOG.info(<span class="string">"====== Beginning Service Fencing Process... ======"</span>);</span><br><span class="line">  <span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line">  <span class="comment">// 可以设置多个fence method，以回车分隔</span></span><br><span class="line">  <span class="keyword">for</span> (FenceMethodWithArg method : methods) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Trying method "</span> + (++i) + <span class="string">"/"</span> + methods.size() +<span class="string">": "</span> + method);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    	<span class="comment">// SshFenceByTcpPort 和 ShellCommandFencer 实现了tryFence的具体逻辑</span></span><br><span class="line">      <span class="keyword">if</span> (method.method.tryFence(fromSvc, method.arg)) &#123;</span><br><span class="line">        LOG.info(<span class="string">"====== Fencing successful by method "</span> + method + <span class="string">" ======"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; </span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>fenceOldActive成功之后则调用<code>writeBreadCrumbNode</code>将当前standby节点的信息写入zk中，通过回调类<code>ElectorCallbacks</code>的becomeActive方法将standby节点变为active。状态转变的过程是通过rpc最终调用NameNode的transitionToActive方法将ACTIVE_STATE设置为当前节点的状态。切换成功之后则进入监控，调用<code>monitorActiveStatus</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">monitorActiveStatus</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> wantToBeInElection;</span><br><span class="line">  LOG.debug(<span class="string">"Monitoring active leader for "</span> + <span class="keyword">this</span>);</span><br><span class="line">  statRetryCount = <span class="number">0</span>;</span><br><span class="line">  monitorLockNodeAsync();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">monitorLockNodeAsync</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  zkClient.exists(zkLockFilePath, </span><br><span class="line">      watcher, <span class="keyword">this</span>,</span><br><span class="line">      zkClient);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>zkClient.exists将WatcherWithClientRef注册为watcher，监听ActiveStandbyElectorLock znode的状态，exists的执行结果在processResult中捕获，此处的processResult是ActiveStandbyElector实现StatCallback接口需要重写的方法。先来看下捕获exists结果的processResult代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * interface implementation of Zookeeper callback for monitor (exists)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">processResult</span><span class="params">(<span class="keyword">int</span> rc, String path, Object ctx,</span></span></span><br><span class="line"><span class="function"><span class="params">    Stat stat)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  Code code = Code.get(rc);</span><br><span class="line">  <span class="keyword">if</span> (isSuccess(code)) &#123;</span><br><span class="line">    <span class="comment">// the following owner check completes verification in case the lock znode</span></span><br><span class="line">    <span class="comment">// creation was retried</span></span><br><span class="line">    <span class="keyword">if</span> (stat.getEphemeralOwner() == zkClient.getSessionId()) &#123;</span><br><span class="line">      <span class="comment">// we own the lock znode. so we are the leader</span></span><br><span class="line">      <span class="keyword">if</span> (!becomeActive()) &#123;</span><br><span class="line">        reJoinElectionAfterFailureToBecomeActive();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// we dont own the lock znode. so we are a standby.</span></span><br><span class="line">      becomeStandby();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// the watch set by us will notify about changes</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (isNodeDoesNotExist(code)) &#123;</span><br><span class="line">    <span class="comment">// the lock znode disappeared before we started monitoring it</span></span><br><span class="line">    enterNeutralMode();</span><br><span class="line">    joinElectionInternal();</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时状态已经切换完成，原active节点循环进行<code>doHealthChecks</code>，当节点恢复正常之后则调用ActiveStandbyElector.joinElection恢复选举。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">joinElection</span><span class="params">(<span class="keyword">byte</span>[] data)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">throws</span> HadoopIllegalArgumentException </span>&#123;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (data == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="keyword">new</span> HadoopIllegalArgumentException(<span class="string">"data cannot be null"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> (wantToBeInElection) &#123;</span><br><span class="line">    LOG.info(<span class="string">"Already in election. Not re-connecting."</span>);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 将节点信息写入appData中</span></span><br><span class="line">  appData = <span class="keyword">new</span> <span class="keyword">byte</span>[data.length];</span><br><span class="line">  System.arraycopy(data, <span class="number">0</span>, appData, <span class="number">0</span>, data.length);</span><br><span class="line"></span><br><span class="line">  LOG.debug(<span class="string">"Attempting active election for "</span> + <span class="keyword">this</span>);</span><br><span class="line">  joinElectionInternal();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整个HA的故障转移到此分析完毕</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文主要分析了HA模式下，active与standby进行切换的流程，其大致流程是active nn通过HealthMonitor线程(ha.health-monitor.check-interval.ms 默认1000)检测到<em>磁盘空间不足</em>或者<em>rpc调用没有响应</em>，捕获到<em>SERVICE_UNHEALTHY</em>或者<em>SERVICE_NOT_RESPONDING</em>状态，将退出选举，关闭zk连接，此时zk上<em>ActiveStandbyElectorLock</em>临时节点自动删除，standby节点上的watcher监听到NODEDELETED事件，进行抢锁，去zk上创建ActiveStandbyElectorLock节点，<em>创建成功之后进行状态的转换becomActive</em>，在becomeActive时会判断zk上是否存有原active节点创建的<em>ActiveBreadCrumb</em>节点，如果有则进行fence操作，先由<em>FailoverController</em>执行gracefullFence，如果不成功则执行NodeFence的fence方法(fence method有两个，分别是SSHFence和ShellFence)，fence成功之后将当前节点的信息写入ActiveBreadCrumb节点，并将当前节点的状态转换为active。</p>
<p>原active节点的HealthMonitor线程一直循环检测nn的健康状况，等到nn健康之后再将其加入选举，加入选举也就是创建于zk的连接。</p>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> HA </tag>
            
            <tag> ZKFC </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[hexo启动4000端口无法访问]]></title>
      <url>http://bigdatadecode.club/hexo%E5%90%AF%E5%8A%A84000%E7%AB%AF%E5%8F%A3%E6%97%A0%E6%B3%95%E8%AE%BF%E9%97%AE.html</url>
      <content type="html"><![CDATA[<h2 id="hexo-blog启动流程"><a href="#hexo-blog启动流程" class="headerlink" title="hexo blog启动流程"></a>hexo blog启动流程</h2><ul>
<li>新建一个目录<code>hexo-demo</code></li>
<li>按住<code>shift</code>，点击鼠标右键，选择<code>在此处打开命令窗口</code></li>
<li><code>hexo init</code> （第一次创建blog）</li>
<li><code>npm install</code> 安装依赖</li>
<li><code>hexo g</code> 生成静态文件</li>
<li><code>hexo s</code> 启动hexo服务, debug模式启动<code>hexo s --debug</code>，指定端口启动 <code>hexo server -p port</code></li>
<li><code>hexo d</code> 部署blog到github</li>
</ul>
<h2 id="升级hexo和主题"><a href="#升级hexo和主题" class="headerlink" title="升级hexo和主题"></a>升级hexo和主题</h2><p>在blog目录执行 <code>npm update</code></p>
<h2 id="所遇问题及解决方法"><a href="#所遇问题及解决方法" class="headerlink" title="所遇问题及解决方法"></a>所遇问题及解决方法</h2><p>运行正常时会显示如下<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">INFO  Hexo is running at http://0.0.0.0:4000/. Press Ctrl+C to stop.</span><br></pre></td></tr></table></figure></p>
<p>这时打开<code>localhost:4000</code>可以看到hexo的博客。</p>
<p>如果<code>localhost:4000</code>打开失败，一直处于缓冲状态时，可能的原因很多，我遇到两种情况</p>
<ol>
<li>如果不执行<code>npm install</code>，会导致<code>localhost:4000</code>打开失败</li>
<li>4000端口占用，一般情况下，端口占用，hexo会提示<code>FATAL Port 4000 has been used. Try other port instead.</code>，但是不排除特殊情况，保险的方法还是检查一遍是否是端口占用。</li>
</ol>
<h2 id="windows下检查端口是否占用并杀死该进程"><a href="#windows下检查端口是否占用并杀死该进程" class="headerlink" title="windows下检查端口是否占用并杀死该进程"></a>windows下检查端口是否占用并杀死该进程</h2><ul>
<li><code>netstat -ano | findstr 4000</code>  （最后一列是pid）</li>
<li><code>tasklist | findstr pid</code></li>
<li><code>taskkill -PID pid -F</code></li>
</ul>
]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> hexo </tag>
            
            <tag> 4000 </tag>
            
            <tag> 打开失败 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[HDFS维持副本平衡的流程]]></title>
      <url>http://bigdatadecode.club/HDFS%E7%BB%B4%E6%8C%81%E5%89%AF%E6%9C%AC%E5%B9%B3%E8%A1%A1%E7%9A%84%E6%B5%81%E7%A8%8B.html</url>
      <content type="html"><![CDATA[<p>HDFS上文件的block默认会存放3个副本，一个副本存在一个rack的某个dn上，第二个和第三个副本存放在另一个机架的某两个dn上，nn会维持block的副本平衡，但是当集群上的副本数超过3个时，nn会删除那些节点上的副本来维护副本平衡呢？当集群上的副本数少于3个时，会原则那些节点作为原点进行复制呢？那就查下代码看nn是怎么搞的</p>
<a id="more"></a>
<h2 id="HDFS删除多余副本"><a href="#HDFS删除多余副本" class="headerlink" title="HDFS删除多余副本"></a>HDFS删除多余副本</h2><h3 id="多余副本的场景"><a href="#多余副本的场景" class="headerlink" title="多余副本的场景"></a>多余副本的场景</h3><ul>
<li>rack0上有一个副本，rack1上有两个副本，此时rack0的dn下线，nn维持副本平衡，复制一个副本到其它的rack上，3副本平衡，但是下线的dn又重新上线了，这就出现了4个副本，需要删除一个副本</li>
<li>调用<code>hadoop fs -setrep -R 3</code>相关命令人为修改副本的个数，</li>
</ul>
<h3 id="删除多余副本"><a href="#删除多余副本" class="headerlink" title="删除多余副本"></a>删除多余副本</h3><p>BlockManager主要管理block存储在集群中的相关信息，查看其<code>processOverReplicatedBlock</code>方法，处理多余副本，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 查出有多少个副本</span></span><br><span class="line"><span class="comment"> * 如果有多余的副本，则调用chooseExcessReplicates()</span></span><br><span class="line"><span class="comment"> * 将多余副本放入excessReplicateMap中</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processOverReplicatedBlock</span><span class="params">(<span class="keyword">final</span> Block block,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> <span class="keyword">short</span> replication, <span class="keyword">final</span> DatanodeDescriptor addedNode,</span></span></span><br><span class="line"><span class="function"><span class="params">    DatanodeDescriptor delNodeHint)</span> </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="comment">// block正常副本所在节点的集合</span></span><br><span class="line">  Collection&lt;DatanodeStorageInfo&gt; nonExcess = <span class="keyword">new</span> ArrayList&lt;DatanodeStorageInfo&gt;();</span><br><span class="line">  <span class="comment">// 用于存放该block损坏的副本所在的节点(多余的副本不包含损坏的副本)</span></span><br><span class="line">  Collection&lt;DatanodeDescriptor&gt; corruptNodes = corruptReplicas</span><br><span class="line">      .getNodes(block);</span><br><span class="line">  <span class="keyword">for</span>(DatanodeStorageInfo storage : blocksMap.getStorages(block, State.NORMAL)) &#123;</span><br><span class="line">    <span class="keyword">final</span> DatanodeDescriptor cur = storage.getDatanodeDescriptor();</span><br><span class="line">    ...</span><br><span class="line">    LightWeightLinkedSet&lt;Block&gt; excessBlocks = excessReplicateMap.get(cur</span><br><span class="line">        .getDatanodeUuid());</span><br><span class="line">    <span class="keyword">if</span> (excessBlocks == <span class="keyword">null</span> || !excessBlocks.contains(block)) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!cur.isDecommissionInProgress() &amp;&amp; !cur.isDecommissioned()) &#123;</span><br><span class="line">        <span class="comment">// exclude corrupt replicas</span></span><br><span class="line">        <span class="keyword">if</span> (corruptNodes == <span class="keyword">null</span> || !corruptNodes.contains(cur)) &#123;</span><br><span class="line">          nonExcess.add(storage);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// </span></span><br><span class="line">  chooseExcessReplicates(nonExcess, block, replication, </span><br><span class="line">      addedNode, delNodeHint, blockplacement);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>processOverReplicatedBlock将block的副本所在的节点放在nonExcess集合中，然后调用chooseExcessReplicates</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * We want "replication" replicates for the block, but we now have too many.  </span></span><br><span class="line"><span class="comment"> * In this method, copy enough nodes from 'srcNodes' into 'dstNodes' such that:</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * srcNodes.size() - dstNodes.size() == replication</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 尽量使副本遍布rack，尽量选择剩余空间不足的节点</span></span><br><span class="line"><span class="comment"> * 选取规则是首先从不只一个副本的机架上选取剩余空间最小的节点</span></span><br><span class="line"><span class="comment"> * So removing such a replica won't remove a rack.  ？？？？？？什么意思</span></span><br><span class="line"><span class="comment"> * 如果没有这样的节点可以选择那就选剩余空间最小的节点</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">chooseExcessReplicates</span><span class="params">(<span class="keyword">final</span> Collection&lt;DatanodeStorageInfo&gt; nonExcess, </span></span></span><br><span class="line"><span class="function"><span class="params">                            Block b, <span class="keyword">short</span> replication,</span></span></span><br><span class="line"><span class="function"><span class="params">                            DatanodeDescriptor addedNode,</span></span></span><br><span class="line"><span class="function"><span class="params">                            DatanodeDescriptor delNodeHint,</span></span></span><br><span class="line"><span class="function"><span class="params">                            BlockPlacementPolicy replicator)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> namesystem.hasWriteLock();</span><br><span class="line">  <span class="comment">// first form a rack to datanodes map and</span></span><br><span class="line">  <span class="comment">// BlockCollection是该block的所属信息，INodeFile实现此接口</span></span><br><span class="line">  BlockCollection bc = getBlockCollection(b);</span><br><span class="line">  <span class="keyword">final</span> BlockStoragePolicy storagePolicy = storagePolicySuite.getPolicy(bc.getStoragePolicyID());</span><br><span class="line">  <span class="comment">// 这是个什么东西待验证？？？？</span></span><br><span class="line">  <span class="keyword">final</span> List&lt;StorageType&gt; excessTypes = storagePolicy.chooseExcess(</span><br><span class="line">      replication, DatanodeStorageInfo.toStorageTypes(nonExcess));</span><br><span class="line">  <span class="comment">// rack和dn的映射</span></span><br><span class="line">  <span class="keyword">final</span> Map&lt;String, List&lt;DatanodeStorageInfo&gt;&gt; rackMap</span><br><span class="line">      = <span class="keyword">new</span> HashMap&lt;String, List&lt;DatanodeStorageInfo&gt;&gt;();</span><br><span class="line">  <span class="comment">// 某个机架上副本数超过1个的dn集合    </span></span><br><span class="line">  <span class="keyword">final</span> List&lt;DatanodeStorageInfo&gt; moreThanOne = <span class="keyword">new</span> ArrayList&lt;DatanodeStorageInfo&gt;();</span><br><span class="line">  <span class="comment">// 机架上只有一个副本的dn集合</span></span><br><span class="line">  <span class="keyword">final</span> List&lt;DatanodeStorageInfo&gt; exactlyOne = <span class="keyword">new</span> ArrayList&lt;DatanodeStorageInfo&gt;();</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// split nodes into two sets</span></span><br><span class="line">  <span class="comment">// moreThanOne contains nodes on rack with more than one replica</span></span><br><span class="line">  <span class="comment">// exactlyOne contains the remaining nodes</span></span><br><span class="line">  <span class="comment">// 将nonExcess根据所在机架上副本的个数分为两个集合</span></span><br><span class="line">  replicator.splitNodesWithRack(nonExcess, rackMap, moreThanOne, exactlyOne);</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// pick one node to delete that favors the delete hint</span></span><br><span class="line">  <span class="comment">// otherwise pick one with least space from priSet if it is not empty</span></span><br><span class="line">  <span class="comment">// otherwise one node with least space from remains</span></span><br><span class="line">  <span class="keyword">boolean</span> firstOne = <span class="keyword">true</span>;</span><br><span class="line">  <span class="keyword">final</span> DatanodeStorageInfo delNodeHintStorage</span><br><span class="line">      = DatanodeStorageInfo.getDatanodeStorageInfo(nonExcess, delNodeHint);</span><br><span class="line">  <span class="keyword">final</span> DatanodeStorageInfo addedNodeStorage</span><br><span class="line">      = DatanodeStorageInfo.getDatanodeStorageInfo(nonExcess, addedNode);</span><br><span class="line">  <span class="comment">// 删除多余副本，replication为期望副本数    </span></span><br><span class="line">  <span class="keyword">while</span> (nonExcess.size() - replication &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">final</span> DatanodeStorageInfo cur;</span><br><span class="line">    <span class="comment">// delNodeHint不为null，则先从delNodeHint中删除</span></span><br><span class="line">    <span class="comment">// 只有第一次才会判断</span></span><br><span class="line">    <span class="keyword">if</span> (useDelHint(firstOne, delNodeHintStorage, addedNodeStorage,</span><br><span class="line">        moreThanOne, excessTypes)) &#123;</span><br><span class="line">      cur = delNodeHintStorage;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">// regular excessive replica removal</span></span><br><span class="line">      cur = replicator.chooseReplicaToDelete(bc, b, replication,</span><br><span class="line">          moreThanOne, exactlyOne, excessTypes);</span><br><span class="line">    &#125;</span><br><span class="line">    firstOne = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// adjust rackmap, moreThanOne, and exactlyOne</span></span><br><span class="line">    replicator.adjustSetsWithChosenReplica(rackMap, moreThanOne,</span><br><span class="line">        exactlyOne, cur);</span><br><span class="line"></span><br><span class="line">    nonExcess.remove(cur);</span><br><span class="line">    addToExcessReplicate(cur.getDatanodeDescriptor(), b);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// The 'excessblocks' tracks blocks until we get confirmation</span></span><br><span class="line">    <span class="comment">// that the datanode has deleted them; the only way we remove them</span></span><br><span class="line">    <span class="comment">// is when we get a "removeBlock" message.  </span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// The 'invalidate' list is used to inform the datanode the block </span></span><br><span class="line">    <span class="comment">// should be deleted.  Items are removed from the invalidate list</span></span><br><span class="line">    <span class="comment">// upon giving instructions to the namenode.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    addToInvalidates(b, cur.getDatanodeDescriptor());</span><br><span class="line">    blockLog.info(<span class="string">"BLOCK* chooseExcessReplicates: "</span></span><br><span class="line">              +<span class="string">"("</span>+cur+<span class="string">", "</span>+b+<span class="string">") is added to invalidated blocks set"</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>chooseExcessReplicates的处理逻辑是，调用<code>replicator.splitNodesWithRack</code>将nonExcess分为两个集合，然后循环的调用<code>replicator.chooseReplicaToDelete</code>选出要删除副本的节点，放入excessReplicateMap和invalidateBlocks中，等待delete掉。</p>
<p>moreThanOne和exactlyOne的划分规则在<code>splitNodesWithRack</code>中，代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">splitNodesWithRack</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> Iterable&lt;DatanodeStorageInfo&gt; storages,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> Map&lt;String, List&lt;DatanodeStorageInfo&gt;&gt; rackMap,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> List&lt;DatanodeStorageInfo&gt; moreThanOne,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> List&lt;DatanodeStorageInfo&gt; exactlyOne)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 构建rackMap</span></span><br><span class="line">  <span class="comment">// rackMap中key是rack name，value是副本的list</span></span><br><span class="line">  <span class="keyword">for</span>(DatanodeStorageInfo s: storages) &#123;</span><br><span class="line">    <span class="keyword">final</span> String rackName = getRack(s.getDatanodeDescriptor());</span><br><span class="line">    List&lt;DatanodeStorageInfo&gt; storageList = rackMap.get(rackName);</span><br><span class="line">    <span class="keyword">if</span> (storageList == <span class="keyword">null</span>) &#123;</span><br><span class="line">      storageList = <span class="keyword">new</span> ArrayList&lt;DatanodeStorageInfo&gt;();</span><br><span class="line">      rackMap.put(rackName, storageList);</span><br><span class="line">    &#125;</span><br><span class="line">    storageList.add(s);</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="comment">// split nodes into two sets</span></span><br><span class="line">  <span class="comment">// 根据value的个数进行划分exactlyOne和moreThanOne</span></span><br><span class="line">  <span class="keyword">for</span>(List&lt;DatanodeStorageInfo&gt; storageList : rackMap.values()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (storageList.size() == <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="comment">// exactlyOne contains nodes on rack with only one replica</span></span><br><span class="line">      exactlyOne.add(storageList.get(<span class="number">0</span>));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="comment">// moreThanOne contains nodes on rack with more than one replica</span></span><br><span class="line">      moreThanOne.addAll(storageList);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>splitNodesWithRack划分结束之后，在chooseExcessReplicates中进行while循环来删除多余的副本，直到达到期望副本个数。</p>
<p>删除节点的选择是在<code>chooseReplicaToDelete</code>中决定的，该方法在<em>BlockPlacementPolicyDefault</em>中被重写。选取规则为</p>
<ul>
<li>如果moreThanOne不是empty，则先把moreThanOne做为节点集合</li>
<li>首先选择心跳时间间隔最长的节点或者</li>
<li>如果所有的心跳都在允许的间隔之内，则选择剩余空间最少的节点，</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// BlockPlacementPolicyDefault.class</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> DatanodeStorageInfo <span class="title">chooseReplicaToDelete</span><span class="params">(BlockCollection bc,</span></span></span><br><span class="line"><span class="function"><span class="params">    Block block, <span class="keyword">short</span> replicationFactor,</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;DatanodeStorageInfo&gt; first,</span></span></span><br><span class="line"><span class="function"><span class="params">    Collection&lt;DatanodeStorageInfo&gt; second,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">final</span> List&lt;StorageType&gt; excessTypes)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// 两次心跳之间允许的最大间隔，为时间点数值  	</span></span><br><span class="line">  <span class="keyword">long</span> oldestHeartbeat =</span><br><span class="line">    now() - heartbeatInterval * tolerateHeartbeatMultiplier;</span><br><span class="line">  DatanodeStorageInfo oldestHeartbeatStorage = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">long</span> minSpace = Long.MAX_VALUE;</span><br><span class="line">  DatanodeStorageInfo minSpaceStorage = <span class="keyword">null</span>;</span><br><span class="line">  <span class="comment">// 如果first集合不为null，则从first集合中选取要删除的节点，否则从second</span></span><br><span class="line">  <span class="keyword">for</span>(DatanodeStorageInfo storage : pickupReplicaSet(first, second)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!excessTypes.contains(storage.getStorageType())) &#123;</span><br><span class="line">      <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> DatanodeDescriptor node = storage.getDatanodeDescriptor();</span><br><span class="line">    <span class="keyword">long</span> free = node.getRemaining();</span><br><span class="line">    <span class="keyword">long</span> lastHeartbeat = node.getLastUpdate();</span><br><span class="line">    <span class="comment">// 心跳间隔最长的节点赋值</span></span><br><span class="line">    <span class="keyword">if</span>(lastHeartbeat &lt; oldestHeartbeat) &#123;</span><br><span class="line">      oldestHeartbeat = lastHeartbeat;</span><br><span class="line">      oldestHeartbeatStorage = storage;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 对剩余空间最小的节点赋值</span></span><br><span class="line">    <span class="keyword">if</span> (minSpace &gt; free) &#123;</span><br><span class="line">      minSpace = free;</span><br><span class="line">      minSpaceStorage = storage;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 首先选择心跳时间间隔最长的节点或者</span></span><br><span class="line">  <span class="comment">// 如果所有的心跳都在允许的间隔之内，则选择剩余空间最少的节点，</span></span><br><span class="line">  <span class="keyword">final</span> DatanodeStorageInfo storage;</span><br><span class="line">  <span class="keyword">if</span> (oldestHeartbeatStorage != <span class="keyword">null</span>) &#123;</span><br><span class="line">    storage = oldestHeartbeatStorage;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (minSpaceStorage != <span class="keyword">null</span>) &#123;</span><br><span class="line">    storage = minSpaceStorage;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  excessTypes.remove(storage.getStorageType());</span><br><span class="line">  <span class="keyword">return</span> storage;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>选出要删除的节点cur之后，调用<code>adjustSetsWithChosenReplica</code>重新调整rackMap、moreThanOne和exactlyOne，并调用<code>addToExcessReplicate</code>将cur放入<em>excessReplicateMap</em>中</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addToExcessReplicate</span><span class="params">(DatanodeInfo dn, Block block)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> namesystem.hasWriteLock();</span><br><span class="line">  LightWeightLinkedSet&lt;Block&gt; excessBlocks = excessReplicateMap.get(dn.getDatanodeUuid());</span><br><span class="line">  <span class="keyword">if</span> (excessBlocks == <span class="keyword">null</span>) &#123;</span><br><span class="line">    excessBlocks = <span class="keyword">new</span> LightWeightLinkedSet&lt;Block&gt;();</span><br><span class="line">    excessReplicateMap.put(dn.getDatanodeUuid(), excessBlocks);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (excessBlocks.add(block)) &#123;</span><br><span class="line">    excessBlocksCount.incrementAndGet();</span><br><span class="line">    <span class="keyword">if</span>(blockLog.isDebugEnabled()) &#123;</span><br><span class="line">      blockLog.debug(<span class="string">"BLOCK* addToExcessReplicate:"</span></span><br><span class="line">          + <span class="string">" ("</span> + dn + <span class="string">", "</span> + block</span><br><span class="line">          + <span class="string">") is added to excessReplicateMap"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后会将cur放入<em>invalidateBlocks</em>中，随后cur会被删除</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">addToInvalidates</span><span class="params">(<span class="keyword">final</span> Block block, <span class="keyword">final</span> DatanodeInfo datanode)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!namesystem.isPopulatingReplQueues()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  invalidateBlocks.add(block, datanode, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>invalidateBlocks在哪被删除(在ReplicationMonitor的中)</p>
</blockquote>
<h2 id="HDFS修复缺少副本"><a href="#HDFS修复缺少副本" class="headerlink" title="HDFS修复缺少副本"></a>HDFS修复缺少副本</h2><p>当HDFS上某个block的副本数低于期望的副本数时，会调用<code>processMisReplicatedBlock</code>进行处理</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Process a single possibly misreplicated block. This adds it to the</span></span><br><span class="line"><span class="comment"> * appropriate queues if necessary, and returns a result code indicating</span></span><br><span class="line"><span class="comment"> * what happened with it.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> MisReplicationResult <span class="title">processMisReplicatedBlock</span><span class="params">(BlockInfo block)</span> </span>&#123;</span><br><span class="line">  BlockCollection bc = block.getBlockCollection();</span><br><span class="line">  <span class="comment">// bc 为null，则该block没有所属文件信息，是无效的，应该被删除</span></span><br><span class="line">  <span class="keyword">if</span> (bc == <span class="keyword">null</span>) &#123;</span><br><span class="line">    <span class="comment">// block does not belong to any file</span></span><br><span class="line">    addToInvalidates(block);</span><br><span class="line">    <span class="keyword">return</span> MisReplicationResult.INVALID;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (!block.isComplete()) &#123;</span><br><span class="line">    <span class="comment">// Incomplete blocks are never considered mis-replicated --</span></span><br><span class="line">    <span class="comment">// they'll be reached when they are completed or recovered.</span></span><br><span class="line">    <span class="keyword">return</span> MisReplicationResult.UNDER_CONSTRUCTION;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// calculate current replication</span></span><br><span class="line">  <span class="keyword">short</span> expectedReplication = bc.getBlockReplication();</span><br><span class="line">  <span class="comment">// 计算该block的副本数，不包含损坏的</span></span><br><span class="line">  NumberReplicas num = countNodes(block);</span><br><span class="line">  <span class="keyword">int</span> numCurrentReplica = num.liveReplicas();</span><br><span class="line">  <span class="comment">// add to under-replicated queue if need to be</span></span><br><span class="line">  <span class="keyword">if</span> (isNeededReplication(block, expectedReplication, numCurrentReplica)) &#123;</span><br><span class="line">    <span class="keyword">if</span> (neededReplications.add(block, numCurrentReplica, num</span><br><span class="line">        .decommissionedReplicas(), expectedReplication)) &#123;</span><br><span class="line">      <span class="keyword">return</span> MisReplicationResult.UNDER_REPLICATED;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (numCurrentReplica &gt; expectedReplication) &#123;</span><br><span class="line">    <span class="keyword">if</span> (num.replicasOnStaleNodes() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// If any of the replicas of this block are on nodes that are</span></span><br><span class="line">      <span class="comment">// considered "stale", then these replicas may in fact have</span></span><br><span class="line">      <span class="comment">// already been deleted. So, we cannot safely act on the</span></span><br><span class="line">      <span class="comment">// over-replication until a later point in time, when</span></span><br><span class="line">      <span class="comment">// the "stale" nodes have block reported.</span></span><br><span class="line">      <span class="keyword">return</span> MisReplicationResult.POSTPONE;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// over-replicated block</span></span><br><span class="line">    <span class="comment">// 超出了expectedReplication，则删除多余副本</span></span><br><span class="line">    processOverReplicatedBlock(block, expectedReplication, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">    <span class="keyword">return</span> MisReplicationResult.OVER_REPLICATED;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> MisReplicationResult.OK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>processMisReplicatedBlock根据该block的信息，将block打上标签并放入不同的队列中进行处理。利用<code>countNodes</code>计算其副本数</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Return the number of nodes hosting a given block, grouped</span></span><br><span class="line"><span class="comment"> * by the state of those replicas.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> NumberReplicas <span class="title">countNodes</span><span class="params">(Block b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> decommissioned = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> live = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> corrupt = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> excess = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">int</span> stale = <span class="number">0</span>;</span><br><span class="line">  Collection&lt;DatanodeDescriptor&gt; nodesCorrupt = corruptReplicas.getNodes(b);</span><br><span class="line">  <span class="keyword">for</span>(DatanodeStorageInfo storage : blocksMap.getStorages(b, State.NORMAL)) &#123;</span><br><span class="line">    <span class="keyword">final</span> DatanodeDescriptor node = storage.getDatanodeDescriptor();</span><br><span class="line">    <span class="keyword">if</span> ((nodesCorrupt != <span class="keyword">null</span>) &amp;&amp; (nodesCorrupt.contains(node))) &#123;</span><br><span class="line">      corrupt++;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (node.isDecommissionInProgress() || node.isDecommissioned()) &#123;</span><br><span class="line">      decommissioned++;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      LightWeightLinkedSet&lt;Block&gt; blocksExcess = excessReplicateMap.get(node</span><br><span class="line">          .getDatanodeUuid());</span><br><span class="line">      <span class="keyword">if</span> (blocksExcess != <span class="keyword">null</span> &amp;&amp; blocksExcess.contains(b)) &#123;</span><br><span class="line">        excess++;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        live++;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (storage.areBlockContentsStale()) &#123;</span><br><span class="line">      stale++;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">new</span> NumberReplicas(live, decommissioned, corrupt, excess, stale);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>processMisReplicatedBlock中用isNeededReplication判断是否需要进行增加副本数，<code>current &lt; expected || !blockHasEnoughRacks(b)</code>为true时，则调用<code>neededReplications.add</code>进行增加副本，neededReplications是UnderReplicatedBlocks的实例，<em>UnderReplicatedBlocks是HDFS中关于块复制的一个重要数据结构</em>。add方法如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">synchronized</span> <span class="keyword">boolean</span> <span class="title">add</span><span class="params">(Block block,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">int</span> curReplicas, </span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">int</span> decomissionedReplicas,</span></span></span><br><span class="line"><span class="function"><span class="params">                         <span class="keyword">int</span> expectedReplicas)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> curReplicas &gt;= <span class="number">0</span> : <span class="string">"Negative replicas!"</span>;</span><br><span class="line">  <span class="keyword">int</span> priLevel = getPriority(block, curReplicas, decomissionedReplicas,</span><br><span class="line">                             expectedReplicas);</span><br><span class="line">  <span class="keyword">if</span>(priLevel != LEVEL &amp;&amp; priorityQueues.get(priLevel).add(block)) &#123;</span><br><span class="line">    <span class="keyword">if</span>(NameNode.blockStateChangeLog.isDebugEnabled()) &#123;</span><br><span class="line">      NameNode.blockStateChangeLog.debug(</span><br><span class="line">        <span class="string">"BLOCK* NameSystem.UnderReplicationBlock.add:"</span></span><br><span class="line">        + block</span><br><span class="line">        + <span class="string">" has only "</span> + curReplicas</span><br><span class="line">        + <span class="string">" replicas and need "</span> + expectedReplicas</span><br><span class="line">        + <span class="string">" replicas so is added to neededReplications"</span></span><br><span class="line">        + <span class="string">" at priority level "</span> + priLevel);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>add将根据block相关副本的优先级放入under replication queue中，优先级从<code>getPriority</code>中获取，级别有5中，从0开始，0的优先级最高，则4最低。</p>
<ol>
<li>QUEUE_HIGHEST_PRIORITY = 0<br> 最高优先级，主要针对数据块副本数非常的、严重的不足的情况，当前副本数低于期望值，且仅有1个或者干脆没有，比如副本数仅有1个，或者副本数干脆为0，但是还存在退役副本，这种情况最危险，数据最容易丢失，所以复制的优先级也最高</li>
<li>QUEUE_VERY_UNDER_REPLICATED = 1<br> 主要针对数据块副本数不足但没有上面严重的情况，如<em>当前副本数低于期望值，但是副本数大于1</em>，<strong>其判断公式为当前副本数curReplicas乘以3还小于期望副本数expectedReplicas</strong>，这种情况也比较危险，数据也容易丢失，所以复制的优先级也很高</li>
<li>QUEUE_UNDER_REPLICATED = 2<br> 主要针对数据块副本数低于期望值，但是还不是很严重，也可以理解为正常缺失副本块</li>
<li>QUEUE_REPLICAS_BADLY_DISTRIBUTED = 3<br> 有足够(大于或者等于正确的副本数)的副本个数，但是并不符合副本的放置策略，副本分布不均衡</li>
<li>QUEUE_WITH_CORRUPT_BLOCKS = 4<br> 主要针对<em>损坏的数据块的情况，其副本数位0</em>，但是还没有退役副本</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">getPriority</span><span class="params">(Block block,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">int</span> curReplicas, </span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">int</span> decommissionedReplicas,</span></span></span><br><span class="line"><span class="function"><span class="params">                        <span class="keyword">int</span> expectedReplicas)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">assert</span> curReplicas &gt;= <span class="number">0</span> : <span class="string">"Negative replicas!"</span>;</span><br><span class="line">  <span class="keyword">if</span> (curReplicas &gt;= expectedReplicas) &#123;</span><br><span class="line">    <span class="comment">// Block has enough copies, but not enough racks</span></span><br><span class="line">    <span class="keyword">return</span> QUEUE_REPLICAS_BADLY_DISTRIBUTED;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curReplicas == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// If there are zero non-decommissioned replicas but there are</span></span><br><span class="line">    <span class="comment">// some decommissioned replicas, then assign them highest priority</span></span><br><span class="line">    <span class="keyword">if</span> (decommissionedReplicas &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> QUEUE_HIGHEST_PRIORITY;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//all we have are corrupt blocks</span></span><br><span class="line">    <span class="keyword">return</span> QUEUE_WITH_CORRUPT_BLOCKS;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> (curReplicas == <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="comment">//only on replica -risk of loss</span></span><br><span class="line">    <span class="comment">// highest priority</span></span><br><span class="line">    <span class="keyword">return</span> QUEUE_HIGHEST_PRIORITY;</span><br><span class="line">  &#125; <span class="keyword">else</span> <span class="keyword">if</span> ((curReplicas * <span class="number">3</span>) &lt; expectedReplicas) &#123;</span><br><span class="line">    <span class="comment">//there is less than a third as many blocks as requested;</span></span><br><span class="line">    <span class="comment">//this is considered very under-replicated</span></span><br><span class="line">    <span class="keyword">return</span> QUEUE_VERY_UNDER_REPLICATED;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">//add to the normal queue for under replicated blocks</span></span><br><span class="line">    <span class="keyword">return</span> QUEUE_UNDER_REPLICATED;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>通过getPriority得到优先级之后，从<em>priorityQueues</em> list中拿到相同优先级的<em>LightWeightLinkedSet</em> set，将block放入set中。最后在<code>processMisReplicatedBlock</code>方法中返回该block的标记<em>MisReplicationResult.UNDER_REPLICATED</em></p>
<p>通过上面的代码nn将缺少副本的block根据复制优先级放入不同的queue中，等待复制线程进行复制。</p>
<h2 id="附加：副本默认放置策略"><a href="#附加：副本默认放置策略" class="headerlink" title="附加：副本默认放置策略"></a>附加：副本默认放置策略</h2><p>默认的放置策略大家都熟悉，3副本分布在两个rack上，一个rack上有一个副本，另一个rack上有两个副本，这里就只简单的列出代码的部分实现，代码入口是BlockPlacementPolicyDefault.chooseTarget，这里只列主要的逻辑代码chooseTarget：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">chooseTarget</span><span class="params">(<span class="keyword">int</span> numOfReplicas,</span></span></span><br><span class="line"><span class="function"><span class="params">                          Node writer,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> Set&lt;Node&gt; excludedNodes,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">long</span> blocksize,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">int</span> maxNodesPerRack,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> List&lt;DatanodeStorageInfo&gt; results,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">boolean</span> avoidStaleNodes,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> BlockStoragePolicy storagePolicy,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> EnumSet&lt;StorageType&gt; unavailableStorages,</span></span></span><br><span class="line"><span class="function"><span class="params">                          <span class="keyword">final</span> <span class="keyword">boolean</span> newBlock)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (numOfReplicas == <span class="number">0</span> || clusterMap.getNumOfLeaves()==<span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> (writer <span class="keyword">instanceof</span> DatanodeDescriptor) ? writer : <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> numOfResults = results.size();</span><br><span class="line">  <span class="keyword">final</span> <span class="keyword">int</span> totalReplicasExpected = numOfReplicas + numOfResults;</span><br><span class="line">  <span class="keyword">if</span> ((writer == <span class="keyword">null</span> || !(writer <span class="keyword">instanceof</span> DatanodeDescriptor)) &amp;&amp; !newBlock) &#123;</span><br><span class="line">    writer = results.get(<span class="number">0</span>).getDatanodeDescriptor();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Keep a copy of original excludedNodes</span></span><br><span class="line">  <span class="keyword">final</span> Set&lt;Node&gt; oldExcludedNodes = <span class="keyword">new</span> HashSet&lt;Node&gt;(excludedNodes);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// choose storage types; use fallbacks for unavailable storages</span></span><br><span class="line">  <span class="keyword">final</span> List&lt;StorageType&gt; requiredStorageTypes = storagePolicy</span><br><span class="line">      .chooseStorageTypes((<span class="keyword">short</span>) totalReplicasExpected,</span><br><span class="line">          DatanodeStorageInfo.toStorageTypes(results),</span><br><span class="line">          unavailableStorages, newBlock);</span><br><span class="line">  <span class="keyword">final</span> EnumMap&lt;StorageType, Integer&gt; storageTypes =</span><br><span class="line">      getRequiredStorageTypes(requiredStorageTypes);</span><br><span class="line">  <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">    LOG.trace(<span class="string">"storageTypes="</span> + storageTypes);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> ((numOfReplicas = requiredStorageTypes.size()) == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> NotEnoughReplicasException(</span><br><span class="line">          <span class="string">"All required storage types are unavailable: "</span></span><br><span class="line">          + <span class="string">" unavailableStorages="</span> + unavailableStorages</span><br><span class="line">          + <span class="string">", storagePolicy="</span> + storagePolicy);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 第一个dn的选择，如果client在dn上，则选择此dn，否则随机选dn</span></span><br><span class="line">    <span class="keyword">if</span> (numOfResults == <span class="number">0</span>) &#123;</span><br><span class="line">      writer = chooseLocalStorage(writer, excludedNodes, blocksize,</span><br><span class="line">          maxNodesPerRack, results, avoidStaleNodes, storageTypes, <span class="keyword">true</span>)</span><br><span class="line">              .getDatanodeDescriptor();</span><br><span class="line">      <span class="keyword">if</span> (--numOfReplicas == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> writer;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 从results列表中取出第一个副本所在的dn0</span></span><br><span class="line">    <span class="keyword">final</span> DatanodeDescriptor dn0 = results.get(<span class="number">0</span>).getDatanodeDescriptor();</span><br><span class="line">    <span class="comment">// 第二个副本从非dn0的机架上选择一个dn</span></span><br><span class="line">    <span class="keyword">if</span> (numOfResults &lt;= <span class="number">1</span>) &#123;</span><br><span class="line">      chooseRemoteRack(<span class="number">1</span>, dn0, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">          results, avoidStaleNodes, storageTypes);</span><br><span class="line">      <span class="keyword">if</span> (--numOfReplicas == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> writer;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (numOfResults &lt;= <span class="number">2</span>) &#123;</span><br><span class="line">      <span class="comment">// 从results中取出第二个副本所在的dn1</span></span><br><span class="line">      <span class="keyword">final</span> DatanodeDescriptor dn1 = results.get(<span class="number">1</span>).getDatanodeDescriptor();</span><br><span class="line">      <span class="comment">// 如果dn0和dn1在一个机架上，则从另一个机架中选择一个dn</span></span><br><span class="line">      <span class="keyword">if</span> (clusterMap.isOnSameRack(dn0, dn1)) &#123;</span><br><span class="line">        chooseRemoteRack(<span class="number">1</span>, dn0, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">            results, avoidStaleNodes, storageTypes);</span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (newBlock)&#123;</span><br><span class="line">      	<span class="comment">// 如果是新block，即results.isEmpty。</span></span><br><span class="line">      	<span class="comment">// dn0和dn1不在同一个机架，则从dn1所在的机架上选一个dn</span></span><br><span class="line">        chooseLocalRack(dn1, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">            results, avoidStaleNodes, storageTypes);</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      	<span class="comment">// 选择一个同writer同rack的dn</span></span><br><span class="line">        chooseLocalRack(writer, excludedNodes, blocksize, maxNodesPerRack,</span><br><span class="line">            results, avoidStaleNodes, storageTypes);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (--numOfReplicas == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span> writer;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 超出3个副本的情况，则后面的副本随机选择dn</span></span><br><span class="line">    chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,</span><br><span class="line">        maxNodesPerRack, results, avoidStaleNodes, storageTypes);</span><br><span class="line">  &#125; <span class="keyword">catch</span> (NotEnoughReplicasException e) &#123;</span><br><span class="line">    <span class="keyword">final</span> String message = <span class="string">"Failed to place enough replicas, still in need of "</span></span><br><span class="line">        + (totalReplicasExpected - results.size()) + <span class="string">" to reach "</span></span><br><span class="line">        + totalReplicasExpected</span><br><span class="line">        + <span class="string">" (unavailableStorages="</span> + unavailableStorages</span><br><span class="line">        + <span class="string">", storagePolicy="</span> + storagePolicy</span><br><span class="line">        + <span class="string">", newBlock="</span> + newBlock + <span class="string">")"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (LOG.isTraceEnabled()) &#123;</span><br><span class="line">      LOG.trace(message, e);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      LOG.warn(message + <span class="string">" "</span> + e.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (avoidStaleNodes) &#123;</span><br><span class="line">      <span class="comment">// Retry chooseTarget again, this time not avoiding stale nodes.</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">// excludedNodes contains the initial excludedNodes and nodes that were</span></span><br><span class="line">      <span class="comment">// not chosen because they were stale, decommissioned, etc.</span></span><br><span class="line">      <span class="comment">// We need to additionally exclude the nodes that were added to the </span></span><br><span class="line">      <span class="comment">// result list in the successful calls to choose*() above.</span></span><br><span class="line">      <span class="keyword">for</span> (DatanodeStorageInfo resultStorage : results) &#123;</span><br><span class="line">        addToExcludedNodes(resultStorage.getDatanodeDescriptor(), oldExcludedNodes);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// Set numOfReplicas, since it can get out of sync with the result list</span></span><br><span class="line">      <span class="comment">// if the NotEnoughReplicasException was thrown in chooseRandom().</span></span><br><span class="line">      numOfReplicas = totalReplicasExpected - results.size();</span><br><span class="line">      <span class="keyword">return</span> chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,</span><br><span class="line">          maxNodesPerRack, results, <span class="keyword">false</span>, storagePolicy, unavailableStorages,</span><br><span class="line">          newBlock);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">boolean</span> retry = <span class="keyword">false</span>;</span><br><span class="line">    <span class="comment">// simply add all the remaining types into unavailableStorages and give</span></span><br><span class="line">    <span class="comment">// another try. No best effort is guaranteed here.</span></span><br><span class="line">    <span class="keyword">for</span> (StorageType type : storageTypes.keySet()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!unavailableStorages.contains(type)) &#123;</span><br><span class="line">        unavailableStorages.add(type);</span><br><span class="line">        retry = <span class="keyword">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (retry) &#123;</span><br><span class="line">      <span class="keyword">for</span> (DatanodeStorageInfo resultStorage : results) &#123;</span><br><span class="line">        addToExcludedNodes(resultStorage.getDatanodeDescriptor(),</span><br><span class="line">            oldExcludedNodes);</span><br><span class="line">      &#125;</span><br><span class="line">      numOfReplicas = totalReplicasExpected - results.size();</span><br><span class="line">      <span class="keyword">return</span> chooseTarget(numOfReplicas, writer, oldExcludedNodes, blocksize,</span><br><span class="line">          maxNodesPerRack, results, <span class="keyword">false</span>, storagePolicy, unavailableStorages,</span><br><span class="line">          newBlock);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> writer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> replication </tag>
            
            <tag> excess </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Spark编译与部署]]></title>
      <url>http://bigdatadecode.club/Spark%E7%BC%96%E8%AF%91%E4%B8%8E%E9%83%A8%E7%BD%B2.html</url>
      <content type="html"><![CDATA[<h2 id="编译spark-1-6-1"><a href="#编译spark-1-6-1" class="headerlink" title="编译spark-1.6.1"></a>编译spark-1.6.1</h2><h3 id="使用maven编译"><a href="#使用maven编译" class="headerlink" title="使用maven编译"></a>使用maven编译</h3><p>编译spark时需要先将maven(<em>maven需要3.3以上</em>)的内存加大，执行命令<br><code>export MAVEN_OPTS=&quot;-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m&quot;</code></p>
<p>然后执行编译命令(<em>编译继承hadoop和hive的版本</em>)<br><code>mvn -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0 -Phive -Phive-thriftserver -DskipTests clean package</code></p>
<p>此处只是将spark源码进行编译，并没有打包成可部署的tar包，类似可部署tar解压之后的结果，但包含源码和别的jar包。为了部署方便还是要将spark编译为tar包，执行命令<br><code>./make-distribution.sh --tgz -Phadoop-2.6 -Phive -Phive-thriftserver -Pyarn -DskipTests -Dhadoop.version=2.6.0</code><br><em>执行此条命令时可能需要等待一段时间才会显示编译的过程，不要心急，慢慢等会</em></p>
<p>编译时如果不指定scala的版本，默认是2.10。如果需要改变scala的版本，执行如下命令：<br><code>./dev/change-scala-version.sh 2.11</code><br>然后再执行编译命令。<br><a id="more"></a></p>
<h2 id="部署spark-on-yarn"><a href="#部署spark-on-yarn" class="headerlink" title="部署spark on yarn"></a>部署spark on yarn</h2><p>spark on yarn部署比较简单<br>在spark-env.sh中配置HADOOP_CONF_DIR和YARN_CONF_DIR，HADOOP_CONF_DIR用来连接HDFS，YARN_CONF_DIR用来连接ResourceManager。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">HADOOP_CONF_DIR=/home/hadoop/hadoop/etc/hadoop</span><br><span class="line">YARN_CONF_DIR=/home/hadoop/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure>
<p>部署好之后运行个例子检测下</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --<span class="class"><span class="keyword">class</span>\ <span class="title">org</span>.<span class="title">apache</span>.<span class="title">spark</span>.<span class="title">examples</span>.<span class="title">SparkPi</span> --<span class="title">master</span> <span class="title">yarn</span> --<span class="title">deploy</span>-<span class="title">mode</span> <span class="title">cluster</span> --<span class="title">driver</span>-<span class="title">memory</span> 4<span class="title">g</span> --<span class="title">executor</span>-<span class="title">memory</span> 2<span class="title">g</span> --<span class="title">executor</span>-<span class="title">cores</span> 1 <span class="title">lib</span>/<span class="title">spark</span>-<span class="title">examples</span>-1.6.1-<span class="title">hadoop2</span>.6.0.<span class="title">jar</span> 100</span></span><br></pre></td></tr></table></figure>
<p>可以使用<code>--jars</code>参数添加依赖的jar包</p>
<h2 id="spark-sql-with-hive"><a href="#spark-sql-with-hive" class="headerlink" title="spark sql with hive"></a>spark sql with hive</h2><ul>
<li>将hive-site.xml scp 到hadoop03的spark/conf中 (<em>hive client可以和spark client不在一台机器上</em>)</li>
<li>将lib/mysql-connector-java-5.1.38-bin.jar scp hadoop03的spark/lib</li>
</ul>
<p>运行spark-shell检验是否部署成功<br><code>bin/spark-shell --driver-class-path lib/mysql-connector-java-5.1.38-bin.jar</code><br>打开spark-shell执行一些hive命令进行测试。<br>也可执行spark-sql<br><code>bin/spark-sql --master yarn --driver-class-path lib/mysql-connector-java-5.1.38-bin.jar</code></p>
<p>用spark sql操作hive时，必须构建一个HiveContext对象，其继承自SQLContext。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// sc is an existing SparkContext.</span></span><br><span class="line">val sqlContext = <span class="keyword">new</span> org.apache.spark.sql.hive.HiveContext(sc)</span><br><span class="line"><span class="comment">// SQLContext</span></span><br><span class="line"><span class="comment">// val sqlContext = new org.apache.spark.sql.SQLContext(sc)</span></span><br><span class="line"><span class="comment">// val df = sqlContext.sql("SELECT * FROM table")</span></span><br><span class="line">sqlContext.sql(<span class="string">"CREATE TABLE IF NOT EXISTS src (key INT, value STRING)"</span>)</span><br><span class="line">sqlContext.sql(<span class="string">"LOAD DATA LOCAL INPATH 'examples/src/main/resources/kv1.txt' INTO TABLE src"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// Queries are expressed in HiveQL</span></span><br><span class="line">sqlContext.sql(<span class="string">"FROM src SELECT key, value"</span>).collect().foreach(println)</span><br></pre></td></tr></table></figure>
<h2 id="启动history-server"><a href="#启动history-server" class="headerlink" title="启动history server"></a>启动history server</h2><ul>
<li>在hdfs上创建存放spark log的目录<br><code>hadoop fs -mkdir /spark_hislog</code></li>
<li>spark-env.sh中添加SPARK_DAEMON_MEMORY、SPARK_DAEMON_JAVA_OPTS、SPARK_PUBLIC_DNS、SPARK_HISTORY_OPTS</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#SPARK_DAEMON_MEMORY=2g # 这个貌似没有起作用，随后再测</span><br><span class="line">#SPARK_PUBLIC_DNS=xx.xx.xx.xx # 可能是ip地址 </span><br><span class="line">PARK_HISTORY_OPTS=<span class="string">"-Dspark.history.ui.port=18080 -Dspark.history.fs.logDirectory=hdfs://localhost:8020/spark_hislog"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>spark-default.conf 中添加如下配置</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 开启日志记录</span><br><span class="line">spark.eventLog.enabled             <span class="keyword">true</span></span><br><span class="line"># 日志存储地址</span><br><span class="line"># spark.eventLog.dir应该与spark.history.fs.logDirectory目录一样</span><br><span class="line"># spark.history.fs.logDirectory：spark history server页面只展示该指定路径下的信息</span><br><span class="line"># spark.eventLog.dir：application在运行过程中所有的信息均记录在该属性指定的路径下</span><br><span class="line">spark.eventLog.dir                 hdfs:<span class="comment">//localhost:8020/spark_hislog</span></span><br><span class="line"># 是否进行压缩</span><br><span class="line">spark.eventLog.compress            <span class="keyword">true</span></span><br></pre></td></tr></table></figure>
<ul>
<li>启动history server <code>sbin/start-history-server.sh</code></li>
<li>访问xx.xx.xx.xx:18080</li>
</ul>
<h2 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h2><p><strong>在编译和部署的过程中我并没有安装scala，scala何时需要安装是必须的还是什么？暂时还不清楚，但之前在工作中貌似遇到spark on yarn时，spark client需要安装scala，但现在还没有遇到。</strong></p>
]]></content>
      
        <categories>
            
            <category> Spark </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Spark </tag>
            
            <tag> Build </tag>
            
            <tag> 部署 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[linux配置ssh并更改默认端口]]></title>
      <url>http://bigdatadecode.club/linux%E9%85%8D%E7%BD%AEssh%E5%B9%B6%E6%9B%B4%E6%94%B9%E9%BB%98%E8%AE%A4%E7%AB%AF%E5%8F%A3.html</url>
      <content type="html"><![CDATA[<h2 id="各机器打通ssh"><a href="#各机器打通ssh" class="headerlink" title="各机器打通ssh"></a>各机器打通ssh</h2><ol>
<li><p>安装 ssh(hadoop 用户)<br> <code>mkdir .ssh  #( __创建的.ssh目录的权限必须是 700__，否则会导致ssh不通 )</code><br> <code>ssh-keygen -t rsa</code><br> <code>cat .ssh/id\_rsa.pub &gt;&gt; .ssh/authorized\_keys</code><br> <strong><code>chmod 600 .ssh/authorized_keys #(修改文件权限，否则不起作用 )  必须为600</code></strong><br>执行完以后，可以在本机上测试下，用 ssh连接自己，即：<code>ssh localhost</code> (或 ssh master),如果不幸还是提示要输入密码，说明还没起作用（ <em><code>ssh user@hostname –v</code>  是debug 模式</em>）</p>
</li>
<li><p>在其它机器上生成公钥、密钥，并将公钥文件复制到 master<br>a) 以 hadoop身份登录其它二台机器 slave01、 slave02，执行 <code>ssh-keygen -t rsa -P &#39;&#39;</code> 生成公钥、密钥<br>b) 然后用 scp命令，把公钥文件发放给 master（即：刚才已经搞定的那台机器）<br>slave01上：<br> <code>scp .ssh/id\_rsa.pub hadoop@master:/home/hadoop/id\_rsa\_01.pub</code><br>slave02上：<br> <code>scp .ssh/id\_rsa.pub hadoop@master:/home/hadoop/id\_rsa\_02.pub</code><br>这二行执行完后，回到master中，查看下 /home/hadoop目录，应该有二个新文件 id_rsa_01.pub、id_rsa_02.pub ，然后在 master上，导入这二个公钥<br> <code>cat id\_rsa\_01.pub &gt;&gt; .ssh/authorized_keys</code><br> <code>cat id\_rsa\_02.pub &gt;&gt; .ssh/authorized_keys</code><br>这样，master 这台机器上，就有所有 3台机器的公钥了。</p>
</li>
<li><p>将 master上的“ 最全”公钥，复制到其它机器<br>a) 继续保持在 master上，<br> <code>scp .ssh/authorized\_keys hadoop@slave01:/home/hadoop/.ssh/authorized\_keys</code><br> <code>scp .ssh/authorized\_keys hadoop@slave02:/home/hadoop/.ssh/authorized\_keys</code><br>b) 修改其它机器上 authorized_keys文件的权限<br>slave01以及 slave02机器上，均执行命令<br> <code>chmod 600 .ssh/authorized_keys</code></p>
</li>
<li><p>验证<br>在每个虚拟机上，均用 ssh 其它机器的 hostname 验证下，如果能正常无密码连接成功，表示 ok</p>
</li>
</ol>
<a id="more"></a>
<h2 id="改默认端口"><a href="#改默认端口" class="headerlink" title="改默认端口"></a>改默认端口</h2><p>（防火墙关闭状态）<br>    <code>cp /etc/ssh/ssh\_config   /etc/ssh/ssh\_configbak</code><br>    <code>cp /etc/ssh/sshd\_config  /etc/ssh/sshd\_configbak</code></p>
<p>修改ssh端口为：2222<br>    <code>vi /etc/ssh/sshd_config</code><br>在端口#Port 22下面增加<code>Port 2222</code><br>    <code>vi /etc/ssh/ssh_config</code><br>在端口#Port 22下面增加<code>Port 2222</code></p>
<p>重启：<br>    <code>/etc/init.d/sshd restart</code><br>    <code>service sshd restart</code></p>
<p>用2222端口可以正常连接之后，再返回去重复上面的步骤。把22端口禁用了，以后ssh就只能用2222端口连接了！增强了系统的安全性。</p>
]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> linux </tag>
            
            <tag> ssh </tag>
            
            <tag> 端口 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[python开发环境安装及restapi demo开发]]></title>
      <url>http://bigdatadecode.club/python%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E5%8F%8Arestapi%20demo%E5%BC%80%E5%8F%91.html</url>
      <content type="html"><![CDATA[<h2 id="linux下安装"><a href="#linux下安装" class="headerlink" title="linux下安装"></a>linux下安装</h2><p>linux中一般默认安装python，在命令行中输入python，查看当前版本</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ python</span><br><span class="line"></span><br><span class="line">Python 2.6.6 (r266:84292, Nov 22 2013, 12:16:22) </span><br><span class="line">[GCC 4.4.7 20120313 (Red Hat 4.4.7-4)] on linux2</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>在安装python之前先安装<code>sqlite-devel</code>，否则随后运行django时可能会报错，错误内容为<code>django.core.exceptions.ImproperlyConfigured: Error loading either pysqlite2 or sqlite3 modules (tried in that order): No module named _sqlite3</code>。运行命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install sqlite-devel</span><br></pre></td></tr></table></figure>
<p>当前版本是2.6.6，安装的版本是2.7.11</p>
<ul>
<li>下载python的二进制包 Python-2.7.11.tgz 并解压</li>
<li>进入解压后的目录中 运行 如下命令</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">make install  (权限有问题，则执行 sudo make install)</span><br></pre></td></tr></table></figure>
<p>(<code>source ~/.bashrc</code>)再次运行<code>python</code>，如果发现版本依然没有发生变化，则继续执行下面的命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo su - root</span><br><span class="line"><span class="built_in">cd</span> /usr/bin</span><br><span class="line">rm -rf python</span><br><span class="line">ln -s <span class="variable">$&#123;PYTHON_HOME&#125;</span>/python python</span><br></pre></td></tr></table></figure>
<p>此时python安装成功，但可能会导致centos的<code>yum</code>命令无法使用，提示如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ yum</span><br><span class="line">There was a problem importing one of the Python modules</span><br><span class="line">required to run yum. The error leading to this problem was:</span><br><span class="line"></span><br><span class="line">   No module named yum</span><br><span class="line"></span><br><span class="line">Please install a package <span class="built_in">which</span> provides this module, or</span><br><span class="line">verify that the module is installed correctly.</span><br><span class="line"></span><br><span class="line">It<span class="string">'s possible that the above module doesn'</span>t match the</span><br><span class="line">current version of Python, <span class="built_in">which</span> is:</span><br><span class="line">2.7.11 (default, Apr 19 2016, 14:52:39) </span><br><span class="line">[GCC 4.4.7 20120313 (Red Hat 4.4.7-4)]</span><br><span class="line"></span><br><span class="line">If you cannot solve this problem yourself, please go to </span><br><span class="line">the yum faq at:</span><br><span class="line">  http://yum.baseurl.org/wiki/Faq</span><br></pre></td></tr></table></figure>
<p>此问题是由于机器上有多个python版本，而yum依赖的版本与默认的python版本不一致造成的，修改yum，将开头的<code>#!/usr/bin/python</code>改为<code>#!/usr/bin/python2.6</code>：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">which</span> yum</span><br><span class="line">vim /usr/bin/yum</span><br></pre></td></tr></table></figure>
<h2 id="安装pip，用来安装第三方包"><a href="#安装pip，用来安装第三方包" class="headerlink" title="安装pip，用来安装第三方包"></a>安装pip，用来安装第三方包</h2><p>在安装pip之前，要先安装setuptools</p>
<ul>
<li>wget –no-check-certificate <a href="https://bootstrap.pypa.io/ez_setup.py" target="_blank" rel="noopener">https://bootstrap.pypa.io/ez_setup.py</a></li>
<li>python ez_setup.py –user  （在用户目录下安装）</li>
<li>python ez_setup.py –insecure  （需要管理员权限）<br>【如果使用 –user，安装pip时，报找不到setuptools模块，则使用–insecure安装】</li>
</ul>
<p>安装pip</p>
<ul>
<li>下载pip pip-8.1.1.tar.gz，解压并进入该目录中</li>
<li>sudo python setup.py install </li>
</ul>
<!-- sudo yum install MySQL-python -->
<h2 id="安装python的虚拟环境virtualenv"><a href="#安装python的虚拟环境virtualenv" class="headerlink" title="安装python的虚拟环境virtualenv"></a>安装python的虚拟环境virtualenv</h2><p>pip install virtualenv （root or sudo）</p>
<h2 id="在virtualenv环境中创建应用"><a href="#在virtualenv环境中创建应用" class="headerlink" title="在virtualenv环境中创建应用"></a>在virtualenv环境中创建应用</h2><p>新建个目录，用于存放python项目</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir djangorest</span><br><span class="line"><span class="built_in">cd</span> djangorest</span><br></pre></td></tr></table></figure>
<ol>
<li>创建虚拟环境，命令<code>virtualenv djangoenv</code></li>
<li>激活虚拟环境，命令<code>source djangoenv/bin/activate</code>，此时命令行显示如下</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(djangoenv) [hadoop@centos djangorest]$</span><br></pre></td></tr></table></figure>
<h2 id="rest-api-demo开发"><a href="#rest-api-demo开发" class="headerlink" title="rest api demo开发"></a>rest api demo开发</h2><p>安装第三方依赖包</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pip install django</span><br><span class="line">pip install djangorestframework</span><br><span class="line">pip install uwsgi</span><br><span class="line">pip install MySQL-python</span><br></pre></td></tr></table></figure>
<blockquote>
<p>安装pyhs2<br>    yum install gcc-c++<br>    yum install python-devel.x86_64 cyrus-sasl-devel.x86_64<br>    pip install pyhs2</p>
</blockquote>
<p>创建web application</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">django-admin.py startproject restful .   <span class="comment">#("."代表当前目录)</span></span><br><span class="line">python manage.py startapp rest</span><br></pre></td></tr></table></figure>
<p>编辑<code>rest/views.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> rest_framework.decorators <span class="keyword">import</span> api_view</span><br><span class="line"><span class="keyword">from</span> rest_framework.response <span class="keyword">import</span> Response</span><br><span class="line"><span class="keyword">from</span> rest_framework <span class="keyword">import</span> status</span><br><span class="line"><span class="keyword">from</span> django.http <span class="keyword">import</span> HttpResponse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># REST接口测试</span></span><br><span class="line"><span class="meta">@api_view(['GET', 'POST'])</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">restapitest</span><span class="params">(request)</span>:</span></span><br><span class="line">    response = HttpResponse()</span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">'POST'</span>:</span><br><span class="line">        response.write(<span class="string">"This method is post."</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br><span class="line">    <span class="keyword">elif</span> request.method == <span class="string">'GET'</span>:</span><br><span class="line">        response.write(<span class="string">"This method is get."</span>)</span><br><span class="line">        <span class="keyword">return</span> response</span><br></pre></td></tr></table></figure>
<p>创建<code>rest/urls.py</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> url</span><br><span class="line"><span class="keyword">from</span> rest_framework.urlpatterns <span class="keyword">import</span> format_suffix_patterns</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> rest_framework.routers <span class="keyword">import</span> DefaultRouter</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> views</span><br><span class="line"></span><br><span class="line">urlpatterns = [</span><br><span class="line">    url(<span class="string">r'^restapitest/$'</span>, views.restapitest, name = <span class="string">'restapitest'</span>),</span><br><span class="line">]</span><br><span class="line">urlpatterns = format_suffix_patterns(urlpatterns)</span><br></pre></td></tr></table></figure>
<p>在<code>restful/urls.py</code>中添加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> include, url</span><br><span class="line">urlpatterns = [</span><br><span class="line">    url(<span class="string">r'^admin/'</span>, admin.site.urls),</span><br><span class="line">    url(<span class="string">r'^rest/'</span>, include(<span class="string">'rest.urls'</span>)),</span><br><span class="line">]</span><br></pre></td></tr></table></figure>
<p>编译测试脚本<code>rest.test</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get</span><span class="params">(url, data)</span>:</span></span><br><span class="line">    <span class="comment">#req = urllib2.Request(url)</span></span><br><span class="line">    data = urllib.urlencode(data)</span><br><span class="line">    opener = urllib2.build_opener(urllib2.HTTPCookieProcessor())</span><br><span class="line">    <span class="comment">#response = opener.open(req + "?" + data)</span></span><br><span class="line">    response = opener.open(<span class="string">"%s?%s"</span>%(url, data))</span><br><span class="line">    <span class="keyword">print</span> data</span><br><span class="line">    <span class="keyword">return</span> response.read()</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">post</span><span class="params">(url, data)</span>:</span></span><br><span class="line">    req = urllib2.Request(url)</span><br><span class="line">    data = urllib.urlencode(data)</span><br><span class="line">    opener = urllib2.build_opener(urllib2.HTTPCookieProcessor())</span><br><span class="line">    response = opener.open(req, data)</span><br><span class="line">    <span class="keyword">print</span> data</span><br><span class="line">    <span class="keyword">return</span> response.read()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gettest</span><span class="params">()</span>:</span></span><br><span class="line">    posturl = <span class="string">"http://xxxx:8000/rest/restapitest"</span></span><br><span class="line">    data = dict(fromDate=<span class="string">"2016-02-02"</span>,toDate=<span class="string">"2016-02-24"</span>)</span><br><span class="line">    <span class="keyword">print</span> posturl</span><br><span class="line">    <span class="keyword">print</span> get(posturl, data)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">posttest</span><span class="params">()</span>:</span></span><br><span class="line">    posturl = <span class="string">"http://xxxx:8000/rest/restapitest"</span></span><br><span class="line">    data = dict(fromDate=<span class="string">"2016-02-02"</span>,toDate=<span class="string">"2016-02-04"</span>)</span><br><span class="line">    <span class="keyword">print</span> posturl</span><br><span class="line">    <span class="keyword">print</span> post(posturl, data)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#gettest()</span></span><br><span class="line">    posttest()</span><br></pre></td></tr></table></figure>
<p>uwsgi启动server (加&amp;，表示后台运行)</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uwsgi --socket xxxx:8000 --<span class="built_in">chdir</span> /xxx/djangorest/ --wsgi-file restful/wsgi.py --protocol=http --pidfile rest-uwsgi.pid</span><br></pre></td></tr></table></figure>
<p>运行测试脚本，或者从浏览器访问</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python rest.test</span><br></pre></td></tr></table></figure>
]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> pyhotn </tag>
            
            <tag> 安装 </tag>
            
            <tag> restapi </tag>
            
            <tag> django </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[将sublime text 2 添加到右键菜单中]]></title>
      <url>http://bigdatadecode.club/%E5%B0%86sublime%20text2%E6%B7%BB%E5%8A%A0%E5%88%B0%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95%E4%B8%AD.html</url>
      <content type="html"><![CDATA[<h2 id="将sublime-text2添加到右键菜单中"><a href="#将sublime-text2添加到右键菜单中" class="headerlink" title="将sublime text2添加到右键菜单中"></a>将sublime text2添加到右键菜单中</h2><p>Windows安装sublime text2，右键文件不能使用sublime text打开，右键中并无此快捷键，所以需要手动添加使用sublime text编辑的选项。</p>
<p>将Sublime Text添加到右键可以概括为一个统一的功能，就是讲应用程序的快捷键添加到鼠标右键中。</p>
<h3 id="修改注册表"><a href="#修改注册表" class="headerlink" title="修改注册表"></a>修改注册表</h3><hr>
<ol>
<li>开始-&gt;运行-&gt;regedit打开注册表编辑器。(快捷键 window+R 输入regedit 回车)</li>
<li>选择<code>HKEY_CLASSES_ROOT</code>-&gt;<code>*</code>-&gt;<code>shell</code>，然后右键选择<code>新建项</code>，命名为Edit with Sublime Text(这个值就是鼠标右键菜单中显示的名称，可以随便改)，然后在右边空白区域右键<code>新建</code>-&gt;<code>字符串值</code>，命名为<code>Icon</code>(这个不能改，这里设置的是的右键菜单中显示的图标)，值为<code>D:\Program Files\Sublime Text 2\sublime_text.exe,0</code>。</li>
<li>在<code>Edit with Sublime Text</code>下右键<code>新建</code>-&gt;<code>项</code>，命名为<code>Command</code>，然后修改右边的默认值为<code>D:\Program Files\Sublime Text 2\sublime_text.exe %1</code></li>
</ol>
<p>完成，关闭注册表就可以用右键打开文件进行编辑了。</p>
]]></content>
      
        <categories>
            
            <category> tool </category>
            
        </categories>
        
        
        <tags>
            
            <tag> sublime text </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[常用Hadoop命令]]></title>
      <url>http://bigdatadecode.club/%E5%B8%B8%E7%94%A8Hadoop%E5%91%BD%E4%BB%A4.html</url>
      <content type="html"><![CDATA[<p>记录下常用的Hadoop相关的命令，忘记了容易找</p>
<a id="more"></a>
<h2 id="HDFS命令"><a href="#HDFS命令" class="headerlink" title="HDFS命令"></a>HDFS命令</h2><ul>
<li>某个文件的blocks信息</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fsck /user/xx -files -blocks -locations</span><br></pre></td></tr></table></figure>
<ul>
<li>改变一个文件或者目录的副本因子</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -setrep -R 3 /user/xx</span><br></pre></td></tr></table></figure>
<ul>
<li><p>查看app的log<br><code>yarn logs -applicationId application_1452250357031_0175</code></p>
</li>
<li><p>set datanode 日志级别<br><code>hadoop daemonlog  -setlevel namenodeip:50070 datanode DEBUG</code><br>或者 在hadoop-env.sh中添加<br><code>export HADOOP_ROOT_LOGGER=DEBUG,RFA</code></p>
</li>
<li><p>查看sequence文件<br><code>hadoop dfs -text sequenceFile</code></p>
</li>
<li><p>查看压缩文件<br>lzo文件(先按照lzop命令) <code>hadoop fs -cat /user/2017-03-06/part-r-00255.lzo | lzop -dc | head -1</code><br>gz压缩 <code>hadoop fs -cat /tmp/temp.txt.gz | gzip -d​</code>  或者 <code>hadoop fs -cat /tmp/temp.txt.gz | zcat</code>​  </p>
</li>
<li>lzo建立索引(方便切分多个split，会在当前hdfs目录下创建一个.index文件)<br><code>hadoop jar lib/hadoop-lzo-0.4.15.jar com.hadoop.compression.lzo.DistributedLzoIndexer /user/news_74_8000_201705091820.lzo</code></li>
</ul>
<h2 id="kafka-amp-zk命令"><a href="#kafka-amp-zk命令" class="headerlink" title="kafka&amp;zk命令"></a>kafka&amp;zk命令</h2><ul>
<li><p>启动kafka<br><code>nohup bin/kafka-server-start.sh config/server.properties &amp;</code><br><code>bin/kafka-server-start.sh -daemon config/server.properties</code></p>
</li>
<li><p>停止Kafka<br><code>bin/bin/kafka-server-stop.sh</code></p>
</li>
<li><p>列出kafka的topic<br><code>bin/kafka-topics.sh --list --zookeeper 127.0.0.1:2181,10.xx:2181,10.xx:2181</code></p>
</li>
<li><p>创建topic<br><code>bin/kafka-topics.sh --create --zookeeper 127.0.0.1:2181,10.xx:2181,10.xx:2181 --topic test --partitions 3 --replication-factor 2</code></p>
</li>
<li><p>增加topic的partitions<br><code>bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --alter --topic three_replica --partitions 5</code> </p>
</li>
<li><p>topic的描述信息<br><code>bin/kafka-topics.sh --describe --zookeeper 10.xx:2181,10.xx:2181,10.xx:2181 --topic test</code></p>
</li>
<li><p>命令行生产消息<br><code>bin/kafka-console-producer.sh --broker-list 127.0.0.1:9092,10.xx:9092,10.xx:9092 --topic test</code></p>
</li>
<li><p>命令行消费消息<br><code>bin/kafka-console-consumer.sh --zookeeper 127.0.0.1:2181,10.xx:2181,10.1xx:2181 --topic test --from-beginning</code></p>
</li>
<li><p>打开zk客户端<br><code>bin/zkCli.sh -server xxx:2181,xx:2181</code></p>
</li>
<li><p>删除zk上节点</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">delete /path  //删除指定节点，只能删除非空节点</span><br><span class="line">rmr /path    //删除path节点及子节点</span><br></pre></td></tr></table></figure>
<ul>
<li>查看zk目录</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls /      //使用ls查看当前zookeeper中所包含的内容</span><br><span class="line">ls2 /     //查看当前节点数据并能看到更新次数等数据</span><br></pre></td></tr></table></figure>
<ul>
<li><p>查看zk中哪个是leader及follower<br><code>for i in {55..57};do echo stat | nc 10.102.143.$i 2181;done</code></p>
</li>
<li><p>zk</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> dump| nc 127.0.0.1 2181  //列出未经处理的会话和临时节点</span><br><span class="line"><span class="built_in">echo</span> conf | nc 127.0.0.1 2181  //输出相关服务配置的详细信息</span><br></pre></td></tr></table></figure>
<h2 id="redis命令"><a href="#redis命令" class="headerlink" title="redis命令"></a>redis命令</h2><ul>
<li>redis-cli 进入</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis-cli  <span class="comment"># localhost</span></span><br><span class="line">redis-cli -h hostname -p port -a password</span><br></pre></td></tr></table></figure>
<p>进入之后使用<code>ping</code>命令测试下链接是否成功，返回<code>PONG</code>表示链接成功。</p>
<ul>
<li>查看redis中的key</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ keys * <span class="comment"># redis 中所有的key</span></span><br><span class="line">$ keys h*  <span class="comment"># redis 中h开头的所有key</span></span><br><span class="line">$ randomkey  <span class="comment"># 随机显示一个key</span></span><br></pre></td></tr></table></figure>
<p>在client中使用上述命令时，有可能会报<code>Error: Server closed the connection</code>，导致命令无法使用，但其它命令正常，如lrange。</p>
<ul>
<li>查看key的数据类型</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">type</span> xx:xx  <span class="comment"># xx:xx 为key</span></span><br></pre></td></tr></table></figure>
<ul>
<li>使用scan查看匹配key</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SCAN cursor [MATCH pattern] [COUNT count] </span></span><br><span class="line">scan 107102208 MATCH net:20170830:V* COUNT 1000</span><br><span class="line"><span class="comment">#注意：返回的游标不一定是递增的，可能后一次返回的游标比前一次的小。</span></span><br></pre></td></tr></table></figure>
<ul>
<li>查看list中key对应的值</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ lrange top:article 1 2   <span class="comment"># 显示key为top:article的list中start索引为1到end索引为2的数据</span></span><br><span class="line">1) <span class="string">"&#123;\"id\":\"CS25FCED05148UNS\",\"value\":[3873,11,64096,0,0,0]&#125;"</span></span><br><span class="line">2) <span class="string">"&#123;\"id\":\"CS2EK6TU0001875P\",\"value\":[3850,10,94762,0,0,0]&#125;"</span></span><br></pre></td></tr></table></figure>
<ul>
<li>查看hash所有的key/value</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hgetall xx:xx <span class="comment"># xx:xx 为key</span></span><br><span class="line">1) key1        <span class="comment"># hash中的key</span></span><br><span class="line">2) value1      <span class="comment"># hash中的value</span></span><br></pre></td></tr></table></figure>
<!-- redis-cli -h 10.160.249.83 -p 6379 keys net:20170830:0503* | head -10 -->
<h3 id="redis-cluster命令"><a href="#redis-cluster命令" class="headerlink" title="redis cluster命令"></a>redis cluster命令</h3><ul>
<li>连接客户端命令<br><code>redis-cli -h ip -p port -c</code></li>
</ul>
]]></content>
      
        <categories>
            
            <category> Hadoop </category>
            
        </categories>
        
        
        <tags>
            
            <tag> BigData </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> read </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Java设计模式之Builder模式]]></title>
      <url>http://bigdatadecode.club/Builder%20%E6%A8%A1%E5%BC%8F.html</url>
      <content type="html"><![CDATA[<p>在这里我暂时这样理解，就是把复杂对象的构建过程和结果进行分离        也就是解耦</p>
<h2 id="Builder模式概念"><a href="#Builder模式概念" class="headerlink" title="Builder模式概念"></a>Builder模式概念</h2><p>The builder pattern is an object creation software design pattern. Unlike the abstract factory pattern and the factory method pattern whose intention is to enable polymorphism, the intention of the builder pattern is to find a solution to the telescoping constructor anti-pattern[citation needed]. The telescoping constructor anti-pattern occurs when the increase of object constructor parameter combination leads to an exponential list of constructors. Instead of using numerous constructors, the builder pattern uses another object, a builder, that receives each initialization parameter step by step and then returns the resulting constructed object at once. （代替构造函数）</p>
<p>The builder pattern has another benefit. It can be used for objects that contain flat data (html code, SQL query, X.509 certificate…), that is to say, data that can’t be easily edited. This type of data cannot be edited step by step and must be edited at once. The best way to construct such an object is to use a builder class.（创建不可变对象）</p>
<p>定义<br>原文 – The intent of the Builder design pattern is to separate the construction of a complex object from its representation. By doing so the same construction process can create different representations.   （from wikipedia）<br>译文 – 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。</p>
<p>定义有点抽象，先来看个Builder的一个比较直观的使用场景 —— 使用Builder代替具有多个参数（4个以上）的构造函数</p>
<a id="more"></a>
<h3 id="场景简介"><a href="#场景简介" class="headerlink" title="场景简介"></a>场景简介</h3><blockquote>
<p>如一个类表示包装食品外面显示的营养成分标签，标签中有些域是必须的，不过有些也是可选域。大多数产品在某几个可选域中都有非0值。对于这样的类，一般都使用重叠构造器（telescoping sconstructor）模式。这种模式将会出现过个构造函数，创建实例的时候选择合适的构造函数。例如如下代码：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Telescoping constructor pattern - does not scale well!</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;  <span class="comment">//(ml) required</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;     <span class="comment">//(per container) required</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> calories;     <span class="comment">//  optional</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> fat;              <span class="comment">//  optional</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sodium;           <span class="comment">//  optional</span></span><br><span class="line">    privatefinalintcarbohydrate;        <span class="comment">//  optional</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> calories)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, calories, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> calories, <span class="keyword">int</span> fat)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, calories, fat, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> calories, <span class="keyword">int</span> fat, <span class="keyword">int</span> sodium)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, calories, fat, sodium, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings, <span class="keyword">int</span> calories, <span class="keyword">int</span> fat, <span class="keyword">int</span> sodium, <span class="keyword">int</span> carbohydrate)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.servingSize  = servingSize;</span><br><span class="line">        <span class="keyword">this</span>.servings = servings;</span><br><span class="line">        <span class="keyword">this</span>.calories = calories;</span><br><span class="line">        <span class="keyword">this</span>.fat = fat;</span><br><span class="line">        <span class="keyword">this</span>.sodium = sodium;</span><br><span class="line">        <span class="keyword">this</span>.carbohydrate = carbohydrate;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用的时候使用NutritionFacts nut = new NutritionFacts(xx, xx, xx, xx, 0, xx); 这样的话可能就存在你不想给sodium赋值，但是你又得给carbohydrate赋值，就导致你必须给sodium传入0。如果参数数目更多的话，这种情况更糟糕，难以控制，而且当你传参的顺序弄错时，并不会提示错误，但运行可能会报错，对别人的可读性也不高。</p>
<h2 id="JavaBeans模式"><a href="#JavaBeans模式" class="headerlink" title="JavaBeans模式"></a>JavaBeans模式</h2><p>先来看第一种解决方案 —— JavaBeans模式</p>
<p>JavaBeans模式是调用一个无参构造函数创建对象，然后调用属性的setter方法对每个属性赋值。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// JavaBeans Pattern - allows inconsistency, mandates mutability</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">   <span class="comment">// Parameters initialized to default values (if any)</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> servingSize = -<span class="number">1</span>; <span class="comment">// Required; no default value</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> servings=-<span class="number">1</span>;<span class="comment">//""""</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> calories=<span class="number">0</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> fat=<span class="number">0</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> sodium=<span class="number">0</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> carbohydrate = <span class="number">0</span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">   <span class="comment">// Setters  汉子</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setServingSize</span><span class="params">(<span class="keyword">int</span> val)</span>  </span>&#123; servingSize = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setServings</span><span class="params">(<span class="keyword">int</span> val)</span>    </span>&#123; servings = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCalories</span><span class="params">(<span class="keyword">int</span> val)</span>    </span>&#123; calories = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFat</span><span class="params">(<span class="keyword">int</span> val)</span>         </span>&#123; fat = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSodium</span><span class="params">(<span class="keyword">int</span> val)</span>      </span>&#123; sodium = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCarbohydrate</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123; carbohydrate = val; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个代码比使用重叠构造函数的代码简单了点，阅读也较为容易，但是调用方法为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NutritionFacts cocaCola = <span class="keyword">new</span> NutritionFacts();</span><br><span class="line">cocaCola.setServingSize(<span class="number">240</span>);</span><br><span class="line">cocaCola.setServings(<span class="number">8</span>);</span><br><span class="line">cocaCola.setCalories(<span class="number">100</span>);</span><br><span class="line">cocaCola.setSodium(<span class="number">35</span>);</span><br><span class="line">cocaCola.setCarbohydrate(<span class="number">27</span>);</span><br></pre></td></tr></table></figure>
<p>这种模式弥补了重叠构造函数的不足，使代码简单，可阅读；但是在调用时要先new一个对象，而无法保证我们在使用这个对象之前已经对相应的属性进行赋值。</p>
<p>JavaBeans模式的缺点是：使对象的构建过程分到几个调用中，在构造过程中可能处于不一致的状态。类无法仅仅通过检验构造器参数的有效性来保证一致性。试图使用处于不一致状态的对象，将会导致失败。这种失败与包含错误的代码大相劲庭，因为其调试起来十分困难。JavaBeans不能创建不可变的实例，因为需要你付出额外的代价来保证这个类是线程安全的。</p>
<h2 id="Builder模式"><a href="#Builder模式" class="headerlink" title="Builder模式"></a>Builder模式</h2><p>第二种解决方案 —— Builder模式</p>
<p>既能保证向重叠构造器模式那样的安全性，也能保证向JavaBeans模式那么好的可读性。这就是Builde模式的一种形式。不直接生成想要的对象，而是让客户端利用所有必要的参数调用构造器或者静态工厂，得到一个builder对象。然后客户端在builder上调用类似setter的方法来设置每个相关的可选参数。最后客户端调用无参的build方法来生成不可变的对象。这个builder是它构造的类的静态的成员类。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Builder Pattern</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> calories;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> fat;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sodium;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> carbohydrate;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> </span>&#123;</span><br><span class="line">	    <span class="comment">// Required parameters</span></span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">	    <span class="comment">// Optional parameters - initialized to default values</span></span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> calories = <span class="number">0</span>;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> fat = <span class="number">0</span>;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> carbohydrate = <span class="number">0</span>;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> sodium = <span class="number">0</span>;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> <span class="title">Builder</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings)</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">this</span>.servingSize = servingSize;</span><br><span class="line">	        <span class="keyword">this</span>.servings = servings;</span><br><span class="line">	    &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">calories</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; calories = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">fat</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; fat = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">carbohydrate</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; carbohydrate = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">sodium</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; sodium = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> NutritionFacts <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">return</span> <span class="keyword">new</span> NutritionFacts(<span class="keyword">this</span>);</span><br><span class="line">	    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">NutritionFacts</span><span class="params">(Builder builder)</span> </span>&#123;</span><br><span class="line">        servingSize = builder.servingSize;</span><br><span class="line">        servings = builder.servings;</span><br><span class="line">        calories = builder.calories;</span><br><span class="line">        fat = builder.fat;</span><br><span class="line">        sodium = builder.sodium;</span><br><span class="line">        carbohydrate = builder.carbohydrate;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用时是这样的：<br><code>NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8).calories(100).sodium(35).carbohydrate(27).build();</code></p>
<p>就像构造器那样，builder 可以强加给它的参数变量（这个强加的参数变量可以作为创建对象的必须参数），build 方法实例化实体类，实例化前，可以对参数进行检查，如果不满足条件的，应该抛出 IllegalStateException，或者其他自定义异常。<br>另外一个小优点是 builder 可以有多个可变参数。构造器，像方法一样，可能只有一个可变参数。因为 builder 用不同的方法设置参数，只要你喜欢，他们可以有很多可变参数。</p>
<p>代码中NutritionFacts类中属性都是final类型的，这是必须的呢还是只是为了让对象实例一旦创建，其状态就不能在改变。而JavaBeans却无法创建这种不可变对象。</p>
<p>与JavaBeans的区别其实是在于真正构造对象的时间点上。其实Builder并没有提前把对象构造出来然后再一个个地对参数进行设置，而是先设定值，再在最后的build()方法中构建出对象。这样在一些参数存在依赖关系的时候，可以很好地解决依赖的问题。当然，对于参数的传递也不一定要按照上面写的方式，Setter其实也是可以的，其思想不在于模拟按名字传递参数，在于后面的build()。</p>
<p>从上面的例子中可以看出，Builder模式多数是用于对象比较复杂，可以逐步去构建的时候，其核心在于将类的构建逻辑转移到类的实例化外部。其经典应用是从一段文本中构建对象，因为文本的读入是以流的形式，那么一开始的时候可能没有办法创建完整的目标对象，这时候可以使用构建者模式来进行构建。但是在注重性能的环境下，每次创建实例都必须先创建Builder构造器也会是一笔开销，而且代码也有点冗长。总的来说如果类有多个属性需要多个构造函数，Builder模式还是一个不错的选择。</p>
<h2 id="Builder部件解析"><a href="#Builder部件解析" class="headerlink" title="Builder部件解析"></a>Builder部件解析</h2><p>再回到Builder的定义，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。在这里我暂时这样理解，就是把复杂对象的构建过程和结果进行分离。Builder的uml图为：<br><img src="/blogimgs/Builder模式/builderuml.png" alt="Builder uml图" title="Builder uml图"><br>有点类似工厂模式，其中</p>
<ul>
<li>Builder：生成器接口，定义创建一个Product对象所需要的各个部件的操作。</li>
<li>ConcreteBuilder：具体的生成器实现，实现各个部件的创建，并负责组装Product对象的各个部件，同时还提供一个让用户获取组装完成后的产品对象的方法。</li>
<li>Director：指导者，也被称导向者，主要用来使用Builder接口，以一个统一的过程来构建所需要的Product对象。</li>
<li>Product：产品，表示被生成器构建的复杂对象，包含多个部件。</li>
</ul>
<p>看了上面的uml图和各个部件的解释，可能就会产生疑问了，上面的使用Builder代替构造函数的场景中使用的角色和UML中的角色不对称了，不要着急，下面进行解释：</p>
<p>上面的使用场景比较明确，就是创建某个复制对象，可以进行适当的简化。其中Builder模式只是用来创建某个对象，则就没有必要定义Builder的接口，直接提供一个具体的ConcreteBuilder就行；如果只创建一个复杂的对象，不可能会有很多种不同的选择和步骤，导演类Director就可以干掉了，将其功能与Client的功能合并，使Client具备Director的功能，来指导构建器来构建需要的复杂对象。</p>
<h2 id="Builder模式的功能"><a href="#Builder模式的功能" class="headerlink" title="Builder模式的功能"></a>Builder模式的功能</h2><p>生成器模式的主要功能是构建复杂的产品，而且是细化的，分步骤的构建产品，也就是生成器模式重在一步一步解决构造复杂对象的问题。如果仅仅这么认知生成器模式的功能是不够的。<br>更为重要的是，这个构建的过程是统一的、固定不变的，变化的部分放到生成器部分了，只要配置不同的生成器，那么同样的构建过程，就能构建出不同的产品来。 这是对定义（将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示 ）更进一步的解释。</p>
<p>正常的Builder模式的代码示例如下：<br>1、生成器接口定义的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 生成器接口，定义创建一个产品对象所需的各个部件的操作 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 示意方法，构建某个部件 </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildPart</span><span class="params">()</span></span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、具体生成器实现的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 具体的生成器实现对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteBuilder</span> <span class="keyword">implements</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">      </span><br><span class="line">    <span class="keyword">private</span> Product resultProduct;  </span><br><span class="line">      </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 获取生成器最终构建的产品对象 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> Product <span class="title">getResultProduct</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> resultProduct;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildPart</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="comment">//构建某个部件的功能处理  </span></span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>3、相应的产品对象接口的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 被构建的产品对象的接口 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Product</span> </span>&#123;  </span><br><span class="line">    <span class="comment">//定义产品的操作  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4、最后是指导者的实现示意，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 指导者，指导使用生成器的接口来构建产品对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Director</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 持有当前需要使用的生成器对象 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> Builder builder;  </span><br><span class="line">   </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构造方法，传人生成器对象 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> builder </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">Director</span><span class="params">(Builder builder)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.builder = builder;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 示意方法，指导生成器构建最终的产品对象 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">construct</span><span class="params">()</span></span>&#123;  </span><br><span class="line">         <span class="comment">//通过使用生成器接口来构建最终的产品对象  </span></span><br><span class="line">         builder.buildPart();  </span><br><span class="line">     &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="应用场景–-导出数据的应用框架"><a href="#应用场景–-导出数据的应用框架" class="headerlink" title="应用场景– 导出数据的应用框架"></a>应用场景– 导出数据的应用框架</h2><p>在讨论工厂方法模式的时候，提供了一个导出数据的应用框架。<br>对于导出数据的应用框架，通常在导出数据上，会有一些约束的方式，比如导出成文本格式、数据库备份形式、Excel格式、Xml格式等。<br>在工厂方法模式章节里面，讨论并使用工厂方法模式来解决了如何选择具体导出方式的问题，并没有涉及到每种方式具体如何实现。<br>换句话说，在讨论工厂方法模式的时候，并没有讨论如何实现导出成文本、Xml等具体格式，本章就来讨论这个问题。<br>对于导出数据的应用框架，通常对于具体的导出内容和格式是有要求的，加入现在有如下要求，简单描述一下：</p>
<ul>
<li>导出的文件，不管是什么格式，都分成3个部分，分别是文件头、文件体、文件尾。</li>
<li>在文件头部分，需要描述如下信息：分公司或者门市编号、导出数据的日期。</li>
<li>在文件体部分，需要描述如下信息：表名称，然后分条描述数据。</li>
<li>在文件尾部分，需要描述如下信息：输出人。</li>
</ul>
<p>1、下面将描述文件各个部分的数据对象定义出来<br>描述输出到文件头的内容的对象，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 描述输出到文件头的内容的对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportHeaderModel</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 分公司或者门市编号 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String depId;  </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 导出数据的日期 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String exportDate;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getDepId</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> depId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDepId</span><span class="params">(String depId)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.depId = depId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getExportDate</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> exportDate;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setExportDate</span><span class="params">(String exportDate)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.exportDate = exportDate;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>描述输出数据的对象，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 描述输出数据的对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportDataModel</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 产品编号 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String productId;  </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 销售价格 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">double</span> price;  </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 销售数量 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">double</span> amount;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getProductId</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> productId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProductId</span><span class="params">(String productId)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.productId = productId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getPrice</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> price;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrice</span><span class="params">(<span class="keyword">double</span> price)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.price = price;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getAmount</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> amount;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAmount</span><span class="params">(<span class="keyword">double</span> amount)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.amount = amount;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>描述输出到文件尾的内容的对象，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 描述输出到文件尾的内容的对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportFooterModel</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 输出人 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String exportUser;  </span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getExportUser</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> exportUser;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setExportUser</span><span class="params">(String exportUser)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.exportUser = exportUser;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>2、定义Builder接口，主要是把导出各种格式文件的处理过程的步骤定义出来，每个步骤负责构建最终导出文件的一部分。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 生成器接口，定义创建一个输出文件对象所需的各个部件的操作 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 构建输出文件的Header部分 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> ehm </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildHeader</span><span class="params">(ExportHeaderModel ehm)</span></span>;  </span><br><span class="line">       </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构建输出文件的Body部分 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> mapData </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildBody</span><span class="params">(Map&lt;String,List&lt;ExportDataModel&gt;&gt; mapData)</span></span>;  </span><br><span class="line">       </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构建输出文件的Footer部分 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> efm </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildFooter</span><span class="params">(ExportFooterModel efm)</span></span>;  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>3、具体的生成器实现。<br>导出到文本文件的的生成器实现。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 实现导出文件到文本文件的生成器对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TxtBuilder</span> <span class="keyword">implements</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 用来记录构建的文件的内容，相当于产品 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> StringBuffer buffer = <span class="keyword">new</span> StringBuffer();  </span><br><span class="line">       </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildHeader</span><span class="params">(ExportHeaderModel ehm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(ehm.getDepId()+<span class="string">","</span>+ehm.getExportDate()+<span class="string">"\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildBody</span><span class="params">(Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">for</span>(String tablName : mapData.keySet())&#123;  </span><br><span class="line">               </span><br><span class="line">             <span class="comment">//先拼接表名  </span></span><br><span class="line">             buffer.append(tablName+<span class="string">"\n"</span>);  </span><br><span class="line">             <span class="comment">//然后循环拼接具体数据  </span></span><br><span class="line">             <span class="keyword">for</span>(ExportDataModel edm : mapData.get(tablName))&#123;  </span><br><span class="line">                 buffer.append(edm.getProductId()+<span class="string">","</span>+edm.getPrice()+<span class="string">","</span>+edm.getAmount()+<span class="string">"\n"</span>)</span><br><span class="line">             &#125;  </span><br><span class="line">         &#125;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildFooter</span><span class="params">(ExportFooterModel efm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(efm.getExportUser());  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> StringBuffer <span class="title">getResult</span><span class="params">()</span></span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> buffer;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>导出到Xml文件的的生成器实现。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 实现导出文件到Xml文件的生成器对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">XmlBuilder</span> <span class="keyword">implements</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 用来记录构建的文件的内容，相当于产品 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> StringBuffer buffer = <span class="keyword">new</span> StringBuffer();  </span><br><span class="line">       </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildHeader</span><span class="params">(ExportHeaderModel ehm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(<span class="string">"&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"&lt;Report&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;Header&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t\t&lt;DepId&gt;"</span>+ehm.getDepId()+<span class="string">"&lt;/DepId&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t\t&lt;ExportDate&gt;"</span>+ehm.getExportDate()+<span class="string">"&lt;/ExportDate&gt;\n"</span>);  </span><br><span class="line">           </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;/Header&gt;\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildBody</span><span class="params">(Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData)</span> </span>&#123;  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;Body&gt;\n"</span>);  </span><br><span class="line">         <span class="keyword">for</span>(String tablName : mapData.keySet())&#123;  </span><br><span class="line">             <span class="comment">//先拼接表名  </span></span><br><span class="line">             buffer.append(<span class="string">"\t\t&lt;Datas TableName=\""</span>+tablName+<span class="string">"\"&gt;\n"</span>);  </span><br><span class="line">             <span class="comment">//然后循环拼接具体数据  </span></span><br><span class="line">             <span class="keyword">for</span>(ExportDataModel edm : mapData.get(tablName))&#123;  </span><br><span class="line">                   </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t&lt;Data&gt;\n"</span>);  </span><br><span class="line">                   </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t\t&lt;ProductId&gt;"</span>+edm.getProductId()+<span class="string">"&lt;/ProductId&gt;\n"</span>);  </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t\t&lt;Price&gt;"</span>+edm.getPrice()+<span class="string">"&lt;/Price&gt;\n"</span>);  </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t\t&lt;Amount&gt;"</span>+edm.getAmount()+<span class="string">"&lt;/Amount&gt;\n"</span>);  </span><br><span class="line">                   </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t&lt;/Data&gt;\n"</span>);  </span><br><span class="line">             &#125;  </span><br><span class="line">               </span><br><span class="line">             buffer.append(<span class="string">"\t\t&lt;/Datas&gt;\n"</span>);  </span><br><span class="line">         &#125;  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;/Body&gt;\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildFooter</span><span class="params">(ExportFooterModel efm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;Footer&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t\t&lt;ExportUser&gt;"</span>+efm.getExportUser()+<span class="string">"&lt;/ExportUser&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;/Footer&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"&lt;/Report&gt;\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> StringBuffer <span class="title">getResult</span><span class="params">()</span></span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> buffer;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>4、指导者。有了具体的生成器实现后，需要由指导者来指导它进行具体的产品构建。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 指导者，指导使用生成器的接口来构建输出的文件对象 </span></span><br><span class="line"><span class="comment"> *  </span></span><br><span class="line"><span class="comment"> *  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Director</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 持有当前需要的使用的生成器对象 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> Builder builder;  </span><br><span class="line">   </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构造方法，传入生成器对象 </span></span><br><span class="line"><span class="comment">      *  </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> builder </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">Director</span><span class="params">(Builder builder)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.builder = builder;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">construct</span><span class="params">(ExportHeaderModel ehm,  </span></span></span><br><span class="line"><span class="function"><span class="params">             Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData, ExportFooterModel efm)</span> </span>&#123;  </span><br><span class="line">   </span><br><span class="line">         <span class="comment">//1.先构建Header  </span></span><br><span class="line">         builder.buildHeader(ehm);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//2.然后构建Body  </span></span><br><span class="line">         builder.buildBody(mapData);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//3.再构建Footer  </span></span><br><span class="line">         builder.buildFooter(efm);  </span><br><span class="line">     &#125;  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>5、客户端测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line">          </span><br><span class="line">        <span class="comment">//准备测试数据  </span></span><br><span class="line">        ExportHeaderModel ehm = <span class="keyword">new</span> ExportHeaderModel();  </span><br><span class="line">         ehm.setDepId(<span class="string">"一分公司"</span>);  </span><br><span class="line">         ehm.setExportDate(<span class="string">"2010-05-18"</span>);  </span><br><span class="line">           </span><br><span class="line">         Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData = <span class="keyword">new</span> HashMap&lt;String, List&lt;ExportDataModel&gt;&gt;  </span><br><span class="line">         List&lt;ExportDataModel&gt; col = <span class="keyword">new</span> ArrayList&lt;ExportDataModel&gt;();  </span><br><span class="line">           </span><br><span class="line">         ExportDataModel edm1 = <span class="keyword">new</span> ExportDataModel();  </span><br><span class="line">         edm1.setProductId(<span class="string">"产品001号"</span>);  </span><br><span class="line">         edm1.setPrice(<span class="number">100</span>);  </span><br><span class="line">         edm1.setAmount(<span class="number">80</span>);  </span><br><span class="line">           </span><br><span class="line">         ExportDataModel edm2 = <span class="keyword">new</span> ExportDataModel();  </span><br><span class="line">         edm2.setProductId(<span class="string">"产品002号"</span>);  </span><br><span class="line">         edm2.setPrice(<span class="number">120</span>);  </span><br><span class="line">         edm2.setAmount(<span class="number">280</span>);  </span><br><span class="line">           </span><br><span class="line">         ExportDataModel edm3 = <span class="keyword">new</span> ExportDataModel();  </span><br><span class="line">         edm3.setProductId(<span class="string">"产品003号"</span>);  </span><br><span class="line">         edm3.setPrice(<span class="number">320</span>);  </span><br><span class="line">         edm3.setAmount(<span class="number">380</span>);  </span><br><span class="line">           </span><br><span class="line">         col.add(edm1);  </span><br><span class="line">         col.add(edm2);  </span><br><span class="line">         col.add(edm3);  </span><br><span class="line">           </span><br><span class="line">         mapData.put(<span class="string">"销售记录表"</span>, col);  </span><br><span class="line">           </span><br><span class="line">         ExportFooterModel efm = <span class="keyword">new</span> ExportFooterModel();  </span><br><span class="line">         efm.setExportUser(<span class="string">"张三"</span>);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//测试输出到文本文件  </span></span><br><span class="line">         TxtBuilder txtBuilder = <span class="keyword">new</span> TxtBuilder();  </span><br><span class="line">         <span class="comment">//创建指导者对象  </span></span><br><span class="line">         Director director = <span class="keyword">new</span> Director(txtBuilder);  </span><br><span class="line">         director.construct(ehm, mapData, efm);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//把要输出的内容输出到控制台看看  </span></span><br><span class="line">         System.out.println(<span class="string">"输出到文本文件的内容:"</span>+txtBuilder.getResult().toString());  </span><br><span class="line">           </span><br><span class="line">         XmlBuilder xmlBuilder = <span class="keyword">new</span> XmlBuilder();  </span><br><span class="line">         Director director2 = <span class="keyword">new</span> Director(xmlBuilder);  </span><br><span class="line">         director2.construct(ehm, mapData, efm);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//把要输出的内容输出到控制台看看  </span></span><br><span class="line">         System.out.println(<span class="string">"输出到Xml文件的内容:"</span>+xmlBuilder.getResult().toString());  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="生成器模式的功能"><a href="#生成器模式的功能" class="headerlink" title="生成器模式的功能"></a>生成器模式的功能</h2><p>生成器模式的主要功能是构建复杂的产品，而且是细化的，分步骤的构建产品，也就是生成器模式重在一步一步解决构造复杂对象的问题。如果仅仅这么认知生成器模式的功能是不够的。<br>更为重要的是，这个构建的过程是统一的、固定不变的，变化的部分放到生成器部分了，只要配置不同的生成器，那么同样的构建过程，就能构建出不同的产品来。</p>
<p>##参考<br><a href="http://blog.csdn.net/top_code/article/details/8469297" target="_blank" rel="noopener">http://blog.csdn.net/top_code/article/details/8469297</a><br><a href="https://en.wikipedia.org/wiki/Builder_pattern" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Builder_pattern</a></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> 设计模式 </tag>
            
            <tag> Builder </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Builder 模式]]></title>
      <url>http://bigdatadecode.club/test.html</url>
      <content type="html"><![CDATA[<p>在这里我暂时这样理解，就是把复杂对象的构建过程和结果进行分离        也就是解耦</p>
<h2 id="Builder模式概念"><a href="#Builder模式概念" class="headerlink" title="Builder模式概念"></a>Builder模式概念</h2><p>The builder pattern is an object creation software design pattern. Unlike the abstract factory pattern and the factory method pattern whose intention is to enable polymorphism, the intention of the builder pattern is to find a solution to the telescoping constructor anti-pattern[citation needed]. The telescoping constructor anti-pattern occurs when the increase of object constructor parameter combination leads to an exponential list of constructors. Instead of using numerous constructors, the builder pattern uses another object, a builder, that receives each initialization parameter step by step and then returns the resulting constructed object at once. （代替构造函数）</p>
<p>The builder pattern has another benefit. It can be used for objects that contain flat data (html code, SQL query, X.509 certificate…), that is to say, data that can’t be easily edited. This type of data cannot be edited step by step and must be edited at once. The best way to construct such an object is to use a builder class.（创建不可变对象）</p>
<p>定义<br>原文 – The intent of the Builder design pattern is to separate the construction of a complex object from its representation. By doing so the same construction process can create different representations.   （from wikipedia）<br>译文 – 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。</p>
<p>定义有点抽象，先来看个Builder的一个比较直观的使用场景 —— 使用Builder代替具有多个参数（4个以上）的构造函数</p>
<h3 id="场景简介"><a href="#场景简介" class="headerlink" title="场景简介"></a>场景简介</h3><blockquote>
<p>如一个类表示包装食品外面显示的营养成分标签，标签中有些域是必须的，不过有些也是可选域。大多数产品在某几个可选域中都有非0值。对于这样的类，一般都使用重叠构造器（telescoping sconstructor）模式。这种模式将会出现过个构造函数，创建实例的时候选择合适的构造函数。例如如下代码：</p>
</blockquote>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Telescoping constructor pattern - does not scale well!</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;  <span class="comment">//(ml) required</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;     <span class="comment">//(per container) required</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> calories;     <span class="comment">//  optional</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> fat;              <span class="comment">//  optional</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sodium;           <span class="comment">//  optional</span></span><br><span class="line">    privatefinalintcarbohydrate;        <span class="comment">//  optional</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> calories)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, calories, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> calories, <span class="keyword">int</span> fat)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, calories, fat, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings,</span></span></span><br><span class="line"><span class="function"><span class="params">        <span class="keyword">int</span> calories, <span class="keyword">int</span> fat, <span class="keyword">int</span> sodium)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(servingSize, servings, calories, fat, sodium, <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings, <span class="keyword">int</span> calories, <span class="keyword">int</span> fat, <span class="keyword">int</span> sodium, <span class="keyword">int</span> carbohydrate)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.servingSize  = servingSize;</span><br><span class="line">        <span class="keyword">this</span>.servings = servings;</span><br><span class="line">        <span class="keyword">this</span>.calories = calories;</span><br><span class="line">        <span class="keyword">this</span>.fat = fat;</span><br><span class="line">        <span class="keyword">this</span>.sodium = sodium;</span><br><span class="line">        <span class="keyword">this</span>.carbohydrate = carbohydrate;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用的时候使用NutritionFacts nut = new NutritionFacts(xx, xx, xx, xx, 0, xx); 这样的话可能就存在你不想给sodium赋值，但是你又得给carbohydrate赋值，就导致你必须给sodium传入0。如果参数数目更多的话，这种情况更糟糕，难以控制，而且当你传参的顺序弄错时，并不会提示错误，但运行可能会报错，对别人的可读性也不高。</p>
<h2 id="JavaBeans模式"><a href="#JavaBeans模式" class="headerlink" title="JavaBeans模式"></a>JavaBeans模式</h2><p>先来看第一种解决方案 —— JavaBeans模式</p>
<p>JavaBeans模式是调用一个无参构造函数创建对象，然后调用属性的setter方法对每个属性赋值。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// JavaBeans Pattern - allows inconsistency, mandates mutability</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">   <span class="comment">// Parameters initialized to default values (if any)</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> servingSize = -<span class="number">1</span>; <span class="comment">// Required; no default value</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> servings=-<span class="number">1</span>;<span class="comment">//""""</span></span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> calories=<span class="number">0</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> fat=<span class="number">0</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> sodium=<span class="number">0</span>;</span><br><span class="line">   <span class="keyword">private</span> <span class="keyword">int</span> carbohydrate = <span class="number">0</span>;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="title">NutritionFacts</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">   <span class="comment">// Setters  汉子</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setServingSize</span><span class="params">(<span class="keyword">int</span> val)</span>  </span>&#123; servingSize = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setServings</span><span class="params">(<span class="keyword">int</span> val)</span>    </span>&#123; servings = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCalories</span><span class="params">(<span class="keyword">int</span> val)</span>    </span>&#123; calories = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setFat</span><span class="params">(<span class="keyword">int</span> val)</span>         </span>&#123; fat = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSodium</span><span class="params">(<span class="keyword">int</span> val)</span>      </span>&#123; sodium = val; &#125;</span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setCarbohydrate</span><span class="params">(<span class="keyword">int</span> val)</span> </span>&#123; carbohydrate = val; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个代码比使用重叠构造函数的代码简单了点，阅读也较为容易，但是调用方法为：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">NutritionFacts cocaCola = <span class="keyword">new</span> NutritionFacts();</span><br><span class="line">cocaCola.setServingSize(<span class="number">240</span>);</span><br><span class="line">cocaCola.setServings(<span class="number">8</span>);</span><br><span class="line">cocaCola.setCalories(<span class="number">100</span>);</span><br><span class="line">cocaCola.setSodium(<span class="number">35</span>);</span><br><span class="line">cocaCola.setCarbohydrate(<span class="number">27</span>);</span><br></pre></td></tr></table></figure>
<p>这种模式弥补了重叠构造函数的不足，使代码简单，可阅读；但是在调用时要先new一个对象，而无法保证我们在使用这个对象之前已经对相应的属性进行赋值。</p>
<p>JavaBeans模式的缺点是：使对象的构建过程分到几个调用中，在构造过程中可能处于不一致的状态。类无法仅仅通过检验构造器参数的有效性来保证一致性。试图使用处于不一致状态的对象，将会导致失败。这种失败与包含错误的代码大相劲庭，因为其调试起来十分困难。JavaBeans不能创建不可变的实例，因为需要你付出额外的代价来保证这个类是线程安全的。</p>
<h2 id="Builder模式"><a href="#Builder模式" class="headerlink" title="Builder模式"></a>Builder模式</h2><p>第二种解决方案 —— Builder模式</p>
<p>既能保证向重叠构造器模式那样的安全性，也能保证向JavaBeans模式那么好的可读性。这就是Builde模式的一种形式。不直接生成想要的对象，而是让客户端利用所有必要的参数调用构造器或者静态工厂，得到一个builder对象。然后客户端在builder上调用类似setter的方法来设置每个相关的可选参数。最后客户端调用无参的build方法来生成不可变的对象。这个builder是它构造的类的静态的成员类。代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Builder Pattern</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NutritionFacts</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> calories;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> fat;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> sodium;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> carbohydrate;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Builder</span> </span>&#123;</span><br><span class="line">	    <span class="comment">// Required parameters</span></span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servingSize;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> servings;</span><br><span class="line">	    <span class="comment">// Optional parameters - initialized to default values</span></span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> calories = <span class="number">0</span>;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> fat = <span class="number">0</span>;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> carbohydrate = <span class="number">0</span>;</span><br><span class="line">	    <span class="keyword">private</span> <span class="keyword">int</span> sodium = <span class="number">0</span>;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> <span class="title">Builder</span><span class="params">(<span class="keyword">int</span> servingSize, <span class="keyword">int</span> servings)</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">this</span>.servingSize = servingSize;</span><br><span class="line">	        <span class="keyword">this</span>.servings = servings;</span><br><span class="line">	    &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">calories</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; calories = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">fat</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; fat = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">carbohydrate</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; carbohydrate = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> Builder <span class="title">sodium</span><span class="params">(<span class="keyword">int</span> val)</span></span></span><br><span class="line"><span class="function">	        </span>&#123; sodium = val; <span class="keyword">return</span> <span class="keyword">this</span>; &#125;</span><br><span class="line">	    <span class="function"><span class="keyword">public</span> NutritionFacts <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">	        <span class="keyword">return</span> <span class="keyword">new</span> NutritionFacts(<span class="keyword">this</span>);</span><br><span class="line">	    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">NutritionFacts</span><span class="params">(Builder builder)</span> </span>&#123;</span><br><span class="line">        servingSize = builder.servingSize;</span><br><span class="line">        servings = builder.servings;</span><br><span class="line">        calories = builder.calories;</span><br><span class="line">        fat = builder.fat;</span><br><span class="line">        sodium = builder.sodium;</span><br><span class="line">        carbohydrate = builder.carbohydrate;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用时是这样的：<br><code>NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8).calories(100).sodium(35).carbohydrate(27).build();</code></p>
<p>就像构造器那样，builder 可以强加给它的参数变量（这个强加的参数变量可以作为创建对象的必须参数），build 方法实例化实体类，实例化前，可以对参数进行检查，如果不满足条件的，应该抛出 IllegalStateException，或者其他自定义异常。<br>另外一个小优点是 builder 可以有多个可变参数。构造器，像方法一样，可能只有一个可变参数。因为 builder 用不同的方法设置参数，只要你喜欢，他们可以有很多可变参数。</p>
<p>代码中NutritionFacts类中属性都是final类型的，这是必须的呢还是只是为了让对象实例一旦创建，其状态就不能在改变。而JavaBeans却无法创建这种不可变对象。</p>
<p>与JavaBeans的区别其实是在于真正构造对象的时间点上。其实Builder并没有提前把对象构造出来然后再一个个地对参数进行设置，而是先设定值，再在最后的build()方法中构建出对象。这样在一些参数存在依赖关系的时候，可以很好地解决依赖的问题。当然，对于参数的传递也不一定要按照上面写的方式，Setter其实也是可以的，其思想不在于模拟按名字传递参数，在于后面的build()。</p>
<p>从上面的例子中可以看出，Builder模式多数是用于对象比较复杂，可以逐步去构建的时候，其核心在于将类的构建逻辑转移到类的实例化外部。其经典应用是从一段文本中构建对象，因为文本的读入是以流的形式，那么一开始的时候可能没有办法创建完整的目标对象，这时候可以使用构建者模式来进行构建。但是在注重性能的环境下，每次创建实例都必须先创建Builder构造器也会是一笔开销，而且代码也有点冗长。总的来说如果类有多个属性需要多个构造函数，Builder模式还是一个不错的选择。</p>
<h2 id="Builder部件解析"><a href="#Builder部件解析" class="headerlink" title="Builder部件解析"></a>Builder部件解析</h2><p>再回到Builder的定义，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。在这里我暂时这样理解，就是把复杂对象的构建过程和结果进行分离。Builder的uml图为：<br><img src="/blogimgs/Builder模式/builderuml.png" alt="Builder uml图" title="Builder uml图"><br>有点类似工厂模式，其中</p>
<ul>
<li>Builder：生成器接口，定义创建一个Product对象所需要的各个部件的操作。</li>
<li>ConcreteBuilder：具体的生成器实现，实现各个部件的创建，并负责组装Product对象的各个部件，同时还提供一个让用户获取组装完成后的产品对象的方法。</li>
<li>Director：指导者，也被称导向者，主要用来使用Builder接口，以一个统一的过程来构建所需要的Product对象。</li>
<li>Product：产品，表示被生成器构建的复杂对象，包含多个部件。</li>
</ul>
<p>看了上面的uml图和各个部件的解释，可能就会产生疑问了，上面的使用Builder代替构造函数的场景中使用的角色和UML中的角色不对称了，不要着急，下面进行解释：</p>
<p>上面的使用场景比较明确，就是创建某个复制对象，可以进行适当的简化。其中Builder模式只是用来创建某个对象，则就没有必要定义Builder的接口，直接提供一个具体的ConcreteBuilder就行；如果只创建一个复杂的对象，不可能会有很多种不同的选择和步骤，导演类Director就可以干掉了，将其功能与Client的功能合并，使Client具备Director的功能，来指导构建器来构建需要的复杂对象。</p>
<h2 id="Builder模式的功能"><a href="#Builder模式的功能" class="headerlink" title="Builder模式的功能"></a>Builder模式的功能</h2><p>生成器模式的主要功能是构建复杂的产品，而且是细化的，分步骤的构建产品，也就是生成器模式重在一步一步解决构造复杂对象的问题。如果仅仅这么认知生成器模式的功能是不够的。<br>更为重要的是，这个构建的过程是统一的、固定不变的，变化的部分放到生成器部分了，只要配置不同的生成器，那么同样的构建过程，就能构建出不同的产品来。 这是对定义（将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示 ）更进一步的解释。</p>
<p>正常的Builder模式的代码示例如下：<br>1、生成器接口定义的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 生成器接口，定义创建一个产品对象所需的各个部件的操作 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 示意方法，构建某个部件 </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildPart</span><span class="params">()</span></span>;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、具体生成器实现的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 具体的生成器实现对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConcreteBuilder</span> <span class="keyword">implements</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">      </span><br><span class="line">    <span class="keyword">private</span> Product resultProduct;  </span><br><span class="line">      </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 获取生成器最终构建的产品对象 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@return</span> </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> Product <span class="title">getResultProduct</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> resultProduct;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildPart</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="comment">//构建某个部件的功能处理  </span></span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>3、相应的产品对象接口的示例代码</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 被构建的产品对象的接口 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Product</span> </span>&#123;  </span><br><span class="line">    <span class="comment">//定义产品的操作  </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>4、最后是指导者的实现示意，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 指导者，指导使用生成器的接口来构建产品对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Director</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 持有当前需要使用的生成器对象 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> Builder builder;  </span><br><span class="line">   </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构造方法，传人生成器对象 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> builder </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">Director</span><span class="params">(Builder builder)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.builder = builder;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 示意方法，指导生成器构建最终的产品对象 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">construct</span><span class="params">()</span></span>&#123;  </span><br><span class="line">         <span class="comment">//通过使用生成器接口来构建最终的产品对象  </span></span><br><span class="line">         builder.buildPart();  </span><br><span class="line">     &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="应用场景–-导出数据的应用框架"><a href="#应用场景–-导出数据的应用框架" class="headerlink" title="应用场景– 导出数据的应用框架"></a>应用场景– 导出数据的应用框架</h2><p>在讨论工厂方法模式的时候，提供了一个导出数据的应用框架。<br>对于导出数据的应用框架，通常在导出数据上，会有一些约束的方式，比如导出成文本格式、数据库备份形式、Excel格式、Xml格式等。<br>在工厂方法模式章节里面，讨论并使用工厂方法模式来解决了如何选择具体导出方式的问题，并没有涉及到每种方式具体如何实现。<br>换句话说，在讨论工厂方法模式的时候，并没有讨论如何实现导出成文本、Xml等具体格式，本章就来讨论这个问题。<br>对于导出数据的应用框架，通常对于具体的导出内容和格式是有要求的，加入现在有如下要求，简单描述一下：</p>
<ul>
<li>导出的文件，不管是什么格式，都分成3个部分，分别是文件头、文件体、文件尾。</li>
<li>在文件头部分，需要描述如下信息：分公司或者门市编号、导出数据的日期。</li>
<li>在文件体部分，需要描述如下信息：表名称，然后分条描述数据。</li>
<li>在文件尾部分，需要描述如下信息：输出人。</li>
</ul>
<p>1、下面将描述文件各个部分的数据对象定义出来<br>描述输出到文件头的内容的对象，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 描述输出到文件头的内容的对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportHeaderModel</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 分公司或者门市编号 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String depId;  </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 导出数据的日期 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String exportDate;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getDepId</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> depId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setDepId</span><span class="params">(String depId)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.depId = depId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getExportDate</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> exportDate;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setExportDate</span><span class="params">(String exportDate)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.exportDate = exportDate;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>描述输出数据的对象，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 描述输出数据的对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportDataModel</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 产品编号 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String productId;  </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 销售价格 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">double</span> price;  </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 销售数量 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> <span class="keyword">double</span> amount;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getProductId</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> productId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setProductId</span><span class="params">(String productId)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.productId = productId;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getPrice</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> price;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setPrice</span><span class="params">(<span class="keyword">double</span> price)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.price = price;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getAmount</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> amount;  </span><br><span class="line">     &#125;  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAmount</span><span class="params">(<span class="keyword">double</span> amount)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.amount = amount;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>描述输出到文件尾的内容的对象，示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 描述输出到文件尾的内容的对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportFooterModel</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 输出人 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> String exportUser;  </span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">public</span> String <span class="title">getExportUser</span><span class="params">()</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> exportUser;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setExportUser</span><span class="params">(String exportUser)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.exportUser = exportUser;  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>2、定义Builder接口，主要是把导出各种格式文件的处理过程的步骤定义出来，每个步骤负责构建最终导出文件的一部分。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 生成器接口，定义创建一个输出文件对象所需的各个部件的操作 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 构建输出文件的Header部分 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> ehm </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildHeader</span><span class="params">(ExportHeaderModel ehm)</span></span>;  </span><br><span class="line">       </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构建输出文件的Body部分 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> mapData </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildBody</span><span class="params">(Map&lt;String,List&lt;ExportDataModel&gt;&gt; mapData)</span></span>;  </span><br><span class="line">       </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构建输出文件的Footer部分 </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> efm </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildFooter</span><span class="params">(ExportFooterModel efm)</span></span>;  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>3、具体的生成器实现。<br>导出到文本文件的的生成器实现。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 实现导出文件到文本文件的生成器对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TxtBuilder</span> <span class="keyword">implements</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 用来记录构建的文件的内容，相当于产品 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> StringBuffer buffer = <span class="keyword">new</span> StringBuffer();  </span><br><span class="line">       </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildHeader</span><span class="params">(ExportHeaderModel ehm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(ehm.getDepId()+<span class="string">","</span>+ehm.getExportDate()+<span class="string">"\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildBody</span><span class="params">(Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">for</span>(String tablName : mapData.keySet())&#123;  </span><br><span class="line">               </span><br><span class="line">             <span class="comment">//先拼接表名  </span></span><br><span class="line">             buffer.append(tablName+<span class="string">"\n"</span>);  </span><br><span class="line">             <span class="comment">//然后循环拼接具体数据  </span></span><br><span class="line">             <span class="keyword">for</span>(ExportDataModel edm : mapData.get(tablName))&#123;  </span><br><span class="line">                 buffer.append(edm.getProductId()+<span class="string">","</span>+edm.getPrice()+<span class="string">","</span>+edm.getAmount()+<span class="string">"\n"</span>)</span><br><span class="line">             &#125;  </span><br><span class="line">         &#125;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildFooter</span><span class="params">(ExportFooterModel efm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(efm.getExportUser());  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> StringBuffer <span class="title">getResult</span><span class="params">()</span></span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> buffer;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>导出到Xml文件的的生成器实现。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 实现导出文件到Xml文件的生成器对象 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">XmlBuilder</span> <span class="keyword">implements</span> <span class="title">Builder</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * 用来记录构建的文件的内容，相当于产品 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> StringBuffer buffer = <span class="keyword">new</span> StringBuffer();  </span><br><span class="line">       </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildHeader</span><span class="params">(ExportHeaderModel ehm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(<span class="string">"&lt;?xml version='1.0' encoding='UTF-8'?&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"&lt;Report&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;Header&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t\t&lt;DepId&gt;"</span>+ehm.getDepId()+<span class="string">"&lt;/DepId&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t\t&lt;ExportDate&gt;"</span>+ehm.getExportDate()+<span class="string">"&lt;/ExportDate&gt;\n"</span>);  </span><br><span class="line">           </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;/Header&gt;\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildBody</span><span class="params">(Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData)</span> </span>&#123;  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;Body&gt;\n"</span>);  </span><br><span class="line">         <span class="keyword">for</span>(String tablName : mapData.keySet())&#123;  </span><br><span class="line">             <span class="comment">//先拼接表名  </span></span><br><span class="line">             buffer.append(<span class="string">"\t\t&lt;Datas TableName=\""</span>+tablName+<span class="string">"\"&gt;\n"</span>);  </span><br><span class="line">             <span class="comment">//然后循环拼接具体数据  </span></span><br><span class="line">             <span class="keyword">for</span>(ExportDataModel edm : mapData.get(tablName))&#123;  </span><br><span class="line">                   </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t&lt;Data&gt;\n"</span>);  </span><br><span class="line">                   </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t\t&lt;ProductId&gt;"</span>+edm.getProductId()+<span class="string">"&lt;/ProductId&gt;\n"</span>);  </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t\t&lt;Price&gt;"</span>+edm.getPrice()+<span class="string">"&lt;/Price&gt;\n"</span>);  </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t\t&lt;Amount&gt;"</span>+edm.getAmount()+<span class="string">"&lt;/Amount&gt;\n"</span>);  </span><br><span class="line">                   </span><br><span class="line">                 buffer.append(<span class="string">"\t\t\t&lt;/Data&gt;\n"</span>);  </span><br><span class="line">             &#125;  </span><br><span class="line">               </span><br><span class="line">             buffer.append(<span class="string">"\t\t&lt;/Datas&gt;\n"</span>);  </span><br><span class="line">         &#125;  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;/Body&gt;\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="meta">@Override</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">buildFooter</span><span class="params">(ExportFooterModel efm)</span> </span>&#123;  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;Footer&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t\t&lt;ExportUser&gt;"</span>+efm.getExportUser()+<span class="string">"&lt;/ExportUser&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"\t&lt;/Footer&gt;\n"</span>);  </span><br><span class="line">         buffer.append(<span class="string">"&lt;/Report&gt;\n"</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">       </span><br><span class="line">     <span class="function"><span class="keyword">public</span> StringBuffer <span class="title">getResult</span><span class="params">()</span></span>&#123;  </span><br><span class="line">         <span class="keyword">return</span> buffer;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>4、指导者。有了具体的生成器实现后，需要由指导者来指导它进行具体的产品构建。示例代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * 指导者，指导使用生成器的接口来构建输出的文件对象 </span></span><br><span class="line"><span class="comment"> *  </span></span><br><span class="line"><span class="comment"> *  </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Director</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 持有当前需要的使用的生成器对象 </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="keyword">private</span> Builder builder;  </span><br><span class="line">   </span><br><span class="line">     <span class="comment">/** </span></span><br><span class="line"><span class="comment">      * 构造方法，传入生成器对象 </span></span><br><span class="line"><span class="comment">      *  </span></span><br><span class="line"><span class="comment">      * <span class="doctag">@param</span> builder </span></span><br><span class="line"><span class="comment">      */</span>  </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="title">Director</span><span class="params">(Builder builder)</span> </span>&#123;  </span><br><span class="line">         <span class="keyword">this</span>.builder = builder;  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">construct</span><span class="params">(ExportHeaderModel ehm,  </span></span></span><br><span class="line"><span class="function"><span class="params">             Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData, ExportFooterModel efm)</span> </span>&#123;  </span><br><span class="line">   </span><br><span class="line">         <span class="comment">//1.先构建Header  </span></span><br><span class="line">         builder.buildHeader(ehm);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//2.然后构建Body  </span></span><br><span class="line">         builder.buildBody(mapData);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//3.再构建Footer  </span></span><br><span class="line">         builder.buildFooter(efm);  </span><br><span class="line">     &#125;  </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>5、客户端测试代码如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Client</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">/** </span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> args </span></span><br><span class="line"><span class="comment">     */</span>  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;  </span><br><span class="line">          </span><br><span class="line">        <span class="comment">//准备测试数据  </span></span><br><span class="line">        ExportHeaderModel ehm = <span class="keyword">new</span> ExportHeaderModel();  </span><br><span class="line">         ehm.setDepId(<span class="string">"一分公司"</span>);  </span><br><span class="line">         ehm.setExportDate(<span class="string">"2010-05-18"</span>);  </span><br><span class="line">           </span><br><span class="line">         Map&lt;String, List&lt;ExportDataModel&gt;&gt; mapData = <span class="keyword">new</span> HashMap&lt;String, List&lt;ExportDataModel&gt;&gt;  </span><br><span class="line">         List&lt;ExportDataModel&gt; col = <span class="keyword">new</span> ArrayList&lt;ExportDataModel&gt;();  </span><br><span class="line">           </span><br><span class="line">         ExportDataModel edm1 = <span class="keyword">new</span> ExportDataModel();  </span><br><span class="line">         edm1.setProductId(<span class="string">"产品001号"</span>);  </span><br><span class="line">         edm1.setPrice(<span class="number">100</span>);  </span><br><span class="line">         edm1.setAmount(<span class="number">80</span>);  </span><br><span class="line">           </span><br><span class="line">         ExportDataModel edm2 = <span class="keyword">new</span> ExportDataModel();  </span><br><span class="line">         edm2.setProductId(<span class="string">"产品002号"</span>);  </span><br><span class="line">         edm2.setPrice(<span class="number">120</span>);  </span><br><span class="line">         edm2.setAmount(<span class="number">280</span>);  </span><br><span class="line">           </span><br><span class="line">         ExportDataModel edm3 = <span class="keyword">new</span> ExportDataModel();  </span><br><span class="line">         edm3.setProductId(<span class="string">"产品003号"</span>);  </span><br><span class="line">         edm3.setPrice(<span class="number">320</span>);  </span><br><span class="line">         edm3.setAmount(<span class="number">380</span>);  </span><br><span class="line">           </span><br><span class="line">         col.add(edm1);  </span><br><span class="line">         col.add(edm2);  </span><br><span class="line">         col.add(edm3);  </span><br><span class="line">           </span><br><span class="line">         mapData.put(<span class="string">"销售记录表"</span>, col);  </span><br><span class="line">           </span><br><span class="line">         ExportFooterModel efm = <span class="keyword">new</span> ExportFooterModel();  </span><br><span class="line">         efm.setExportUser(<span class="string">"张三"</span>);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//测试输出到文本文件  </span></span><br><span class="line">         TxtBuilder txtBuilder = <span class="keyword">new</span> TxtBuilder();  </span><br><span class="line">         <span class="comment">//创建指导者对象  </span></span><br><span class="line">         Director director = <span class="keyword">new</span> Director(txtBuilder);  </span><br><span class="line">         director.construct(ehm, mapData, efm);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//把要输出的内容输出到控制台看看  </span></span><br><span class="line">         System.out.println(<span class="string">"输出到文本文件的内容:"</span>+txtBuilder.getResult().toString());  </span><br><span class="line">           </span><br><span class="line">         XmlBuilder xmlBuilder = <span class="keyword">new</span> XmlBuilder();  </span><br><span class="line">         Director director2 = <span class="keyword">new</span> Director(xmlBuilder);  </span><br><span class="line">         director2.construct(ehm, mapData, efm);  </span><br><span class="line">           </span><br><span class="line">         <span class="comment">//把要输出的内容输出到控制台看看  </span></span><br><span class="line">         System.out.println(<span class="string">"输出到Xml文件的内容:"</span>+xmlBuilder.getResult().toString());  </span><br><span class="line">     &#125;  </span><br><span class="line">   </span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<h2 id="生成器模式的功能"><a href="#生成器模式的功能" class="headerlink" title="生成器模式的功能"></a>生成器模式的功能</h2><p>生成器模式的主要功能是构建复杂的产品，而且是细化的，分步骤的构建产品，也就是生成器模式重在一步一步解决构造复杂对象的问题。如果仅仅这么认知生成器模式的功能是不够的。<br>更为重要的是，这个构建的过程是统一的、固定不变的，变化的部分放到生成器部分了，只要配置不同的生成器，那么同样的构建过程，就能构建出不同的产品来。</p>
<p>##参考<br><a href="http://blog.csdn.net/top_code/article/details/8469297" target="_blank" rel="noopener">http://blog.csdn.net/top_code/article/details/8469297</a><br><a href="https://en.wikipedia.org/wiki/Builder_pattern" target="_blank" rel="noopener">https://en.wikipedia.org/wiki/Builder_pattern</a></p>
]]></content>
      
        <categories>
            
            <category> Java </category>
            
        </categories>
        
        
        <tags>
            
            <tag> java </tag>
            
            <tag> 设计模式 </tag>
            
            <tag> Builder </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
